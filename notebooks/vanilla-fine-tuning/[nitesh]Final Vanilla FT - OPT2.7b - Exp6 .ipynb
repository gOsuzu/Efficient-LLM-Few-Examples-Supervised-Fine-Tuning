{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ytKBpLWHGEZQNGuMGDJ_A9tpviXlMHQ3","timestamp":1714461631160},{"file_id":"1-WeRH2m8157msxCi4BWAFEMa6fmYdKHQ","timestamp":1714452733001},{"file_id":"1o7G7hBqY_teAY1dfBxFaPYfOS218mNZb","timestamp":1714201977972},{"file_id":"1-Eg41pChNrXtqPstHWgyHtI5d4QPSb7-","timestamp":1714174001163},{"file_id":"1uf_FvSnFW56aaBHVBm6yJQDBTn20lRBQ","timestamp":1713724435266}],"machine_shape":"hm","gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a13237c9304d4afba25f83e9c58ee691":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_766ca5f0cde943988a68d3d229fd5efc","IPY_MODEL_4b275c4a45a041be86f6de0d865c1b40","IPY_MODEL_898ef85ffa8a4772b32f2a51b73dea1d"],"layout":"IPY_MODEL_b8a3b59709784216a3d0c5bbe94a27be"}},"766ca5f0cde943988a68d3d229fd5efc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee2cbebb71194bd5aac58827f6c977d1","placeholder":"​","style":"IPY_MODEL_def41d09ebf046519aaf53fe5db57c05","value":"Downloading data: 100%"}},"4b275c4a45a041be86f6de0d865c1b40":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d35ad7393ef4b60b0f64ac906085e11","max":3144823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d7e257f56e34315852bc9f5af95b590","value":3144823}},"898ef85ffa8a4772b32f2a51b73dea1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_670f0468a910478c831b81c6d6e8ecf9","placeholder":"​","style":"IPY_MODEL_91366996f97749378ade3a93f4e1739d","value":" 3.14M/3.14M [00:00&lt;00:00, 13.2MB/s]"}},"b8a3b59709784216a3d0c5bbe94a27be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee2cbebb71194bd5aac58827f6c977d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"def41d09ebf046519aaf53fe5db57c05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d35ad7393ef4b60b0f64ac906085e11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d7e257f56e34315852bc9f5af95b590":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"670f0468a910478c831b81c6d6e8ecf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91366996f97749378ade3a93f4e1739d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"091ddcc555fb458e96701fd3e91aba65":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_209ebe2647834086976147b51369dbdf","IPY_MODEL_0e873f5ab2c847a4ad534b1471543057","IPY_MODEL_afee1147442546c2818837706c0b57c9"],"layout":"IPY_MODEL_e84c64efbbeb492a93a961e5da97ef69"}},"209ebe2647834086976147b51369dbdf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6e31be71d4d4ec9b81d569c06cd72d5","placeholder":"​","style":"IPY_MODEL_f1c0568548f24c60be163795437da9ba","value":"Downloading data: 100%"}},"0e873f5ab2c847a4ad534b1471543057":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_11057ebad6284ad19551a1cef1c74049","max":3139577,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1d9800ce646a4f11963b1cee2d2a4478","value":3139577}},"afee1147442546c2818837706c0b57c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39a2a290a49e4acba9dc0dc5779af7a1","placeholder":"​","style":"IPY_MODEL_5bd275ee83934638a490282896519a3d","value":" 3.14M/3.14M [00:00&lt;00:00, 24.7MB/s]"}},"e84c64efbbeb492a93a961e5da97ef69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6e31be71d4d4ec9b81d569c06cd72d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1c0568548f24c60be163795437da9ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11057ebad6284ad19551a1cef1c74049":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d9800ce646a4f11963b1cee2d2a4478":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"39a2a290a49e4acba9dc0dc5779af7a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bd275ee83934638a490282896519a3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7fe52000a36048f4b46bdde93774867e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3a7dd727c0e44c269ed3b131c5b5875f","IPY_MODEL_c78d9dbca0cc43c0878f0fa361197750","IPY_MODEL_8b3aebf155f041bc996e97d8e91ccabc"],"layout":"IPY_MODEL_aa8bfb44dbdb474dbaf4e8ad6df4f0d8"}},"3a7dd727c0e44c269ed3b131c5b5875f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_597157d92d3f4800bc8001503543c67f","placeholder":"​","style":"IPY_MODEL_98e074baaf90471e8117ff24cba20e4d","value":"Generating train split: 100%"}},"c78d9dbca0cc43c0878f0fa361197750":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4ac3f7086504d82923a906f323961a8","max":30000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a60ba0d860d4dc89c97fca1c4040292","value":30000}},"8b3aebf155f041bc996e97d8e91ccabc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d2875f620c84b08ac7a1d66d7d59636","placeholder":"​","style":"IPY_MODEL_cfe464f7b0d6477c86b9ef4e23888e3f","value":" 30000/30000 [00:00&lt;00:00, 344095.32 examples/s]"}},"aa8bfb44dbdb474dbaf4e8ad6df4f0d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"597157d92d3f4800bc8001503543c67f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98e074baaf90471e8117ff24cba20e4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4ac3f7086504d82923a906f323961a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a60ba0d860d4dc89c97fca1c4040292":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3d2875f620c84b08ac7a1d66d7d59636":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfe464f7b0d6477c86b9ef4e23888e3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c5c3cab437d406095c4602baf0e9d42":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_87b8945f6084406394d81afc2260685d","IPY_MODEL_d848971821704ae5b9ecb0655b20ec92","IPY_MODEL_2b64327ceb8843fa9a3270f9b99257dd"],"layout":"IPY_MODEL_c78206537b844d2f89ca6ea6d592df2f"}},"87b8945f6084406394d81afc2260685d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_568ba7e16ce44ba195a039c6393ebd28","placeholder":"​","style":"IPY_MODEL_0426804b34ac4d39b5ffcf7e1e5353f4","value":"Generating validation split: 100%"}},"d848971821704ae5b9ecb0655b20ec92":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_88ca81e10a564a75be3de20535e53624","max":30000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_00a543cee1ee435d9d35d2a16a941d11","value":30000}},"2b64327ceb8843fa9a3270f9b99257dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58d5c1b536604f0fb0e69db6bb1df58a","placeholder":"​","style":"IPY_MODEL_3e867375f09f40ab9477e62a9e94626f","value":" 30000/30000 [00:00&lt;00:00, 459493.65 examples/s]"}},"c78206537b844d2f89ca6ea6d592df2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"568ba7e16ce44ba195a039c6393ebd28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0426804b34ac4d39b5ffcf7e1e5353f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88ca81e10a564a75be3de20535e53624":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00a543cee1ee435d9d35d2a16a941d11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58d5c1b536604f0fb0e69db6bb1df58a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e867375f09f40ab9477e62a9e94626f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"445e00a6fc2142d8af10098d9fa721bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_50c398eb51b241c19d15c530d4dab174","IPY_MODEL_6b09247000f44837a4a15a229879c89d","IPY_MODEL_a84c3ac6851b45fd8a11e77f12ef6c15"],"layout":"IPY_MODEL_9af0bac0d1f848899d4b5a494ceb20fa"}},"50c398eb51b241c19d15c530d4dab174":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de49086f74114cd795e1a5ad3c4fe83f","placeholder":"​","style":"IPY_MODEL_940ea668d13641c2b46106e6ada431a2","value":"Filter: 100%"}},"6b09247000f44837a4a15a229879c89d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6dcbe74b4b548e49426f2dd6c964362","max":30000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1c66687f10d4df5b1029e33688046fc","value":30000}},"a84c3ac6851b45fd8a11e77f12ef6c15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3dc3da07dace4435898b471648424f19","placeholder":"​","style":"IPY_MODEL_18d8f011fa0142598bfac07bd4bbae0e","value":" 30000/30000 [00:00&lt;00:00, 85339.38 examples/s]"}},"9af0bac0d1f848899d4b5a494ceb20fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de49086f74114cd795e1a5ad3c4fe83f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"940ea668d13641c2b46106e6ada431a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6dcbe74b4b548e49426f2dd6c964362":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1c66687f10d4df5b1029e33688046fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3dc3da07dace4435898b471648424f19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18d8f011fa0142598bfac07bd4bbae0e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47ffef0a31b14486b84927d41eb289c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_612e96a197644280a09c306e15b2cacd","IPY_MODEL_155276c85f35411180f37600e98cb43f","IPY_MODEL_2a0c2466ec5b480481307cf713d5e828"],"layout":"IPY_MODEL_7853ff85f1b44205ae86eea24b94c4e6"}},"612e96a197644280a09c306e15b2cacd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f04d6de2a28d4a08896e02bbf03854a7","placeholder":"​","style":"IPY_MODEL_683ac1a586474ba4aefa1edfc0fc7b59","value":"Map: 100%"}},"155276c85f35411180f37600e98cb43f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e134b1b6f60b4bfab3b545ecc611be6d","max":1024,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12e924a6eb2047d288185ac90d16cf39","value":1024}},"2a0c2466ec5b480481307cf713d5e828":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e8e073f4e9a486abe81c5685ce75ac2","placeholder":"​","style":"IPY_MODEL_2c858acd3352489f9125ca575f4b25c1","value":" 1024/1024 [00:00&lt;00:00, 7020.52 examples/s]"}},"7853ff85f1b44205ae86eea24b94c4e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f04d6de2a28d4a08896e02bbf03854a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"683ac1a586474ba4aefa1edfc0fc7b59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e134b1b6f60b4bfab3b545ecc611be6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12e924a6eb2047d288185ac90d16cf39":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e8e073f4e9a486abe81c5685ce75ac2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c858acd3352489f9125ca575f4b25c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# 1. IMPORT LIBRARIES"],"metadata":{"id":"Tw8CFJ12Pp6T"}},{"cell_type":"code","source":["#!pip install -q datasets accelerate\n","#!pip install -q git+https://github.com/huggingface/transformers.git@main\n","# !pip install -q git+https://github.com/huggingface/peft.git\n","# !pip install -q bitsandbytes datasets accelerate loralib\n","\n","\n","\n","#!pip install -q datasets accelerate\n","# !pip install -q git+https://github.com/huggingface/transformers.git@main\n","# !pip install -q git+https://github.com/huggingface/peft.git\n","# !pip install -q bitsandbytes datasets accelerate loralib\n","!pip install -q datasets\n","!pip install --upgrade transformers\n","!pip install tensorflow\n","\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import gc\n","from torch.cuda.amp import autocast, GradScaler\n","\n","\n","from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, OPTForCausalLM, GPT2Tokenizer, AdamW, AutoModelForSequenceClassification\n","\n","!pip install -q accelerate\n","\n","# !pip install -q git+https://github.com/huggingface/transformers.git@main\n","# !pip install -q git+https://github.com/huggingface/peft.git\n","# !pip install -q bitsandbytes datasets accelerate loralib\n","\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ayaqVMRAXaT","outputId":"ec21ab0a-8263-42a8-e394-694b0f63f990","executionInfo":{"status":"ok","timestamp":1714453186803,"user_tz":240,"elapsed":25071,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.22.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.2)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"]}]},{"cell_type":"code","source":["\n","!python --version\n","!nvcc --version\n","!pip install nvcc4jupyter\n","%load_ext nvcc4jupyter\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mY6pDshTHDtg","outputId":"1c2040b9-4316-4d52-b684-fded250456c2","executionInfo":{"status":"ok","timestamp":1714453192216,"user_tz":240,"elapsed":5415,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.12\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Tue_Aug_15_22:02:13_PDT_2023\n","Cuda compilation tools, release 12.2, V12.2.140\n","Build cuda_12.2.r12.2/compiler.33191640_0\n","Requirement already satisfied: nvcc4jupyter in /usr/local/lib/python3.10/dist-packages (1.2.1)\n","Detected platform \"Colab\". Running its setup...\n","Source files will be saved in \"/tmp/tmp5dwk70yl\".\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import random"],"metadata":{"id":"hOBeMp00RKSi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. SET MAIN INPUTS FOR NOTEBOOK"],"metadata":{"id":"gBZINjFskJOT"}},{"cell_type":"code","source":["bx_size = 1                                 # batch size for inference OR TRAIN with the OPT\n","format_train_val = 'gpt3'                   # 'minimal' or 'gpt3\n","task_name = 'mnli'                          # 'mnli'\n","model_name = \"facebook/opt-2.7b\"            # model options below\n","examples_per_exp =  16                       # 16\n","num_experiments = 10                         # 10\n","num_validations = 1024   # not used yet in this NB (when later on doing validation needs to be specified at 1024)\n","\n","SEL_EXP_TRAIN_CD = 6                        # Select experiment to run\n","\n","\n","# model_name = \"facebook/opt-125m\"\n","# model_name = \"facebook/opt-350m\"\n","# model_name = \"facebook/opt-1.3b\"\n","# model_name = \"facebook/opt-2.7b\"\n","# model_name = \"facebook/opt-6.7b\""],"metadata":{"id":"tvPGy9EnkIKK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. SET DEVICE"],"metadata":{"id":"ZBgRakKbCXl3"}},{"cell_type":"code","source":["import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""],"metadata":{"id":"aKf7vOw2MTPk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","# Check if CUDA (GPU support) is available\n","cuda_available = torch.cuda.is_available()\n","print(f\"CUDA Available: {cuda_available}\")\n","\n","# If CUDA is available, print the GPU name(s)\n","if cuda_available:\n","    print(f\"GPU Name(s): {torch.cuda.get_device_name(0)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"18useFCOLdX2","outputId":"9234b7aa-7754-47a9-d24a-8b9c7db46048","executionInfo":{"status":"ok","timestamp":1714453192357,"user_tz":240,"elapsed":142,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA Available: True\n","GPU Name(s): NVIDIA L4\n"]}]},{"cell_type":"code","source":["device = \"cpu\"\n","\n","# device_count = torch.cuda.device_count()\n","# if device_count > 0:\n","#     print(\"Select GPU device\")\n","#     device = torch.device(\"cuda\")\n","# else:\n","#     print(\"Select GPU device\")\n","#     device = torch.device(\"cpu\")\n","\n","print(device)\n","# torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QXFJO33ECUVB","outputId":"1c835175-905d-4e5f-faaf-b678f521626e","executionInfo":{"status":"ok","timestamp":1714453192357,"user_tz":240,"elapsed":2,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"cell_type":"markdown","source":["## 3. IMPORT TOKENIZER AND SELECT MODEL"],"metadata":{"id":"DjaLyC3l7hVV"}},{"cell_type":"code","source":["# Choose model to work with:\n","\n","# model_name = \"facebook/opt-125m\"\n","# model_name = \"facebook/opt-350m\"\n","# model_name = \"facebook/opt-1.3b\"\n","# model_name = \"facebook/opt-2.7b\"\n","# model_name = \"facebook/opt-6.7b\"\n","\n","model_name = model_name # it is set up in top of NB"],"metadata":{"id":"2Kt5rM4s7g0T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["OPT_tokenizer = GPT2Tokenizer.from_pretrained(model_name)"],"metadata":{"id":"g49c1NTt_rcO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. IMPORT NLI DATASET FOR TRAINING AND VALIDATION: MNLI"],"metadata":{"id":"kMS1b9WqPZWC"}},{"cell_type":"code","source":["# reference: https://github.com/uds-lsv/llmft/blob/main/notebooks/majority_baseline.ipynb\n","# this reference is useful for cleaning the neutral sentences of the dataset, just keeping the 0 and 1."],"metadata":{"id":"kGFeGMISPx7D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import Counter\n","from datasets import load_dataset, ClassLabel"],"metadata":{"id":"9bQUsgPp7g9m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# this comes from original paper, to remove neutral examples from MNLI\n","def binarize_mnli(dataset, remove_neutral=True):\n","    if remove_neutral:\n","        # neutral class has label 1\n","        dataset = dataset.filter(lambda example: example[\"label\"] != 1)\n","\n","    # change labels of contradiction examples from 2 to 1\n","    def change_label(example):\n","        # convert labels 2 into labels 1. this merges the neutral and contradiction class\n","        example[\"label\"] = 1 if example[\"label\"] == 2 else example[\"label\"]\n","        return example\n","\n","    # change labels\n","    dataset = dataset.map(change_label)\n","\n","    # change features to reflect the new labels\n","    features = dataset[\"train\"].features.copy()\n","    features[\"label\"] = ClassLabel(num_classes=2, names=['entailment', 'contradiction'], id=None)\n","    dataset = dataset.cast(features)  # overwrite old features\n","\n","    return dataset\n"],"metadata":{"id":"l1N1cM5z7m16"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = load_dataset(\"glue\", task_name)"],"metadata":{"id":"T10hQZj079Le"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# binarize dataset\n","if task_name == \"mnli\":\n","    dataset = binarize_mnli(dataset, remove_neutral=True) # mnli\n"],"metadata":{"id":"QI3oAEj279Hl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# analyze and visualize dataset imported\n","\n","print(\"task_name:\", task_name)\n","for split in [\"train\", \"validation_matched\"]:\n","    c = Counter(dataset[split][\"label\"])\n","    total = len(list(c.elements()))\n","    print(\"Total number of samples:\", total)\n","    print(split)\n","    for k in c:\n","        print(f\"fraction of labels per class: {k}={c[k] / total}\")\n","print(dataset)"],"metadata":{"id":"qIFzmEFR8GQ1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714453196906,"user_tz":240,"elapsed":215,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}},"outputId":"20715293-4c6b-42f1-d6a0-b9ad14274afd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["task_name: mnli\n","Total number of samples: 261802\n","train\n","fraction of labels per class: 0=0.49999236063895613\n","fraction of labels per class: 1=0.5000076393610439\n","Total number of samples: 6692\n","validation_matched\n","fraction of labels per class: 1=0.4801255230125523\n","fraction of labels per class: 0=0.5198744769874477\n","DatasetDict({\n","    train: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 261802\n","    })\n","    validation_matched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 6692\n","    })\n","    validation_mismatched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 6703\n","    })\n","    test_matched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 9796\n","    })\n","    test_mismatched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 9847\n","    })\n","})\n"]}]},{"cell_type":"code","source":["# Perform the filters and splits from the original datasets\n","\n","\n","random_split_seed = 42\n","\n","examples_per_exp =  examples_per_exp # set above 16\n","num_experiments = num_experiments # set above 10\n","num_validations = num_validations # set above 16*64 #64*16 = 1024 #6692\n","\n","max_train_samples = examples_per_exp*num_experiments\n","train_dataset = dataset['train']\n","print(train_dataset)\n","\n","train_dataset_yes_all = dataset['train'].filter(lambda example: example[\"label\"] == 0)\n","train_dataset_no_all = dataset['train'].filter(lambda example: example[\"label\"] == 1)\n","print(train_dataset_yes_all)\n","print(train_dataset_no_all)\n","\n","val_dataset_all_indomain = dataset['validation_matched']\n","\n","# randomly select a subset of the training data\n","max_train_samples = min(len(train_dataset), max_train_samples)\n","\n","np.random.seed(random_split_seed)\n","indices_yes = np.random.choice(range(len(train_dataset_yes_all)), size=int(max_train_samples/2), replace=False)\n","print(\"indices_yes: \", indices_yes)\n","\n","np.random.seed(random_split_seed+1)\n","indices_no = np.random.choice(range(len(train_dataset_no_all)), size=int(max_train_samples/2), replace=False)\n","print(\"indices_no: \", indices_no)\n","\n","np.random.seed(random_split_seed+2)\n","indices_val_indomain = np.random.choice(range(len(val_dataset_all_indomain)), size=num_validations, replace=False)\n","print(\"indices_val: \", indices_val_indomain)"],"metadata":{"id":"7v9CdYUvSxGf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714453196906,"user_tz":240,"elapsed":5,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}},"outputId":"50d195e8-f8dc-4b0b-e01f-850bfd690e04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 261802\n","})\n","Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 130899\n","})\n","Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 130903\n","})\n","indices_yes:  [108195  86013  39482  39689  10288  11589  94511  78690  36953  74067\n","  93678  83921  83896  21665  76736    651  48482  40811 127490  49367\n"," 121664  39918  60933 126502  65765  12966  33438   7201  19815  49187\n","  29116  48565 125127  60274  33985 130032 104535 120345 104033  44914\n","  89806  87143 103906  15697  29521   4906  46884  75442  57625  32365\n","  70562  78463  18684  45639  30223 118624  40945  75797  63681  77117\n","  16126 130579   2132 113346  68080   7433 120366 122242  75493  64389\n","  95467  86480  52323  42308 101738  51386 126981  27346  45655 121440]\n","indices_no:  [ 54039  34647  34994 102702  14063 110662  33077  24477  24337  19083\n","  61263 109299 107760  88071  22063  90740 113958   9163  45235  32885\n","  58399  59560 102582  10964  38283  16146  72067  55788  60576  21220\n","  41478 123489  38278  15117  71374  69791  39777 122448  10098  35761\n","  74547 109598  19072  61567  56626 102957  18014  14118  46250 117891\n","  87958 113798 107148 121622  88599   8239 119796  69862   2704 112545\n"," 121565 111890  19129 115169  29330  47129  79077  34942  28934  12323\n","  85926 103422  91532  32522   4654 108738  24476  86650 117487  61013]\n","indices_val:  [1771 4591 1869 ... 1111  809 1914]\n"]}]},{"cell_type":"code","source":["train_dataset_yes = train_dataset_yes_all.select(indices_yes)\n","train_dataset_no = train_dataset_no_all.select(indices_no)\n","\n","val_dataset_indomain = val_dataset_all_indomain.select(indices_val_indomain)\n","print(\"Train Dataset Yes: \", train_dataset_yes)\n","print(\"Train Dataset No: \", train_dataset_no)\n","print(\"Validation Dataset (in-domain): \", val_dataset_indomain)"],"metadata":{"id":"W5nx1ugOr5kd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714453196906,"user_tz":240,"elapsed":4,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}},"outputId":"0e5d064c-74ad-4873-a405-2768462fcb2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Dataset Yes:  Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 80\n","})\n","Train Dataset No:  Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 80\n","})\n","Validation Dataset (in-domain):  Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 1024\n","})\n"]}]},{"cell_type":"code","source":["# Calculate the number of 0 and 1 in validation dataset\n","# and calculate the majority class accuracy\n","\n","val_dataset_indomain_yes = val_dataset_indomain.filter(lambda example: example[\"label\"] == 0)\n","val_dataset_indomain_no = val_dataset_indomain.filter(lambda example: example[\"label\"] == 1)\n","print(val_dataset_indomain_yes)\n","print(val_dataset_indomain_no)\n","print(\"Majority Class Accuracy: \", 100*max(len(val_dataset_indomain_yes), len(val_dataset_indomain_no))/(len(val_dataset_indomain_yes) + len(val_dataset_indomain_no)))"],"metadata":{"id":"15sgsMLaVGwC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714453196906,"user_tz":240,"elapsed":3,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}},"outputId":"40ff2c44-82cb-4cf9-f0be-3406dc409a92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 536\n","})\n","Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 488\n","})\n","Majority Class Accuracy:  52.34375\n"]}]},{"cell_type":"code","source":["\n","format_train_val = format_train_val # set it at the top of notebook in a common place\n","\n","def format_examples(example_val, format_val = format_train_val):\n","    if format_val== 'minimal':\n","      # \"minimal\" format\n","      return {'text': \"{\"  + example_val['premise'] + \"} {\" + example_val['hypothesis'] + \"}\" + \" ? Ġ\"}\n","    elif format_val== 'gpt3':\n","      # \"gpt3\" format\n","      return {'text': \"{\"  + example_val['premise'] + \"} question: {\" + example_val['hypothesis'] + \"}\" + \" Yes or No? answer: Ġ\"}\n","\n","def create_combined_dataset(train_ds_yes, train_ds_no, num_expts=num_experiments, num_train_examples=examples_per_exp):\n","    combined_dataset = []\n","    train_examples_yes = [example for example in train_ds_yes]\n","    train_examples_no = [example for example in train_ds_no]\n","\n","    for irep in range(num_expts):\n","          sampled_train_exs_yes = train_examples_yes[int(irep*num_train_examples/2) : int((irep +1)*num_train_examples/2)]\n","          sampled_train_exs_no = train_examples_no[int(irep*num_train_examples/2) : int((irep +1)*num_train_examples/2)]\n","          merged_sampled_train_exs = sampled_train_exs_yes + sampled_train_exs_no\n","          shuffled_list = merged_sampled_train_exs.copy()\n","          random.seed(irep)\n","          random.shuffle(shuffled_list)\n","\n","          for idx_shuffled_list in range(len(shuffled_list)):\n","\n","            if shuffled_list[idx_shuffled_list]['label'] == 0:\n","              target_token = 9904\n","            else:\n","              target_token = 3084\n","\n","            combined_ex = {'text': '', 'label': torch.tensor(shuffled_list[idx_shuffled_list]['label'], dtype=torch.long).to(device), 'exp': irep+1, 'target_token': torch.tensor(target_token, dtype=torch.long).to(device)}\n","\n","            combined_ex['text'] += shuffled_list[idx_shuffled_list]['text']\n","\n","            combined_dataset.append([combined_ex])\n","\n","    return combined_dataset\n","\n","\n","def dynamic_padding_collate_fn(batch):\n","\n","    batch = [item for sublist in batch for item in sublist]\n","\n","    texts = [item['text'] for item in batch]\n","    labels = [item['label'] for item in batch]\n","    exps = [item['exp'] for item in batch]\n","    target_tokens = [item['target_token'] for item in batch]\n","\n","    # choose option\n","    tokenized_inputs = OPT_tokenizer(texts, padding=\"longest\", truncation=True, return_tensors=\"pt\")\n","    # tokenized_inputs = OPT_tokenizer(texts, padding=\"max_length\", max_length = 2048, truncation=True, return_tensors=\"pt\")\n","\n","    labels_tensor = torch.unsqueeze(torch.tensor(labels, dtype=torch.long).to(device),0)\n","    exps_tensor = torch.unsqueeze(torch.tensor(exps, dtype=torch.long).to(device),0)\n","    target_token_tensor = torch.unsqueeze(torch.tensor(target_tokens, dtype=torch.long).to(device),0)\n","\n","    return {\n","        'text': texts,\n","        'input_ids': tokenized_inputs['input_ids'],\n","        'attention_mask': tokenized_inputs['attention_mask'],\n","        'label': labels_tensor,\n","        'exp': exps_tensor,\n","        'target_token': target_token_tensor\n","    }\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, combined_dataset):\n","        self.dataset = combined_dataset\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        return self.dataset[idx]\n"],"metadata":{"id":"JlqLEdhW84X1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","formatted_train_dataset_yes = train_dataset_yes.map(format_examples)\n","formatted_train_dataset_no = train_dataset_no.map(format_examples)\n","\n","# print result to check correctness\n","\n","combined_dataset = create_combined_dataset(\n","                                          train_ds_yes = formatted_train_dataset_yes,\n","                                          train_ds_no = formatted_train_dataset_no,\n","                                          num_expts=num_experiments,\n","                                          num_train_examples=examples_per_exp\n","                                           )\n","\n","custom_dataset = CustomDataset(combined_dataset)\n","custom_dataset_experiment = CustomDataset([item for item in custom_dataset if item[0]['exp'] == SEL_EXP_TRAIN_CD])\n","print(custom_dataset_experiment)\n","\n","# Last step, we create Dataloader passing the bx_size for inference/training (typically: 1, 4, 8, 16)\n","bx_size = bx_size # set it up at the beg of NB\n","dataloader_experiment = DataLoader(custom_dataset_experiment, batch_size=bx_size, collate_fn=dynamic_padding_collate_fn, shuffle=False) #shuffle=False for reproducibility"],"metadata":{"id":"Iux0yDPz9l91","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714453197048,"user_tz":240,"elapsed":144,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}},"outputId":"97b73507-238c-41a6-c898-1727312768e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<__main__.CustomDataset object at 0x7f56c18df3d0>\n"]}]},{"cell_type":"code","source":["# This is to inspect that the dataloader is performing as expected\n","# Also using the decoding to check back that results are expected and examples can be compared\n","\n","# USE SIMILAR TO THIS TO PASS TO YOUR MODEL - SEE TENSOR DIMENSIONS AND ADJUST WITH SQUEEZE / UNSQUEEZE AS NEEDED THE DATALOADER OUTPUT AS INPUT TO YOUR MODEL\n","\n","for i, batch in enumerate(dataloader_experiment):\n","    if i<200:\n","      print(\"Item Number: \", i, \"experiment#: \", batch['exp'])\n","      print(\"DETOKENIZE: \", OPT_tokenizer.batch_decode(batch['input_ids']))\n","      print(\"Labels: \", batch['label'])\n","      print(\"Target Token: \", batch['target_token'])\n","      print(\"Input_ids: \", batch['input_ids'])\n","      print(\"Attention_Mask: \", batch['attention_mask'])\n","    else:\n","      break"],"metadata":{"id":"gLkf358E_4kn","executionInfo":{"status":"ok","timestamp":1714453197048,"user_tz":240,"elapsed":4,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a98f4ad4-6be5-44ad-ab78-c010f739526e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]},{"output_type":"stream","name":"stdout","text":["Item Number:  0 experiment#:  tensor([[3]])\n","DETOKENIZE:  [\"</s>{Corruption and tax-evasion continued, but police clamped down on the political terrorism of the Red Brigades and neo-Fascists and the age-old criminality of the Mafia.} question: {Police didn't fight terrorism at all.} Yes or No? answer: Ġ\"]\n","Labels:  tensor([[1]])\n","Target Token:  tensor([[3084]])\n","Input_ids:  tensor([[    2, 45152, 15228, 26858,     8,   629,    12,  3623, 27720,  1143,\n","             6,    53,   249,  3741, 16458,   159,    15,     5,   559,  4952,\n","             9,     5,  1211, 17443,  4216,     8, 17863,    12,   597,  8631,\n","          1952,     8,     5,  1046,    12,   279, 35322,     9,     5, 37516,\n","         49463,   864,    35, 25522,  9497,   399,    75,  1032,  4952,    23,\n","            70, 49463,  3216,    50,   440,   116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  1 experiment#:  tensor([[3]])\n","DETOKENIZE:  [\"</s>{So that's the next } question: {That isn't going to be next} Yes or No? answer: Ġ\"]\n","Labels:  tensor([[1]])\n","Target Token:  tensor([[3084]])\n","Input_ids:  tensor([[    2, 45152,  2847,    14,    18,     5,   220, 35524,   864,    35,\n","         25522,  1711,   965,    75,   164,     7,    28,   220, 24303,  3216,\n","            50,   440,   116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1]])\n","Item Number:  2 experiment#:  tensor([[3]])\n","DETOKENIZE:  [\"</s>{Second, we held that the LSCA did not explicitly authorize a private right of action against the LSC.} question: {The LCSA's private right of action against the LSC wasn't explicitly authorized.} Yes or No? answer: Ġ\"]\n","Labels:  tensor([[0]])\n","Target Token:  tensor([[9904]])\n","Input_ids:  tensor([[    2, 45152, 32703,     6,    52,   547,    14,     5,   226,  3632,\n","           250,   222,    45, 16369, 29080,    10,   940,   235,     9,   814,\n","           136,     5,   226,  3632, 49463,   864,    35, 25522,   133, 24756,\n","          3603,    18,   940,   235,     9,   814,   136,     5,   226,  3632,\n","           938,    75, 16369,  8672, 49463,  3216,    50,   440,   116,  1948,\n","            35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1]])\n","Item Number:  3 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{uh well for example uh in Greek there are seven different words for love} question: {The word love only has one word meaning in the Greek language.} Yes or No? answer: Ġ']\n","Labels:  tensor([[1]])\n","Target Token:  tensor([[3084]])\n","Input_ids:  tensor([[    2, 45152,  2957,   157,    13,  1246, 37463,    11,  5617,    89,\n","            32,   707,   430,  1617,    13,   657, 24303,   864,    35, 25522,\n","           133,  2136,   657,   129,    34,    65,  2136,  3099,    11,     5,\n","          5617,  2777, 49463,  3216,    50,   440,   116,  1948,    35,  4236,\n","         21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  4 experiment#:  tensor([[3]])\n","DETOKENIZE:  [\"</s>{You yourself did not happen to notice, madame, when you entered Mrs. Inglethorp's room, whether that door was bolted or not?} question: {Did you notice if the door Mrs. Inglethorp's room was locked or not?} Yes or No? answer: Ġ\"]\n","Labels:  tensor([[0]])\n","Target Token:  tensor([[9904]])\n","Input_ids:  tensor([[    2, 45152,  1185,  2512,   222,    45,  1369,     7,  3120,     6,\n","          7758,  4344,     6,    77,    47,  2867,  3801,     4, 11996,   459,\n","           212, 10782,    18,   929,     6,   549,    14,  1883,    21, 37584,\n","            50,    45,   116, 24303,   864,    35, 25522, 20328,    47,  3120,\n","           114,     5,  1883,  3801,     4, 11996,   459,   212, 10782,    18,\n","           929,    21,  5930,    50,    45,   116, 24303,  3216,    50,   440,\n","           116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  5 experiment#:  tensor([[3]])\n","DETOKENIZE:  [\"</s>{If you're up to a climb, take the Mount Austin road to the Victoria Peak Gardens.} question: {It is a hike to get to the Victoria Peak Gardens.} Yes or No? answer: Ġ\"]\n","Labels:  tensor([[0]])\n","Target Token:  tensor([[9904]])\n","Input_ids:  tensor([[    2, 45152,  1106,    47,   214,    62,     7,    10,  8264,     6,\n","           185,     5,  5455,  4224,   921,     7,     5,  4769, 19704, 12222,\n","         49463,   864,    35, 25522,   243,    16,    10,  5960,     7,   120,\n","             7,     5,  4769, 19704, 12222, 49463,  3216,    50,   440,   116,\n","          1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  6 experiment#:  tensor([[3]])\n","DETOKENIZE:  [\"</s>{you didn't yeah} question: {Yes you did.} Yes or No? answer: Ġ\"]\n","Labels:  tensor([[1]])\n","Target Token:  tensor([[3084]])\n","Input_ids:  tensor([[    2, 45152,  6968,   399,    75, 11380, 24303,   864,    35, 25522,\n","          9904,    47,   222, 49463,  3216,    50,   440,   116,  1948,    35,\n","          4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  7 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{Yet Hawaii was still an island paradise in the eyes of travelers, if not in those of its original people.} question: {Travelers think that Hawaii is an island paradise.} Yes or No? answer: Ġ']\n","Labels:  tensor([[0]])\n","Target Token:  tensor([[9904]])\n","Input_ids:  tensor([[    2, 45152, 34995,  6467,    21,   202,    41,  2946, 26215,    11,\n","             5,  2473,     9, 11774,     6,   114,    45,    11,   167,     9,\n","            63,  1461,    82, 49463,   864,    35, 25522, 39258,   268,   206,\n","            14,  6467,    16,    41,  2946, 26215, 49463,  3216,    50,   440,\n","           116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  8 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{Now we have become an atomized society of individuals who get their news--if they get it at all--from TV.} question: {All of our news is on radio and in newspapers.} Yes or No? answer: Ġ']\n","Labels:  tensor([[1]])\n","Target Token:  tensor([[3084]])\n","Input_ids:  tensor([[    2, 45152,  5975,    52,    33,   555,    41, 37113,  1538,  2313,\n","             9,  2172,    54,   120,    49,   340,  5579,  1594,    51,   120,\n","            24,    23,    70,  5579,  7761,  1012, 49463,   864,    35, 25522,\n","          3684,     9,    84,   340,    16,    15,  3188,     8,    11,  9911,\n","         49463,  3216,    50,   440,   116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1]])\n","Item Number:  9 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{ To Help You Order  } question: {Help your order here.} Yes or No? answer: Ġ']\n","Labels:  tensor([[0]])\n","Target Token:  tensor([[9904]])\n","Input_ids:  tensor([[    2, 45152,   598, 10310,   370,  9729,  1437, 35524,   864,    35,\n","         25522, 28780,   110,   645,   259, 49463,  3216,    50,   440,   116,\n","          1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  10 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{Well, they\\'ll produce a Jane Finn of their own say at a pensionnat in Paris.\" Tuppence gasped, and Mr. Carter smiled.} question: {Tuppence gasped, and so did Mr. Carter.} Yes or No? answer: Ġ']\n","Labels:  tensor([[1]])\n","Target Token:  tensor([[3084]])\n","Input_ids:  tensor([[    2, 45152,  8346,     6,    51,   581,  2592,    10,  7343, 14533,\n","             9,    49,   308,   224,    23,    10,  4931, 26992,    11,  2201,\n","            72,   255, 12151,  4086, 44918,     6,     8,   427,     4,  5306,\n","         20185, 49463,   864,    35, 25522,   565, 12151,  4086, 44918,     6,\n","             8,    98,   222,   427,     4,  5306, 49463,  3216,    50,   440,\n","           116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  11 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{But I find his storytelling both morally easy and artistically promiscuous.} question: {His storytelling is easy.} Yes or No? answer: Ġ']\n","Labels:  tensor([[0]])\n","Target Token:  tensor([[9904]])\n","Input_ids:  tensor([[    2, 45152,  1708,    38,   465,    39, 17662,   258, 28404,  1365,\n","             8,  3025,  3435, 12206,  4473, 12685, 49463,   864,    35, 25522,\n","          9962, 17662,    16,  1365, 49463,  3216,    50,   440,   116,  1948,\n","            35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  12 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{The estimate of labor includes planning and engineering, general labor, and skilled boilermakers.} question: {To estimate the cost of labor, one must include planning as a component.} Yes or No? answer: Ġ']\n","Labels:  tensor([[0]])\n","Target Token:  tensor([[9904]])\n","Input_ids:  tensor([[    2, 45152,   133,  3278,     9,  4178,  1171,  1884,     8,  4675,\n","             6,   937,  4178,     6,     8, 11086, 33750,  6040, 49463,   864,\n","            35, 25522,  3972,  3278,     5,   701,     9,  4178,     6,    65,\n","           531,   680,  1884,    25,    10,  7681, 49463,  3216,    50,   440,\n","           116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  13 experiment#:  tensor([[3]])\n","DETOKENIZE:  [\"</s>{right yeah well i've i've managed to i guess the work i do gives me a little bit of well a lot of walking and a little bit of lifting on occasion} question: {The work I do is pretty sedentary, so I have to go to they gym.} Yes or No? answer: Ġ\"]\n","Labels:  tensor([[1]])\n","Target Token:  tensor([[3084]])\n","Input_ids:  tensor([[    2, 45152,  4070, 11380,   157,   939,   348,   939,   348,  2312,\n","             7,   939,  4443,     5,   173,   939,   109,  2029,   162,    10,\n","           410,   828,     9,   157,    10,   319,     9,  3051,     8,    10,\n","           410,   828,     9, 10201,    15,  5852, 24303,   864,    35, 25522,\n","           133,   173,    38,   109,    16,  1256, 10195, 39494,     6,    98,\n","            38,    33,     7,   213,     7,    51,  6545, 49463,  3216,    50,\n","           440,   116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  14 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{The Ayuntamiento houses a small picture gallery and a chapel with tiles from Manises, an important Valencian ceramics centre.} question: {While attractive from the outside, there is nothing to be seen inside the Ayuntamiento.} Yes or No? answer: Ġ']\n","Labels:  tensor([[1]])\n","Target Token:  tensor([[3084]])\n","Input_ids:  tensor([[    2, 45152,   133,  5847,  5973,   424,  4843,   139,  3960,    10,\n","           650,  2170,  7294,     8,    10, 27070,    19, 26779,    31,  1554,\n","          5504,     6,    41,   505,  3767, 14210,   811, 25380,   424,  2857,\n","          2100, 49463,   864,    35, 25522,  5771,  6043,    31,     5,   751,\n","             6,    89,    16,  1085,     7,    28,   450,  1025,     5,  5847,\n","          5973,   424,  4843,   139, 49463,  3216,    50,   440,   116,  1948,\n","            35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  15 experiment#:  tensor([[3]])\n","DETOKENIZE:  [\"</s>{Rennie was not too common a name, but he did not see how Johnny could possibly have hit upon the truth.} question: {He didn't know how Johnny had discovered the truth.} Yes or No? answer: Ġ\"]\n","Labels:  tensor([[0]])\n","Target Token:  tensor([[9904]])\n","Input_ids:  tensor([[    2, 45152,   500,  4734,   324,    21,    45,   350,  1537,    10,\n","           766,     6,    53,    37,   222,    45,   192,   141,  8781,   115,\n","          3544,    33,   478,  2115,     5,  3157, 49463,   864,    35, 25522,\n","           894,   399,    75,   216,   141,  8781,    56,  2967,     5,  3157,\n","         49463,  3216,    50,   440,   116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1]])\n"]}]},{"cell_type":"markdown","source":["# IN-DOMAIN VALIDATION DATASET"],"metadata":{"id":"4gxoA3Lop7hO"}},{"cell_type":"code","source":["\n","def create_combined_dataset_indomain_VALIDATION(val_dataset, num_expts=num_experiments):\n","    combined_dataset = []\n","\n","    for irep in range(num_expts):\n","      for val_ex in val_dataset:\n","\n","            if val_ex['label'] == 0:\n","              target_token = 9904\n","            else:\n","              target_token = 3084\n","\n","            combined_ex = {'text': '', 'label': torch.tensor(val_ex['label'], dtype=torch.long).to(device), 'exp': irep+1, 'target_token': torch.tensor(target_token, dtype=torch.long).to(device)}\n","\n","            combined_ex['text'] += val_ex['text']\n","\n","            # Append the new combined example to the combined dataset\n","            combined_dataset.append([combined_ex])\n","\n","    return combined_dataset\n"],"metadata":{"id":"wc31z8yZUQWm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["formatted_val_dataset_indomain = val_dataset_indomain.map(format_examples)\n","\n","combined_dataset_INDOMAIN_VALIDATION = create_combined_dataset_indomain_VALIDATION(\n","                                          val_dataset = formatted_val_dataset_indomain,\n","                                          num_expts=num_experiments\n","                                           )\n","\n","custom_dataset_indomain_validation = CustomDataset(combined_dataset_INDOMAIN_VALIDATION)\n","custom_dataset_indomain_val_experiment = CustomDataset([item for item in custom_dataset_indomain_validation if item[0]['exp'] == SEL_EXP_TRAIN_CD])\n","print(custom_dataset_indomain_val_experiment)\n","\n","# Last step, we create Dataloader passing the bx_size for inference/training (typically: 1, 4, 8, 16)\n","bx_size = bx_size # set it up at the beg of NB\n","dataloader_indomain_val_experiment = DataLoader(custom_dataset_indomain_val_experiment, batch_size=bx_size, collate_fn=dynamic_padding_collate_fn, shuffle=False) #shuffle=False for reproducibility"],"metadata":{"id":"7XG7PTIOrV1O","executionInfo":{"status":"ok","timestamp":1714453197971,"user_tz":240,"elapsed":924,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9aea2505-772f-4a71-fa7d-1a18f879aa6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<__main__.CustomDataset object at 0x7f56c18dd150>\n"]}]},{"cell_type":"code","source":["\n","for i, batch in enumerate(dataloader_indomain_val_experiment):\n","    if i<20:\n","      print(\"Item Number: \", i, \"experiment#: \", batch['exp'])\n","      print(\"DETOKENIZE: \", OPT_tokenizer.batch_decode(batch['input_ids']))\n","      print(\"Labels: \", batch['label'])\n","      print(\"Target Token: \", batch['target_token'])\n","      print(\"Input_ids: \", batch['input_ids'])\n","      print(\"Attention_Mask: \", batch['attention_mask'])\n","    else:\n","      break"],"metadata":{"id":"oQBs1lgxsPhO","executionInfo":{"status":"ok","timestamp":1714453198133,"user_tz":240,"elapsed":164,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b7d63507-7983-405a-ca12-23aa61776c1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Item Number:  0 experiment#:  tensor([[3]])\n","DETOKENIZE:  [\"</s>{no it didn't} question: {Yes it did.} Yes or No? answer: Ġ\"]\n","Labels:  tensor([[1]])\n","Target Token:  tensor([[3084]])\n","Input_ids:  tensor([[    2, 45152,  2362,    24,   399,    75, 24303,   864,    35, 25522,\n","          9904,    24,   222, 49463,  3216,    50,   440,   116,  1948,    35,\n","          4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  1 experiment#:  tensor([[3]])\n","DETOKENIZE:  [\"</s>{Who? asked Tommy.} question: {Tommy didn't know, who.} Yes or No? answer: Ġ\"]\n","Labels:  tensor([[0]])\n","Target Token:  tensor([[9904]])\n","Input_ids:  tensor([[    2, 45152, 12375,   116,   553,  8880, 49463,   864,    35, 25522,\n","         15691,  4783,   399,    75,   216,     6,    54, 49463,  3216,    50,\n","           440,   116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1]])\n","Item Number:  2 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{Paroseas cave, reef, and wreck diving around its shores, giving the diver a wide range of environments to explore.} question: {The diver has no variety in places to explore, they are monotonous. } Yes or No? answer: Ġ']\n","Labels:  tensor([[1]])\n","Target Token:  tensor([[3084]])\n","Input_ids:  tensor([[    2, 45152, 22011,  3876,   281, 12742,     6, 28350,     6,     8,\n","         15107, 12909,   198,    63, 20597,     6,  1311,     5, 13105,    10,\n","          1810,  1186,     9, 11534,     7,  5393, 49463,   864,    35, 25522,\n","           133, 13105,    34,   117,  3143,    11,  2127,     7,  5393,     6,\n","            51,    32,  6154, 27334,  1827,     4, 35524,  3216,    50,   440,\n","           116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  3 experiment#:  tensor([[3]])\n","DETOKENIZE:  [\"</s>{um i've visited the Wyoming area i'm not sure exactly where Dances with Wolves was filmed} question: {I don't know even though I visited the area.} Yes or No? answer: Ġ\"]\n","Labels:  tensor([[0]])\n","Target Token:  tensor([[9904]])\n","Input_ids:  tensor([[    2, 45152,   783,   939,   348,  3790,     5, 11027,   443,   939,\n","           437,    45,   686,  2230,   147,   211,  5332,    19, 13889,    21,\n","         10571, 24303,   864,    35, 25522,   100,   218,    75,   216,   190,\n","           600,    38,  3790,     5,   443, 49463,  3216,    50,   440,   116,\n","          1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  4 experiment#:  tensor([[3]])\n","DETOKENIZE:  [\"</s>{i think Buffalo is an up an coming team they're going to they're showing some real promise for the next uh few years} question: {Buffalo is showing some real promise for the next few years, I think they are an up and coming team.} Yes or No? answer: Ġ\"]\n","Labels:  tensor([[0]])\n","Target Token:  tensor([[9904]])\n","Input_ids:  tensor([[    2, 45152,   118,   206,  5958,    16,    41,    62,    41,   567,\n","           165,    51,   214,   164,     7,    51,   214,  2018,   103,   588,\n","          4198,    13,     5,   220, 37463,   367,   107, 24303,   864,    35,\n","         25522, 42021,  7747,    16,  2018,   103,   588,  4198,    13,     5,\n","           220,   367,   107,     6,    38,   206,    51,    32,    41,    62,\n","             8,   567,   165, 49463,  3216,    50,   440,   116,  1948,    35,\n","          4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  5 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{They did this to us.} question: {This was done by them.} Yes or No? answer: Ġ']\n","Labels:  tensor([[0]])\n","Target Token:  tensor([[9904]])\n","Input_ids:  tensor([[    2, 45152,  1213,   222,    42,     7,   201, 49463,   864,    35,\n","         25522,   713,    21,   626,    30,   106, 49463,  3216,    50,   440,\n","           116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1]])\n","Item Number:  6 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{uh-huh how about any matching programs} question: {What about matching programs? } Yes or No? answer: Ġ']\n","Labels:  tensor([[0]])\n","Target Token:  tensor([[9904]])\n","Input_ids:  tensor([[    2, 45152,  2957,    12,   298,  2957,   141,    59,   143,  8150,\n","          1767, 24303,   864,    35, 25522,  2264,    59,  8150,  1767,   116,\n","         35524,  3216,    50,   440,   116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1]])\n","Item Number:  7 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{MC2000-2, was initially considered and recommended by the Commission under the market test rules.} question: {MC2000-2 was recommended by the Commission.} Yes or No? answer: Ġ']\n","Labels:  tensor([[0]])\n","Target Token:  tensor([[9904]])\n","Input_ids:  tensor([[    2, 45152,  6018, 17472,    12,   176,     6,    21,  3225,  1687,\n","             8,  5131,    30,     5,  1463,   223,     5,   210,  1296,  1492,\n","         49463,   864,    35, 25522,  6018, 17472,    12,   176,    21,  5131,\n","            30,     5,  1463, 49463,  3216,    50,   440,   116,  1948,    35,\n","          4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  8 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{Asked about abortion the other day on CNN, Republican National Committee Chairman Jim Nicholson also invoked what is apparently the party-line  inclusive party.} question: {The Republican National Committee Chairman freelanced on the topic of abortion when asked about it on CNN instead of reiterating the party-line.} Yes or No? answer: Ġ']\n","Labels:  tensor([[1]])\n","Target Token:  tensor([[3084]])\n","Input_ids:  tensor([[    2, 45152, 46688,    59,  6428,     5,    97,   183,    15,  3480,\n","             6,  1172,   496,  1674,  3356,  2488, 19408,    67, 29198,    99,\n","            16,  4100,     5,   537,    12,  1902,  1437, 10510,   537, 49463,\n","           864,    35, 25522,   133,  1172,   496,  1674,  3356, 30270, 16325,\n","            15,     5,  5674,     9,  6428,    77,   553,    59,    24,    15,\n","          3480,  1386,     9, 26209,  1295,     5,   537,    12,  1902, 49463,\n","          3216,    50,   440,   116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  9 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{It was like looking into a mirror, except infinitely more realistic.} question: {It was more realistic than looking in a mirror. } Yes or No? answer: Ġ']\n","Labels:  tensor([[0]])\n","Target Token:  tensor([[9904]])\n","Input_ids:  tensor([[    2, 45152,   243,    21,   101,   546,    88,    10,  9807,     6,\n","          4682, 40489,    55, 10556, 49463,   864,    35, 25522,   243,    21,\n","            55, 10556,    87,   546,    11,    10,  9807,     4, 35524,  3216,\n","            50,   440,   116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  10 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{John Kasich dropped his presidential bid.} question: {John Kasich recommitted himself to the presidential bid and plans on winning.} Yes or No? answer: Ġ']\n","Labels:  tensor([[1]])\n","Target Token:  tensor([[3084]])\n","Input_ids:  tensor([[    2, 45152, 10567, 26004,  1882,    39,  1939,  2311, 49463,   864,\n","            35, 25522, 10567, 26004, 37573, 16430,  1003,     7,     5,  1939,\n","          2311,     8,   708,    15,  1298, 49463,  3216,    50,   440,   116,\n","          1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  11 experiment#:  tensor([[3]])\n","DETOKENIZE:  [\"</s>{well that's good that's great} question: {Shit, that is bad, that is horrible.} Yes or No? answer: Ġ\"]\n","Labels:  tensor([[1]])\n","Target Token:  tensor([[3084]])\n","Input_ids:  tensor([[    2, 45152,  3056,    14,    18,   205,    14,    18,   372, 24303,\n","           864,    35, 25522,  3609,   405,     6,    14,    16,  1099,     6,\n","            14,    16, 11385, 49463,  3216,    50,   440,   116,  1948,    35,\n","          4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  12 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{There were beads of perspiration on his brow.} question: {He was perfectly calm and dry as he waited.} Yes or No? answer: Ġ']\n","Labels:  tensor([[1]])\n","Target Token:  tensor([[3084]])\n","Input_ids:  tensor([[    2, 45152,   970,    58, 35036,     9, 20187, 41678,    15,    39,\n","         27423, 49463,   864,    35, 25522,   894,    21,  6683,  6327,     8,\n","          3841,    25,    37,  9010, 49463,  3216,    50,   440,   116,  1948,\n","            35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  13 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{Even the most aged and infirm travel here to die, for nothing is more blessed for a devout Hindu than to die in the great waters of the Varanasi and thus be released from the eternal cycle of rebirth.} question: {Devout Hindus believe that dying in the Varanasi frees a soul from the cycle of rebirth.} Yes or No? answer: Ġ']\n","Labels:  tensor([[0]])\n","Target Token:  tensor([[9904]])\n","Input_ids:  tensor([[    2, 45152,  8170,     5,   144,  5180,     8,  4047,  9856,  1504,\n","           259,     7,  1597,     6,    13,  1085,    16,    55, 12230,    13,\n","            10, 36906, 12316,    87,     7,  1597,    11,     5,   372,  5794,\n","             9,     5,  9676, 16264,   118,     8,  4634,    28,   703,    31,\n","             5, 25023,  4943,     9, 39652, 49463,   864,    35, 25522, 30504,\n","           995, 30618,   679,    14,  8180,    11,     5,  9676, 16264,   118,\n","          7619,   293,    10,  7047,    31,     5,  4943,     9, 39652, 49463,\n","          3216,    50,   440,   116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1]])\n","Item Number:  14 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{You and your friends are not welcome here, said Severn.} question: {Severn said the people were always welcome there.} Yes or No? answer: Ġ']\n","Labels:  tensor([[1]])\n","Target Token:  tensor([[3084]])\n","Input_ids:  tensor([[    2, 45152,  1185,     8,   110,   964,    32,    45,  2814,   259,\n","             6,    26,  1608, 12170, 49463,   864,    35, 25522, 14696, 12170,\n","            26,     5,    82,    58,   460,  2814,    89, 49463,  3216,    50,\n","           440,   116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  15 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{Current Chinese leaders have distinctive characteristics that give them significant advantages over the United States in foreign policy.} question: {The us has advantages over China in foreign policy. } Yes or No? answer: Ġ']\n","Labels:  tensor([[1]])\n","Target Token:  tensor([[3084]])\n","Input_ids:  tensor([[    2, 45152, 42124,  1111,   917,    33, 16141, 12720,    14,   492,\n","           106,  1233, 12340,    81,     5,   315,   532,    11,  1093,   714,\n","         49463,   864,    35, 25522,   133,   201,    34, 12340,    81,   436,\n","            11,  1093,   714,     4, 35524,  3216,    50,   440,   116,  1948,\n","            35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  16 experiment#:  tensor([[3]])\n","DETOKENIZE:  [\"</s>{The Chinese calendar was used to calculate the year of Japan's foundation by counting back the 1,260 years of the Chinese cosmological cycle.} question: {Japan's foundation was determined by using the Chinese calendar.} Yes or No? answer: Ġ\"]\n","Labels:  tensor([[0]])\n","Target Token:  tensor([[9904]])\n","Input_ids:  tensor([[    2, 45152,   133,  1111,  7127,    21,   341,     7, 15756,     5,\n","            76,     9,  1429,    18,  4811,    30, 10581,   124,     5,   112,\n","             6, 21566,   107,     9,     5,  1111, 12793,   119,  9779,  4943,\n","         49463,   864,    35, 25522, 21318,    18,  4811,    21,  3030,    30,\n","           634,     5,  1111,  7127, 49463,  3216,    50,   440,   116,  1948,\n","            35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1]])\n","Item Number:  17 experiment#:  tensor([[3]])\n","DETOKENIZE:  [\"</s>{Two clues in the Pennsylvania  1) The boy had said, I'm going to go to the dinner dance and kill some people.} question: {There was only one clue in Pennsylvania and it had nothing to do with the boy.} Yes or No? answer: Ġ\"]\n","Labels:  tensor([[1]])\n","Target Token:  tensor([[3084]])\n","Input_ids:  tensor([[    2, 45152,  9058, 14885,    11,     5,  4367,  1437,   112,    43,\n","            20,  2143,    56,    26,     6,    38,   437,   164,     7,   213,\n","             7,     5,  3630,  3836,     8,  3549,   103,    82, 49463,   864,\n","            35, 25522,   970,    21,   129,    65, 18664,    11,  4367,     8,\n","            24,    56,  1085,     7,   109,    19,     5,  2143, 49463,  3216,\n","            50,   440,   116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  18 experiment#:  tensor([[3]])\n","DETOKENIZE:  ['</s>{8 A stoichiometry of 1.03 is typical when the FGD process is producing gypsum by-product, while a stoichiometry of 1.05 is needed to produce waste suitable for a landfill.} question: {A stoichiometry of 1.07 is typical when the FGD process is producing gypsum by-product} Yes or No? answer: Ġ']\n","Labels:  tensor([[1]])\n","Target Token:  tensor([[3084]])\n","Input_ids:  tensor([[    2, 45152,   398,    83, 20572, 20000, 40899,     9,   112,     4,\n","          3933,    16,  6097,    77,     5, 25408,   495,   609,    16,  5591,\n","         18124,  3275,   783,    30,    12, 20565,     6,   150,    10, 20572,\n","         20000, 40899,     9,   112,     4,  2546,    16,   956,     7,  2592,\n","          3844, 10686,    13,    10, 21289, 49463,   864,    35, 25522,   250,\n","         20572, 20000, 40899,     9,   112,     4,  3570,    16,  6097,    77,\n","             5, 25408,   495,   609,    16,  5591, 18124,  3275,   783,    30,\n","            12, 20565, 24303,  3216,    50,   440,   116,  1948,    35,  4236,\n","         21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","Item Number:  19 experiment#:  tensor([[3]])\n","DETOKENIZE:  [\"</s>{oh yes yeah yeah yeah that's true too that's true} question: {It is true} Yes or No? answer: Ġ\"]\n","Labels:  tensor([[0]])\n","Target Token:  tensor([[9904]])\n","Input_ids:  tensor([[    2, 45152,  2678,  4420, 11380, 11380, 11380,    14,    18,  1528,\n","           350,    14,    18,  1528, 24303,   864,    35, 25522,   243,    16,\n","          1528, 24303,  3216,    50,   440,   116,  1948,    35,  4236, 21402]])\n","Attention_Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1]])\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qCU9xUpVx1ei"},"outputs":[],"source":["# Custom model class for sequence classification\n","\n","import torch.nn as nn\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","\n","class OPT_VanillaFT(nn.Module):\n","    def __init__(self, model_name, num_labels):\n","        super().__init__()\n","        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n","\n","    def forward(self, input_ids, attention_mask=None, labels=None):\n","        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","        logits = outputs.logits\n","        return logits"]},{"cell_type":"code","source":["# Define optimizer and loss function\n","model = OPT_VanillaFT(model_name, num_labels=2)\n","# print(model)\n","optimizer = AdamW(model.parameters(), lr=1e-6)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Training loop\n","model.to(device)\n","model.train()\n","\n","train_losses = []\n","val_losses = []\n","train_accuracies = []\n","val_accuracies = []\n","\n","num_epochs = 6\n","batch_size = 1  # Reduce batch size to 4\n","for epoch in range(num_epochs):\n","    print(\"epoch: \", epoch)\n","    total_loss = 0.0\n","    train_acc = 0.0\n","    for i, batch in enumerate(dataloader_experiment):\n","\n","        # print(\"input_ids: \", batch[\"input_ids\"])\n","\n","\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"label\"].to(device).squeeze(0)\n","\n","\n","        # print(\"labels: \", batch[\"label\"], labels.shape)\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(input_ids, None, labels) #, labels=labels)\n","        labels = torch.nn.functional.one_hot(labels, num_classes=2).float()\n","        # print(\"outputs SHAPE: \", outputs.shape)\n","        # print(outputs)\n","        # # Compute loss\n","        loss = criterion(outputs, labels)\n","        # print(\"loss: \", loss)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","\n","        # Compute accuracy\n","        train_acc = train_acc + 1*(torch.argmax(outputs, dim=1).item()==batch[\"label\"].to(device).squeeze(0).item())\n","\n","    average_loss = total_loss / (i+1)\n","    train_losses.append(average_loss)\n","    train_accuracies.append(train_acc / (i+1))\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {average_loss:.6f}, Accuracy: {train_accuracies[-1]:.9f}\")\n","\n","    # val_losses.append(val_loss / num_validations)\n","    # val_accuracies.append(val_accuracy / num_validations)\n","\n","    # print(f\"Validation Loss: {val_losses[-1]:.6f}, Validation Accuracy: {val_accuracies[-1]:.9f}\")\n","\n","    # model.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKFssGNxx40D","outputId":"3910823b-2129-4fd2-c7d0-cd3f8a1dd02b","executionInfo":{"status":"ok","timestamp":1714453909879,"user_tz":240,"elapsed":711747,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-2.7b and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["epoch:  0\n","Epoch 1/6, Train Loss: 0.970775, Accuracy: 0.437500000\n","epoch:  1\n","Epoch 2/6, Train Loss: 0.692332, Accuracy: 0.500000000\n","epoch:  2\n","Epoch 3/6, Train Loss: 0.453571, Accuracy: 0.812500000\n","epoch:  3\n","Epoch 4/6, Train Loss: 0.280789, Accuracy: 1.000000000\n","epoch:  4\n","Epoch 5/6, Train Loss: 0.237810, Accuracy: 0.875000000\n","epoch:  5\n","Epoch 6/6, Train Loss: 0.135239, Accuracy: 0.937500000\n"]}]},{"cell_type":"code","source":["# Validation\n","model.eval()\n","val_loss = 0.0\n","val_accuracy = 0.0\n","with torch.no_grad():\n","    for batch in dataloader_indomain_val_experiment:\n","        src = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"label\"].to(device).squeeze(0)\n","\n","        # Forward pass\n","        outputs = model(input_ids, None, labels)\n","\n","        # Compute loss\n","        # if 'logits' in outputs:\n","        loss = criterion(outputs, labels)\n","        val_loss += loss.item()\n","\n","        # Compute accuracy\n","        val_accuracy += 1*(torch.argmax(outputs, dim=1).item()==batch[\"label\"].to(device).squeeze(0).item())\n","    val_loss = val_loss/num_validations\n","    val_accuracy = val_accuracy/num_validations\n","    print(f\"Validation Loss: {val_loss:.6f}, Validation Accuracy: {val_accuracy:.9f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sGIvEE4MZPMw","executionInfo":{"status":"ok","timestamp":1714461575538,"user_tz":240,"elapsed":164,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}},"outputId":"83735402-43b8-4dc8-98c9-9804d1e0b274"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Loss: 1.501443, Validation Accuracy: 0.523437500\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i7DXLZYPedey","colab":{"base_uri":"https://localhost:8080/","height":353,"referenced_widgets":["a13237c9304d4afba25f83e9c58ee691","766ca5f0cde943988a68d3d229fd5efc","4b275c4a45a041be86f6de0d865c1b40","898ef85ffa8a4772b32f2a51b73dea1d","b8a3b59709784216a3d0c5bbe94a27be","ee2cbebb71194bd5aac58827f6c977d1","def41d09ebf046519aaf53fe5db57c05","1d35ad7393ef4b60b0f64ac906085e11","7d7e257f56e34315852bc9f5af95b590","670f0468a910478c831b81c6d6e8ecf9","91366996f97749378ade3a93f4e1739d","091ddcc555fb458e96701fd3e91aba65","209ebe2647834086976147b51369dbdf","0e873f5ab2c847a4ad534b1471543057","afee1147442546c2818837706c0b57c9","e84c64efbbeb492a93a961e5da97ef69","d6e31be71d4d4ec9b81d569c06cd72d5","f1c0568548f24c60be163795437da9ba","11057ebad6284ad19551a1cef1c74049","1d9800ce646a4f11963b1cee2d2a4478","39a2a290a49e4acba9dc0dc5779af7a1","5bd275ee83934638a490282896519a3d","7fe52000a36048f4b46bdde93774867e","3a7dd727c0e44c269ed3b131c5b5875f","c78d9dbca0cc43c0878f0fa361197750","8b3aebf155f041bc996e97d8e91ccabc","aa8bfb44dbdb474dbaf4e8ad6df4f0d8","597157d92d3f4800bc8001503543c67f","98e074baaf90471e8117ff24cba20e4d","d4ac3f7086504d82923a906f323961a8","3a60ba0d860d4dc89c97fca1c4040292","3d2875f620c84b08ac7a1d66d7d59636","cfe464f7b0d6477c86b9ef4e23888e3f","4c5c3cab437d406095c4602baf0e9d42","87b8945f6084406394d81afc2260685d","d848971821704ae5b9ecb0655b20ec92","2b64327ceb8843fa9a3270f9b99257dd","c78206537b844d2f89ca6ea6d592df2f","568ba7e16ce44ba195a039c6393ebd28","0426804b34ac4d39b5ffcf7e1e5353f4","88ca81e10a564a75be3de20535e53624","00a543cee1ee435d9d35d2a16a941d11","58d5c1b536604f0fb0e69db6bb1df58a","3e867375f09f40ab9477e62a9e94626f"]},"executionInfo":{"status":"ok","timestamp":1714454952191,"user_tz":240,"elapsed":3406,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}},"outputId":"3b7e5ee0-95af-4acc-8095-059c4721302e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/3.14M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a13237c9304d4afba25f83e9c58ee691"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/3.14M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"091ddcc555fb458e96701fd3e91aba65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/30000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fe52000a36048f4b46bdde93774867e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/30000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c5c3cab437d406095c4602baf0e9d42"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'parse_premise', 'parse_hypothesis', 'binary_parse_premise', 'binary_parse_hypothesis', 'heuristic', 'subcase', 'template'],\n","        num_rows: 30000\n","    })\n","    validation: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'parse_premise', 'parse_hypothesis', 'binary_parse_premise', 'binary_parse_hypothesis', 'heuristic', 'subcase', 'template'],\n","        num_rows: 30000\n","    })\n","})"]},"metadata":{},"execution_count":29}],"source":["dataset_ood = load_dataset(\"hans\")\n","dataset_ood"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oAFcefWkwmPs","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["445e00a6fc2142d8af10098d9fa721bd","50c398eb51b241c19d15c530d4dab174","6b09247000f44837a4a15a229879c89d","a84c3ac6851b45fd8a11e77f12ef6c15","9af0bac0d1f848899d4b5a494ceb20fa","de49086f74114cd795e1a5ad3c4fe83f","940ea668d13641c2b46106e6ada431a2","b6dcbe74b4b548e49426f2dd6c964362","d1c66687f10d4df5b1029e33688046fc","3dc3da07dace4435898b471648424f19","18d8f011fa0142598bfac07bd4bbae0e"]},"executionInfo":{"status":"ok","timestamp":1714454952484,"user_tz":240,"elapsed":300,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}},"outputId":"9e9ce602-df34-4dec-af2c-ecc4450a77b1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/30000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"445e00a6fc2142d8af10098d9fa721bd"}},"metadata":{}}],"source":["dataset_ood_val = (dataset_ood['validation']).filter(lambda example: example[\"heuristic\"] == 'lexical_overlap')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jn4ufgMzwmNS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714454952485,"user_tz":240,"elapsed":9,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}},"outputId":"81167773-6490-460f-9eb3-95ff7f0469aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["indices_ood_val:  [6252 4684 1731 ... 9410 1671  474]\n"]},{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'parse_premise', 'parse_hypothesis', 'binary_parse_premise', 'binary_parse_hypothesis', 'heuristic', 'subcase', 'template'],\n","    num_rows: 1024\n","})"]},"metadata":{},"execution_count":31}],"source":["# Perform the filters and splits from the original datasets\n","\n","\n","random_split_seed_ood = 42 # set above, equal to 42\n","\n","examples_per_exp =  examples_per_exp # 16\n","num_experiments = num_experiments # 10\n","num_validations = num_validations # 16*64 #64*16 = 1024 #6692\n","\n","np.random.seed(random_split_seed_ood)\n","indices_ood_val = np.random.choice(range(len(dataset_ood_val)), size=num_validations, replace=False)\n","print(\"indices_ood_val: \", indices_ood_val)\n","\n","dataset_ood_val_sel = dataset_ood_val.select(indices_ood_val)\n","dataset_ood_val_sel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3aAqJWOqwmKR"},"outputs":[],"source":["# format examples functions formats according to different types of formats for ICL both training and validation examples\n","\n","# select format to use here:\n","format_train_val = format_train_val # set it at the top of notebook in a common place\n","\n","\n","def format_examples_validation_VALOOD(example_val, format_val = format_train_val):\n","    if format_val== 'minimal':\n","      # \"minimal\" format\n","      return {'text': \"{\"  + example_val['premise'] + \"} {\" + example_val['hypothesis'] + \"}\" + \" ? Ġ\"}\n","    elif format_val== 'gpt3':\n","      # \"minimal\" format\n","      return {'text': \"{\"  + example_val['premise'] + \"} question: {\" + example_val['hypothesis'] + \"}\" + \" Yes or No? answer: Ġ\"}\n","\n","def create_combined_dataset(val_dataset, num_expts=num_experiments):\n","    combined_dataset = []\n","\n","    for irep in range(num_expts):\n","      for val_ex in val_dataset:\n","\n","        combined_ex = {'text': '', 'label': torch.tensor(val_ex['label'], dtype=torch.long).to(device), 'exp': irep+1}\n","\n","        combined_ex['text'] += val_ex['text']\n","\n","        combined_dataset.append([combined_ex])\n","\n","    return combined_dataset\n","\n","\n","def dynamic_padding_collate_fn_VALOOD(batch):\n","    # This function is created to be able to tokenize dynamically to max length within each batch\n","    # Also, by modifying the tokenizer used, several other options are available\n","    # for example, if we set padding to a specified max_length, for example the model max_length, is also an option, not the default though\n","    # the default is the dynamic padding\n","\n","    batch = [item for sublist in batch for item in sublist]\n","\n","    texts = [item['text'] for item in batch]\n","    labels = [item['label'] for item in batch]\n","    exps = [item['exp'] for item in batch]\n","\n","    # choose option\n","    tokenized_inputs = OPT_tokenizer(texts, padding=\"longest\", truncation=True, return_tensors=\"pt\")\n","\n","    labels_tensor = torch.unsqueeze(torch.tensor(labels, dtype=torch.long).to(device),0)\n","    exps_tensor = torch.unsqueeze(torch.tensor(exps, dtype=torch.long).to(device),0)\n","\n","    return {\n","        'text': texts,\n","        'input_ids': tokenized_inputs['input_ids'],\n","        'attention_mask': tokenized_inputs['attention_mask'],\n","        'label': labels_tensor,\n","        'exp': exps_tensor,\n","    }\n","\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, combined_dataset):\n","        self.dataset = combined_dataset\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        return self.dataset[idx]\n"]},{"cell_type":"code","source":["# First the samples are formatted according to selection above\n","# Important to check selection and re-run cell above so that it is taken by the mapping function correctly\n","\n","formatted_val_dataset_ood = dataset_ood_val_sel.map(format_examples_validation_VALOOD)\n","\n","# Initialize custom dataset with the combined dataset\n","# print result to check correctness\n","\n","combined_dataset_VALOOD = create_combined_dataset(\n","                                          val_dataset = formatted_val_dataset_ood,\n","                                          num_expts=num_experiments\n","                                           )\n","\n","custom_dataset_VALOOD = CustomDataset(combined_dataset_VALOOD)\n","print(custom_dataset_VALOOD)\n","\n","custom_dataset_VALOOD_EXP = CustomDataset([item for item in custom_dataset_VALOOD if item[0]['exp'] == SEL_EXP_TRAIN_CD])\n","\n","# Last step, we create Dataloader passing the bx_size for inference (typically: 1, 4, 8, 16)\n","bx_size = bx_size # set it up at the beg of NB\n","dataloader_VALOOD = DataLoader(custom_dataset_VALOOD_EXP, batch_size=bx_size, collate_fn=dynamic_padding_collate_fn_VALOOD, shuffle=False) #shuffle=False for reproducibility"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["47ffef0a31b14486b84927d41eb289c4","612e96a197644280a09c306e15b2cacd","155276c85f35411180f37600e98cb43f","2a0c2466ec5b480481307cf713d5e828","7853ff85f1b44205ae86eea24b94c4e6","f04d6de2a28d4a08896e02bbf03854a7","683ac1a586474ba4aefa1edfc0fc7b59","e134b1b6f60b4bfab3b545ecc611be6d","12e924a6eb2047d288185ac90d16cf39","0e8e073f4e9a486abe81c5685ce75ac2","2c858acd3352489f9125ca575f4b25c1"]},"id":"2u9wEYxr2OLD","executionInfo":{"status":"ok","timestamp":1714454953952,"user_tz":240,"elapsed":1472,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}},"outputId":"9c9d5635-c535-4973-eac9-160b8a9fe936"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1024 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47ffef0a31b14486b84927d41eb289c4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<__main__.CustomDataset object at 0x7f57077b84f0>\n"]}]},{"cell_type":"code","source":["# Validation\n","model.eval()\n","val_loss = 0.0\n","val_accuracy = 0.0\n","with torch.no_grad():\n","    for batch in dataloader_VALOOD:\n","        # print(batch)\n","\n","        src = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"label\"].to(device).squeeze(0)\n","\n","        # Forward pass\n","        outputs = model(input_ids, None, labels)\n","\n","        # Compute loss\n","        # if 'logits' in outputs:\n","        loss = criterion(outputs, labels)\n","        val_loss += loss.item()\n","        # break\n","\n","        # Compute accuracy\n","        val_accuracy += 1*(torch.argmax(outputs, dim=1).item()==batch[\"label\"].to(device).squeeze(0).item())\n","    val_loss = val_loss/num_validations\n","    val_accuracy = val_accuracy/num_validations\n","    print(f\"Validation Loss: {val_loss:.6f}, Validation Accuracy: {val_accuracy:.9f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wBWNm-Cbx72J","executionInfo":{"status":"ok","timestamp":1714461544985,"user_tz":240,"elapsed":138,"user":{"displayName":"Nitesh Agarwal","userId":"18032940909522888771"}},"outputId":"3dd1760f-90bd-44a0-f649-e454f9bfff80"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Loss: 1.555123, Validation Accuracy: 0.505859375\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"yu95zGyZrS9E"},"execution_count":null,"outputs":[]}]}