{"cells":[{"cell_type":"markdown","metadata":{"id":"Tw8CFJ12Pp6T"},"source":["# 1. IMPORT LIBRARIES"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ayaqVMRAXaT","outputId":"35917c05-fc30-44dc-d95a-827526a0e974","executionInfo":{"status":"ok","timestamp":1714523619524,"user_tz":-120,"elapsed":14788,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","  torch.utils._pytree._register_pytree_node(\n","/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","  torch.utils._pytree._register_pytree_node(\n"]}],"source":["\n","!pip install -q datasets\n","!pip install -q transformers==4.33.1\n","\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import gc\n","from torch.cuda.amp import autocast, GradScaler\n","\n","\n","from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, OPTForCausalLM, GPT2Tokenizer"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"mY6pDshTHDtg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523624706,"user_tz":-120,"elapsed":5186,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"f346b2ed-6ace-4cef-e7a2-e126c432bd87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.12\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Tue_Aug_15_22:02:13_PDT_2023\n","Cuda compilation tools, release 12.2, V12.2.140\n","Build cuda_12.2.r12.2/compiler.33191640_0\n","Requirement already satisfied: nvcc4jupyter in /usr/local/lib/python3.10/dist-packages (1.2.1)\n","Detected platform \"Colab\". Running its setup...\n","Source files will be saved in \"/tmp/tmp0yqjag8j\".\n"]}],"source":["\n","!python --version\n","!nvcc --version\n","!pip install nvcc4jupyter\n","%load_ext nvcc4jupyter\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"hOBeMp00RKSi","executionInfo":{"status":"ok","timestamp":1714523624706,"user_tz":-120,"elapsed":10,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import random"]},{"cell_type":"markdown","metadata":{"id":"gBZINjFskJOT"},"source":["## 2. SET MAIN INPUTS FOR NOTEBOOK"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"tvPGy9EnkIKK","executionInfo":{"status":"ok","timestamp":1714523624706,"user_tz":-120,"elapsed":10,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["bx_size = 1                                 # batch size for inference with the OPT\n","format_train_val = 'gpt3'                   # 'minimal' or 'gpt3\n","task_name = 'mnli'                          # 'mnli'\n","model_name = \"facebook/opt-1.3b\"            # model options below\n","examples_per_exp =  16                       # 16\n","num_experiments = 10                         # 10\n","num_validations = 1024   # not used yet in this NB (when later on doing validation needs to be specified at 1024)\n","num_reasoning_context_per_example = 16\n","\n","# for context distillation\n","number_max_probs_match = 50\n","SEL_EXP_TRAIN_CD = 5\n","\n","\n","# model_name = \"facebook/opt-125m\"\n","# model_name = \"facebook/opt-350m\"\n","# model_name = \"facebook/opt-1.3b\"\n","# model_name = \"facebook/opt-2.7b\"\n","# model_name = \"facebook/opt-6.7b\""]},{"cell_type":"markdown","metadata":{"id":"ZBgRakKbCXl3"},"source":["## 2. SET DEVICE"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"aKf7vOw2MTPk","executionInfo":{"status":"ok","timestamp":1714523624706,"user_tz":-120,"elapsed":9,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""]},{"cell_type":"code","execution_count":6,"metadata":{"id":"18useFCOLdX2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523624706,"user_tz":-120,"elapsed":9,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"10154373-3280-4bae-a540-5f000e41f3e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA Available: True\n","GPU Name(s): NVIDIA L4\n"]}],"source":["import torch\n","\n","# Check if CUDA (GPU support) is available\n","cuda_available = torch.cuda.is_available()\n","print(f\"CUDA Available: {cuda_available}\")\n","\n","# If CUDA is available, print the GPU name(s)\n","if cuda_available:\n","    print(f\"GPU Name(s): {torch.cuda.get_device_name(0)}\")"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"QXFJO33ECUVB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523624706,"user_tz":-120,"elapsed":7,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"940d8ad6-000d-45a7-a3ce-5da0958bb4eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Select GPU device\n","cuda\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}],"source":["device = torch.device(\"cuda\")\n","\n","device_count = torch.cuda.device_count()\n","if device_count > 0:\n","    print(\"Select GPU device\")\n","    device = torch.device(\"cuda\")\n","else:\n","    print(\"Select GPU device\")\n","    device = torch.device(\"cpu\")\n","\n","print(device)\n","torch.cuda.is_available()"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"JFPP4q0dABLX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523624707,"user_tz":-120,"elapsed":7,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"2adad31e-b6ab-4675-cfe7-7aba1df5da5d"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["device = torch.device(\"cuda\")\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"DjaLyC3l7hVV"},"source":["## 3. IMPORT TOKENIZER AND SELECT MODEL"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"2Kt5rM4s7g0T","executionInfo":{"status":"ok","timestamp":1714523624707,"user_tz":-120,"elapsed":6,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["# Choose model to work with:\n","\n","# model_name = \"facebook/opt-125m\"\n","# model_name = \"facebook/opt-350m\"\n","# model_name = \"facebook/opt-1.3b\"\n","# model_name = \"facebook/opt-2.7b\"\n","# model_name = \"facebook/opt-6.7b\"\n","\n","model_name = model_name # it is set up in top of NB"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"g49c1NTt_rcO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523626044,"user_tz":-120,"elapsed":1343,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"f4521014-704b-4aad-d842-6e12575293cc"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}],"source":["OPT_tokenizer = GPT2Tokenizer.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"TCFZjYH4oP_O","executionInfo":{"status":"ok","timestamp":1714523626044,"user_tz":-120,"elapsed":3,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["# Create class as myBaseOPT_ICL to work with in-context learning set up\n","\n","class myBaseOPT_CD(nn.Module):\n","\n","  def __init__(self, load_model_name = \"facebook/opt-350m\",model_max_tokens=2048, device = 'cuda'):\n","    super(myBaseOPT_CD, self).__init__()\n","\n","    self.model_max_tokens = model_max_tokens\n","    self.device = device\n","\n","    self.coreOPT = OPTForCausalLM.from_pretrained(\n","    load_model_name,\n","    load_in_8bit=False,\n","    torch_dtype=torch.float16,\n","    ).model\n","\n","    self.lm_OPT_head = OPTForCausalLM.from_pretrained(\n","    load_model_name,\n","    load_in_8bit=False,\n","    torch_dtype=torch.float16,\n","    ).lm_head\n","\n","  def forward(self, src, attention_mask):\n","\n","    #src.to(device)\n","    #attention_mask.to(device)\n","\n","    core_outputs = self.coreOPT.forward(\n","        src,\n","        attention_mask=attention_mask\n","    )['last_hidden_state']\n","\n","    final_outputs = self.lm_OPT_head.forward(core_outputs)\n","\n","    return final_outputs\n","\n","  def forward_generate(self, src, attention_mask):\n","    # forward used in generate_text function,\n","    # separated from forward function to avoid sending again to device to avoid any issues\n","\n","    core_outputs = self.coreOPT.forward(\n","        src,\n","        attention_mask=attention_mask\n","    )['last_hidden_state']\n","\n","\n","    final_outputs = self.lm_OPT_head.forward(core_outputs)\n","\n","    return final_outputs\n","\n","\n","  def generate_text(self, src_inputs, src_attn, gen_tokens=torch.tensor(1)):\n","\n","\n","    src_len = src_inputs.shape[1]\n","\n","    gen_tokens = gen_tokens.item()\n","\n","\n","    outputs = torch.zeros((src_inputs.shape[0], src_inputs.shape[1] + gen_tokens), dtype=torch.long).to(self.device)\n","    att_mask = torch.zeros((src_attn.shape[0], src_attn.shape[1] + gen_tokens), dtype=torch.long).to(self.device)\n","\n","    outputs[:,0:src_inputs.shape[1]] = src_inputs\n","    att_mask[:,0:src_attn.shape[1]] = src_attn\n","\n","    for t_step in range(gen_tokens):\n","\n","      all_scores = self.forward_generate(outputs[:,0:src_inputs.shape[1]+t_step], att_mask[:,0:src_attn.shape[1]+t_step])\n","\n","      new_tokens = torch.argmax(all_scores[:,-1,:], dim=1)\n","\n","      outputs[:,src_inputs.shape[1]+t_step] = new_tokens\n","      att_mask[:,src_attn.shape[1]+t_step] = 1\n","\n","    # Yes token = 9904\n","    # No token = 3084\n","    binary_yes_no = torch.zeros(all_scores.shape[0]).half().to(self.device)\n","    binary_yes_no[:] = all_scores[:,-1,9904] - all_scores[:,-1,3084]\n","\n","    binary_yes_no[binary_yes_no >= 0] = 0 # or 9904 if token used \"Yes\"\n","    binary_yes_no[binary_yes_no < 0] = 1 # or 3084 if token used \"No\"\n","\n","    last_scores = all_scores[:,-1,:]\n","\n","    return outputs, binary_yes_no, last_scores\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Wuc_Rrsztehg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523667347,"user_tz":-120,"elapsed":41305,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"4b086037-a484-437b-8c88-5d5e5efa3af5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["myBaseOPT_CD(\n","  (coreOPT): OPTModel(\n","    (decoder): OPTDecoder(\n","      (embed_tokens): Embedding(50272, 2048, padding_idx=1)\n","      (embed_positions): OPTLearnedPositionalEmbedding(2050, 2048)\n","      (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n","      (layers): ModuleList(\n","        (0-23): 24 x OPTDecoderLayer(\n","          (self_attn): OPTAttention(\n","            (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n","            (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n","            (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n","            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n","          )\n","          (activation_fn): ReLU()\n","          (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n","          (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n","          (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (lm_OPT_head): Linear(in_features=2048, out_features=50272, bias=False)\n",")"]},"metadata":{},"execution_count":12}],"source":["# Instantiate model and send to selected device\n","example_myBaseOPT_CD = myBaseOPT_CD(load_model_name = model_name, device = device)\n","#example_myBaseOPT_CD.half()\n","example_myBaseOPT_CD.to(device)\n","\n","for param in example_myBaseOPT_CD.parameters():\n","  if param.ndim <=2:\n","    param.data = param.data.to(torch.float32)\n","\n","example_myBaseOPT_CD"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"izZnlRubR5Uu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523667347,"user_tz":-120,"elapsed":12,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"fbe9c389-e1d0-4cdd-a504-a7fe0eb7cbd4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model Parameters:  1418715136\n"]}],"source":["# Check total number of model parameters\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(\"Model Parameters: \", count_parameters(example_myBaseOPT_CD))"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"5j4mJgVYSxH8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523673238,"user_tz":-120,"elapsed":5902,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"94d1e383-a809-480e-ab53-f7042198b8ca"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['</s>A chat between a curious human and the Statue of Liberty.\\n\\nHuman: What is your name?\\nStatue: I am the Statue of Liberty.\\nHuman: Where do you live?\\nStatue: New York City.\\nHuman: How long have you lived there?\\nStatue: I have lived here for over 100 years.\\nHuman: What do you do?\\nStatue: I am a tourist attraction.\\nHuman: What do you do when you are not a tourist attraction?\\nStatue: I am a tourist attraction.\\nHuman: What do you do when you are not a tourist attraction?\\nStatue: I am a tourist attraction.\\nHuman: What do you do when you are not a tourist attraction?\\nStatue:']"]},"metadata":{},"execution_count":14}],"source":["# Check base model output correctness (from OPT HF example)\n","prompt_example = (\"A chat between a curious human and the Statue of Liberty.\\n\\nHuman: What is your name?\\nStatue: I am the \"\n","              \"Statue of Liberty.\\nHuman: Where do you live?\\nStatue: New York City.\\nHuman: How long have you lived \"\n","              \"there?\")\n","prompt_example_tokenized = OPT_tokenizer(prompt_example )\n","example_myBaseOPT_CD.eval()\n","outputs_ex_sp, binary_ex_sp, scores_ex_sp = example_myBaseOPT_CD.generate_text(src_inputs = torch.unsqueeze(torch.tensor(prompt_example_tokenized['input_ids']),0).to(device),\n","                                    src_attn = torch.unsqueeze(torch.tensor(prompt_example_tokenized['attention_mask']),0).to(device),\n","                                    gen_tokens=torch.tensor(100).to(device))\n","OPT_tokenizer.batch_decode(outputs_ex_sp)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kMS1b9WqPZWC"},"source":["## 4. IMPORT NLI DATASET FOR TRAINING AND VALIDATION: MNLI"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"kGFeGMISPx7D","executionInfo":{"status":"ok","timestamp":1714523673238,"user_tz":-120,"elapsed":12,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["# reference: https://github.com/uds-lsv/llmft/blob/main/notebooks/majority_baseline.ipynb\n","# this reference is useful for cleaning the neutral sentences of the dataset, just keeping the 0 and 1."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"9bQUsgPp7g9m","executionInfo":{"status":"ok","timestamp":1714523673238,"user_tz":-120,"elapsed":12,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["from collections import Counter\n","from datasets import load_dataset, ClassLabel"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"l1N1cM5z7m16","executionInfo":{"status":"ok","timestamp":1714523673238,"user_tz":-120,"elapsed":11,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["# this comes from original paper, to remove neutral examples from MNLI\n","def binarize_mnli(dataset, remove_neutral=True):\n","    if remove_neutral:\n","        # neutral class has label 1\n","        dataset = dataset.filter(lambda example: example[\"label\"] != 1)\n","\n","    # change labels of contradiction examples from 2 to 1\n","    def change_label(example):\n","        # convert labels 2 into labels 1. this merges the neutral and contradiction class\n","        example[\"label\"] = 1 if example[\"label\"] == 2 else example[\"label\"]\n","        return example\n","\n","    # change labels\n","    dataset = dataset.map(change_label)\n","\n","    # change features to reflect the new labels\n","    features = dataset[\"train\"].features.copy()\n","    features[\"label\"] = ClassLabel(num_classes=2, names=['entailment', 'contradiction'], id=None)\n","    dataset = dataset.cast(features)  # overwrite old features\n","\n","    return dataset\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"TpPOr_LH7msU","executionInfo":{"status":"ok","timestamp":1714523673239,"user_tz":-120,"elapsed":12,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["# Select GLUE task (set it at the top of NB for simplicity with all other inputs)\n","\n","# task_name = \"rte\"\n","# task_name = \"mnli\"\n","# task_name = \"qqp\"\n","# task_name = \"cola\"\n","\n","task_name = task_name"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"T10hQZj079Le","executionInfo":{"status":"ok","timestamp":1714523676516,"user_tz":-120,"elapsed":3289,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["dataset = load_dataset(\"glue\", task_name)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"QI3oAEj279Hl","executionInfo":{"status":"ok","timestamp":1714523676517,"user_tz":-120,"elapsed":13,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["# binarize dataset\n","if task_name == \"mnli\":\n","    dataset = binarize_mnli(dataset, remove_neutral=True) # mnli\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"qIFzmEFR8GQ1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523676517,"user_tz":-120,"elapsed":12,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"3b17f410-6157-46a4-f92f-8c97bdf3cdc7"},"outputs":[{"output_type":"stream","name":"stdout","text":["task_name: mnli\n","Total number of samples: 261802\n","train\n","fraction of labels per class: 0=0.49999236063895613\n","fraction of labels per class: 1=0.5000076393610439\n","Total number of samples: 6692\n","validation_matched\n","fraction of labels per class: 1=0.4801255230125523\n","fraction of labels per class: 0=0.5198744769874477\n","DatasetDict({\n","    train: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 261802\n","    })\n","    validation_matched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 6692\n","    })\n","    validation_mismatched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 6703\n","    })\n","    test_matched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 9796\n","    })\n","    test_mismatched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 9847\n","    })\n","})\n"]}],"source":["# analyze and visualize dataset imported\n","\n","print(\"task_name:\", task_name)\n","# for split in [\"train\", \"validation\"]:\n","for split in [\"train\", \"validation_matched\"]:\n","    c = Counter(dataset[split][\"label\"])\n","    total = len(list(c.elements()))\n","    print(\"Total number of samples:\", total)\n","    print(split)\n","    for k in c:\n","        print(f\"fraction of labels per class: {k}={c[k] / total}\")\n","print(dataset)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"7v9CdYUvSxGf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523676861,"user_tz":-120,"elapsed":356,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"af8ff08e-b8e8-4c0d-fe36-c6b650bb3363"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 261802\n","})\n","Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 130899\n","})\n","Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 130903\n","})\n","indices_yes:  [108195  86013  39482  39689  10288  11589  94511  78690  36953  74067\n","  93678  83921  83896  21665  76736    651  48482  40811 127490  49367\n"," 121664  39918  60933 126502  65765  12966  33438   7201  19815  49187\n","  29116  48565 125127  60274  33985 130032 104535 120345 104033  44914\n","  89806  87143 103906  15697  29521   4906  46884  75442  57625  32365\n","  70562  78463  18684  45639  30223 118624  40945  75797  63681  77117\n","  16126 130579   2132 113346  68080   7433 120366 122242  75493  64389\n","  95467  86480  52323  42308 101738  51386 126981  27346  45655 121440]\n","indices_no:  [ 54039  34647  34994 102702  14063 110662  33077  24477  24337  19083\n","  61263 109299 107760  88071  22063  90740 113958   9163  45235  32885\n","  58399  59560 102582  10964  38283  16146  72067  55788  60576  21220\n","  41478 123489  38278  15117  71374  69791  39777 122448  10098  35761\n","  74547 109598  19072  61567  56626 102957  18014  14118  46250 117891\n","  87958 113798 107148 121622  88599   8239 119796  69862   2704 112545\n"," 121565 111890  19129 115169  29330  47129  79077  34942  28934  12323\n","  85926 103422  91532  32522   4654 108738  24476  86650 117487  61013]\n","indices_val:  [1771 4591 1869 ... 1111  809 1914]\n"]}],"source":["# Perform the filters and splits from the original datasets\n","\n","\n","random_split_seed = 42\n","\n","examples_per_exp =  examples_per_exp # 16\n","num_experiments = num_experiments # 10\n","num_validations = num_validations # 16*64 #64*16 = 1024 #6692\n","\n","max_train_samples = examples_per_exp*num_experiments\n","train_dataset = dataset['train']\n","print(train_dataset)\n","\n","train_dataset_yes_all = dataset['train'].filter(lambda example: example[\"label\"] == 0)\n","train_dataset_no_all = dataset['train'].filter(lambda example: example[\"label\"] == 1)\n","print(train_dataset_yes_all)\n","print(train_dataset_no_all)\n","\n","val_dataset_all = dataset['validation_matched']\n","\n","# randomly select a subset of the training data\n","max_train_samples = min(len(train_dataset), max_train_samples)\n","\n","np.random.seed(random_split_seed)\n","indices_yes = np.random.choice(range(len(train_dataset_yes_all)), size=int(max_train_samples/2), replace=False)\n","print(\"indices_yes: \", indices_yes)\n","\n","np.random.seed(random_split_seed+1)\n","indices_no = np.random.choice(range(len(train_dataset_no_all)), size=int(max_train_samples/2), replace=False)\n","print(\"indices_no: \", indices_no)\n","\n","np.random.seed(random_split_seed+2)\n","indices_val = np.random.choice(range(len(val_dataset_all)), size=num_validations, replace=False)\n","print(\"indices_val: \", indices_val)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"W5nx1ugOr5kd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523676861,"user_tz":-120,"elapsed":4,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"c2db5f8d-bb9e-4e08-c5fa-88ee9d9dbac2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Dataset Yes:  Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 80\n","})\n","Train Dataset No:  Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 80\n","})\n","Validation Dataset (in-domain):  Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 1024\n","})\n"]}],"source":["train_dataset_yes = train_dataset_yes_all.select(indices_yes)\n","train_dataset_no = train_dataset_no_all.select(indices_no)\n","\n","val_dataset = val_dataset_all.select(indices_val)\n","print(\"Train Dataset Yes: \", train_dataset_yes)\n","print(\"Train Dataset No: \", train_dataset_no)\n","print(\"Validation Dataset (in-domain): \", val_dataset)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"1SJ7JNABsxhz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523741641,"user_tz":-120,"elapsed":1494,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"ad91ddbf-bb40-427c-dad7-de8342f7e75e"},"outputs":[{"output_type":"stream","name":"stdout","text":["train_dataset_remaining: 261642\n","Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 261642\n","})\n","train_dataset_remaining_yes_all: 130819\n","Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 130819\n","})\n","train_dataset_remaining_no_all: 130823\n","Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 130823\n","})\n"]}],"source":["\n","# Combine indices of selected subsets\n","\n","used_indices_yes_no = train_dataset_yes['idx'] + train_dataset_no['idx']\n","\n","train_ind_remaining = [i for i, element in enumerate(train_dataset['idx']) if element not in used_indices_yes_no]\n","\n","#train_dataset_remaining = train_dataset.filter(lambda example, idx: idx not in train_ind_remaining, with_indices=True)\n","train_dataset_remaining = train_dataset.select(train_ind_remaining)\n","\n","print(\"train_dataset_remaining:\", len(train_dataset_remaining))\n","print(train_dataset_remaining)\n","\n","train_dataset_remaining_yes_all = train_dataset_remaining.filter(lambda example: example[\"label\"] == 0)\n","train_dataset_remaining_no_all = train_dataset_remaining.filter(lambda example: example[\"label\"] == 1)\n","\n","print(\"train_dataset_remaining_yes_all:\", len(train_dataset_remaining_yes_all))\n","print(train_dataset_remaining_yes_all)\n","#print(train_dataset_remaining_yes_all['idx'])\n","\n","print(\"train_dataset_remaining_no_all:\", len(train_dataset_remaining_no_all))\n","print(train_dataset_remaining_no_all)\n","#print(train_dataset_remaining_no_all['idx'])\n","\n"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"PL9Ra6rK-CON","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523741641,"user_tz":-120,"elapsed":7,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"4e5e3a92-97d4-4acb-d4d7-a51c97b7592e"},"outputs":[{"output_type":"stream","name":"stdout","text":["total_to_select_CD_YES:  1280\n","total_to_select_CD_NO:  1280\n"]}],"source":["num_reasoning_context_per_example = num_reasoning_context_per_example\n","total_to_select_CD_YES = int(num_experiments*examples_per_exp*num_reasoning_context_per_example/2)\n","total_to_select_CD_NO = int(num_experiments*examples_per_exp*num_reasoning_context_per_example/2)\n","print(\"total_to_select_CD_YES: \", total_to_select_CD_YES)\n","print(\"total_to_select_CD_NO: \", total_to_select_CD_NO)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"kvuU4sgf_a-y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523741642,"user_tz":-120,"elapsed":8,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"77b79dec-70dd-48f6-c25c-2aabf6b8c1fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["total_to_select_CD_YES:  1280\n","total_to_select_CD_NO:  1280\n","indices_yes:  [108195  86013  39482  39689  10288  11589  94511  78690  36953  74067\n","  93678  83921  83896  21665  76736    651  48482  40811 127490  49367\n"," 121664  39918  60933 126502  65765  12966  33438   7201  19815  49187\n","  29116  48565 125127  60274  33985 130032 104535 120345 104033  44914\n","  89806  87143 103906  15697  29521   4906  46884  75442  57625  32365\n","  70562  78463  18684  45639  30223 118624  40945  75797  63681  77117\n","  16126 130579   2132 113346  68080   7433 120366 122242  75493  64389\n","  95467  86480  52323  42308 101738  51386 126981  27346  45655 121440]\n","indices_no:  [ 54039  34647  34994 102702  14063 110662  33077  24477  24337  19083\n","  61263 109299 107760  88071  22063  90740 113958   9163  45235  32885\n","  58399  59560 102582  10964  38283  16146  72067  55788  60576  21220\n","  41478 123489  38278  15117  71374  69791  39777 122448  10098  35761\n","  74547 109598  19072  61567  56626 102957  18014  14118  46250 117891\n","  87958 113798 107148 121622  88599   8239 119796  69862   2704 112545\n"," 121565 111890  19129 115169  29330  47129  79077  34942  28934  12323\n","  85926 103422  91532  32522   4654 108738  24476  86650 117487  61013]\n","Train Dataset CD Yes:  Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 1280\n","})\n","Train Dataset CD No:  Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 1280\n","})\n"]}],"source":["random_split_seed_CD = 100\n","\n","num_reasoning_context_per_example = num_reasoning_context_per_example\n","total_to_select_CD_YES = int(num_experiments*examples_per_exp*num_reasoning_context_per_example/2)\n","total_to_select_CD_NO = int(num_experiments*examples_per_exp*num_reasoning_context_per_example/2)\n","print(\"total_to_select_CD_YES: \", total_to_select_CD_YES)\n","print(\"total_to_select_CD_NO: \", total_to_select_CD_NO)\n","\n","np.random.seed(random_split_seed_CD)\n","indices_rem_yes = np.random.choice(range(len(train_dataset_remaining_yes_all)), size=total_to_select_CD_YES, replace=False)\n","print(\"indices_yes: \", indices_yes)\n","\n","np.random.seed(random_split_seed_CD+1)\n","indices_rem_no = np.random.choice(range(len(train_dataset_remaining_no_all)), size=total_to_select_CD_NO, replace=False)\n","print(\"indices_no: \", indices_no)\n","\n","train_dataset_CD_yes = train_dataset_remaining_yes_all.select(indices_rem_yes)\n","train_dataset_CD_no = train_dataset_remaining_no_all.select(indices_rem_no)\n","\n","print(\"Train Dataset CD Yes: \", train_dataset_CD_yes)\n","print(\"Train Dataset CD No: \", train_dataset_CD_no)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"15sgsMLaVGwC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523741642,"user_tz":-120,"elapsed":6,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"4816a3f4-ad41-4430-b58e-1cc3a60e8339"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 536\n","})\n","Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'idx'],\n","    num_rows: 488\n","})\n","Majority Class Accuracy:  52.34375\n"]}],"source":["# Calculate the number of 0 and 1 in validation dataset\n","# and calculate the majority class accuracy\n","\n","val_dataset_yes = val_dataset.filter(lambda example: example[\"label\"] == 0)\n","val_dataset_no = val_dataset.filter(lambda example: example[\"label\"] == 1)\n","print(val_dataset_yes)\n","print(val_dataset_no)\n","print(\"Majority Class Accuracy: \", 100*max(len(val_dataset_yes), len(val_dataset_no))/(len(val_dataset_yes) + len(val_dataset_no)))"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"JlqLEdhW84X1","executionInfo":{"status":"ok","timestamp":1714523741642,"user_tz":-120,"elapsed":4,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["# This is specific for Context Distillation obtaining data\n","# format examples functions formats according to different types of formats for CD (based on ICL format options)\n","\n","# select format to use here:\n","format_train_val = format_train_val # set it at the top of notebook in a common place\n","\n","\n","def format_examples_CD_train(example_train, format_train=format_train_val):\n","    # format examples of train data for ICL\n","    # select format\n","\n","    if format_train == 'minimal':\n","      # \"minimal\" format\n","      if example_train['label'] == 0:\n","        return {'text': \"{\"  + example_train['premise'] + \"} {\" + example_train['hypothesis'] + \"}\" + \" ? ĠYes \\n\\n\"}\n","      elif example_train['label'] == 1:\n","        return {'text': \"{\"  + example_train['premise'] + \"} {\" + example_train['hypothesis'] + \"}\" + \" ? ĠNo \\n\\n\"}\n","    elif format_train == 'gpt3':\n","      # \"gpt-3\" format\n","      if example_train['label'] == 0:\n","        return {'text': \"{\"  + example_train['premise'] + \"} question: {\" + example_train['hypothesis'] + \"}\" + \" Yes or No? answer: ĠYes \\n\\n\"}\n","      elif example_train['label'] == 1:\n","        return {'text': \"{\"  + example_train['premise'] + \"} question: {\" + example_train['hypothesis'] + \"}\" + \" Yes or No? answer: ĠNo \\n\\n\"}\n","\n","def format_examples_train(example_val, format_val = format_train_val):\n","    if format_val== 'minimal':\n","      # \"minimal\" format\n","      return {'text': \"{\"  + example_val['premise'] + \"} {\" + example_val['hypothesis'] + \"}\" + \" ? Ġ\"}\n","    elif format_val== 'gpt3':\n","      # \"minimal\" format\n","      return {'text': \"{\"  + example_val['premise'] + \"} question: {\" + example_val['hypothesis'] + \"}\" + \" Yes or No? answer: Ġ\"}\n","\n","def create_combined_dataset(train_ds_yes, train_ds_no, context_ds_yes, context_ds_no, num_expts=num_experiments, num_train_examples=examples_per_exp, num_contxt_dist_examples = num_reasoning_context_per_example):\n","    combined_dataset = []\n","    train_examples_yes = [example for example in train_ds_yes]\n","    train_examples_no = [example for example in train_ds_no]\n","    context_examples_yes = [example for example in context_ds_yes]\n","    context_examples_no = [example for example in context_ds_no]\n","\n","    for irep in range(num_expts):\n","          sampled_train_exs_yes = train_examples_yes[int(irep*num_train_examples/2) : int((irep +1)*num_train_examples/2)]\n","          sampled_train_exs_no = train_examples_no[int(irep*num_train_examples/2) : int((irep +1)*num_train_examples/2)]\n","          # for random option if used below\n","          merged_sampled_train_exs = sampled_train_exs_yes + sampled_train_exs_no\n","          shuffled_list = merged_sampled_train_exs.copy()\n","          # Shuffle the copy\n","          random.seed(irep)\n","          random.shuffle(shuffled_list)\n","\n","\n","          # Way 1: set examples Yes, No, Yes, No, ...\n","          '''\n","          for idx_train in range(len(sampled_train_exs_yes)):\n","            # put order one Yes and another No consecutively\n","            combined_ex['text'] += sampled_train_exs_yes[idx_train]['text']\n","            combined_ex['text'] += sampled_train_exs_no[idx_train]['text']\n","          '''\n","\n","          # Way 2: set randomized\n","          for idx_shuffled_list in range(len(shuffled_list)):\n","\n","            sampled_context_exs_yes = context_examples_yes[int(irep*num_train_examples*num_contxt_dist_examples/2 + idx_shuffled_list*num_contxt_dist_examples/2) : int(irep*num_train_examples*num_contxt_dist_examples/2 + (idx_shuffled_list+1)*num_contxt_dist_examples/2)]\n","            sampled_context_exs_no = context_examples_no[int(irep*num_train_examples*num_contxt_dist_examples/2 + idx_shuffled_list*num_contxt_dist_examples/2) : int(irep*num_train_examples*num_contxt_dist_examples/2 + (idx_shuffled_list+1)*num_contxt_dist_examples/2)]\n","\n","\n","            # random option\n","            merged_sampled_context_exs = sampled_context_exs_yes + sampled_context_exs_no\n","            context_shuffled_list = merged_sampled_context_exs.copy()\n","            # Shuffle the copy\n","            random.seed(idx_shuffled_list)\n","            random.shuffle(context_shuffled_list)\n","\n","            combined_ex = {'text': '', 'label': shuffled_list[idx_shuffled_list]['label'], 'exp': irep+1, 'OPT_prob_CD': torch.zeros(0).half().to(device), 'OPT_idx_CD': torch.zeros(0).half().to(device)}\n","\n","            for example_context_shuffled_list in context_shuffled_list:\n","\n","                combined_ex['text'] += example_context_shuffled_list['text']\n","\n","            # MOVED INTO FOR LOOP: Add the example to predict (validation)\n","            combined_ex['text'] += shuffled_list[idx_shuffled_list]['text']\n","\n","            # MOVED INTO FOR LOOP: Append the new combined example to the combined dataset\n","            combined_dataset.append([combined_ex])\n","\n","    return combined_dataset\n","\n","\n","def dynamic_padding_collate_fn(batch):\n","    # This function is created to be able to tokenize dynamically to max length within each batch\n","    # Also, by modifying the tokenizer used, several other options are available\n","    # for example, if we set padding to a specified max_length, for example the model max_length, is also an option, not the default though\n","    # the default is the dynamic padding\n","\n","    batch = [item for sublist in batch for item in sublist]\n","\n","    texts = [item['text'] for item in batch]\n","    labels = [item['label'] for item in batch]\n","    exps = [item['exp'] for item in batch]\n","    OPT_probs_cd = [item['OPT_prob_CD'] for item in batch]\n","    OPT_idxs_cd = [item['OPT_idx_CD'] for item in batch]\n","\n","\n","    # choose option\n","    tokenized_inputs = OPT_tokenizer(texts, padding=\"longest\", truncation=True, return_tensors=\"pt\")\n","    # tokenized_inputs = OPT_tokenizer(texts, padding=\"max_length\", max_length = 2048, truncation=True, return_tensors=\"pt\")\n","\n","    labels_tensor = torch.tensor(labels, dtype=torch.long).to(device)\n","    exps_tensor = torch.tensor(exps, dtype=torch.long).to(device)\n","    OPT_probs_cd_tensor = torch.cat(OPT_probs_cd, dim=0)\n","\n","\n","    OPT_idxs_cd_tensor = torch.cat(OPT_idxs_cd, dim=0)\n","\n","    return {\n","        'input_ids': tokenized_inputs['input_ids'],\n","        'attention_mask': tokenized_inputs['attention_mask'],\n","        'labels': labels_tensor,\n","        'exps': exps_tensor,\n","        'OPT_probs': OPT_probs_cd_tensor,\n","        'OPT_idxs': OPT_idxs_cd_tensor,\n","    }\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, combined_dataset):\n","        self.dataset = combined_dataset\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        return self.dataset[idx]\n"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"Iux0yDPz9l91","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523742003,"user_tz":-120,"elapsed":365,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"e615e3ce-14f6-4500-d5ad-b1c014b61f04"},"outputs":[{"output_type":"stream","name":"stdout","text":["<__main__.CustomDataset object at 0x7a1f708326b0>\n"]}],"source":["# First the samples are formatted according to selection above\n","# Important to check selection and re-run cell above so that it is taken by the mapping function correctly\n","\n","formatted_train_dataset_yes = train_dataset_yes.map(format_examples_train)\n","formatted_train_dataset_no = train_dataset_no.map(format_examples_train)\n","formatted_train_CD_dataset_yes = train_dataset_CD_yes.map(format_examples_CD_train)\n","formatted_train_CD_dataset_no = train_dataset_CD_no.map(format_examples_CD_train)\n","\n","# Initialize custom dataset with the combined dataset\n","# print result to check correctness\n","\n","combined_dataset = create_combined_dataset(\n","                                          train_ds_yes = formatted_train_dataset_yes,\n","                                          train_ds_no = formatted_train_dataset_no,\n","                                          context_ds_yes = formatted_train_CD_dataset_yes,\n","                                          context_ds_no = formatted_train_CD_dataset_no,\n","                                          num_expts=num_experiments,\n","                                          num_train_examples=examples_per_exp,\n","                                          num_contxt_dist_examples = num_reasoning_context_per_example\n","                                           )\n","\n","custom_dataset = CustomDataset(combined_dataset)\n","print(custom_dataset)\n","\n","# Last step, we create Dataloader passing the bx_size for inference (typically: 1, 4, 8, 16)\n","bx_size = bx_size # set it up at the beg of NB\n","dataloader = DataLoader(custom_dataset, batch_size=bx_size, collate_fn=dynamic_padding_collate_fn, shuffle=False) #shuffle=False for reproducibility"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"gLkf358E_4kn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523742004,"user_tz":-120,"elapsed":15,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"f21fd955-3123-43f4-ea96-b0a0c90384e0"},"outputs":[{"output_type":"stream","name":"stderr","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]},{"output_type":"stream","name":"stdout","text":["ORIGINAL:  0 experiment#:  tensor([1], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  [\"</s>{Give yourself plenty of time for a spectacular walk out on the roof.} question: {There is nothing to see on the roof.} Yes or No? answer: ĠNo \\n\\n{what uh how they develop uh what the candidate stands for the you know the views and uh} question: {There is no candidate in the election at all.} Yes or No? answer: ĠNo \\n\\n{yeah i like that} question: {I enjoy that.} Yes or No? answer: ĠYes \\n\\n{The Satheri must be going crazy.} question: {The Satheri have to be going crazy. } Yes or No? answer: ĠYes \\n\\n{repayments is included in the calculation of the subsidy cost of direct loans, and this subsidy cost is recognized as an expense when the loans are disbursed.} question: {Repayments are not included in the calculation of subsidy cost of direct loans. } Yes or No? answer: ĠNo \\n\\n{You knew Pa! Anse shouldered past Drew.} question: {Anse moved past Drew.} Yes or No? answer: ĠYes \\n\\n{Since 1997, LSC has significantly tightened its requirements for what constitutes a case.} question: {Since 1997, LSC has made it harder to have a case.} Yes or No? answer: ĠYes \\n\\n{The net $85 billion cut, they note, is less than 1 percent of the taxes the government expects to collect over the next five years.} question: {More than 30% of taxes will be cut.} Yes or No? answer: ĠNo \\n\\n{Visitors entering the temple are confronted by a dense pall of smoke from all the burning joss sticks and the incense coils hanging from the ceiling (these will burn for as long as a month).} question: {The creators of the smoke can be found sitting on the ground.} Yes or No? answer: ĠNo \\n\\n{yeah and uh i was talking to my older sister the other day and uh she said she had to get a new car and they were thinking of getting something big enough she's got two teenage kids and they go camping a lot} question: { My older sister want to get a car big enough to suit her needs.} Yes or No? answer: ĠYes \\n\\n{Note that when haggling, the merchant assumes you are prepared to pay cash.} question: {The merchants will assume you are paying with credit. } Yes or No? answer: ĠNo \\n\\n{Derry's head snapped up.} question: {Derry looked up.} Yes or No? answer: ĠYes \\n\\n{Lunch isn't ready in any case, Doctor. The Industrialist turned once more to his son.} question: {Lunch isn't prepared yet, Doctor and the Industrialist turned back to his child.} Yes or No? answer: ĠYes \\n\\n{During the night, he'd partially awakened in agony to find Nema chanting and gesturing desperately beside him, and he'd been sure he was on the verge of his second death.} question: {He woke in the middle of the night to find Nema chanting and gesturing beside him.} Yes or No? answer: ĠYes \\n\\n{Another shock, eh? said Julius thoughtfully.} question: {No more shocks, right? said Julius thoughtfully.} Yes or No? answer: ĠNo \\n\\n{yeah it's all politics} question: {There's nothing related to politics.} Yes or No? answer: ĠNo \\n\\n{The chief complaint of reformers these days is that the power of special-interest money is breeding public cynicism about the political process.} question: {Reformers never complain about special interest money.  } Yes or No? answer: Ġ\"]\n","ORIGINAL:  1 experiment#:  tensor([1], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  [\"</s>{This vision became a touchstone for decisions as to program governance, delivery issues, including office staffing, support, training, technology, and increased access to high quality legal advice, brief service and more extensive legal representation.} question: {The vision led to decisions as to program governance, delivery issues, including office staffing, support, training, technology, and increased access to high quality legal advice, brief service and more extensive legal representation.} Yes or No? answer: ĠYes \\n\\n{yeah i never tried that} question: {I've tried that.} Yes or No? answer: ĠNo \\n\\n{The analysis describes, and estimates the number of, small entities to which the rule will apply as required by section 604(a)(3).} question: {The analysis describes small entities to which the rule will apply.} Yes or No? answer: ĠYes \\n\\n{Each performance element will include a fully successful performance standard.} question: {There are two performance standards with each performance element.} Yes or No? answer: ĠNo \\n\\n{To be sure, people who have to switch HMOs may have to change doctors.} question: {Changing HMOs may result in having to switch doctors.} Yes or No? answer: ĠYes \\n\\n{As is true with the other principles, the business requirements of an enterprise drive decisions related to the specific types of resources needed to implement technology successfully.} question: {The business requirements of an enterprise affect technology related decision-making.} Yes or No? answer: ĠYes \\n\\n{The forum led to the creation of the Justice Action Group, staffed by the State Bar Association and chaired by U.S.} question: {The Justice Action Group was formed as the result of the forum.} Yes or No? answer: ĠYes \\n\\n{and then last year that's when they really had that cold spell} question: {Temperatures were higher than usual last year, with no cold spells observed.} Yes or No? answer: ĠNo \\n\\n{The discount rate used for the calculation is the average interest rate (yield) on marketable Treasury securities of similar maturity to the loan, applicable to the time when the loans are disbursed.} question: {The discount rate is the average interest rate on treasury securities.} Yes or No? answer: ĠYes \\n\\n{Funding for this organization is provided by IOLTA, private foundations, attorney fees, and donations.} question: {The organization did not recieve any donations.} Yes or No? answer: ĠNo \\n\\n{yeah yeah it's a it's a beautiful city} question: {The city was filthy and disgusting. } Yes or No? answer: ĠNo \\n\\n{He blames himself for their predicament, including the Fieldstone Mortgage loan he persuaded his wife to sign with her good credit. } question: {He blames himself for the predicament he talked his wife into joining him in.} Yes or No? answer: ĠYes \\n\\n{It is the oldest building in Edinburgh and is still the site of weddings and baptisms.} question: {You can't get married there anymore.} Yes or No? answer: ĠNo \\n\\n{Although oranges grow all around you, freshly squeezed juice is hard to find.} question: {Fresh squeezed orange juice is easy to find. } Yes or No? answer: ĠNo \\n\\n{There are events and concerts, plus a museum bookshop and a cafe in the vaults.} question: {There aren't any events or concerts, this place sucks.} Yes or No? answer: ĠNo \\n\\n{He was no more fanciful than the majority of young Englishmen, but he could not rid himself of the impression that some unusually potent force 58 emanated from the man.} question: {The man was extremely desirable. } Yes or No? answer: ĠYes \\n\\n{The game's up.} question: {The game keeps going.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  2 experiment#:  tensor([1], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  [\"</s>{yeah i don't i i couldn't see it worth getting a nomination for uh best picture} question: {It could get a nomination.} Yes or No? answer: ĠNo \\n\\n{Among the historical sites along the shore of the Dead Sea is Qumran, believed to have housed a community of Essenes, an austere, mystical Jewish sect that existed 2,000 years ago.} question: {The Essenes were a community of relaxed, laid back people.} Yes or No? answer: ĠNo \\n\\n{! Doing a better job of marketing legal services by telling the story of what LSC grantees are contributing to their communities through the partnerships they have created and the wide range of solutions they have put in place.} question: {Through partnerships they have created a wide range of solutions to be put in place.} Yes or No? answer: ĠYes \\n\\n{and it's still that's still a big thing here in this backwards state} question: {That is one of the biggest things in this Utopian state.} Yes or No? answer: ĠNo \\n\\n{uh thirty two years} question: {32 years.  } Yes or No? answer: ĠYes \\n\\n{Oh, I know a joint venture! } question: {We should form a joint venture.} Yes or No? answer: ĠYes \\n\\n{Comments were solicited from the public, other federal agencies and the Office of Management and Budget (OMB).} question: {Only federal agencies were allowed to comment on it.} Yes or No? answer: ĠNo \\n\\n{Village households still wash their laundry in these waters.} question: {People of the village use local streams to wash clothes.} Yes or No? answer: ĠYes \\n\\n{The rugged southern peninsula is hemmed in by low-lying mountains the Vindhya and Satpura to the north and the Western and Eastern Ghats running parallel to the coasts.} question: {The peninsula is flat and surrounded by valleys.} Yes or No? answer: ĠNo \\n\\n{i haven't caught that one yet} question: {I haven't captured that one yet.} Yes or No? answer: ĠYes \\n\\n{At least we won't have to read The Healing Process on the editorial page the following day.} question: {The Healing Process is always printed on the editorial page.} Yes or No? answer: ĠNo \\n\\n{A real sight she looked. } question: {She was very beautiful.} Yes or No? answer: ĠYes \\n\\n{A region-wide community economic development initiative housed at an LSC program provides expertise and other resources to all IOTA recipients a third region.} question: {The LSC program provides expertise and other resources.} Yes or No? answer: ĠYes \\n\\n{But Tioman Island has the best of the peninsula's beaches, particularly if you like secluded coves.} question: {Tioman Island's beaches are too rocky to enjoy.} Yes or No? answer: ĠNo \\n\\n{She went to the World Cup final in L.A. anyway.} question: {She missed her flight and stayed in New York.} Yes or No? answer: ĠNo \\n\\n{What had happened? } question: {Something happened?} Yes or No? answer: ĠYes \\n\\n{Nobody pointed out that at Chappaquiddick, unlike Dallas and Los Angeles, the person most responsible for the tragedy was a Kennedy, whereas the victim was not--and that Ted Kennedy's invocation of the family curse was a clever way of papering over these differences.} question: {Ted Kennedy invoked a family curse that has plagued the Kennedys.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  3 experiment#:  tensor([1], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  [\"</s>{I've always felt it was private.} question: {I have felt that it was not public.} Yes or No? answer: ĠYes \\n\\n{Given events, he's beginning to think you might be a corrupt copy- and even if you're not, you're fast on the road to becoming a nuisance.'} question: {He thinks you're very helpful.} Yes or No? answer: ĠNo \\n\\n{so we i i know that and i've been to Israel and i know and i sort of toured the area and i know that it really is very lots of different cultures in one place i mean and and it's the same thing i it's it's almost the same thing out out in the Soviet Union right now there you know there are} question: {Both Israel and the Soviet Union are lucky because the population is so homogenous and unified.} Yes or No? answer: ĠNo \\n\\n{I needn't tell the next part, because you know it.} question: {I will have to repeat the ending of the story for you, since you have forgotten.} Yes or No? answer: ĠNo \\n\\n{But the regulation of power generators does not end with existing regulations.} question: {Power generators, being needed for modern-day life, are under no regulations. } Yes or No? answer: ĠNo \\n\\n{The art historian Linda Nochlin has traced what she calls Degas' perfectly ordinary anti-Semitism to status anxiety.} question: {Linda Nochlin is an art historian who has researched Degas.} Yes or No? answer: ĠYes \\n\\n{His back greeted them unwelcomingly, and the silence lengthened uncomfortably until Drew did as he always had and met the unpleasant head-on.} question: {They were greeted by his back and an uncomfortable silence.} Yes or No? answer: ĠYes \\n\\n{Up-front knowledge of future requirements for multiple pollutants would lead firms to follow significantly different and less expensive compliance strategies at individual plants, compared with compliance choices which must be made as requirements are addressed in a sequential manner under the current law.} question: {Knowing future requirements that they must comply with at set future dates allows firms to implement less costly strategies for compliance.} Yes or No? answer: ĠYes \\n\\n{Dark and cramped, crawling and chipping at an invisible wall in front hoping the mountain didn't collapse.} question: {They were trying to keep the mountain intact while chipping away.} Yes or No? answer: ĠYes \\n\\n{Several centres provide all equipment, a dive boat, expert local knowledge, and sometimes tuition as well.} question: {The centers have equipment, but not dive boats.} Yes or No? answer: ĠNo \\n\\n{On the Via dell'Abbondanza running east from the Forum, those are ancient, not modern graffiti you find scratched and daubed in red on the walls of the houses and shops.} question: {All the houses are free from graffiti.} Yes or No? answer: ĠNo \\n\\n{Naturally it was very annoying for the Cavendishes. } question: {The Cavendishes found that it was extremely annoying.} Yes or No? answer: ĠYes \\n\\n{so they'd just rather replace something and charge you for the new part rather than just you know fixing the part} question: {They prefer replacing it rather than fixing it.} Yes or No? answer: ĠYes \\n\\n{Inevitably, popular and authentic became chic and the ambience is now somewhat contested by higher rents and the change in character that guarantees.} question: {There has been no change in character, despite low rents.} Yes or No? answer: ĠNo \\n\\n{Shiloh! León must have read something of Drew's blazing anger in his face, for the Mexican's mouth went a little slack and his hand came up in an involuntary gesture as if to ward off a blow.} question: {Leon wasn't afraid of Drew at all. } Yes or No? answer: ĠNo \\n\\n{Chinese President Jiang Zemin is attracting scrutiny now that his mentor, Deng Xiaoping, is dead.} question: {Deng Xiaoping is dead.} Yes or No? answer: ĠYes \\n\\n{Check with the tourist information centers for details about these and similar events at Dalemain, Holker Hall, and Muncaster Castle.} question: {The tourist information centers have information about events at Holker Hall.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  4 experiment#:  tensor([1], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  [\"</s>{so how do you think we can get people to vote} question: {How do we make people unwilling to vote?} Yes or No? answer: ĠNo \\n\\n{On a more mundane but equally fascinating level, you will see the collar and bowl of Greyfriars Bobby.} question: {A more ordinary detail you will see is Greyfriars Bobby's collar and bowl.} Yes or No? answer: ĠYes \\n\\n{yeah well i find myself watching just a whole lot of whatever is geared for children because with two kids and you know i don't want them watching something that i don't think they should watch i i used to be really hooked on All My Children and i watched that for like} question: {I watch primarily adult content because I do not have children. } Yes or No? answer: ĠNo \\n\\n{This is celestially ordained blondness, the mark of God's favor, affirming the signal beauty of the old pagan deities who had already given all blondes--torrid or chilly, fake or real--an edge for 2,000 years.} question: {Blondness has never been seen as beautiful.} Yes or No? answer: ĠNo \\n\\n{Suppose you want to be frugal in the future.} question: {You're rich, no need to be frugal at all.} Yes or No? answer: ĠNo \\n\\n{OIRA approved the final rule as complying with the order on November 7, 1997.} question: {The final rule was marked as complied with on November 7, 1997.} Yes or No? answer: ĠYes \\n\\n{The next time he got a limp fish that had been dead far too long.} question: {The next fish he got was limp and had been dead a long time.} Yes or No? answer: ĠYes \\n\\n{One ring.} question: {Two necklaces.} Yes or No? answer: ĠNo \\n\\n{The other venerable house in the square, now a restaurant, is the Maison Kam?\\xadmer?\\xadzell.} question: {There are no other venerable houses in the square.} Yes or No? answer: ĠNo \\n\\n{especially if you've got kids} question: {Especially if you have kids.} Yes or No? answer: ĠYes \\n\\n{They each ate a chunk of the bread, enjoying every crumb.} question: {They enjoyed every crumb of the chunk of cheese.} Yes or No? answer: ĠNo \\n\\n{Then he walked up Shaftesbury Avenue, finally turning off into the maze of mean streets round Soho.} question: {He went into the maze of streets in Soho.} Yes or No? answer: ĠYes \\n\\n{Back in Durbar Square, pigeons swirl constantly around one of Kathmandu's most colorful shrines, the Kala (Black) Bhairav.} question: {Pigeons went extinct here about 10 years ago, and cannot be found anywhere in the country.} Yes or No? answer: ĠNo \\n\\n{Fear we shall be too late anyway.} question: {Afraid that we will not be in time though. } Yes or No? answer: ĠYes \\n\\n{Exhibits 12 and 13 present a summary of health effects benefits resulting from improvements in air quality between the Base Case and the Clear Skies Act scenarios.} question: {There is a summary of health effects benefits in exhibits 12 and 13.} Yes or No? answer: ĠYes \\n\\n{ Farther along, you come to Sant Josep, a village known for its handicrafts where several shops sell local embroidery and souvenirs.} question: {Souvenirs and handicrafts can be bought in Sant Josep.} Yes or No? answer: ĠYes \\n\\n{He set up a national e-mail tree designed to get people to send their friends in Iowa to Ames as Forbes supporters.} question: {He wanted to set up a national e-mail tree, but gave up halfway.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  5 experiment#:  tensor([1], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  [\"</s>{At Buy Buy Baby, the suburban Washington store with which I'm most familiar, the Wall of Death rises 16 feet into the air and stretches 10 feet wide, and every inch of the wall is covered with child safety products, some of which are absolutely useless and most of which I have bought.} question: {I am quite familiar with Buy Buy Baby.} Yes or No? answer: ĠYes \\n\\n{i going to have to keep that in mind for my future because i hope to have lots of dinner parties  because i like to i mean i'm} question: {I love to invite people over for dinner.} Yes or No? answer: ĠYes \\n\\n{Whither away so fast?} question: {Why so fast away from her?} Yes or No? answer: ĠYes \\n\\n{just one of them} question: {All of them.} Yes or No? answer: ĠNo \\n\\n{Until the late 19th century, this marked the eastern edge of Madrid.} question: {The eastern edge of Madrid didn't change until the 20th century.} Yes or No? answer: ĠNo \\n\\n{ If word of his journey had already spread, word of the attack must have also spread, but he saw no sign of panic in the village at all.} question: {He thought word had spread but the village was not paniced.} Yes or No? answer: ĠYes \\n\\n{I don't know what to make of it. } question: {I don't know what to think. } Yes or No? answer: ĠYes \\n\\n{The final rule was issued pursuant to the authority of the Federal Food, Drug, and Cosmetic Act and the Public Health Service Act as codified at 21 U.S.C.} question: {The last rule can be enforced per two other acts.} Yes or No? answer: ĠYes \\n\\n{and he was coming he came to America to to go to school and i think he was going to go back be an engineer out there} question: {He was coming to America to go and become an engineer.} Yes or No? answer: ĠYes \\n\\n{We asked officials of the various organizations highlighted in the case illustrations and throughout the report to verify the accuracy of the information presented on their activities and incorporated their comments as appropriate.} question: {We didn't ask any of the officials from the organizations highlighted in the case illustrations to verify the accuracy of the information presented.} Yes or No? answer: ĠNo \\n\\n{it does seem to have quieted down there just a little bit that's that's for sure no i the US policy uh towards Central America as far as uh well i kind of go back to to the El Salvador thing because Texas Instruments had a a plant down there for a while and i worked in there for a little while and at that particular time let's let's see that was seventy three seventy four kind of before the the uh the the uh Civil War really picked up down there and US policy at that particular time there was of course military assistance to uh to the government itself you know anything that's that's anticommunist you know we kind of had a tendency to be pro  it don't matter what their excesses were and i believe at the time that i was down there that uh the} question: {The government was against military assistance. } Yes or No? answer: ĠNo \\n\\n{He struggled for several hours to keep the rebellion together, but innumerable weak links were revealed in his improvised chain of command.} question: {The improvised chain of command allowed the rebellion to be strong and secure it's goals.} Yes or No? answer: ĠNo \\n\\n{'Oh, great,' I rubbed my temple.} question: {I rubbed the end of my foot.} Yes or No? answer: ĠNo \\n\\n{I am glad it has all ended so happily. } question: {I'm happy that it has all come to an end.} Yes or No? answer: ĠYes \\n\\n{The kick connected but not hard.} question: {The kick was crushingly hard. } Yes or No? answer: ĠNo \\n\\n{He was naked, old, and small.} question: {He was a fat, young man wearing leather clothes.} Yes or No? answer: ĠNo \\n\\n{The English philanthropist visited the city several times and organized the construction of Mishkenot Sha'ananim, a row of dwellings built to encourage Jews to move from the overcrowded Jewish Quarter of the Old Cityto more modern and healthy places outside the walls.} question: {Mishkenot Sha'ananim was constructed by an English philanthropist.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  6 experiment#:  tensor([1], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  ['</s>{yeah because you\\'re endangering everybody\\'s lives if you\\'ve if it\\'s something like that} question: {What you are doing is keeping others safe.} Yes or No? answer: ĠNo \\n\\n{well well the mini the you\\'d be surprised if if you drive a one of the the mini vans uh fact there all more or less alike the the uh Chevrolet and uh well of course Oldsmo bile has got one and Chryslers got one but they drive remarkably like cars} question: {all of the minivans are pretty much the same and they feel like cars when you drive them} Yes or No? answer: ĠYes \\n\\n{On a peninsula separated from the mainland by islands, the old part of the town is known as Fort Cochin, where Vasco da Gama set up Portugal\\'s first Indian trading station.} question: {Fort Cochin lies on an island that is inaccessible from the mainland.  } Yes or No? answer: ĠNo \\n\\n{oh torn apart oh yeah} question: {Yes, torn apart.} Yes or No? answer: ĠYes \\n\\n{However, they are not intended to limit or interfere with duly granted authority related to developing legislation, rule-making, or other discretionary policy-making in an agency.} question: {They\\'re not meant to limit or interfere with authority. } Yes or No? answer: ĠYes \\n\\n{big paper files are disappearing} question: {The files are all right there on the counter.} Yes or No? answer: ĠNo \\n\\n{They were justifiably concerned, advocates say.} question: {They were unreasonably concerned people.} Yes or No? answer: ĠNo \\n\\n{I know better than even to suggest going without you, Miss Tuppence  \"} question: {I cannot go on without Miss Tuppence} Yes or No? answer: ĠYes \\n\\n{\\'Don\\'t say who it is wants it.} question: {I want you to say who wants it. } Yes or No? answer: ĠNo \\n\\n{He was still bewildered by the introduction of tragedy into his cheerful commonplace existence.} question: {Even after the tragedy his life continued on its even keel.} Yes or No? answer: ĠNo \\n\\n{uh-huh so you find yourself you find yourself in the rough a lot} question: {So you have found yourself on easy street.} Yes or No? answer: ĠNo \\n\\n{Their only  It\\'s more of an extended character study than a full-fledged drama.} question: {The drama focuses more on character studies rather than complex plots.} Yes or No? answer: ĠYes \\n\\n{well that\\'s interesting yeah well} question: {It is interesting.} Yes or No? answer: ĠYes \\n\\n{Time explains why the anti-sweatshop movement is growing on college  The AFL-CIO has jump-started the protests by lavishing student activists with internships and trips to countries with poor working conditions.} question: {The AFL-CIO is against the protests.} Yes or No? answer: ĠNo \\n\\n{Two adjoining chapels, Capilla del Obis?\\xadpo (Bishop\\'s chapel) and Capilla de San Isidro, the first Gothic and the second Baroque, are also worth a look.} question: {There are two chapels from different artistic eras that are worth visiting.} Yes or No? answer: ĠYes \\n\\n{There is a fine collection of historical memorabilia as well as old paintings and etchings, and a 19th-century Chinese bridal chamber.} question: {There is a 19th-century Chinese bridal chamber among the memorabilia.} Yes or No? answer: ĠYes \\n\\n{Since NOx emissions result in formation of ground-level ozone, reducing NOx emissions will reduce ozone levels and thus reduce the deleterious effects of ozone on human health and ecosystems.} question: {The formation of ground level ozone is affected by NOx emissions.} Yes or No? answer: Ġ']\n","ORIGINAL:  7 experiment#:  tensor([1], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  ['</s>{i i wonder if that was really you know the real reason and then i know my daughter uh well she\\'s twenty now but i got her a Voter Registration and gave it to her} question: {My daughter is registered to vote.} Yes or No? answer: ĠYes \\n\\n{The youngster took a long time in getting on with it.} question: {The youngster got on with it immediately.} Yes or No? answer: ĠNo \\n\\n{Inadequate access to treatment/ineffective treatment} question: {They have bad access to treatment.} Yes or No? answer: ĠYes \\n\\n{just exactly} question: {Not at all.} Yes or No? answer: ĠNo \\n\\n{I guess I\\'m a bit behind the times!\" The upshot of these confidential relations was that Tommy and Tuppence took up their abode forthwith at the Ritz, in order, as Tuppence put it, to keep in touch with Jane Finn\\'s only living relation.} question: {I\\'m with the times and know everything.} Yes or No? answer: ĠNo \\n\\n{Fifth, put your money where your mouth is.} question: {Don\\'t place your money where your mouth is. } Yes or No? answer: ĠNo \\n\\n{That\\'s what happened on Meet the Press, where Russert, after hosting Bradley\\'s jocks for much of the show, explained the absence of a Gore representative by reporting, We asked the Al Gore campaign to provide celebrities who would support him.} question: {On Meet the Press, we asked the Al Gore campaign to provide names of celebrities who would support him.} Yes or No? answer: ĠYes \\n\\n{Drive out of town south along the D93, sign?\\xadposted Route des Plages, to Tahiti or Pampelonne for the best beaches, which have fine sand shaded by lovely umbrella pines.} question: {Umbrella pine trees overlook the beaches in Tahiti and Pampelonne.} Yes or No? answer: ĠYes \\n\\n{and little things like that i i\\'ve noticed the speed difference in and i do some graphics uh i haven\\'t done any well i\\'ve done a little bit for the for the house at work but uh if i were to bring it home uh or have a machine at home i would like to be able to put together small uh brochure type things with the the front page being a little little bit of graphics and the inside being printed in a uh what i would call a booklet form there are some editors that will produce uh the you know print it sideways and and collate it in such a way that this page comes out right so that you can fold all these eight and a half by elevens and make a little booklet and} question: {I have lots of graphics.} Yes or No? answer: ĠNo \\n\\n{They brought him a note, a few kind words of sympathy from Peel Edgerton, who had read the news in the paper.} question: {Peel Edgerton wasn\\'t sympathetic at all, even after reading the news in the paper.} Yes or No? answer: ĠNo \\n\\n{Ionian Greeks from the island of Samos settled in Ephesus around 1000 b.c.} question: {Around 3000 years ago, Greeks traveled from Samos to Ephesus.} Yes or No? answer: ĠYes \\n\\n{An impressive private collection it certainly is, but there are those who have criticized it as an ostentatious collection of minor works by major artists.} question: {Some people have complained that the collection lacks major works.} Yes or No? answer: ĠYes \\n\\n{Aside from the beach, the Third Street Promenade has become the most popular destination in Santa Monica.} question: {Aside from the beach, the Fifth Street Promenade has become the most popular destination.} Yes or No? answer: ĠNo \\n\\n{that stuff is expensive} question: {The cost for that is very high.} Yes or No? answer: ĠYes \\n\\n{huh-uh huh-uh i cook mine well do you have a uh like a black iron skillet} question: {Mine always turn out well. } Yes or No? answer: ĠYes \\n\\n{And this month\\'s votes are but a skirmish in the crusades.} question: {The votes of this month changed the outcome.} Yes or No? answer: ĠNo \\n\\n{Thus, in 1997, on average, households made less than one payment by mail for every two bills received in the mail.} question: {Households make 80% of their payments by mail.} Yes or No? answer: Ġ']\n","ORIGINAL:  8 experiment#:  tensor([1], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  [\"</s>{However, getting that work published requires persistence.} question: {It is a quick and easy process to get that work published.} Yes or No? answer: ĠNo \\n\\n{Congress funded LSC grantees to provide attorneys to represent the interests of indigent clients.} question: {The funds were given by congress for representation of foreign interests.} Yes or No? answer: ĠNo \\n\\n{The CityHall complex was architect Tange Kenzo's magnum opus, arguably the last great work of his career.} question: {The CityHall comples was Tange Kenzo's worst work of all time.} Yes or No? answer: ĠNo \\n\\n{oh we i i don't go that uh that deep it starts getting cold when as soon as the cold weather comes it stunts the growth of the uh the grass} question: {The grass grows at a rapid rate in winter.} Yes or No? answer: ĠNo \\n\\n{i stopped payment on a check oh that's funny oh this last week we bought a sewing machine at Zak's and then i found that you could get the same machine better for less locally not much less but it was enough less and i found they locally serviced it and we just stopped payment on the check so i hope they don't sue us over it  but we never received any merchandise either so i don't think it would hold any} question: {I received my sewing machine. } Yes or No? answer: ĠNo \\n\\n{The quality of both is excellent and considered the best in Greece.} question: {Both are very high quality for Greece and some of the best.} Yes or No? answer: ĠYes \\n\\n{The spectacular growth of India' s boom town in electronics, aviation, telecommunications, and machine tools has noticeably changed the climate since the 1970s; it is several degrees hotter here now than it was thirty years ago.} question: {It's now much cooler in the region than it was decades ago.} Yes or No? answer: ĠNo \\n\\n{The increase in citizenship applications has led to longer processing periods and, according to critics, to some immigrants being wrongly naturalized.} question: {According to critics, all immigrants should be naturalized.  } Yes or No? answer: ĠNo \\n\\n{I guess I'd better go down and ease his young mind.} question: {I'll leave him bee since he seems okay.} Yes or No? answer: ĠNo \\n\\n{The Royal Academy also has a magnificent collection of paintings by Zurbar?¡n, rivaling that of the Prado Museum.} question: {The Royal Academy has a collection of paintings that are close in quality and quantity to the collection of Prado Museum.} Yes or No? answer: ĠYes \\n\\n{Shall I tell you what made Monsieur Lawrence turn so pale when he first entered his mother's room on the fatal night? } question: {Will I explain to you what it was that caused Monsieur Lawrence to become pale?} Yes or No? answer: ĠYes \\n\\n{O'Connell Street is lined with more downscale stores, but two landmarks are still  Eason's books and art supplies, and Dublin's largest department store, Clerys, with its famous clock.} question: {O'Connell street houses the well known Eason's books and art supplies and Clerys department store. } Yes or No? answer: ĠYes \\n\\n{and i i it was uh really odd but we went home to Missouri at at at Christmas and i we had well we ran into town and in the ice} question: {There was ice in the town.} Yes or No? answer: ĠYes \\n\\n{Vice President Enclosure 2 Chronology of GAOas Attempts to Obtain Information} question: {Enclosed is a list of the GAO's attempt to obtain information.} Yes or No? answer: ĠYes \\n\\n{He knocked and entered.} question: {The man knocked before he entered. } Yes or No? answer: ĠYes \\n\\n{As these false stations gained credence with pilgrims, the Franciscan monks living in the area decided that faith could be served by accommodating the fabrications, and so legend was allowed to became reality. } question: {There were false stations gained credibility with pilgrims as the Franciscan monks who are living in the area determined faith to be served, as legends stated.} Yes or No? answer: ĠYes \\n\\n{Mary and John stand on either side of the crucified Jesus upheld by his Father, while the dove of the Holy Spirit hovers between them, the whole forming an inspiring triangle under the coffered ceiling of a Renaissance chapel.} question: {Only Jesus, alone on the cross, is depicted on the chapel's ceiling.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  9 experiment#:  tensor([1], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  [\"</s>{you know this is the way i feel about this and this is the way because i it's you know when you when you if you if you teach them when they're little the way you want them to be and the things that are important to you then you just you add onto it as they get older} question: {teach them how you want them to act when they're young} Yes or No? answer: ĠYes \\n\\n{5 events, we use the distributed lag model for PM10 reported in Schwartz (2000) to develop an adjustment factor which we then apply to the} question: {Schwartz reported the distribute lag model for PM10.} Yes or No? answer: ĠYes \\n\\n{but exactly} question: {Although certainly true.} Yes or No? answer: ĠYes \\n\\n{I drew, stabbed through the man's shoulder, and took off his left ear.} question: {I quietly snuck past the man, not wanting to draw my sword because of him.} Yes or No? answer: ĠNo \\n\\n{Contribution by the General Fund to the SMI trust fund.} question: {There was no contribution.} Yes or No? answer: ĠNo \\n\\n{In the 15th century, they built the Castle of the Knights of St. John at the water's edge.} question: {In the 20th century, the Castle of the Knights of St. John was built.} Yes or No? answer: ĠNo \\n\\n{Triumphant flagbearers are flanked by armed guards while another soldier helps a wounded comrade.} question: {The flagbearers were the ones flanking the armed guards.} Yes or No? answer: ĠNo \\n\\n{He's calling you out, I realised.} question: {I just realized that he's calling you out.} Yes or No? answer: ĠYes \\n\\n{William Powell and Myrna Loy star, a reminder of the time when classy (if drunken) wit equalled box-office success.} question: {The two stars were cheap and boring, that's why their movie flopped.  } Yes or No? answer: ĠNo \\n\\n{Brother! the thick man said, smiling.} question: {The man smiled at the person.} Yes or No? answer: ĠYes \\n\\n{The reason appears to be that as efficiency technology penetrates the market and reduces carbon prices, more of a price signal is required to generate further reductions in the three conventional pollutants.} question: {Price signal's need to be decreased in order to get reductions in pollutants.} Yes or No? answer: ĠNo \\n\\n{Its effort to reorganize political parties on a social and economic rather than ethnic basis misread the temper of the Malay masses.} question: {The Malay people were not concerned with the organization of political parties.} Yes or No? answer: ĠYes \\n\\n{Traditional Malay Sports} question: {Some Malay sports are traditional.} Yes or No? answer: ĠYes \\n\\n{and basically it it was a motor and you didn't have all the other junk around it and you could get to it to work on it} question: {Since it was just a motor, without any junk around it, you could start working.} Yes or No? answer: ĠYes \\n\\n{you know underwater psychology or some some ridiculous stuff like that} question: {I am the most qualified expert in underwater psychology.} Yes or No? answer: ĠNo \\n\\n{Reluctantly, I raised my hands.} question: {I enthusiastically put my hands up.} Yes or No? answer: ĠNo \\n\\n{'Think about what you're doing,' I implored.} question: {I told him to think about his actions.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  10 experiment#:  tensor([1], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  [\"</s>{right well well i i think they would you know someone on drugs probably misses more work i guess that's why this smoking thing came out too} question: {It's possible that someone who does drugs has to miss work more often that someone who doesn't.} Yes or No? answer: ĠYes \\n\\n{Grisham, it is clear, wants nothing to stand in the way of his central point--that a man who surrenders all his worldly possessions to defend the homeless is a hero.} question: {Grisham is trying to elevate the idea of the selfish man as the ultimate hero.} Yes or No? answer: ĠNo \\n\\n{I believe in coincidences, you know, he said.} question: {There's no such thing as a coincidence. } Yes or No? answer: ĠNo \\n\\n{We can do this.'} question: {The situation was hopeless and I did not believe we could do it.} Yes or No? answer: ĠNo \\n\\n{Just who is in charge, anyway?} question: {The leader stood at the front of the room and was readily apparent. } Yes or No? answer: ĠNo \\n\\n{The Third Wave feminist's third book--part memoir, part sociology, part political tract--gets praised for its lyrically rendered anecdotes and slammed for shoddy thinking.} question: {The feminist hasn't written books yet.} Yes or No? answer: ĠNo \\n\\n{Try to get him to see a mental health professional, using the argument that his behavior goes way beyond not being in a celebratory mood.} question: {He should see a mental health professional.} Yes or No? answer: ĠYes \\n\\n{But don't let that put you off.} question: {Don't let that come in your way.} Yes or No? answer: ĠYes \\n\\n{Many festivals, though, are so spectacular that it is worth planning your visit specifically so you can attend.} question: {There aren't many festivals that are worth seeing.} Yes or No? answer: ĠNo \\n\\n{Moreover, Gore's patron, Bill Clinton, overshadows the campaign as a constant reminder of the contrast between serving and not serving.} question: {Gore was not outshined by anyone.} Yes or No? answer: ĠNo \\n\\n{Of these bits of academic immortality, Black-Scholes is probably the most widely used by nonacademics, so they have made a good buy on the formula's fame value.} question: {Nonacademics most frequently utilize Black-Scholes, a little academic immortality. } Yes or No? answer: ĠYes \\n\\n{At the same time--and this is where Foster's careful discriminations are so useful--Yeats hated obviously ideological poetry.} question: {Yeats hated that kind of poetry.} Yes or No? answer: ĠYes \\n\\n{You now could argue both events were watershed moments for female athletes because Americans simply love a spectacle.} question: {Americans pay no attention to female sports.} Yes or No? answer: ĠNo \\n\\n{Ca'daan and the others circled to see what the rest of the crowd watched.} question: {The crowd stared at something.} Yes or No? answer: ĠYes \\n\\n{Now would one of those fucking geniuses we keep funding build us a time machine?} question: {We keep giving money to geniuses.} Yes or No? answer: ĠYes \\n\\n{uh-huh well Houston's playing really well lately} question: {Houston has been playing really well lately} Yes or No? answer: ĠYes \\n\\n{Rather. Another silence.} question: {Rather. A long period of incessant chatter.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  11 experiment#:  tensor([1], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  ['</s>{In giving content to the presence requirement, it is important to distinguish between the unrestricted categories of aliens and H-2A workers.} question: {There\\'s no difference between H-2A and aliens so it\\'s not important to distinguish between them.} Yes or No? answer: ĠNo \\n\\n{Material, labor, and construction equipment resource estimates presented in this chapter are for LSFO systems and are a conservative estimate compared to less resource intensive magnesium enhanced lime (MEL) or lime spray dryer (LSD) technologies.} question: {Material, labor and construction equipment resource estimates are for LSFO systems.} Yes or No? answer: ĠYes \\n\\n{because i\\'m a mechanical engineer and i\\'ve had to work when i was designing packages for people i mean i had to to work both systems back and forth and it was not hard} question: {I am a mechanical engineer, and I design packages for people.} Yes or No? answer: ĠYes \\n\\n{However, relocation of the air preheater(s) usually is not necessary.} question: {There is usually no need to move the air preheater.} Yes or No? answer: ĠYes \\n\\n{Innovation - Trading under the acid rain program created financial incentives for electricity generators to look for new and low-cost ways to reduce emissions and to do so early.} question: {Trading under the acid rain program was of no innovative value.} Yes or No? answer: ĠNo \\n\\n{Shopping hours have expanded; shops in tourist areas like Grafton street stay open extended hours and on Sunday.} question: {Shops in tourist areas have longer opening hours.} Yes or No? answer: ĠYes \\n\\n{We went into the little morning-room, and Poirot closed the door. } question: {The meeting with Poirot took place in the morning room. } Yes or No? answer: ĠYes \\n\\n{ \"You sure musta pulled outta th\\' war better\\'n th\\' rest of us poor Rebs.} question: {\"You must have gotten out of the war better than the remainder of us Rebs.\"} Yes or No? answer: ĠYes \\n\\n{no i don\\'t think they would} question: {I don\\'t think they\\'d do that.} Yes or No? answer: ĠYes \\n\\n{It won\\'t be listening.\"} question: {Is is listening to you quite closely.} Yes or No? answer: ĠNo \\n\\n{We conduct financial statement, performance and compliance audits of federal entities, and promulgate generally accepted auditing standards for audits of federal entities, and entities that receive federal funds.} question: {We do financial statements for groups that get private funds.} Yes or No? answer: ĠNo \\n\\n{The whole thing is absurd and ridiculous to the last degree.\"} question: {It is entirely ridiculous in every way.} Yes or No? answer: ĠYes \\n\\n{well i sort that sort of goes to my pet peeve about the education system in this country too} question: {I think our educations system is as good as they get.} Yes or No? answer: ĠNo \\n\\n{A DOT official also indicated that the Department\\'s Research and Special Programs Administration had used a chat room arrangement during some of the agency\\'s rulemaking comment periods.} question: {An official from DOT denied claims that a chat room  had been used during some of the agency\\'s rulemaking. } Yes or No? answer: ĠNo \\n\\n{For example in figure 4.1, although federal government saving increased as a share of GDP by 5.5 percentage points from 1990 to 2000, net national saving increased by only 1.1 percentage points because private saving as a share of GDP decreased by 4.9 percentage points over the same period.} question: {Over the period from 1990 to 2000 individual savings rose by a tremendous 100%.} Yes or No? answer: ĠNo \\n\\n{yeah do you ever watch the Mavericks} question: {Do you ever watch the Atlanta Hawks?} Yes or No? answer: ĠNo \\n\\n{Because many different packages are available, and because more than one can be used, auditors should determine what models, if any, are used in their agencies.} question: {Auditors have the option of choosing a model to use.} Yes or No? answer: Ġ']\n","ORIGINAL:  12 experiment#:  tensor([1], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  [\"</s>{The average age of direct-mail respondents is 65 to 70.} question: {Average age of direct mail receivers are 65-70.} Yes or No? answer: ĠYes \\n\\n{There are always several temporary exhibits to explore, along with a cafe and gift shop.} question: {The exhibits change.} Yes or No? answer: ĠYes \\n\\n{As Brookings economist Henry Aaron pointed out in the Committee discussion, if you could pour in enough money to pay for the transition to privatization, the system would no longer be out of balance.} question: {Nothing could be done to put the system back into balance.} Yes or No? answer: ĠNo \\n\\n{but uh i mean they they just moved into the new building he calls it the new building i don't know it's where all the executives are} question: {They have not yet moved into the new building.} Yes or No? answer: ĠNo \\n\\n{The third knowledge point is achieved when a reliable product can be produced repeatedly within established cost, schedule, and quality targets.} question: {The third knowledge point is about how many consumers want the product.} Yes or No? answer: ĠNo \\n\\n{Here, let one of the maids go down and wake Baily and tell him to go for Dr. Wilkins at once. } question: {Baily needs to go get Dr, Wilkins so send one of the maids to wake him.} Yes or No? answer: ĠYes \\n\\n{Yes, siree, this here's th' second time we made th' trip through without havin' to burn up a sight of gunpowder!} question: {We used up all the gunpowder shooting off bandits on this trip. } Yes or No? answer: ĠNo \\n\\n{I do believe the legislators will look askance at new issues.} question: {Legislators will look at new issues with suspicion.} Yes or No? answer: ĠYes \\n\\n{This is the Charles Murray who says late in the book that he half-supports the idea of a negative income tax--a guaranteed income for everyone.} question: {Charles Murray supports the idea of negative income tax. } Yes or No? answer: ĠYes \\n\\n{And they don't need to--the 13 missiles they supposedly have aimed at the United States have always been judged capable of hitting U.S. cities by the Pentagon (though China's difficulty in commercial launches casts doubt on the Pentagon's assessment).} question: {It is not clear if China's missiles are capable of hitting U.S. cities.} Yes or No? answer: ĠYes \\n\\n{There was a screen round it, but I could hear two people talking in the room.} question: {I couldn't see what was happening inside, but I heard two people talking.} Yes or No? answer: ĠYes \\n\\n{Very well. Her mouth opened meekly.} question: {Her lips stayed clasped as she crossed her arms.} Yes or No? answer: ĠNo \\n\\n{We're dead, and we're here, and they tell us to make helicopters.} question: {They tell us to make small balloon animals. } Yes or No? answer: ĠNo \\n\\n{These would be smaller planets, comparatively poorer in hydrogen and richer in oxygen.} question: {The planets are comparatively better in hydrogen.} Yes or No? answer: ĠNo \\n\\n{But it also had the effect of permitting a great, distinctive cultural growth with a strong national identity.} question: {It had the effect of permitting cultural growth.} Yes or No? answer: ĠYes \\n\\n{yeah well you can 't} question: {That can certainly be done.} Yes or No? answer: ĠNo \\n\\n{Think of the Briefing section as your quick hit on the day's and week's news.} question: {It contains both daily and weekly information.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  13 experiment#:  tensor([1], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  [\"</s>{That site provided a wealth of information about the proposed rule, including the text of the rule, the agency's regulatory impact assessment, and how to submit comments and search the comments that have already been submitted.} question: {A wealth of information about the proposed rule was provided.} Yes or No? answer: ĠYes \\n\\n{no i mean it's it's actually there's an interstate} question: {There is no road.} Yes or No? answer: ĠNo \\n\\n{House, Ernest R. The Logic of Evaluative Argument.} question: {The Logic Of Evaluative Argument, by Ernest R. House.} Yes or No? answer: ĠYes \\n\\n{In the United States, GDP per capita has doubled about every 35 years.} question: {GDP has doubled roughly every 5 years.} Yes or No? answer: ĠNo \\n\\n{but i wonder if yeah and i i still haven't been called yet in fact yeah in fact out of our office staff is let's see there's uh four six there's seven of us and there's only one been called} question: {Only one person, out of the seven who work in our office, has been called.} Yes or No? answer: ĠYes \\n\\n{Pursuant to our court rules, participation in the IOLTA program is mandatory.} question: {The IOLTA program cannot be opted out of.} Yes or No? answer: ĠYes \\n\\n{He doesn't seem to think the Chinese reliance on Western markets, say, or Hong Kong's thirst for Western capital, can help keep trans-Pacific relations smooth.} question: {It seems that he doesn't believe that the Chinese reliance on Western markets will trans-Pacific relations going smoothly.} Yes or No? answer: ĠYes \\n\\n{Although small temples and shrines remain, visitors will enjoy exploring the covered shopping arcade between Shijo and Sanjo streets, famous for its second-hand bookstores, traditional hand-made paper (washi) shops, trendy but sometimes creative clothing stores, and numerous pickle shops.} question: {There are no temples and shrines near the marketplace area.} Yes or No? answer: ĠNo \\n\\n{A bookcase crammed with tightly squeezed volumes provided a resting place for pieces of native pottery bearing grotesque animal designs.} question: {The books lie strewn across the floor, with no bookcase to hold them. } Yes or No? answer: ĠNo \\n\\n{The powerful Prussians came up with a plan to partition Poland, which gained the support of the Russians.} question: {The Prussians had the intention to partition Poland.} Yes or No? answer: ĠYes \\n\\n{I can get everything, including the kids.} question: {I cannot get anything.} Yes or No? answer: ĠNo \\n\\n{oh i saw it} question: {I viewed it.} Yes or No? answer: ĠYes \\n\\n{Small holdings abound, and traditional houses sit low on the treeless hillsides.} question: {There were no buildings on any of the hills.} Yes or No? answer: ĠNo \\n\\n{In such cases, a wide variety of expenditures or actions could be consistent with legislation and compliance with} question: {There was little cost that was associated with the legislation. } Yes or No? answer: ĠNo \\n\\n{In this chapter, we journey clockwise around the island, starting at Montego Bay on the northwest coast.} question: {We'll start our journey in the northwest coast at Montego Bay.} Yes or No? answer: ĠYes \\n\\n{You will still find the elegant, spare plates of?\\xadnouvelle cuisine, but there is a new focus on heartier dishes and an acceptance of cuisines of other countries.} question: {Acceptance of cuisines of other countries is an old focus.} Yes or No? answer: ĠNo \\n\\n{Who put it in the chest, I wonder?} question: {I'm curious as to who put it in the chest.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  14 experiment#:  tensor([1], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  [\"</s>{Hardly a victory to build an entire reputation.} question: {It's not a big deal to build an entire reputation.} Yes or No? answer: ĠYes \\n\\n{Less grandiosely than Harmony Korine in Julien Donkey-Boy, Soderbergh pores over every scene in search of its essential dramatic gesture.} question: {Soderbergh is looking for the most dramatic gestures in each scene. } Yes or No? answer: ĠYes \\n\\n{In 1464, after the Battle of Hexham, King Henry VI wandered the countryside and many of the landowners, unsure whether he was victor or vanquished, refused to give him shelter.} question: {King Henry VI wandered around after the Battle of Hexham.} Yes or No? answer: ĠYes \\n\\n{Average FGD installation times have commonly been within 24-27 months.} question: {Installation times have averaged about 10 months.} Yes or No? answer: ĠNo \\n\\n{it will be like Italian basketball with the uh with with the uh NBA} question: {It is like an Italian version of the NBA. } Yes or No? answer: ĠYes \\n\\n{tend to be hypercritical of these things and then perhaps perhaps it's unfair because i i i must admit i enjoy these movies um} question: {Even though I like these movies, I am pretty critical of them.} Yes or No? answer: ĠYes \\n\\n{Notable as the only major American city built in the twentieth century, Las Vegas is particularly unfettered by any burden of history or preservation.} question: {Las Vegas has incomparable freedom in its growth potential thanks to its lack of history and preservation efforts.} Yes or No? answer: ĠYes \\n\\n{yeah but it seems like every time at work i look out my window it's gray} question: {It seems that it's sunny every time I look out the window at work.} Yes or No? answer: ĠNo \\n\\n{While magic produced their food and made a better world for them, they hated it because they couldn't do it for themselves.} question: {They hated magic, because while it produced their food, and made a better world for them, they couldn't do it for themselves.} Yes or No? answer: ĠYes \\n\\n{but if you look at what's in that little car and as opposed to what's in some of the American cars you can see where we're probably a half a step behind and i think i think we're trying to do something to correct that but i think we got away from us a little bit so} question: {They had to take their American car to the junk yard.} Yes or No? answer: ĠNo \\n\\n{well when is the NFL draft hasn't has the NFL draft even gone yet} question: {The draft is already complete.} Yes or No? answer: ĠNo \\n\\n{'And you're going to kill White.} question: {You're not going to kill him. } Yes or No? answer: ĠNo \\n\\n{Luis Vaz de Camees (1524 1580), the Portuguese national poet whose work immortalized that country's golden age of discoveries, may have stayed in Macau.} question: {Luis Vaz de Camees hated all forms of poetry.} Yes or No? answer: ĠNo \\n\\n{The Anaheim Convention and Visitors' Bureau has a wealth of information on the area.} question: {There is very little information to be found at the Anaheim Convention and Visitors' Bureau.} Yes or No? answer: ĠNo \\n\\n{uh-huh have you heard the forecast for the week coming up} question: {You didn't hear this week's weather forecast?} Yes or No? answer: ĠNo \\n\\n{have you been to the opera ever} question: {Some people go to the opera.} Yes or No? answer: ĠYes \\n\\n{learn your colors learn your alphabet learn all your your little terms here and and learn how to uh begin learning some of the reading and by the second or third grade uh the little school system that we're in they have uh really a lot of computers uh it's a very wealthy district as as all that fighting's going on over who gets the money and the like but they have} question: {It's a poor district that argues over benches to sleep on } Yes or No? answer: Ġ\"]\n","ORIGINAL:  15 experiment#:  tensor([1], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  ['</s>{The Ritz would enjoy the spectacle of the glad reunion.\" Inquiry at the office revealed the fact that Tuppence had not yet returned.} question: {They would like the glad reunion. Tuppence has not came back yet.} Yes or No? answer: ĠYes \\n\\n{An equally enticing reason to head to the hills is to visit the country\\'s largest urban park, Griffith Park, which separates Burbank and Glendale from Hollywood and covers over 4,000 acres (1,620 hectares).} question: {Griffith Park is one of the smallest parks in the country.} Yes or No? answer: ĠNo \\n\\n{now how do they do the blackened} question: {So, how do they make it blackened?} Yes or No? answer: ĠYes \\n\\n{Gold is sold by weight, with a surcharge for workmanship (gold prices are posted daily in the bazaar); genuine sterling silver should carry a hallmark.} question: {Accordingly, genuine sterling silver does not have to carry a hallmark.} Yes or No? answer: ĠNo \\n\\n{Show us how.} question: {Show us how to do it.} Yes or No? answer: ĠYes \\n\\n{The ground floor dates from 1467, and the beautifully sculpted wooden facade of the superstructure from 1589.} question: {The ground floor is older than the wooden facade of the superstructure.} Yes or No? answer: ĠYes \\n\\n{The bald, pointy-eared vampire in Nosferatu is barely ambulatory, in fact.} question: {The limping vampire has curly hair.} Yes or No? answer: ĠNo \\n\\n{It is the side of Johnson that we are most familiar with, Johnson as the brilliant conniver, trying so diligently and without success to free himself from the spell of the Kennedys.} question: {Johnson had no connection to the Kennedys.} Yes or No? answer: ĠNo \\n\\n{ Do you have a set menu?} question: {Do you have a dynamic menu?} Yes or No? answer: ĠNo \\n\\n{The author\\'s claim that she backed down from that number in later interviews (not cited) is thus groundless.} question: {There is no basis in her saying she backed down from the original number.} Yes or No? answer: ĠYes \\n\\n{Papa believed that in their confused flight you could see the hand of God.} question: {Papa thought he could see the work of the Almighty in their chaotic flight.} Yes or No? answer: ĠYes \\n\\n{so do you have anything else you want to say about it or} question: {I\\'m sure you don\\'t have anything to say about it.} Yes or No? answer: ĠNo \\n\\n{well i love Masterpiece Theatre} question: {I am not a fan of Masterpiece Theatre.} Yes or No? answer: ĠNo \\n\\n{uh puts a whole yeah gets a whole new picture to what  real air pollution can be but uh that stuff going on over there what what uh what part of Pennsylvania are you in} question: {Pennsylvania has very clean air.} Yes or No? answer: ĠNo \\n\\n{Not until 1249 did King Afonso III (1248-1279) complete the Reconquest and secure borders for Portugal 250 years before the Spanish could do the same.} question: {Portugal\\'s borders were not secured by King Afonso the third until 1249.} Yes or No? answer: ĠYes \\n\\n{Total benefit numbers reflect use of three percent discount rate.} question: {Benefit numbers account for the discount rate.} Yes or No? answer: ĠYes \\n\\n{Formal and informal areas are landscaped with pools and fountains, while terraces tumble down the hillsides.} question: {There were no pools or fountains in the informal areas.} Yes or No? answer: Ġ']\n","ORIGINAL:  16 experiment#:  tensor([2], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  [\"</s>{You travel past the vast palm oil and rubber plantations to the state capital of Seremban, 64 km (40 miles) southwest of KL.} question: {The state capital of Seremban is 50 miles Northwest of KL.} Yes or No? answer: ĠNo \\n\\n{absolutely absolutely now i can't wait for uh i i could just picture what's what's going to happen here in the not to distant future we keep hearing well we're going to receive uh eight billion dollars from Japan for the uh uh uh the uh uh the the the big war over there in the Mideast} question: {I couldn't care less what happens here in the not so distant future.} Yes or No? answer: ĠNo \\n\\n{my husband sat in on a jury trial a murder trial that lasted for two weeks} question: {My husband served on a jury for a murder trial that lasted two weeks. } Yes or No? answer: ĠYes \\n\\n{I am Jon, said the man, turning back to the polished metal.} question: {Jon was holding some metal.} Yes or No? answer: ĠYes \\n\\n{that's about that as far as any other everyday occurrences i put a stop to some of them as far as the door-to-door either religious groups or people} question: {I wish more religious people would go door to door.} Yes or No? answer: ĠNo \\n\\n{McCain : Medical Savings Accounts, etcetera.} question: {McCain: Accounts related to health.} Yes or No? answer: ĠYes \\n\\n{yeah no there's no way somebody once said uh i had a car that said fuel injection on the side of it and a woman asked me what that meant and i said that means that i can't work on it you know they've gotten so complicated or so high tech that uh} question: {Sometimes I can't work on a car because it's too high tech.} Yes or No? answer: ĠYes \\n\\n{This category includes entitywide security program planning, management, control over data center operations, system software acquisition and maintenance, access security, and application system development and maintenance.} question: {There is no entity wide security program.} Yes or No? answer: ĠNo \\n\\n{Running downhill from here is Uzuncar?«?? Caddesi, lined with hardware shops, which leads to the Spice Ba?\\xadzaar, the best place to buy lokum (Turkish Delight).} question: {There are no hardware shops in Uzuncar Caddesi.} Yes or No? answer: ĠNo \\n\\n{Readers should recognize, however, that as time shortens, so may the value of the method as a way of presenting a comprehensive understanding of the event as a whole.} question: {Readers should recognize, however, that as time shortens, the value of the method as a way of presenting a comprehensive understanding of the event as a whole also shortens.} Yes or No? answer: ĠYes \\n\\n{The showrooms are for trade only, meaning the only way you can make purchases is to buy through an interior designer.} question: {Anyone can go to the showroom to buy things.} Yes or No? answer: ĠNo \\n\\n{It runs in a straight line north from O'Connell Bridge, and the best way to view it is to walk down the central island, making excursions to the left and right at the zebra crosengs.} question: {You can see it if you walk down the center island.} Yes or No? answer: ĠYes \\n\\n{Representing herself at an administrative hearing, she lost her appeal to restore Medi-Cal benefits because she did not have proper documentation of the rent account.} question: {She couldn't restore her Medi-Cal benefits.} Yes or No? answer: ĠYes \\n\\n{well um most of the stuff up until now in the recent months i i i don't have any problem with} question: {I had been alright with most of the things till now.} Yes or No? answer: ĠYes \\n\\n{The FCC estimates that the new procedure will save industry approximately $250 million annually in administrative expenses.} question: {The industry currently spends less than one million dollars per year on administration.} Yes or No? answer: ĠNo \\n\\n{He can drop the pretense that he's nonpartisan.} question: {He can stop pretending that he's bipartisan.} Yes or No? answer: ĠNo \\n\\n{There's a small zoo area where you can see snakes, lizards, birds of prey, wolves, hyenas, foxes, and various desert cats, including cheetahs and leopards.} question: {The zoo is home to a variety of animals including mammals, birds, lizards, and snakes.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  17 experiment#:  tensor([2], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  [\"</s>{To honor its creators, it was to be called 'Przyrolarouish'.} question: {The name paid tribute to their creators.} Yes or No? answer: ĠYes \\n\\n{Many commercial firms, in recognition of the physical impact and disruption of family life that results from frequent travel, allow their employees to keep frequent flyer awards.} question: {No commercial firms allow their employees to keep their frequent flyer awards.} Yes or No? answer: ĠNo \\n\\n{We believe the bill is missing some provisions -- it should address the allocation scheme and integration with existing programs.} question: {We think the bill is missing some things.} Yes or No? answer: ĠYes \\n\\n{Many are strategically timed.} question: {Many lack strategic timing.} Yes or No? answer: ĠNo \\n\\n{yes when is yours on} question: {Yes, when is yours on?} Yes or No? answer: ĠYes \\n\\n{Reader Survey, Round 2} question: {The reader survey was conducted in rounds.} Yes or No? answer: ĠYes \\n\\n{Something else rasped across his sciatic nerve.} question: {Things have rasped across his sciatic nerve.} Yes or No? answer: ĠYes \\n\\n{If in the above example the cost had been nine cents in the low cost area and 11 cents in the high cost area, it would be much more difficult for inefficient entry to occur.} question: {Cost differentials are not important when considering inefficient entry.} Yes or No? answer: ĠNo \\n\\n{(Incidentally, the WJC page, which links to the Washington Times site, boasts some of the most intrusive music of any site on the Web.)} question: {The WJC page has the most intrusive music.} Yes or No? answer: ĠYes \\n\\n{These islands, known as the eastern Aegean Islands, have been at the forefront of waves of invasion from the east.} question: {The eastern Aegean Islands had never been invaded in it's entire history.} Yes or No? answer: ĠNo \\n\\n{yeah yeah there there are many organizations uh feed the hungry all these there's a lot of drives in school for this type of thing already you know not neccessarily sometimes um} question: {There are no food drives at school.} Yes or No? answer: ĠNo \\n\\n{(Kohler's Dictionary for Accountants) HUMAN CAPITAL -Expenses incurred for education and training programs financed by the Federal Government for the benefit of the public and designed to increase or maintain national economic productive capacity.} question: {The Federal Government educated the public for their benefit.} Yes or No? answer: ĠYes \\n\\n{Portugal has emerged as one of the world's top destinations for golfing vacations, with many companies offering all-inclusive vacations.} question: {Very few people go to Portugal to play golf.} Yes or No? answer: ĠNo \\n\\n{Why don't you take it? } question: {Tell me why you're taking it.} Yes or No? answer: ĠNo \\n\\n{A slatternly looking servant, with an extremely dirty face and a pair of eyes that did not match, answered the door.} question: {The dirty servant didn't answer the door.} Yes or No? answer: ĠNo \\n\\n{On Saturday, Mainichi Shimbun devoted its main editorial to Britain's new defense cuts, pointing out that Britain expects to save 141 billion yen on its defense bill over the next three years, while Japan's defense expenditure continues to rise.} question: {Mainichi Shimbun wrote an article on Britain's defense spending.} Yes or No? answer: ĠYes \\n\\n{and i lived with Dana in school} question: {I didn't lived with Dana} Yes or No? answer: Ġ\"]\n","ORIGINAL:  18 experiment#:  tensor([2], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  [\"</s>{No sugar, said Cynthia, watching him, as he picked up the sugar-tongs. } question: {Cynthia wanted two sugars.} Yes or No? answer: ĠNo \\n\\n{Louis XIV wanted this most elegant of Paris squares to provide an imposing setting for a monument to him.} question: {Louis XIV ignored the idea of building monuments to honor himself.} Yes or No? answer: ĠNo \\n\\n{Tucked away in a comfortable park behind high railings, the Palacio de Liria is the residence of the duchess of Alba.} question: {The duchess of Alba lives in the Palacia de Liria.} Yes or No? answer: ĠYes \\n\\n{how about Silence of the Lambs} question: {We'll just leave Silence of the Lambs out.} Yes or No? answer: ĠNo \\n\\n{He says this will make our system the best.} question: {He says it will make the system great.} Yes or No? answer: ĠYes \\n\\n{A recognized item is depicted in both words and numbers, with the amount included in the statement totals.} question: {Words and numbers are both used to depict the item.} Yes or No? answer: ĠYes \\n\\n{It was built only a dozen years after the Louis XII wing but, reflecting the contrast between the debonair Ren?\\xadais?\\xadsance prince and his dour predecessor, is a world apart in elegance and panache.} question: {Louis XII was a flamboyant rascal with a taste for gaudy styles.} Yes or No? answer: ĠNo \\n\\n{That is an extreme possibility, and I do not believe in its likelihood myself, but that document undoubtedly implicates a number of our statesmen whom we cannot afford to have discredited in any way at the present moment.} question: {A number of our politicians are implicated in that document.  } Yes or No? answer: ĠYes \\n\\n{McCaffrey told the Washington Post that he would make his recommendations to Clinton by Christmas.} question: {McCaffrey has announced that he will not make any more recommendations to Clinton.} Yes or No? answer: ĠNo \\n\\n{Porto Santo is still, at heart, the resort of Madeirans, who seek what they have sand.} question: {Porto Santo, at it's core, is a destination of Madeirans.} Yes or No? answer: ĠYes \\n\\n{In addition, some members of federally sponsored organizations expressed the concern that members' potentially sensitive information voluntarily shared with federal entities could be required to be made publicly available under provisions of the Freedom of Information Act, despite existing exemptions for sensitive or proprietary information.} question: {No members of federally sponsored organizations expressed the concern of members' potentially sensitive information.} Yes or No? answer: ĠNo \\n\\n{well you're my third one and i have never gotten the courage to do it myself isn't that funny} question: {I don't have the courage to do what you do.} Yes or No? answer: ĠYes \\n\\n{and uh uh i don't know it's going to be interesting} question: {I am unsure, it will be quite interesting} Yes or No? answer: ĠYes \\n\\n{The pyramid is made up of six brick tiers, reaching a height of 60 m (196 ft).} question: {The pyramid is composed of 1 brick tier with a height of 10 feet.} Yes or No? answer: ĠNo \\n\\n{Patients were also screened with the CAGE and SMAST.} question: {The patients were not required to go through CAGE screenings.} Yes or No? answer: ĠNo \\n\\n{It had to duplicate the courses of the objects in their sky and simulate the general behavior of the dome.} question: {It had to mirror the paths of the objects in their sky.} Yes or No? answer: ĠYes \\n\\n{I did so, and felt something bitty and sticky shoved down my throat.} question: {I felt something bitty and sticky forced down my throat.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  19 experiment#:  tensor([2], device='cuda:0')\n","TOKENIZE / DETOKENIZE:  [\"</s>{He will happily decorate any TV or radio story with a veneer of American history.} question: {He will be glad to decorate any story in radio or TV.} Yes or No? answer: ĠYes \\n\\n{That year marked the high point for Kosovar aspirations to independence, and it remains the benchmark for NATO's demand at Rambouillet for a restoration of Kosovo's pre-1989 autonomy.} question: {Kosovar's aspirations to become independent were at an all-time low that year.} Yes or No? answer: ĠNo \\n\\n{One leading organization implements a combination of centralized and decentralized IT and structures to best meet the needs of its three diverse lines of business-an international services division, an international industry division, and a retail division.} question: {They only have one line of business.} Yes or No? answer: ĠNo \\n\\n{To avoid possible complications with customs, veteran travelers ask for and retain a receipt (sales slip) for everything purchased.} question: {Veteran travelers know it's a waste of time and effort to keep their receipts.} Yes or No? answer: ĠNo \\n\\n{but i know it was cold i had turn on the heat and get quilts yeah} question: {It was hot where you were.} Yes or No? answer: ĠNo \\n\\n{oh i like it i i i have a foreign actually i have more than one foreign automobile and i i i find the uh i find the the nondecimal system with all the halves and quarters i was trying to build a shed and they give you these measurements like forty two and three eighths inches and we had to go a little less and trying to figure what's less than three eighths uh} question: {I was trying to build a shed for the foreign automobiles I own.} Yes or No? answer: ĠYes \\n\\n{For further information regarding this statement, please contact J.} question: {You can get more information about this statement.} Yes or No? answer: ĠYes \\n\\n{A marked version of the exposure draft is available on the Internet on GAO's Home Page ( www.gao.gov/govaud/ybk01.htm).} question: {There is a marked version on the Internet, which can be accessed on the Home Page.} Yes or No? answer: ĠYes \\n\\n{Their term of stay in the United States is dependent upon the agricultural needs of the employer, but by law cannot exceed one year.} question: {They cannot stay in the USA for longer than one year. } Yes or No? answer: ĠYes \\n\\n{You can't liberate me.} question: {You can certainly liberate me.} Yes or No? answer: ĠNo \\n\\n{17ISO is a worldwide federation of national standards bodies representing 140 countries.} question: {120 countries are represented within ISO.} Yes or No? answer: ĠNo \\n\\n{Cartmel church was saved only because it also served as a parish church for the community.} question: {Cartmel church was preserved so that it could continue to serve the community.} Yes or No? answer: ĠYes \\n\\n{if you're lucky} question: {Whether you are lucky, it will depend } Yes or No? answer: ĠYes \\n\\n{Julius jerked the rusty bell handle.} question: {The bell handle was oiled up and Julius easily slid through it.} Yes or No? answer: ĠNo \\n\\n{in power that's not really seeking God and wanting to do good for the people and not deal for selfish motives is very dangerous and i don't see that this one world this new world order that him and Gorbachev keep talking about i just don't see that um that's just a real good thing but i think it's something that's going to happen but i guess that's what i feel happen with the war and that was the motive of the war was to try and break that up and so that they could be you know get more power over that Arab lands when they try and next year really start pushing this new world order well he talks about it all the time i mean} question: {Him and Gorbachev are talking about the new pizza hut order for their meeting.} Yes or No? answer: ĠNo \\n\\n{Ca'daan felt uncomfortable in the gambling parlor but the crowds left them alone.} question: {Cadaan didn't like the gambling parlor.} Yes or No? answer: ĠYes \\n\\n{Because a large proportion of street costs are fixed,27 the unit (per piece) street cost initially declines rapidly as volume increases and continues to decline at a decreasing rate.} question: {Street costs remain at $0.00 forever no matter what.} Yes or No? answer: Ġ\"]\n"]}],"source":["# This is to inspect that the dataloader is performing as expected\n","# Also using the decoding to check back that results are expected and examples can be compared\n","# Only done for few examples\n","\n","for i, batch in enumerate(dataloader):\n","    if i<20:\n","      print(\"ORIGINAL: \", i, \"experiment#: \", batch['exps'])\n","      print(\"TOKENIZE / DETOKENIZE: \", OPT_tokenizer.batch_decode(batch['input_ids']))\n","    else:\n","      break"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"PEQCg6v-_4hd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523749063,"user_tz":-120,"elapsed":7062,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"8447867b-1644-49d1-c447-a52044e4b1a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["BATCH#:  64 NUM RUNS TOTAL:  65\n","BATCH#:  65 NUM RUNS TOTAL:  66\n","BATCH#:  66 NUM RUNS TOTAL:  67\n","BATCH#:  67 NUM RUNS TOTAL:  68\n","BATCH#:  68 NUM RUNS TOTAL:  69\n","BATCH#:  69 NUM RUNS TOTAL:  70\n","BATCH#:  70 NUM RUNS TOTAL:  71\n","BATCH#:  71 NUM RUNS TOTAL:  72\n","BATCH#:  72 NUM RUNS TOTAL:  73\n","BATCH#:  73 NUM RUNS TOTAL:  74\n","BATCH#:  74 NUM RUNS TOTAL:  75\n","BATCH#:  75 NUM RUNS TOTAL:  76\n","BATCH#:  76 NUM RUNS TOTAL:  77\n","BATCH#:  77 NUM RUNS TOTAL:  78\n","BATCH#:  78 NUM RUNS TOTAL:  79\n","BATCH#:  79 NUM RUNS TOTAL:  80\n","model_target_probs SHAPE:  torch.Size([160, 50272])\n","model_target_probs:  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n"]}],"source":["# Set eval model for inference\n","# initialize to store results of model predictions and compare with ground-truth\n","# use generate text with only one token\n","# extract all probabilities of next token\n","\n","example_myBaseOPT_CD.eval()\n","\n","model_target_probs_int = torch.zeros(0, dtype=torch.long).to(device)\n","#ground_truth = torch.zeros(0, dtype=torch.long).to(device)\n","\n","with torch.no_grad():\n","    for i, batch in enumerate(dataloader):\n","      if batch['exps'].item() == SEL_EXP_TRAIN_CD:\n","          print(\"BATCH#: \", i, \"NUM RUNS TOTAL: \", (i+1)*bx_size)\n","\n","          input_ids = batch['input_ids'].to(device)\n","          attention_mask = batch['attention_mask'].to(device)\n","\n","          # output only the binary yes/no,\n","          output_scores = (example_myBaseOPT_CD.forward(input_ids, attention_mask))[:,-1,:]\n","\n","          output_probs = torch.softmax(output_scores, dim=1)\n","          #print(\"output_probs.shape: \", output_probs.shape)\n","\n","          model_target_probs_int = torch.cat((model_target_probs_int, output_probs), dim=0)\n","      else:\n","          output_probs = torch.zeros(1, 50272).to(device)\n","          model_target_probs_int = torch.cat((model_target_probs_int, output_probs), dim=0)\n","\n","model_target_probs = model_target_probs_int.detach()\n","print(\"model_target_probs SHAPE: \", model_target_probs.shape)\n","print(\"model_target_probs: \", model_target_probs)"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"ari7GUC2Kysq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523749063,"user_tz":-120,"elapsed":18,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"32035444-274a-4a0d-c269-ed4cb7975028"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.float32"]},"metadata":{},"execution_count":33}],"source":["model_target_probs.dtype"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"PX1NMUso5pyM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523749064,"user_tz":-120,"elapsed":18,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"5bb34c1f-df93-4382-e3fb-8e041e8cc796"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.4410, 0.6279, 0.4736, 0.3758, 0.5180, 0.5380, 0.7914, 0.3978,\n","        0.5758, 0.4653, 0.5595, 0.5019, 0.3637, 0.3319, 0.6488, 0.6114, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","       device='cuda:0')"]},"metadata":{},"execution_count":34}],"source":["# Scores for YES token\n","model_target_probs[:, 9904]"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"Du0laVTx5w6K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523749064,"user_tz":-120,"elapsed":17,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"e9a9238e-20f1-489a-b5d1-8f87684582cc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.5431, 0.3595, 0.5154, 0.6087, 0.4664, 0.4537, 0.1980, 0.5857,\n","        0.3835, 0.5100, 0.4114, 0.4868, 0.6254, 0.6615, 0.3383, 0.3715, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","       device='cuda:0')"]},"metadata":{},"execution_count":35}],"source":["# Scores for NO token\n","model_target_probs[:, 3084]"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"s1AU4OLmlSpp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523749064,"user_tz":-120,"elapsed":15,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"4e22f8d0-196f-461f-80e0-22bf043f486e"},"outputs":[{"output_type":"stream","name":"stdout","text":["sorted_probs SHAPE:  torch.Size([160, 50272])\n","idx_probs SHAPE:  torch.Size([160, 50272])\n"]}],"source":["\n","\n","sorted_probs, idx_probs = model_target_probs.sort(dim=1, descending=True)\n","print(\"sorted_probs SHAPE: \", sorted_probs.shape)\n","print(\"idx_probs SHAPE: \", idx_probs.shape)"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"mrjw239WhNb8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523749064,"user_tz":-120,"elapsed":14,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"a0f95e3c-2709-447b-a45b-ddda17b6b731"},"outputs":[{"output_type":"stream","name":"stdout","text":["target_prob_match SHAPE:  torch.Size([160, 51])\n","target_prob_match:  tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n","        [0., 0., 0.,  ..., 0., 0., 1.],\n","        [0., 0., 0.,  ..., 0., 0., 1.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 1.],\n","        [0., 0., 0.,  ..., 0., 0., 1.],\n","        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0', dtype=torch.float16)\n","Check sum 1:  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n","       device='cuda:0', dtype=torch.float16)\n","target_idx_match SHAPE:  torch.Size([160, 50])\n","target_idx_match:  tensor([[ 0,  1,  2,  ..., 47, 48, 49],\n","        [ 0,  1,  2,  ..., 47, 48, 49],\n","        [ 0,  1,  2,  ..., 47, 48, 49],\n","        ...,\n","        [ 0,  1,  2,  ..., 47, 48, 49],\n","        [ 0,  1,  2,  ..., 47, 48, 49],\n","        [ 0,  1,  2,  ..., 47, 48, 49]], device='cuda:0')\n"]}],"source":["# EXTRACT PROBABILITIES\n","\n","# TOP x PROBS TO MATCH\n","target_prob_match = torch.zeros(sorted_probs.shape[0], number_max_probs_match + 1).half().to(device)\n","target_prob_match[:, 0:number_max_probs_match] = sorted_probs[:, 0:number_max_probs_match]\n","target_prob_match[:, number_max_probs_match] = 1-torch.sum(target_prob_match, dim=1)\n","print(\"target_prob_match SHAPE: \", target_prob_match.shape)\n","print(\"target_prob_match: \", target_prob_match)\n","print(\"Check sum 1: \", torch.sum(target_prob_match, dim=1))\n","\n","# INDEX TOP X TO MATCH\n","target_idx_match = torch.zeros(idx_probs.shape[0], number_max_probs_match, dtype=torch.long).to(device)\n","target_idx_match[:, 0:number_max_probs_match] = idx_probs[:,0:number_max_probs_match]\n","print(\"target_idx_match SHAPE: \", target_idx_match.shape)\n","print(\"target_idx_match: \", target_idx_match)"]},{"cell_type":"markdown","metadata":{"id":"psxNlOotdXF1"},"source":["### PREPARE DATASET FOR CONTEXT DISTILLATION TRAINING"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"Bok4IJ9MyAAX","executionInfo":{"status":"ok","timestamp":1714523749064,"user_tz":-120,"elapsed":13,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["# This is specific for Context Distillation obtaining data\n","# format examples functions formats according to different types of formats for CD (based on ICL format options)\n","\n","# select format to use here:\n","format_train_val = format_train_val # set it at the top of notebook in a common place\n","\n","\n","\n","def format_examples_train_CDTRAIN(example_val, format_val = format_train_val):\n","    if format_val== 'minimal':\n","      # \"minimal\" format\n","      return {'text': \"{\"  + example_val['premise'] + \"} {\" + example_val['hypothesis'] + \"}\" + \" ? Ġ\"}\n","    elif format_val== 'gpt3':\n","      # \"minimal\" format\n","      return {'text': \"{\"  + example_val['premise'] + \"} question: {\" + example_val['hypothesis'] + \"}\" + \" Yes or No? answer: Ġ\"}\n","\n","def create_combined_dataset_CDTRAIN(train_ds_yes, train_ds_no, num_expts=num_experiments, num_train_examples=examples_per_exp):\n","    combined_dataset = []\n","    train_examples_yes = [example for example in train_ds_yes]\n","    train_examples_no = [example for example in train_ds_no]\n","\n","\n","    for irep in range(num_expts):\n","          sampled_train_exs_yes = train_examples_yes[int(irep*num_train_examples/2) : int((irep +1)*num_train_examples/2)]\n","          sampled_train_exs_no = train_examples_no[int(irep*num_train_examples/2) : int((irep +1)*num_train_examples/2)]\n","          # for random option if used below\n","          merged_sampled_train_exs = sampled_train_exs_yes + sampled_train_exs_no\n","          shuffled_list = merged_sampled_train_exs.copy()\n","          # Shuffle the copy\n","          random.seed(irep)\n","          random.shuffle(shuffled_list)\n","\n","          # RETHINK THIS, MOVE INSIDE NEXT FOR LOOP\n","          # combined_ex = {'text': '', 'label': val_ex['label'], 'exp': irep}\n","\n","          # Way 1: set examples Yes, No, Yes, No, ...\n","          '''\n","          for idx_train in range(len(sampled_train_exs_yes)):\n","            # put order one Yes and another No consecutively\n","            combined_ex['text'] += sampled_train_exs_yes[idx_train]['text']\n","            combined_ex['text'] += sampled_train_exs_no[idx_train]['text']\n","          '''\n","\n","          # Way 2: set randomized\n","          for idx_shuffled_list in range(len(shuffled_list)):\n","\n","            combined_ex = {'text': '', 'label': shuffled_list[idx_shuffled_list]['label'], 'exp': torch.tensor(irep+1).to(device), 'OPT_prob_CD': torch.zeros(0).half().to(device), 'OPT_idx_CD': torch.zeros(0).half().to(device)}\n","            combined_ex['text'] += shuffled_list[idx_shuffled_list]['text']\n","            combined_dataset.append([combined_ex])\n","\n","    return combined_dataset\n","\n","\n","def dynamic_padding_collate_fn_CDTRAIN(batch):\n","    # This function is created to be able to tokenize dynamically to max length within each batch\n","    # Also, by modifying the tokenizer used, several other options are available\n","    # for example, if we set padding to a specified max_length, for example the model max_length, is also an option, not the default though\n","    # the default is the dynamic padding\n","\n","    batch = [item for sublist in batch for item in sublist]\n","\n","    texts = [item['text'] for item in batch]\n","    labels = [item['label'] for item in batch]\n","    exps = [item['exp'] for item in batch]\n","    OPT_probs_cd = [item['OPT_prob_CD'] for item in batch]\n","    OPT_idxs_cd = [item['OPT_idx_CD'] for item in batch]\n","\n","\n","    # choose option\n","    tokenized_inputs = OPT_tokenizer(texts, padding=\"longest\", truncation=True, return_tensors=\"pt\")\n","    # tokenized_inputs = OPT_tokenizer(texts, padding=\"max_length\", max_length = 2048, truncation=True, return_tensors=\"pt\")\n","\n","    labels_tensor = torch.tensor(labels, dtype=torch.long).to(device)\n","    exps_tensor = torch.tensor(exps, dtype=torch.long).to(device)\n","    OPT_probs_cd_tensor = torch.cat(OPT_probs_cd, dim=0)\n","    OPT_idxs_cd_tensor = torch.cat(OPT_idxs_cd, dim=0)\n","\n","\n","    return {\n","        'input_ids': tokenized_inputs['input_ids'],\n","        'attention_mask': tokenized_inputs['attention_mask'],\n","        'labels': labels_tensor,\n","        'exps': exps_tensor,\n","        'OPT_probs': OPT_probs_cd_tensor,\n","        'OPT_idxs': OPT_idxs_cd_tensor,\n","    }\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, combined_dataset):\n","        self.dataset = combined_dataset\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        return self.dataset[idx]\n"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"8NbM9NJC0syK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523749064,"user_tz":-120,"elapsed":12,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"4845f151-db3f-47c8-d84e-1932ffcfe2c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["<__main__.CustomDataset object at 0x7a1f709a2a70>\n"]}],"source":["\n","\n","formatted_train_dataset_yes_CDTRAIN = train_dataset_yes.map(format_examples_train_CDTRAIN)\n","formatted_train_dataset_no_CDTRAIN = train_dataset_no.map(format_examples_train_CDTRAIN)\n","\n","\n","combined_dataset_CDTRAIN = create_combined_dataset_CDTRAIN(\n","                                          train_ds_yes = formatted_train_dataset_yes_CDTRAIN,\n","                                          train_ds_no = formatted_train_dataset_no_CDTRAIN,\n","                                          num_expts=num_experiments,\n","                                          num_train_examples=examples_per_exp,\n","                                           )\n","\n","custom_dataset_CDTRAIN = CustomDataset(combined_dataset_CDTRAIN)\n","print(custom_dataset_CDTRAIN)\n","\n","# Last step, we create Dataloader passing the bx_size for inference (typically: 1, 4, 8, 16)\n","bx_size = bx_size # set it up at the beg of NB\n","dataloader_CDTRAIN = DataLoader(custom_dataset_CDTRAIN, batch_size=bx_size, collate_fn=dynamic_padding_collate_fn_CDTRAIN, shuffle=False) #shuffle=False for reproducibility"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"sFxoLA5q9ZL5","executionInfo":{"status":"ok","timestamp":1714523749064,"user_tz":-120,"elapsed":11,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["def add_scores_to_dataset(dataset, probs_tensor, idx_tensor):\n","    new_data = []\n","    idx = 0\n","    for item in dataset:\n","        # Copy the original item\n","        new_item = item.copy()\n","        #print(\"new item: \", new_item)\n","\n","        # Compute the score for this item using a provided function\n","        new_item[0]['OPT_prob_CD'] = torch.unsqueeze(probs_tensor[idx,:],0)\n","        new_item[0]['OPT_idx_CD'] = torch.unsqueeze(idx_tensor[idx,:],0)\n","\n","        # Append the new item to the new data list\n","        new_data.append(new_item)\n","        idx = idx +1\n","\n","    # Return a new dataset instance with the updated data\n","    return CustomDataset(new_data)\n"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"Nz-BRVBS9f5S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523749532,"user_tz":-120,"elapsed":479,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"66c943ef-84d2-4eae-bb23-bc0e4513eb51"},"outputs":[{"output_type":"stream","name":"stdout","text":["<__main__.CustomDataset object at 0x7a20e6a68a60>\n","ORIGINAL:  0 experiment#:  tensor([1], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  ['</s>{The chief complaint of reformers these days is that the power of special-interest money is breeding public cynicism about the political process.} question: {Reformers never complain about special interest money.  } Yes or No? answer: Ġ']\n","ORIGINAL:  1 experiment#:  tensor([1], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  [\"</s>{The game's up.} question: {The game keeps going.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  2 experiment#:  tensor([1], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  [\"</s>{Nobody pointed out that at Chappaquiddick, unlike Dallas and Los Angeles, the person most responsible for the tragedy was a Kennedy, whereas the victim was not--and that Ted Kennedy's invocation of the family curse was a clever way of papering over these differences.} question: {Ted Kennedy invoked a family curse that has plagued the Kennedys.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  3 experiment#:  tensor([1], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  ['</s>{Check with the tourist information centers for details about these and similar events at Dalemain, Holker Hall, and Muncaster Castle.} question: {The tourist information centers have information about events at Holker Hall.} Yes or No? answer: Ġ']\n","ORIGINAL:  4 experiment#:  tensor([1], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  ['</s>{He set up a national e-mail tree designed to get people to send their friends in Iowa to Ames as Forbes supporters.} question: {He wanted to set up a national e-mail tree, but gave up halfway.} Yes or No? answer: Ġ']\n","ORIGINAL:  5 experiment#:  tensor([1], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  [\"</s>{The English philanthropist visited the city several times and organized the construction of Mishkenot Sha'ananim, a row of dwellings built to encourage Jews to move from the overcrowded Jewish Quarter of the Old Cityto more modern and healthy places outside the walls.} question: {Mishkenot Sha'ananim was constructed by an English philanthropist.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  6 experiment#:  tensor([1], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  ['</s>{Since NOx emissions result in formation of ground-level ozone, reducing NOx emissions will reduce ozone levels and thus reduce the deleterious effects of ozone on human health and ecosystems.} question: {The formation of ground level ozone is affected by NOx emissions.} Yes or No? answer: Ġ']\n","ORIGINAL:  7 experiment#:  tensor([1], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  ['</s>{Thus, in 1997, on average, households made less than one payment by mail for every two bills received in the mail.} question: {Households make 80% of their payments by mail.} Yes or No? answer: Ġ']\n","ORIGINAL:  8 experiment#:  tensor([1], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  [\"</s>{Mary and John stand on either side of the crucified Jesus upheld by his Father, while the dove of the Holy Spirit hovers between them, the whole forming an inspiring triangle under the coffered ceiling of a Renaissance chapel.} question: {Only Jesus, alone on the cross, is depicted on the chapel's ceiling.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  9 experiment#:  tensor([1], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  [\"</s>{'Think about what you're doing,' I implored.} question: {I told him to think about his actions.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  10 experiment#:  tensor([1], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  ['</s>{Rather. Another silence.} question: {Rather. A long period of incessant chatter.} Yes or No? answer: Ġ']\n","ORIGINAL:  11 experiment#:  tensor([1], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  ['</s>{Because many different packages are available, and because more than one can be used, auditors should determine what models, if any, are used in their agencies.} question: {Auditors have the option of choosing a model to use.} Yes or No? answer: Ġ']\n","ORIGINAL:  12 experiment#:  tensor([1], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  [\"</s>{Think of the Briefing section as your quick hit on the day's and week's news.} question: {It contains both daily and weekly information.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  13 experiment#:  tensor([1], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  [\"</s>{Who put it in the chest, I wonder?} question: {I'm curious as to who put it in the chest.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  14 experiment#:  tensor([1], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  [\"</s>{learn your colors learn your alphabet learn all your your little terms here and and learn how to uh begin learning some of the reading and by the second or third grade uh the little school system that we're in they have uh really a lot of computers uh it's a very wealthy district as as all that fighting's going on over who gets the money and the like but they have} question: {It's a poor district that argues over benches to sleep on } Yes or No? answer: Ġ\"]\n","ORIGINAL:  15 experiment#:  tensor([1], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  ['</s>{Formal and informal areas are landscaped with pools and fountains, while terraces tumble down the hillsides.} question: {There were no pools or fountains in the informal areas.} Yes or No? answer: Ġ']\n","ORIGINAL:  16 experiment#:  tensor([2], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  [\"</s>{There's a small zoo area where you can see snakes, lizards, birds of prey, wolves, hyenas, foxes, and various desert cats, including cheetahs and leopards.} question: {The zoo is home to a variety of animals including mammals, birds, lizards, and snakes.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  17 experiment#:  tensor([2], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  [\"</s>{and i lived with Dana in school} question: {I didn't lived with Dana} Yes or No? answer: Ġ\"]\n","ORIGINAL:  18 experiment#:  tensor([2], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  ['</s>{I did so, and felt something bitty and sticky shoved down my throat.} question: {I felt something bitty and sticky forced down my throat.} Yes or No? answer: Ġ']\n","ORIGINAL:  19 experiment#:  tensor([2], device='cuda:0')\n","CD_probs:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16)\n","TOKENIZE / DETOKENIZE:  ['</s>{Because a large proportion of street costs are fixed,27 the unit (per piece) street cost initially declines rapidly as volume increases and continues to decline at a decreasing rate.} question: {Street costs remain at $0.00 forever no matter what.} Yes or No? answer: Ġ']\n"]}],"source":["custom_dataset_probs_CDTRAIN = add_scores_to_dataset(custom_dataset_CDTRAIN, target_prob_match, target_idx_match)\n","print(custom_dataset_probs_CDTRAIN)\n","dataloader_CD_probs_CDTRAIN = DataLoader(custom_dataset_probs_CDTRAIN, batch_size=bx_size, collate_fn=dynamic_padding_collate_fn_CDTRAIN, shuffle=False) #shuffle=False for reproducibility\n","dataloader_CD_probs_CDTRAIN\n","\n","for i, batch in enumerate(dataloader_CD_probs_CDTRAIN):\n","    if i<20:\n","      print(\"ORIGINAL: \", i, \"experiment#: \", batch['exps'])\n","      print(\"CD_probs: \", batch['OPT_probs'])\n","      print(\"TOKENIZE / DETOKENIZE: \", OPT_tokenizer.batch_decode(batch['input_ids']))\n","    else:\n","      break"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"3JzKifzY240B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523750058,"user_tz":-120,"elapsed":548,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"7538d24e-cc07-411d-e015-0d171232fa60"},"outputs":[{"output_type":"stream","name":"stdout","text":["[{'text': '{The chief complaint of reformers these days is that the power of special-interest money is breeding public cynicism about the political process.} question: {Reformers never complain about special interest money.  } Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(1, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{The game's up.} question: {The game keeps going.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(1, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{Nobody pointed out that at Chappaquiddick, unlike Dallas and Los Angeles, the person most responsible for the tragedy was a Kennedy, whereas the victim was not--and that Ted Kennedy's invocation of the family curse was a clever way of papering over these differences.} question: {Ted Kennedy invoked a family curse that has plagued the Kennedys.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(1, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Check with the tourist information centers for details about these and similar events at Dalemain, Holker Hall, and Muncaster Castle.} question: {The tourist information centers have information about events at Holker Hall.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(1, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{He set up a national e-mail tree designed to get people to send their friends in Iowa to Ames as Forbes supporters.} question: {He wanted to set up a national e-mail tree, but gave up halfway.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(1, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{The English philanthropist visited the city several times and organized the construction of Mishkenot Sha'ananim, a row of dwellings built to encourage Jews to move from the overcrowded Jewish Quarter of the Old Cityto more modern and healthy places outside the walls.} question: {Mishkenot Sha'ananim was constructed by an English philanthropist.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(1, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Since NOx emissions result in formation of ground-level ozone, reducing NOx emissions will reduce ozone levels and thus reduce the deleterious effects of ozone on human health and ecosystems.} question: {The formation of ground level ozone is affected by NOx emissions.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(1, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Thus, in 1997, on average, households made less than one payment by mail for every two bills received in the mail.} question: {Households make 80% of their payments by mail.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(1, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{Mary and John stand on either side of the crucified Jesus upheld by his Father, while the dove of the Holy Spirit hovers between them, the whole forming an inspiring triangle under the coffered ceiling of a Renaissance chapel.} question: {Only Jesus, alone on the cross, is depicted on the chapel's ceiling.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(1, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{'Think about what you're doing,' I implored.} question: {I told him to think about his actions.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(1, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Rather. Another silence.} question: {Rather. A long period of incessant chatter.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(1, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Because many different packages are available, and because more than one can be used, auditors should determine what models, if any, are used in their agencies.} question: {Auditors have the option of choosing a model to use.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(1, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{Think of the Briefing section as your quick hit on the day's and week's news.} question: {It contains both daily and weekly information.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(1, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{Who put it in the chest, I wonder?} question: {I'm curious as to who put it in the chest.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(1, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{learn your colors learn your alphabet learn all your your little terms here and and learn how to uh begin learning some of the reading and by the second or third grade uh the little school system that we're in they have uh really a lot of computers uh it's a very wealthy district as as all that fighting's going on over who gets the money and the like but they have} question: {It's a poor district that argues over benches to sleep on } Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(1, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Formal and informal areas are landscaped with pools and fountains, while terraces tumble down the hillsides.} question: {There were no pools or fountains in the informal areas.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(1, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{There's a small zoo area where you can see snakes, lizards, birds of prey, wolves, hyenas, foxes, and various desert cats, including cheetahs and leopards.} question: {The zoo is home to a variety of animals including mammals, birds, lizards, and snakes.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(2, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{and i lived with Dana in school} question: {I didn't lived with Dana} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(2, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{I did so, and felt something bitty and sticky shoved down my throat.} question: {I felt something bitty and sticky forced down my throat.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(2, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Because a large proportion of street costs are fixed,27 the unit (per piece) street cost initially declines rapidly as volume increases and continues to decline at a decreasing rate.} question: {Street costs remain at $0.00 forever no matter what.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(2, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{The value of scale is about $4.} question: {The scale has a value of $4.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(2, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{yeah it's it's been uh we we bought this house with the idea that we were going to spend you know spend a lot of time working on it and uh it was part you know part of the excitement was was getting a good deal on an older house it just it really hadn't been taken care of very well it it was actually it was rented out for a couple of years and things like that so we uh we ended up getting a fairly good deal on it but uh there just isn't enough time i i've i find myself going to work knowing that that there's a job about half done at home and i really if i would if i'd just stay home and finish it i'd feel a lot better but uh i'm i'm starting to learn that there's always something else so that you could  once you get done you can always start over and and you make up all kinds of excuses so uh} question: {we bought the house with the intention of doing it up, but we just haven't had the time, which is really frustrating.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(2, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Here the streets are almost always full of people, who congregate in local bars and restaurants.} question: {The streets are usually filled with people in bars and eateries.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(2, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Somehow I got the feeling, when reading The Microsoft Way , that I was reading about the greatness of the French army and its Maginot line in 1939.} question: {The Microsoft Way did not remind me of the French army.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(2, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{Shouldn't have thought it.} question: {Shouldn't have entertained that idea.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(2, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{As the road climbs higher you'll reach a hidden valley, left behind as the glaciers of the Ice Age melted.} question: {The valley is noticeable almost immediately. } Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(2, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{So it's kind of a problem.} question: {It isn't a problem, this whole situation is not complex.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(2, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Linda Samels Ceballos entered Loyola Law School in Los Angeles knowing she wanted to represent the poor.} question: {Linda Ceballos went to Loyal Law School.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(2, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{I will share her story another time as it has little connection to Susan other than to say I used to work for them and then later I did not.} question: {Her story is totally intertwined with Susan's.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(2, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{The English gutter press, which was just developing a wide audience, whipped up public hatred toward him over his sex crimes and made him a pariah.} question: {He had a clean criminal record.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(2, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{could they do road work and those kind of things and now and then you get somebody like Charles Manson who just even hasn't a guy around} question: {They couldn't do things like roadwork.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(2, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{The Astronomer said, \"I don\\'t understand you.\"} question: {They are confused.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(2, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{Corruption and tax-evasion continued, but police clamped down on the political terrorism of the Red Brigades and neo-Fascists and the age-old criminality of the Mafia.} question: {Police didn't fight terrorism at all.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(3, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{So that's the next } question: {That isn't going to be next} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(3, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{Second, we held that the LSCA did not explicitly authorize a private right of action against the LSC.} question: {The LCSA's private right of action against the LSC wasn't explicitly authorized.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(3, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{uh well for example uh in Greek there are seven different words for love} question: {The word love only has one word meaning in the Greek language.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(3, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{You yourself did not happen to notice, madame, when you entered Mrs. Inglethorp's room, whether that door was bolted or not?} question: {Did you notice if the door Mrs. Inglethorp's room was locked or not?} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(3, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{If you're up to a climb, take the Mount Austin road to the Victoria Peak Gardens.} question: {It is a hike to get to the Victoria Peak Gardens.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(3, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{you didn't yeah} question: {Yes you did.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(3, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Yet Hawaii was still an island paradise in the eyes of travelers, if not in those of its original people.} question: {Travelers think that Hawaii is an island paradise.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(3, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Now we have become an atomized society of individuals who get their news--if they get it at all--from TV.} question: {All of our news is on radio and in newspapers.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(3, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{ To Help You Order  } question: {Help your order here.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(3, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Well, they\\'ll produce a Jane Finn of their own say at a pensionnat in Paris.\" Tuppence gasped, and Mr. Carter smiled.} question: {Tuppence gasped, and so did Mr. Carter.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(3, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{But I find his storytelling both morally easy and artistically promiscuous.} question: {His storytelling is easy.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(3, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{The estimate of labor includes planning and engineering, general labor, and skilled boilermakers.} question: {To estimate the cost of labor, one must include planning as a component.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(3, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{right yeah well i've i've managed to i guess the work i do gives me a little bit of well a lot of walking and a little bit of lifting on occasion} question: {The work I do is pretty sedentary, so I have to go to they gym.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(3, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{The Ayuntamiento houses a small picture gallery and a chapel with tiles from Manises, an important Valencian ceramics centre.} question: {While attractive from the outside, there is nothing to be seen inside the Ayuntamiento.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(3, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{Rennie was not too common a name, but he did not see how Johnny could possibly have hit upon the truth.} question: {He didn't know how Johnny had discovered the truth.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(3, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{The term limits craze makes a nice case study in political demagoguery.} question: {There is a lot of discussion surrounding term limits.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(4, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{um and you know was a a problem with having five children needing to work a uh full-time job that was more than a full-time job i worked about fifty one hours a week because i worked every worked eleven hours every Sunday} question: {I did not work on Sunday.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(4, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Many responses were built on the assumption that Southern Baptists are bad in bed.} question: {There was universal support for the idea that Southern Baptists are great in bed.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(4, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{is it i i'm from i've lived in Ohio and i didn't realize that} question: {I stayed in Michigan and I knew that} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(4, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{'I don't know.} question: {I had all the answers.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(4, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{you know that that they're not in the home by choice anymore} question: {They're not in the home by choice} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(4, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{The meat and the chefs are sometimes imported from South America.} question: {The meat is imported from South America.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(4, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{A $16 billion discrepancy may not seem much when measured against the total budget, with all its sacrosanct or unavoidable obligations.} question: {The total budget is higher than $16 billion.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(4, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{'I am history come to life?' I tried again, uncertainly.} question: {I asked if I was history coming to life.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(4, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{'Well then.} question: {Absolutely not. } Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(4, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{The interim final rule does not impose any unfunded mandates upon state, local or tribal governments or the private sector under the Unfunded Mandates Reform Act of 1995.} question: {The interim final rule imposes many unfunded mandates upon state, local or tribal governments.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(4, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{It concluded the section specified four categories of prohibited activities, of which three appear[ed] to prohibit the type of activity named regardless of viewpoint, while one might be read to prohibit the activity only when it seeks reform.} question: {Four categories of prohibited activities were specified in the section.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(4, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{The Private Express Statutes in the United States do not prevent private firms from delivering parcels, periodicals, catalogs over 24 pages, or saturation mail.} question: {Private firms are allowed to deliver parcels and periodicals.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(4, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{You'll find a self-portrait just right of the room's entrance.} question: {The portrait that once hung near the entrance was just auctioned off last week.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(4, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{It's true that Heston the activist has accomplished more than most private citizens ever hope to.} question: {Heston has proven that he can't accomplish anything.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(4, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{The product may be addressed to committees of jurisdiction or the affected agency.} question: {The product can be sent to the committees of jurisdiction for that agency.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(4, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{We deal with a lot of emergencies, Comart said. } question: {Comart reported that there were never any emergencies.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(5, device='cuda:0'), 'OPT_prob_CD': tensor([[5.4297e-01, 4.4092e-01, 1.4811e-03, 1.0443e-03, 8.8120e-04, 6.8235e-04,\n","         6.5088e-04, 5.0879e-04, 4.9973e-04, 4.6539e-04, 3.0470e-04, 2.8133e-04,\n","         2.5344e-04, 2.2280e-04, 1.9479e-04, 1.9407e-04, 1.9097e-04, 1.8394e-04,\n","         1.7178e-04, 1.5235e-04, 1.4484e-04, 1.4257e-04, 1.3459e-04, 1.2469e-04,\n","         1.2314e-04, 1.2231e-04, 1.1802e-04, 1.1581e-04, 1.1516e-04, 1.1230e-04,\n","         1.1212e-04, 1.0478e-04, 9.4712e-05, 9.3937e-05, 9.3162e-05, 9.2149e-05,\n","         9.2030e-05, 8.8394e-05, 8.8215e-05, 8.8155e-05, 8.1956e-05, 8.0943e-05,\n","         7.7546e-05, 7.6354e-05, 7.3195e-05, 7.2777e-05, 7.1704e-05, 6.5684e-05,\n","         6.4373e-05, 6.3598e-05, 4.8828e-03]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idx_CD': tensor([[ 3084,  9904,  7199, 29802, 39254, 14541,   487, 16991,   100,   243,\n","         13449, 10932,   440,  3216, 14783, 22491,  2362, 36948, 32541,   970,\n","         12350, 33239, 10643,  1213,   170,  1185,   250,  6323,   133,  2895,\n","          7516, 46659,  1711, 50118,  8346,  6766,   104, 32476, 37128,   113,\n","         35882, 14563, 25101, 13624, 19847, 19933, 32458,  1121, 31535, 40671]],\n","       device='cuda:0')}]\n","[{'text': \"{I couldn't help noticing that all of her VR equipment was still up and running.} question: {Her VR equipment still worked.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(5, device='cuda:0'), 'OPT_prob_CD': tensor([[6.2793e-01, 3.5962e-01, 9.1362e-04, 8.0347e-04, 7.2527e-04, 5.0306e-04,\n","         4.7946e-04, 4.3917e-04, 4.2295e-04, 4.1008e-04, 3.4046e-04, 3.1805e-04,\n","         2.6822e-04, 2.1720e-04, 1.6940e-04, 1.4675e-04, 1.4079e-04, 1.3185e-04,\n","         1.3101e-04, 1.2791e-04, 1.1617e-04, 1.0496e-04, 1.0097e-04, 9.8825e-05,\n","         9.2685e-05, 9.2447e-05, 9.2208e-05, 8.7500e-05, 8.3268e-05, 8.1956e-05,\n","         7.5698e-05, 7.4208e-05, 7.3314e-05, 7.1585e-05, 6.7770e-05, 6.5684e-05,\n","         6.4731e-05, 6.3419e-05, 6.2466e-05, 6.1393e-05, 5.9843e-05, 5.6982e-05,\n","         5.5492e-05, 5.4717e-05, 5.4002e-05, 5.3763e-05, 5.2631e-05, 5.0247e-05,\n","         4.8578e-05, 4.8399e-05, 3.4180e-03]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idx_CD': tensor([[ 9904,  3084,  7199, 14541,   100,   243, 14783, 39254, 10932, 16991,\n","           487, 29802,  3216, 32541, 36948,  7516, 13449, 12350,  1185,   440,\n","          2362, 46236,  1711, 10643,   250,   970,  6323,  8346,   170,   133,\n","         50118,  1213,  6766,  4420, 33239,   975,   104,   113, 22491, 33082,\n","         31535, 35882,  2895, 42903,  7608, 32476,   894, 32458, 38980,  8275]],\n","       device='cuda:0')}]\n","[{'text': '{well i think that they uh they seem like they are friends with one another and with all of their guests rather than just interviewing} question: {It is clear that they are not friends as the conversations are all business.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(5, device='cuda:0'), 'OPT_prob_CD': tensor([[5.1562e-01, 4.7363e-01, 9.7513e-04, 8.7023e-04, 8.1158e-04, 4.6325e-04,\n","         4.2319e-04, 3.8052e-04, 3.6764e-04, 2.8253e-04, 2.4390e-04, 2.2936e-04,\n","         1.9825e-04, 1.9050e-04, 1.7691e-04, 1.5700e-04, 1.2565e-04, 1.1176e-04,\n","         1.0419e-04, 1.0306e-04, 9.3043e-05, 9.2804e-05, 8.7023e-05, 7.6532e-05,\n","         7.4744e-05, 7.3314e-05, 7.1645e-05, 7.1645e-05, 6.9976e-05, 6.9499e-05,\n","         6.8963e-05, 6.6102e-05, 6.2466e-05, 6.0439e-05, 6.0022e-05, 5.7876e-05,\n","         5.6744e-05, 5.5432e-05, 5.3763e-05, 5.1498e-05, 4.9770e-05, 4.8518e-05,\n","         4.8220e-05, 4.8220e-05, 4.8161e-05, 4.7684e-05, 4.6015e-05, 4.5419e-05,\n","         4.4882e-05, 4.0174e-05, 2.9297e-03]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idx_CD': tensor([[ 3084,  9904, 39254,  7199, 16991, 14541, 29802, 14783,   487,   100,\n","           243, 32541, 13449,  3216, 10932,  7516,   440, 50118, 12350,  2362,\n","         36948,  8346,  1185, 14563, 40671, 33082, 46236, 10643, 32476, 33239,\n","           970, 42903, 31535,  1711,  1213,  2895,   170,   250, 22491, 37128,\n","          6323, 32523,  6766, 34790,  8275,   133, 35882,  4420,   104, 19847]],\n","       device='cuda:0')}]\n","[{'text': '{French drivers are adventurous and even aggressive, but not unskillful.} question: {French drivers are not agrgessive or adventurous, but they are unskilled. } Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(5, device='cuda:0'), 'OPT_prob_CD': tensor([[6.0889e-01, 3.7573e-01, 1.2321e-03, 9.1362e-04, 9.0027e-04, 7.8106e-04,\n","         7.2765e-04, 6.5756e-04, 4.5848e-04, 4.4394e-04, 3.2282e-04, 2.6059e-04,\n","         2.5558e-04, 2.2662e-04, 2.1243e-04, 2.0838e-04, 1.9550e-04, 1.9264e-04,\n","         1.8263e-04, 1.6558e-04, 1.5998e-04, 1.4257e-04, 1.2434e-04, 1.1575e-04,\n","         1.1390e-04, 1.0699e-04, 9.9719e-05, 9.9540e-05, 9.6083e-05, 9.3222e-05,\n","         9.1612e-05, 9.0420e-05, 9.0241e-05, 8.5711e-05, 8.5115e-05, 8.4102e-05,\n","         8.0287e-05, 7.9930e-05, 7.2598e-05, 7.2122e-05, 6.7472e-05, 6.6698e-05,\n","         6.5863e-05, 6.5446e-05, 6.4254e-05, 6.1452e-05, 5.9724e-05, 5.8234e-05,\n","         5.6267e-05, 5.4479e-05, 4.3945e-03]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idx_CD': tensor([[ 3084,  9904,  7199, 14541, 39254,   487, 16991, 29802,   243, 13449,\n","           100, 14783,   440, 32541,  2362, 10932, 33239, 14563,  3216, 36948,\n","         12350,  6323,   250, 50118,  7516, 37128,   970, 10643,  2895, 32476,\n","          1185,   133,  8346, 32458,   104, 22491,  1711, 46659,  6766, 35882,\n","          1121, 40671,   170, 46236, 19933,  8275, 25101,  1213, 31535, 33082]],\n","       device='cuda:0')}]\n","[{'text': '{It is also a comfort if the message comes from a total stranger, as long as the message is for you specifically and personally and not for a name on a mailing list.} question: {It is a comfort to receive a message tha is not personal and is from a mailing list.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(5, device='cuda:0'), 'OPT_prob_CD': tensor([[5.1807e-01, 4.6631e-01, 1.5717e-03, 7.6056e-04, 7.2718e-04, 6.8140e-04,\n","         5.7173e-04, 5.1880e-04, 5.1308e-04, 4.7874e-04, 3.9649e-04, 2.9302e-04,\n","         2.6059e-04, 2.5487e-04, 2.4438e-04, 2.2519e-04, 2.1565e-04, 1.9860e-04,\n","         1.9395e-04, 1.5938e-04, 1.5295e-04, 1.5068e-04, 1.4496e-04, 1.4353e-04,\n","         1.4269e-04, 1.2326e-04, 1.1808e-04, 1.1700e-04, 1.1516e-04, 1.1492e-04,\n","         1.0026e-04, 9.7573e-05, 9.6679e-05, 9.6440e-05, 9.0241e-05, 8.9943e-05,\n","         8.6844e-05, 8.3387e-05, 7.9274e-05, 7.8082e-05, 7.0810e-05, 7.0572e-05,\n","         6.7890e-05, 6.7353e-05, 6.5327e-05, 6.4075e-05, 6.2048e-05, 6.1989e-05,\n","         6.1572e-05, 6.1333e-05, 4.3945e-03]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idx_CD': tensor([[ 9904,  3084,  7199,   243, 14541, 39254, 16991,   100, 29802, 10932,\n","           487,  3216, 13449,  2362,   440, 32541, 14783, 50118, 33239, 10643,\n","          1185, 12350,   970,  6323,   250,  7516, 36948,   133, 32476, 22491,\n","         19933, 40671,  8346, 32458,   113, 13624,  1121,  2895,  6766, 14563,\n","           170,  8275,  1711, 25101,   104,  4420,  1106, 31535, 32523,   713]],\n","       device='cuda:0')}]\n","[{'text': \"{The Department of Defense's (DOD) acquisition policy9 establishes a good framework for developing weapon systems; however, disciplined adherence, more specific criteria, and stronger acquisition incentives are needed to ensure the timely capture and use of knowledge in decision making.} question: {The Department of Defense acquisition policy includes a framework for developing weapon systems.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(5, device='cuda:0'), 'OPT_prob_CD': tensor([[5.3809e-01, 4.5361e-01, 7.2575e-04, 5.5361e-04, 3.9077e-04, 3.8433e-04,\n","         3.0637e-04, 2.7990e-04, 2.6393e-04, 2.4843e-04, 2.2924e-04, 2.1029e-04,\n","         1.8191e-04, 1.4257e-04, 1.2541e-04, 1.1873e-04, 1.1605e-04, 1.0931e-04,\n","         8.5890e-05, 8.2672e-05, 8.0466e-05, 7.4863e-05, 6.9439e-05, 6.5625e-05,\n","         5.7995e-05, 5.7340e-05, 5.5850e-05, 5.4359e-05, 5.3763e-05, 5.2691e-05,\n","         4.9233e-05, 4.8578e-05, 4.8339e-05, 4.7863e-05, 4.6730e-05, 4.6015e-05,\n","         4.5657e-05, 4.4942e-05, 4.0352e-05, 3.9279e-05, 3.8087e-05, 3.7968e-05,\n","         3.7253e-05, 3.5942e-05, 3.4869e-05, 3.4273e-05, 3.4213e-05, 3.4213e-05,\n","         3.4153e-05, 3.3200e-05, 2.4414e-03]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idx_CD': tensor([[ 9904,  3084,  7199, 39254, 29802,   243, 16991,   100, 14541, 10932,\n","         13449,  3216,   487, 14783,   440,  2362, 50118,   133,  6323,   970,\n","         12350, 33239, 36948,   250, 32541,  2895,  1121, 10643,  4420,   104,\n","          8346, 37128,   713,  1711, 41010, 32476,  1185,  7516,   170, 22491,\n","           113, 25101,  8275, 46659, 14563, 31535,  1213,  6766, 32458, 10787]],\n","       device='cuda:0')}]\n","[{'text': '{Look after her, Mr. Hastings. } question: {Mr. Hastings was told to look after her} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(5, device='cuda:0'), 'OPT_prob_CD': tensor([[7.9150e-01, 1.9800e-01, 6.8998e-04, 6.8474e-04, 6.6042e-04, 5.2166e-04,\n","         3.6669e-04, 3.5429e-04, 3.1924e-04, 2.8944e-04, 2.1696e-04, 1.9658e-04,\n","         1.7571e-04, 1.7476e-04, 1.6403e-04, 1.6379e-04, 1.5342e-04, 1.5092e-04,\n","         1.4734e-04, 1.2898e-04, 1.2803e-04, 1.1200e-04, 9.7096e-05, 9.0539e-05,\n","         8.6546e-05, 8.1360e-05, 7.8917e-05, 7.6830e-05, 7.4923e-05, 7.4744e-05,\n","         7.0453e-05, 6.7830e-05, 6.6280e-05, 6.4194e-05, 6.2346e-05, 6.1810e-05,\n","         6.1631e-05, 6.1452e-05, 6.1333e-05, 5.4538e-05, 5.4359e-05, 5.0426e-05,\n","         5.0008e-05, 4.9114e-05, 4.8578e-05, 4.6492e-05, 4.3333e-05, 4.0650e-05,\n","         4.0591e-05, 4.0054e-05, 2.9297e-03]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idx_CD': tensor([[ 9904,  3084, 39254, 10932, 16991,  7199, 14541,   243, 14783,   100,\n","         29802,  3216, 32541,  2515,  1185,  7516, 12350, 13449,   487,   113,\n","         36948,  1711,   894,  8346, 10643, 22491,   250, 32476, 41010,  2362,\n","         33082, 13987,   133,   170,   104,  4420,   970, 46236,  6323, 31535,\n","         40671, 40566,  7608,  6715,  1213,   713, 32458,   975, 19933,   440]],\n","       device='cuda:0')}]\n","[{'text': \"{it was good talking to you} question: {Let's not talk again.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(5, device='cuda:0'), 'OPT_prob_CD': tensor([[5.8594e-01, 3.9795e-01, 1.2131e-03, 1.0128e-03, 9.7275e-04, 5.3930e-04,\n","         5.1546e-04, 5.1069e-04, 5.1022e-04, 4.4894e-04, 4.4847e-04, 3.7599e-04,\n","         3.1805e-04, 2.7227e-04, 2.6202e-04, 2.4486e-04, 2.3937e-04, 2.3293e-04,\n","         2.1100e-04, 1.8883e-04, 1.4889e-04, 1.3483e-04, 1.2934e-04, 1.2648e-04,\n","         1.2350e-04, 1.2302e-04, 1.1772e-04, 1.1635e-04, 1.1468e-04, 1.1265e-04,\n","         1.0818e-04, 1.0312e-04, 9.9599e-05, 9.3162e-05, 9.1255e-05, 9.0063e-05,\n","         8.8394e-05, 8.7738e-05, 8.1599e-05, 8.0585e-05, 7.8559e-05, 7.7128e-05,\n","         7.6890e-05, 7.6413e-05, 7.4267e-05, 7.2837e-05, 7.1704e-05, 7.0989e-05,\n","         7.0453e-05, 6.9737e-05, 4.8828e-03]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idx_CD': tensor([[ 3084,  9904,  7199, 14541,   487, 14783,   243, 39254, 13449,   100,\n","         29802, 32541, 10932, 16991,  7516,  2362, 22491,   440, 12350,  3216,\n","          1185,  6766,  7939, 33082, 10643, 31535,   170, 33239,   113,  8346,\n","           250, 19847, 32476,  1711, 36948,   970,  8275, 46236, 35882, 37128,\n","         14563,  7608, 50118, 42903,  6323, 19933, 38980,   133, 40671, 13987]],\n","       device='cuda:0')}]\n","[{'text': '{OK, OK, I get the magazine really for the articles, but I always look at the pictures first.} question: {I do not like looking at the pictures in the magazine.  } Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(5, device='cuda:0'), 'OPT_prob_CD': tensor([[5.7568e-01, 3.8354e-01, 3.4275e-03, 2.5177e-03, 2.4204e-03, 2.1782e-03,\n","         1.4448e-03, 1.3494e-03, 1.2150e-03, 1.1578e-03, 1.1435e-03, 8.5020e-04,\n","         7.9966e-04, 7.7677e-04, 6.8426e-04, 5.7459e-04, 5.2547e-04, 4.8113e-04,\n","         4.3249e-04, 4.1294e-04, 3.7742e-04, 3.4523e-04, 2.9755e-04, 2.6846e-04,\n","         2.6631e-04, 2.5177e-04, 2.4796e-04, 2.4319e-04, 2.4056e-04, 2.3437e-04,\n","         2.2745e-04, 2.2519e-04, 2.1791e-04, 2.1303e-04, 2.0611e-04, 2.0385e-04,\n","         2.0266e-04, 1.9276e-04, 1.9240e-04, 1.9169e-04, 1.8847e-04, 1.8215e-04,\n","         1.7953e-04, 1.7643e-04, 1.6475e-04, 1.6332e-04, 1.6165e-04, 1.5557e-04,\n","         1.5533e-04, 1.5295e-04, 1.1719e-02]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idx_CD': tensor([[ 9904,  3084, 39254,  7199,   100, 16991, 14541, 14783,   487, 29802,\n","           243, 13449,  7516,   113, 32541,  3216,  1185, 10932, 42903,  8346,\n","           440, 12350, 22491, 50118, 33239,   133,  1711, 46236,  6323,   970,\n","         31535,  2362,  6766, 40671,   975, 33082,   250, 10643, 36948, 14563,\n","         19933,  2895,  1213, 32476, 41010,  7608, 35882, 13624, 25101,   170]],\n","       device='cuda:0')}]\n","[{'text': \"{you know today's young people are short-term pleasure oriented and everything has to be an immediate reward and it has to be fun} question: {Young people today need to be entertained and get instant gratification. } Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(5, device='cuda:0'), 'OPT_prob_CD': tensor([[5.0977e-01, 4.6533e-01, 1.9150e-03, 1.8024e-03, 1.4992e-03, 1.1177e-03,\n","         1.0681e-03, 6.8378e-04, 5.0449e-04, 4.7350e-04, 4.4489e-04, 4.4489e-04,\n","         3.9387e-04, 3.8815e-04, 3.8028e-04, 3.5024e-04, 3.1042e-04, 2.9874e-04,\n","         2.7084e-04, 2.4748e-04, 2.2840e-04, 2.2554e-04, 2.1410e-04, 2.0850e-04,\n","         1.8978e-04, 1.8346e-04, 1.8251e-04, 1.7524e-04, 1.6999e-04, 1.6892e-04,\n","         1.5867e-04, 1.5843e-04, 1.5807e-04, 1.5700e-04, 1.4865e-04, 1.3733e-04,\n","         1.3697e-04, 1.3530e-04, 1.3280e-04, 1.3244e-04, 1.3161e-04, 1.3030e-04,\n","         1.2743e-04, 1.2624e-04, 1.1945e-04, 1.1557e-04, 1.0836e-04, 1.0377e-04,\n","         1.0109e-04, 1.0008e-04, 7.8125e-03]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idx_CD': tensor([[ 3084,  9904, 14541,  7199,   100, 14783,   243, 10932, 39254,  7516,\n","         29802, 12350, 16991,  2362, 32541,   487,  8346, 13449, 10643,  1185,\n","           440,  6323,  1711,  3216,  6766,   970, 32458,  2895, 32476, 50118,\n","         22491,   133, 35882,   250, 42903, 32523, 33082,   170,   113, 25101,\n","          8275,  1213,   104, 33239,  1121, 13624, 31535, 38980,  7608, 46236]],\n","       device='cuda:0')}]\n","[{'text': \"{no i like the team i really really like the Eagles a lot but uh Buddy Ryan  is not one of my favorite people so i wasn't too disappointed to see them lose} question: {I am in love with Buddy Ryan.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(5, device='cuda:0'), 'OPT_prob_CD': tensor([[5.5957e-01, 4.1138e-01, 2.9068e-03, 1.9073e-03, 1.5755e-03, 1.4610e-03,\n","         1.1110e-03, 8.4019e-04, 8.1730e-04, 7.0047e-04, 6.7663e-04, 6.0844e-04,\n","         5.9986e-04, 4.6325e-04, 4.2915e-04, 4.2725e-04, 3.8695e-04, 3.3903e-04,\n","         3.2091e-04, 3.0875e-04, 2.7609e-04, 2.7037e-04, 2.6393e-04, 2.5868e-04,\n","         2.4259e-04, 2.3258e-04, 2.2364e-04, 2.0683e-04, 2.0111e-04, 1.9217e-04,\n","         1.7011e-04, 1.6093e-04, 1.5700e-04, 1.5402e-04, 1.5354e-04, 1.5068e-04,\n","         1.4877e-04, 1.4758e-04, 1.4305e-04, 1.4043e-04, 1.3208e-04, 1.3018e-04,\n","         1.2839e-04, 1.2290e-04, 1.1796e-04, 1.1575e-04, 1.1551e-04, 1.1498e-04,\n","         1.0735e-04, 1.0264e-04, 8.3008e-03]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idx_CD': tensor([[ 9904,  3084,   100, 14783, 10932, 14541,  7199, 16991,  2362, 39254,\n","          7516,   487,   243,  3216, 13449,   440, 32541, 38980, 12350, 42903,\n","          8346,   894,  1185, 22491, 10643, 29802,   250, 50118, 46236,   975,\n","          1213,  6323, 25101, 35882,  2895, 32523,  1711,   104, 31535,  6766,\n","         33082,  2387,   133, 17425,  4420, 42025,   113, 41010,  7608,   970]],\n","       device='cuda:0')}]\n","[{'text': \"{Be prepared, for it is indeed noisy.} question: {It's noisy in there.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(5, device='cuda:0'), 'OPT_prob_CD': tensor([[5.0195e-01, 4.8682e-01, 7.7915e-04, 6.0844e-04, 4.9448e-04, 4.4894e-04,\n","         4.3178e-04, 3.3140e-04, 3.1543e-04, 3.1018e-04, 2.9206e-04, 2.7919e-04,\n","         2.4557e-04, 2.3031e-04, 2.0194e-04, 1.7428e-04, 1.2165e-04, 1.2141e-04,\n","         1.2112e-04, 1.1790e-04, 1.1271e-04, 1.1188e-04, 1.0204e-04, 9.8288e-05,\n","         9.3281e-05, 8.6784e-05, 7.9453e-05, 7.8917e-05, 7.5102e-05, 7.4208e-05,\n","         7.2598e-05, 7.1645e-05, 6.8367e-05, 6.4909e-05, 6.4492e-05, 6.1810e-05,\n","         6.0081e-05, 5.9187e-05, 5.9187e-05, 5.7697e-05, 5.4717e-05, 5.3406e-05,\n","         5.1975e-05, 4.8459e-05, 4.8459e-05, 4.7028e-05, 4.6313e-05, 4.6074e-05,\n","         4.4525e-05, 4.3273e-05, 3.4180e-03]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idx_CD': tensor([[ 9904,  3084,   243,  7199, 14541, 39254, 14783,   487, 32541, 13449,\n","           100, 29802, 16991,  7516, 10932, 10643,  3216, 22491, 12350, 36948,\n","          8346,  1185,   133,  1711,   970, 32476,  7608,   440,  6766,   250,\n","          2362, 46236,   113, 33239,  8275,   170, 31535, 33082,  6323, 32458,\n","         35882,  2895,  1121,  7939, 40566,  3684, 42903, 19847, 10365,   104]],\n","       device='cuda:0')}]\n","[{'text': '{The carriage creaked and groaned in protest; the whole thing wavering with stress.} question: {The carriage was in great shape.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(5, device='cuda:0'), 'OPT_prob_CD': tensor([[6.2549e-01, 3.6377e-01, 1.6012e-03, 9.9850e-04, 7.5960e-04, 5.8794e-04,\n","         5.4312e-04, 3.6573e-04, 2.7394e-04, 2.3484e-04, 2.1243e-04, 1.9503e-04,\n","         1.2970e-04, 1.2231e-04, 1.2141e-04, 1.1247e-04, 1.1164e-04, 1.0353e-04,\n","         9.8765e-05, 9.6381e-05, 9.3579e-05, 9.0718e-05, 8.6844e-05, 8.6129e-05,\n","         8.4341e-05, 7.9691e-05, 7.5996e-05, 6.8367e-05, 6.5506e-05, 6.0201e-05,\n","         5.9068e-05, 5.6267e-05, 5.5850e-05, 5.4657e-05, 5.2214e-05, 5.0902e-05,\n","         4.8757e-05, 4.7743e-05, 4.6134e-05, 4.3094e-05, 4.2796e-05, 4.2200e-05,\n","         3.8207e-05, 3.7432e-05, 3.6001e-05, 3.5703e-05, 3.4332e-05, 3.3379e-05,\n","         3.2187e-05, 3.1948e-05, 2.4414e-03]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idx_CD': tensor([[ 3084,  9904, 39254, 16991,  7199, 29802,   243, 14541, 13449, 14783,\n","           487,   100, 32541, 10932,  7516, 12350,   440,  3216, 22491, 50118,\n","          2362,  6323,  1711,   133, 33239,   970,  1185,   170,  8346, 36948,\n","          6766, 10643,  2895, 37128,  1213,   104, 19847,   250, 32476,  7608,\n","         14563,  3684, 25101,   894,  8275, 35882, 31535, 33082,   113,   713]],\n","       device='cuda:0')}]\n","[{'text': '{But from there, he goes wrong.} question: {He is wrong starting from there.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(5, device='cuda:0'), 'OPT_prob_CD': tensor([[6.6162e-01, 3.3203e-01, 6.7568e-04, 5.7888e-04, 2.7061e-04, 2.7061e-04,\n","         2.4891e-04, 2.0063e-04, 1.6785e-04, 1.3554e-04, 1.0884e-04, 1.0860e-04,\n","         1.0198e-04, 9.7871e-05, 9.7513e-05, 8.3983e-05, 7.9751e-05, 7.1466e-05,\n","         6.6936e-05, 6.4194e-05, 6.2466e-05, 6.2406e-05, 6.1452e-05, 6.0141e-05,\n","         5.6744e-05, 5.4181e-05, 5.2214e-05, 4.8399e-05, 4.6432e-05, 4.2558e-05,\n","         4.2319e-05, 4.2319e-05, 4.1246e-05, 3.9220e-05, 3.8564e-05, 3.6716e-05,\n","         3.6478e-05, 3.6359e-05, 3.5346e-05, 3.4332e-05, 3.2604e-05, 3.2127e-05,\n","         3.1650e-05, 3.1650e-05, 3.1531e-05, 2.9504e-05, 2.9027e-05, 2.9027e-05,\n","         2.7001e-05, 2.5690e-05, 1.4648e-03]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idx_CD': tensor([[ 3084,  9904,  7199, 14541, 29802,   243,   487, 13449,   440, 39254,\n","           100, 14783,  3216, 10932,  6323, 32541, 10643, 16991,   970,  2362,\n","         22491, 37128,   133,   894, 36948, 32476,   250, 32458,  1185,  7516,\n","         35882,  2895,  1711,  1121, 33239,  8275, 32523,  8346, 13624, 14563,\n","           170,   104, 19847, 46659,  6766, 12350, 19933, 50118, 46236, 10787]],\n","       device='cuda:0')}]\n","[{'text': \"{yeah compared to some of the other ones and you don't have an annual fee there and that helps} question: {It's good because they don't charge you every year for the service. } Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(5, device='cuda:0'), 'OPT_prob_CD': tensor([[6.4893e-01, 3.3813e-01, 1.4925e-03, 9.1839e-04, 7.8249e-04, 5.8937e-04,\n","         4.2868e-04, 3.7265e-04, 3.7193e-04, 2.4152e-04, 2.4009e-04, 2.3615e-04,\n","         2.0552e-04, 1.7238e-04, 1.7166e-04, 1.6570e-04, 1.6177e-04, 1.4913e-04,\n","         1.3566e-04, 1.3494e-04, 1.3280e-04, 1.2743e-04, 1.2130e-04, 1.2124e-04,\n","         1.1337e-04, 1.1128e-04, 9.9063e-05, 9.4414e-05, 8.9228e-05, 8.6963e-05,\n","         8.5354e-05, 7.9572e-05, 7.8380e-05, 7.5698e-05, 7.2598e-05, 6.9737e-05,\n","         6.7055e-05, 6.6459e-05, 6.4969e-05, 6.1989e-05, 6.1154e-05, 6.0916e-05,\n","         6.0499e-05, 5.8532e-05, 5.5254e-05, 5.5194e-05, 5.4598e-05, 5.3763e-05,\n","         5.1439e-05, 5.0306e-05, 3.4180e-03]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idx_CD': tensor([[ 9904,  3084, 14783, 14541,   243,  7199, 10932,   100, 32541,  3216,\n","           487,  7516, 12350, 29802,  2362,  8346,  1185, 46236, 39254, 33082,\n","          1711, 13449, 16991, 10643,   970, 36948, 42903,  6323, 32476,   440,\n","           133, 35882,   975,  4420, 32523, 50118, 31535,   250,  6766, 38980,\n","          1213,   104, 25101,  2895,  1121, 13987, 40566,  7608, 32458,  1106]],\n","       device='cuda:0')}]\n","[{'text': '{Art History} question: {History of Art} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(5, device='cuda:0'), 'OPT_prob_CD': tensor([[6.1133e-01, 3.7158e-01, 1.8101e-03, 1.2369e-03, 7.5865e-04, 7.0858e-04,\n","         7.0143e-04, 5.4789e-04, 5.2738e-04, 4.7827e-04, 3.4666e-04, 3.3426e-04,\n","         2.9922e-04, 2.7013e-04, 2.1899e-04, 1.9443e-04, 1.8728e-04, 1.6642e-04,\n","         1.5903e-04, 1.4484e-04, 1.4102e-04, 1.3363e-04, 1.3292e-04, 1.2493e-04,\n","         1.1593e-04, 1.1075e-04, 1.0967e-04, 1.0449e-04, 1.0437e-04, 1.0151e-04,\n","         9.9838e-05, 9.6381e-05, 9.6321e-05, 9.1255e-05, 9.0241e-05, 8.1599e-05,\n","         7.9870e-05, 7.8559e-05, 7.7963e-05, 7.7367e-05, 7.3254e-05, 7.2837e-05,\n","         7.1645e-05, 6.8545e-05, 6.8545e-05, 6.8545e-05, 6.7770e-05, 6.6161e-05,\n","         6.4075e-05, 6.2227e-05, 5.3711e-03]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idx_CD': tensor([[ 9904,  3084, 16991, 39254,   243, 29802,  7199, 10932,   100, 14541,\n","         13449,   487, 14783,  3216, 32541,   133, 12350,   250,  2362,  7516,\n","         10643, 36948,  1185,  8346,   440,   113,  3684, 41010,   970, 40671,\n","           104,   170, 22491, 33239,  6323,  8275,  7608, 50118,  1711, 19933,\n","          1213,  2895, 46236,   108,  1121,  6766, 33082,   713, 14563, 32476]],\n","       device='cuda:0')}]\n","[{'text': '{maintains the inhouse capabilities to perform the design reviewrelated Do Federal Agencies Face functions listed above.} question: {They need the capability to perform a design review.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(6, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Queens and royal children were buried in a valley separate from their fathers and husbands.} question: {Queens and royal children were buried.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(6, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{The New York City Council yesterday offered a radically different set of priorities for the handling of the city's legal work in its response to Mayor Bloomberg's plan to close a projected $4.} question: {Despite Mayor Bloomberg's decision to close an anticipated $4, the NYC Council offered a completely different list of priorities for dealing with the city's legal work.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(6, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{I saw Adrin fight.} question: {Adrin ran away before the fight started.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(6, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{I can't decide if the woman is an actress, since she's able to get by so easily without doing all that much.} question: {She is obviously the hardest working actress out there.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(6, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Ahead was the appointed track, a beaten stretch of earth, part of the old road leading to the mines.} question: {The track was part of the old road that lead to the mines.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(6, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{This is celestially ordained blondness, the mark of God's favor, affirming the signal beauty of the old pagan deities who had already given all blondes--torrid or chilly, fake or real--an edge for 2,000 years.} question: {Blondness considered to be celestially ordained is thought to be the mark of God's favor.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(6, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Somehow, with the coming of the light, the dreads and fancies of the past night seemed absurd.} question: {It is almost dawn.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(6, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{A free walking tour departs every Saturday at 10:00 a.m. from the Plaza Hotel and points out the town's historic sights, most notably the tombs of prominent rabbis.} question: {There is a free walking tour every Saturday morning to see the town's historic places and the tombs of famous rabbis.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(6, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{Charles Rangel, D-N.Y., called the Archer proposal a Christmas tree that's supposed to appeal to every Republican.} question: {The Archer proposal isn't going to appeal to any Republican.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(6, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{He was to have conducted the Lithuanian Symphony Orchestra in the Red Fort as part of the country's 50 th -anniversary celebrations, but the organizers announced this week that the concert was being canceled for unforeseen reasons, while privately hinting that this was because Menuhin was unwell.} question: {Menuhin conducted the symphony at the celebration.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(6, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{She missed the worst part of the Great Depression.} question: {She experienced the worst part of the Great Depression.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(6, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{The regent Kaahumanu, ruling in the name of her young charge, Kamehameha III, seized the opportunity and followed many of the strictures favored by the Calvinist Congregationalists, who were modernizing the country through the establishment of schools and the printing of books in the Hawaiian language (which they formulated in a written form for the first time).} question: {There was never anyone by the name of Kaahumanu in charge in Hawaii.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(6, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Mr. Carter listened in silence with a resumption of his tired manner.} question: {Mr. Carter repeatedly showed signs he was weary of this conversation.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(6, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Whittington was speaking.} question: {Whittington sat silently.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(6, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{The personal saving rate has largely declined since the 1980s, plummeting in recent years to levels not seen since the Great Depression, as shown in figure S.1.} question: {There has been a sharp increase in personal savings rates in the past 30 years.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(6, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{Somehow, that wasn't the answer I'd hoped for.} question: {I heard exactly what I wanted to hear.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(7, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{yeah i mean i've liked them ever since the season that they won the Super Bowl last i think it was eighty four i think it was} question: {I like them in year 2000.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(7, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{uh-huh no no kids} question: {No, plenty of kids.  } Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(7, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{By the 1980s, thanks to the broad avenues and new subway s tops built for the games, this had become one of the liveliest, trendiest, and demographically youngest quarters of the city.} question: {The city improvements on the youngest quarters made it an attractive area.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(7, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{The 15th-century Gothic Casa y Torre de los Lujanes (House and Tower of the Lujanes) has an imposing stone portal and mudejar tower.} question: {Casa y Torre de los Lujanes is a stone built 15th century building. } Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(7, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Julius wired to town for his own car, and they scoured the neighbourhood daily with unflagging zeal.} question: {Julius went by foot and was soon exhausted of scouring the neighborhood.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(7, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{okay in Star Man he was the guy chasing after um Jeff Bridges and Karen Allen or Nancy Allen you know with short nerdy guy with glasses he's} question: {Nancy Allen was chasing after Jeff Bridges.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(7, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{i mean the Kurds have tried it before they've gotten their butts kicked and this is just another time that it's happening} question: {The Kurds tried it but lost.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(7, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{All but one of the programs provided community legal education, 89 percent engaged in outreach activities, and 75 percent disseminated pro se information.} question: {There were no programs that did not provide community legal education.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(7, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{It was finally abandoned towards the fourth century a.d. when the country looked to a new group of deities.} question: {The country has always worshiped only one group of deities.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(7, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{They can't imagine being a part of it.} question: {They know exactly what it is like. } Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(7, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{right i i think in most cases i'd have to say no not unless somebody really enjoys it or} question: {I do not think so unless somebody likes it.  } Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(7, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{At the end of the legendary road to Hana on Maui's remote and lush east shore, this quiet upscale resort on 66 acres with a wild volcanic oceanfront is the oldest in Maui (1946).} question: {The oldest resort in Maui is located at the end of the road to Hana.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(7, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{The Arab town was erected atop this sandy layer and many treasures are still lost below the surface of the modern streets.} question: {The town has no history underneath it.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(7, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{Once on top you can see the ruins of Herod's once-magnificent palace, the ramp that sealed the Zealots' fate, and, way down below, the sketchy remains of the Roman siege camps.} question: {You can see the ruins of Herod's palace from the top of this site.  } Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(7, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{The neighborhood around the church has enough old-fashioned charm to retain something of the town's 19th-century pioneering atmosphere.} question: {The neighborhood surrounding the church has an old charm. } Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(7, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{A small stone tomb in the southeast corner houses the bones of several members of the royal family.} question: {Several royal family members are interred in the southeast corner.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(8, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{So, I woke up in a different world, is that what you want to suggest? Mieczyslaw said.} question: {Nothing has changed, I know.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(8, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Then in 1017 Benedictine monks started work on the flat-roofed abbey you can see in the Bayeux Tapestry, propped up on a platform with blocks of brown granite brought from the Channel islands of Chausey 40 km (25 miles) away.} question: {The abbey was constructed by monks in 1017.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(8, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{The audience wanted to see her struggle.} question: {The audience really wanted to see her do well. } Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(8, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Do you know the saying, We\\'re all grown-ups here?} question: {I know that you frequently use the saying \"We\\'re all grown-ups here.\"} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(8, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{In the frame game, nuance is almost always a loser.} question: {Nuance is great.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(8, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{Even NASA's most enthusiastic supporters must admit that the early promise of this program has been unfulfilled.} question: {The early promise shown by the program hasn't been fulfilled.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(8, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Fascinating combination of continental European and Jamaican styles.} question: {A pleasing fusion of styles both Jamaican and continental European} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(8, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{The Centre also houses a bookstore, coffeehouse, restaurant, and cinema.} question: {There is no coffeehouse located in the Centre. } Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(8, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{For example, an audit cannot create certainty in an environment where there is no certainty.} question: {Audits always create certainty } Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(8, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{Initially, increasing saving and investment adds to the capital stock and boosts worker productivity and the economy's rate of growth.} question: {One way to increase capital stock is to increase savings and investment.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(8, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{and not really interested in some of the like the Terminator or some of the Schwarzenegger  stuff i just} question: {I don't really like Terminator movies.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(8, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{yeah yeah it was saw a few bears} question: {I didn't see any bears.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(8, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{To assist federal managers, the Committee published guiding principles and key issues for implementing GPRA.} question: {The Committee published guiding principles and key issues to assist federal managers.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(8, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{They didn't meant nothin', jus' funnin'.} question: {They were only telling jokes.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(8, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{The next day they were all dead but Thorn.} question: {Thorn was dead the next day.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(8, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{yeah but do you think he would fine the lawyer} question: {He is being fined by his own lawyer.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(9, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Jeff Rutherford, Trylon Communications  (212) 725-2295 jeffru@tryloncommunications.com} question: {Jeff Rutherford just got fired from Trylon so his contacts are not working anymore.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(9, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Maryland has a lot to trumpet, Bergmark added. } question: {Maryland is struggling.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(9, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Industrious CW-armed terrorists could kill thousands of New York subway riders in a day.} question: {An attack on the quiet New York subway would result in minimal casualties. } Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(9, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{i tend to not want to go anywhere after that but this way you know you can go to the fitness center right from work and they have aerobics and you know all this machines and all that sort of stuff we're not we're not high rollers like Dallas we don't have a pool but} question: {The fitness center has a pool and nothing else.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(9, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Most beaches protected from the open ocean have rowboats, canoes, or pedalos for rent by the hour.} question: {There are beaches protected from the open ocean. } Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(9, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{Increased cost must also be considered with regard to the President's proposal.} question: {There was no cost increase that needs to be considered.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(9, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{Participants believed that boards need to do a better job of identifying their constituencies and understanding and addressing their concerns.} question: {Participants believe that the board is doing a great job and they don't need to change.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(9, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{The foundations of the fort can still be seen, but artifacts from the site are displayed in the Huntly House Museum in Edinburgh.} question: {The artifacts have been bought collectively by an individual.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(9, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{This year's gathering is limited to lawyers and paralegals working for legal aid organizations.} question: {The gathering this year is limited to lawyers and paralegals who work for legal aid organizations.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(9, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{Israel's best accommodation option, according to many travellers, and usually the first stopping place for visiting heads of state.} question: {It is the best hotel in Israel.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(9, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{But since as many as 30 percent to 40 percent of the graduates at schools like CUNY go into small or solo practices within a few years of graduating, the deans argue, it seems folly not to teach them how to stay afloat financially and take on low-income clients at the same time.} question: {The school deans believe that it would be foolish to not endow their students with basic financial knowledge, as well as training in accepting lower-earning clientele, since many of the students become private practitioners or part of a small business. } Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(9, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{And there is Sallie Mae (Student Loan Marketing Association), which creates a similar secondary market in subsidized student loans.} question: {And Sallie Mae is there (Student Loan Marketing Association), it creates a similar secondary market in subsidized student loans.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(9, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{hum-um no i used to i really did uh years ago and uh i was thinking about that not too long ago that} question: {I was thinking about it and I did it years ago.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(9, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Nudity on stage can be powerful, and is still protested, but not as powerful as the frightening glimpse I had as a child of Ethel Merman in Gypsy . Now, if you could get the ghost of Ethel Merman and the undead Mickey Rooney to strip to the waist for 10 rounds of bare-knuckle action, that would be truly frightening stage violence.} question: {Stage violence can be very frightening in some cases.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(9, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{but really the main reason is for fuel you know and and when you read so much information that tells you that meats and different animal products you know are causing uh can cause uh different kinds of diseases you know  like heart heart diseases and different diabetes and things like that different kinds of diseases it's like uh is it really worth it and the people i i really think in general people in the United States just don't eat enough vegetables you know because you can talk grain all you want as far as you know cleaning your system out so to speak but you can't beat vegetables to give you all the nutrients and vitamins and and the the the kind that you can't get from a little pill} question: {Vegetables have a lot of nutrients and vitamins we need.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(9, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Is landing with the survivors.} question: {Is descending with the one who are still alive.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(10, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{These managers could now focus on, and be held accountable for, achieving goals instead of merely complying with rules.} question: {The managers could focus on achieving goals instead of following rules.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(10, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{They think this is some kind of heaven.} question: {They think they're in a good place.} Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(10, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{yeah it's really sad like if they did have a big brother big sister program those those people trying to help the kids the parents might have hostilities towards them} question: {The parents do not want any programs for their kids. } Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(10, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{These districts are home to modern hotels, the offices of numerous international aid organizations and other non-governmental organizations (NGOs), and the homes of many expatriots from around the world.} question: {Nowadays, these districts are disaster zones filled exclusively with homeless natives and dilapidated buildings.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(10, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{EPA's analysis indicates that the first year, 60 percent (2,895) of the small entities will expend less than 1 percent of their annual revenue for the rule's compliance costs, 12 percent (569) will expend between 1 percent and 3 percent, and 119 or 2 percent will expend 3 percent or more of their annual revenues for compliance.} question: {The EPA's rule is extremely expensive to comply with.} Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(10, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{'You at least have a gentleman's honour.' I hoped.} question: {You do not have any honor and I am disappointed in you. } Yes or No? answer: Ġ\", 'label': 1, 'exp': tensor(10, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Just be careful with the detonation range, cuz I just had a stuffed snout with gorgonzola, Clarissesettessimo laughed.} question: {Clarissesettessimo gave a warning to be cautious about the detonation range.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(10, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{Mixed reviews for the latest from the hyperintellectual author of The Gold Bug Variations . Powers tries to shed his reputation as inaccessibly scholarly by writing a straightforward novel about a soap company and an employee who gets ovarian cancer.} question: {Powers cares not about his reputation.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(10, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{It is or should be run for the benefit of ordinary people in their daily lives.} question: {There is something that can benefit people.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(10, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{To reach Carlisle, take the M6 north from Penrith, make an exit at junction 43, and take the A69 road left towards Carlisle city center.} question: {You must never leave the M6 in order to reach Carlisle.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(10, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{A couple blocks back from the beach, the main focus of attention is a tidy square, paved with black, egg-shaped stones from the beach, and its 16th-century church, with a blue-and-white tiled steeple.} question: {The 16th century church is situated roughly a couple of blocks from the beach.} Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(10, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': \"{well that's good yeah that's not bad i had two i managed i guess when i was in high school or junior high i managed to talk my parents into letting me have a gerbil} question: {I talked my parents into letting me have a gerbil in high school.  } Yes or No? answer: Ġ\", 'label': 0, 'exp': tensor(10, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{and today was my thesis defense and i passed} question: {I passed my thesis defense today. } Yes or No? answer: Ġ', 'label': 0, 'exp': tensor(10, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{He is also planning lecture tours and shopping a memoir.} question: {He has no further plans for tours and writing.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(10, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n","[{'text': '{I stuck my head out into the black, breathing in the night.} question: {I put my head inside.} Yes or No? answer: Ġ', 'label': 1, 'exp': tensor(10, device='cuda:0'), 'OPT_prob_CD': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n","       device='cuda:0', dtype=torch.float16), 'OPT_idx_CD': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n","       device='cuda:0')}]\n"]}],"source":["for item in custom_dataset_probs_CDTRAIN:\n","  print(item)"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"jLb8gKILAqpO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523750059,"user_tz":-120,"elapsed":32,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"cb5f162e-93cb-41ec-c6d6-1bd4e45f224f"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': tensor([[    2, 45152,   170,   432,    19,    10,   319,     9, 20601,     6,\n","          4556,  2013,    26,     4, 35524,   864,    35, 25522, 14721,  2013,\n","           431,    14,    89,    58,   393,   143, 20601, 49463,  3216,    50,\n","           440,   116,  1948,    35,  4236, 21402]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([1], device='cuda:0'), 'exps': tensor([5], device='cuda:0'), 'OPT_probs': tensor([[5.4297e-01, 4.4092e-01, 1.4811e-03, 1.0443e-03, 8.8120e-04, 6.8235e-04,\n","         6.5088e-04, 5.0879e-04, 4.9973e-04, 4.6539e-04, 3.0470e-04, 2.8133e-04,\n","         2.5344e-04, 2.2280e-04, 1.9479e-04, 1.9407e-04, 1.9097e-04, 1.8394e-04,\n","         1.7178e-04, 1.5235e-04, 1.4484e-04, 1.4257e-04, 1.3459e-04, 1.2469e-04,\n","         1.2314e-04, 1.2231e-04, 1.1802e-04, 1.1581e-04, 1.1516e-04, 1.1230e-04,\n","         1.1212e-04, 1.0478e-04, 9.4712e-05, 9.3937e-05, 9.3162e-05, 9.2149e-05,\n","         9.2030e-05, 8.8394e-05, 8.8215e-05, 8.8155e-05, 8.1956e-05, 8.0943e-05,\n","         7.7546e-05, 7.6354e-05, 7.3195e-05, 7.2777e-05, 7.1704e-05, 6.5684e-05,\n","         6.4373e-05, 6.3598e-05, 4.8828e-03]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idxs': tensor([[ 3084,  9904,  7199, 29802, 39254, 14541,   487, 16991,   100,   243,\n","         13449, 10932,   440,  3216, 14783, 22491,  2362, 36948, 32541,   970,\n","         12350, 33239, 10643,  1213,   170,  1185,   250,  6323,   133,  2895,\n","          7516, 46659,  1711, 50118,  8346,  6766,   104, 32476, 37128,   113,\n","         35882, 14563, 25101, 13624, 19847, 19933, 32458,  1121, 31535, 40671]],\n","       device='cuda:0')}\n","ORIGINAL:  0 experiment#:  tensor([5], device='cuda:0') tensor([1], device='cuda:0')\n","CD_probs:  tensor([[5.4297e-01, 4.4092e-01, 1.4811e-03, 1.0443e-03, 8.8120e-04, 6.8235e-04,\n","         6.5088e-04, 5.0879e-04, 4.9973e-04, 4.6539e-04, 3.0470e-04, 2.8133e-04,\n","         2.5344e-04, 2.2280e-04, 1.9479e-04, 1.9407e-04, 1.9097e-04, 1.8394e-04,\n","         1.7178e-04, 1.5235e-04, 1.4484e-04, 1.4257e-04, 1.3459e-04, 1.2469e-04,\n","         1.2314e-04, 1.2231e-04, 1.1802e-04, 1.1581e-04, 1.1516e-04, 1.1230e-04,\n","         1.1212e-04, 1.0478e-04, 9.4712e-05, 9.3937e-05, 9.3162e-05, 9.2149e-05,\n","         9.2030e-05, 8.8394e-05, 8.8215e-05, 8.8155e-05, 8.1956e-05, 8.0943e-05,\n","         7.7546e-05, 7.6354e-05, 7.3195e-05, 7.2777e-05, 7.1704e-05, 6.5684e-05,\n","         6.4373e-05, 6.3598e-05, 4.8828e-03]], device='cuda:0',\n","       dtype=torch.float16)\n","CD_idxs:  tensor([[ 3084,  9904,  7199, 29802, 39254, 14541,   487, 16991,   100,   243,\n","         13449, 10932,   440,  3216, 14783, 22491,  2362, 36948, 32541,   970,\n","         12350, 33239, 10643,  1213,   170,  1185,   250,  6323,   133,  2895,\n","          7516, 46659,  1711, 50118,  8346,  6766,   104, 32476, 37128,   113,\n","         35882, 14563, 25101, 13624, 19847, 19933, 32458,  1121, 31535, 40671]],\n","       device='cuda:0')\n","TOKENIZE / DETOKENIZE:  ['</s>{We deal with a lot of emergencies, Comart said. } question: {Comart reported that there were never any emergencies.} Yes or No? answer: Ġ']\n","{'input_ids': tensor([[    2, 45152,   100,  1705,    75,   244, 27515,    14,    70,     9,\n","            69,  8311,  2104,    21,   202,    62,     8,   878, 49463,   864,\n","            35, 25522, 13584,  8311,  2104,   202,  1006, 49463,  3216,    50,\n","           440,   116,  1948,    35,  4236, 21402]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([0], device='cuda:0'), 'exps': tensor([5], device='cuda:0'), 'OPT_probs': tensor([[6.2793e-01, 3.5962e-01, 9.1362e-04, 8.0347e-04, 7.2527e-04, 5.0306e-04,\n","         4.7946e-04, 4.3917e-04, 4.2295e-04, 4.1008e-04, 3.4046e-04, 3.1805e-04,\n","         2.6822e-04, 2.1720e-04, 1.6940e-04, 1.4675e-04, 1.4079e-04, 1.3185e-04,\n","         1.3101e-04, 1.2791e-04, 1.1617e-04, 1.0496e-04, 1.0097e-04, 9.8825e-05,\n","         9.2685e-05, 9.2447e-05, 9.2208e-05, 8.7500e-05, 8.3268e-05, 8.1956e-05,\n","         7.5698e-05, 7.4208e-05, 7.3314e-05, 7.1585e-05, 6.7770e-05, 6.5684e-05,\n","         6.4731e-05, 6.3419e-05, 6.2466e-05, 6.1393e-05, 5.9843e-05, 5.6982e-05,\n","         5.5492e-05, 5.4717e-05, 5.4002e-05, 5.3763e-05, 5.2631e-05, 5.0247e-05,\n","         4.8578e-05, 4.8399e-05, 3.4180e-03]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idxs': tensor([[ 9904,  3084,  7199, 14541,   100,   243, 14783, 39254, 10932, 16991,\n","           487, 29802,  3216, 32541, 36948,  7516, 13449, 12350,  1185,   440,\n","          2362, 46236,  1711, 10643,   250,   970,  6323,  8346,   170,   133,\n","         50118,  1213,  6766,  4420, 33239,   975,   104,   113, 22491, 33082,\n","         31535, 35882,  2895, 42903,  7608, 32476,   894, 32458, 38980,  8275]],\n","       device='cuda:0')}\n","ORIGINAL:  1 experiment#:  tensor([5], device='cuda:0') tensor([0], device='cuda:0')\n","CD_probs:  tensor([[6.2793e-01, 3.5962e-01, 9.1362e-04, 8.0347e-04, 7.2527e-04, 5.0306e-04,\n","         4.7946e-04, 4.3917e-04, 4.2295e-04, 4.1008e-04, 3.4046e-04, 3.1805e-04,\n","         2.6822e-04, 2.1720e-04, 1.6940e-04, 1.4675e-04, 1.4079e-04, 1.3185e-04,\n","         1.3101e-04, 1.2791e-04, 1.1617e-04, 1.0496e-04, 1.0097e-04, 9.8825e-05,\n","         9.2685e-05, 9.2447e-05, 9.2208e-05, 8.7500e-05, 8.3268e-05, 8.1956e-05,\n","         7.5698e-05, 7.4208e-05, 7.3314e-05, 7.1585e-05, 6.7770e-05, 6.5684e-05,\n","         6.4731e-05, 6.3419e-05, 6.2466e-05, 6.1393e-05, 5.9843e-05, 5.6982e-05,\n","         5.5492e-05, 5.4717e-05, 5.4002e-05, 5.3763e-05, 5.2631e-05, 5.0247e-05,\n","         4.8578e-05, 4.8399e-05, 3.4180e-03]], device='cuda:0',\n","       dtype=torch.float16)\n","CD_idxs:  tensor([[ 9904,  3084,  7199, 14541,   100,   243, 14783, 39254, 10932, 16991,\n","           487, 29802,  3216, 32541, 36948,  7516, 13449, 12350,  1185,   440,\n","          2362, 46236,  1711, 10643,   250,   970,  6323,  8346,   170,   133,\n","         50118,  1213,  6766,  4420, 33239,   975,   104,   113, 22491, 33082,\n","         31535, 35882,  2895, 42903,  7608, 32476,   894, 32458, 38980,  8275]],\n","       device='cuda:0')\n","TOKENIZE / DETOKENIZE:  [\"</s>{I couldn't help noticing that all of her VR equipment was still up and running.} question: {Her VR equipment still worked.} Yes or No? answer: Ġ\"]\n","{'input_ids': tensor([[    2, 45152,  3056,   939,   206,    14,    51, 37463,    51,  2045,\n","           101,    51,    32,   964,    19,    65,   277,     8,    19,    70,\n","             9,    49,  3958,  1195,    87,    95, 21514, 24303,   864,    35,\n","         25522,   243,    16,   699,    14,    51,    32,    45,   964,    25,\n","             5,  5475,    32,    70,   265, 49463,  3216,    50,   440,   116,\n","          1948,    35,  4236, 21402]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1]]), 'labels': tensor([1], device='cuda:0'), 'exps': tensor([5], device='cuda:0'), 'OPT_probs': tensor([[5.1562e-01, 4.7363e-01, 9.7513e-04, 8.7023e-04, 8.1158e-04, 4.6325e-04,\n","         4.2319e-04, 3.8052e-04, 3.6764e-04, 2.8253e-04, 2.4390e-04, 2.2936e-04,\n","         1.9825e-04, 1.9050e-04, 1.7691e-04, 1.5700e-04, 1.2565e-04, 1.1176e-04,\n","         1.0419e-04, 1.0306e-04, 9.3043e-05, 9.2804e-05, 8.7023e-05, 7.6532e-05,\n","         7.4744e-05, 7.3314e-05, 7.1645e-05, 7.1645e-05, 6.9976e-05, 6.9499e-05,\n","         6.8963e-05, 6.6102e-05, 6.2466e-05, 6.0439e-05, 6.0022e-05, 5.7876e-05,\n","         5.6744e-05, 5.5432e-05, 5.3763e-05, 5.1498e-05, 4.9770e-05, 4.8518e-05,\n","         4.8220e-05, 4.8220e-05, 4.8161e-05, 4.7684e-05, 4.6015e-05, 4.5419e-05,\n","         4.4882e-05, 4.0174e-05, 2.9297e-03]], device='cuda:0',\n","       dtype=torch.float16), 'OPT_idxs': tensor([[ 3084,  9904, 39254,  7199, 16991, 14541, 29802, 14783,   487,   100,\n","           243, 32541, 13449,  3216, 10932,  7516,   440, 50118, 12350,  2362,\n","         36948,  8346,  1185, 14563, 40671, 33082, 46236, 10643, 32476, 33239,\n","           970, 42903, 31535,  1711,  1213,  2895,   170,   250, 22491, 37128,\n","          6323, 32523,  6766, 34790,  8275,   133, 35882,  4420,   104, 19847]],\n","       device='cuda:0')}\n","ORIGINAL:  2 experiment#:  tensor([5], device='cuda:0') tensor([1], device='cuda:0')\n","CD_probs:  tensor([[5.1562e-01, 4.7363e-01, 9.7513e-04, 8.7023e-04, 8.1158e-04, 4.6325e-04,\n","         4.2319e-04, 3.8052e-04, 3.6764e-04, 2.8253e-04, 2.4390e-04, 2.2936e-04,\n","         1.9825e-04, 1.9050e-04, 1.7691e-04, 1.5700e-04, 1.2565e-04, 1.1176e-04,\n","         1.0419e-04, 1.0306e-04, 9.3043e-05, 9.2804e-05, 8.7023e-05, 7.6532e-05,\n","         7.4744e-05, 7.3314e-05, 7.1645e-05, 7.1645e-05, 6.9976e-05, 6.9499e-05,\n","         6.8963e-05, 6.6102e-05, 6.2466e-05, 6.0439e-05, 6.0022e-05, 5.7876e-05,\n","         5.6744e-05, 5.5432e-05, 5.3763e-05, 5.1498e-05, 4.9770e-05, 4.8518e-05,\n","         4.8220e-05, 4.8220e-05, 4.8161e-05, 4.7684e-05, 4.6015e-05, 4.5419e-05,\n","         4.4882e-05, 4.0174e-05, 2.9297e-03]], device='cuda:0',\n","       dtype=torch.float16)\n","CD_idxs:  tensor([[ 3084,  9904, 39254,  7199, 16991, 14541, 29802, 14783,   487,   100,\n","           243, 32541, 13449,  3216, 10932,  7516,   440, 50118, 12350,  2362,\n","         36948,  8346,  1185, 14563, 40671, 33082, 46236, 10643, 32476, 33239,\n","           970, 42903, 31535,  1711,  1213,  2895,   170,   250, 22491, 37128,\n","          6323, 32523,  6766, 34790,  8275,   133, 35882,  4420,   104, 19847]],\n","       device='cuda:0')\n","TOKENIZE / DETOKENIZE:  ['</s>{well i think that they uh they seem like they are friends with one another and with all of their guests rather than just interviewing} question: {It is clear that they are not friends as the conversations are all business.} Yes or No? answer: Ġ']\n"]}],"source":["# filtering for experiment#1:\n","custom_dataset_probs_exp_CDTRAIN = CustomDataset([item for item in custom_dataset_probs_CDTRAIN if item[0]['exp'] == SEL_EXP_TRAIN_CD])\n","dataloader_CD_probs_exp_CDTRAIN = DataLoader(custom_dataset_probs_exp_CDTRAIN, batch_size=bx_size, collate_fn=dynamic_padding_collate_fn_CDTRAIN, shuffle=False) #shuffle=False for reproducibility\n","\n","for i, batch in enumerate(dataloader_CD_probs_exp_CDTRAIN):\n","    if i<3:\n","      print(batch)\n","      print(\"ORIGINAL: \", i, \"experiment#: \", batch['exps'], batch['labels'])\n","      print(\"CD_probs: \", batch['OPT_probs'])\n","      print(\"CD_idxs: \", batch['OPT_idxs'])\n","      print(\"TOKENIZE / DETOKENIZE: \", OPT_tokenizer.batch_decode(batch['input_ids']))\n","    else:\n","      break"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"SutcDff1MROj","executionInfo":{"status":"ok","timestamp":1714523750059,"user_tz":-120,"elapsed":5,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"g2Ll73ujcfP5"},"source":["# 5. TRAIN LOOP"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"oHNSB4t-7aye","executionInfo":{"status":"ok","timestamp":1714523750059,"user_tz":-120,"elapsed":5,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["class myBaseOPT_CD_FT(nn.Module):\n","\n","  def __init__(self, load_model_name = \"facebook/opt-350m\",model_max_tokens=2048, device = 'cuda'):\n","    super(myBaseOPT_CD_FT, self).__init__()\n","\n","    self.model_max_tokens = model_max_tokens\n","    self.device = device\n","\n","    self.coreOPT = OPTForCausalLM.from_pretrained(\n","    load_model_name,\n","    load_in_8bit=False,\n","    torch_dtype=torch.float16,\n","    ).model.to(self.device)\n","\n","    self.lm_OPT_head = OPTForCausalLM.from_pretrained(\n","    load_model_name,\n","    load_in_8bit=False,\n","    torch_dtype=torch.float16,\n","    ).lm_head.to(self.device)\n","\n","  def forward(self, src, attention_mask):\n","\n","    #src.to(device)\n","    #attention_mask.to(device)\n","\n","    core_outputs = self.coreOPT.forward(\n","        src,\n","        attention_mask=attention_mask\n","    )['last_hidden_state']\n","\n","    #print(\"core_outputs: :\", core_outputs)\n","\n","    final_outputs = self.lm_OPT_head.forward(core_outputs)\n","\n","    return final_outputs\n","\n","\n","  def forward_generate(self, src, attention_mask):\n","    # forward used in generate_text function,\n","    # separated from forward function to avoid sending again to device to avoid any issues\n","\n","    core_outputs = self.coreOPT.forward(\n","        src,\n","        attention_mask=attention_mask\n","    )['last_hidden_state']\n","\n","\n","    final_outputs = self.lm_OPT_head.forward(core_outputs)\n","\n","    return final_outputs.to(torch.float32)\n","\n","\n","  def generate_text(self, src_inputs, src_attn, gen_tokens=torch.tensor(1)):\n","\n","\n","    src_len = src_inputs.shape[1]\n","\n","    gen_tokens = gen_tokens.item()\n","\n","\n","    outputs = torch.zeros((src_inputs.shape[0], src_inputs.shape[1] + gen_tokens), dtype=torch.long).to(self.device)\n","    att_mask = torch.zeros((src_attn.shape[0], src_attn.shape[1] + gen_tokens), dtype=torch.long).to(self.device)\n","\n","    outputs[:,0:src_inputs.shape[1]] = src_inputs\n","    att_mask[:,0:src_attn.shape[1]] = src_attn\n","\n","    for t_step in range(gen_tokens):\n","\n","      all_scores = self.forward_generate(outputs[:,0:src_inputs.shape[1]+t_step], att_mask[:,0:src_attn.shape[1]+t_step])\n","\n","      new_tokens = torch.argmax(all_scores[:,-1,:], dim=1)\n","\n","      outputs[:,src_inputs.shape[1]+t_step] = new_tokens\n","      att_mask[:,src_attn.shape[1]+t_step] = 1\n","\n","    # Yes token = 9904\n","    # No token = 3084\n","    binary_yes_no = torch.zeros(all_scores.shape[0]).to(self.device)\n","    binary_yes_no[:] = all_scores[:,-1,9904] - all_scores[:,-1,3084]\n","\n","    binary_yes_no[binary_yes_no >= 0] = 0 # or 9904 if token used \"Yes\"\n","    binary_yes_no[binary_yes_no < 0] = 1 # or 3084 if token used \"No\"\n","\n","    last_scores = all_scores[:,-1,:]\n","\n","    return outputs, binary_yes_no, last_scores"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"5GMRpu7iuVw8","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1714523750059,"user_tz":-120,"elapsed":5,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"53715b77-e615-4084-c71a-728f0b472614"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nif example_myOPT_CD_FT:\\n  del example_myOPT_CD_FT\\n\\n  gc.collect()\\n  torch.cuda.empty_cache()\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":45}],"source":["'''\n","if example_myOPT_CD_FT:\n","  del example_myOPT_CD_FT\n","\n","  gc.collect()\n","  torch.cuda.empty_cache()\n","'''"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"2xMkrDyh7qKX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523790541,"user_tz":-120,"elapsed":40486,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"bcfa1288-db9d-4f18-c1db-cfc6b5940b2d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["myBaseOPT_CD_FT(\n","  (coreOPT): OPTModel(\n","    (decoder): OPTDecoder(\n","      (embed_tokens): Embedding(50272, 2048, padding_idx=1)\n","      (embed_positions): OPTLearnedPositionalEmbedding(2050, 2048)\n","      (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n","      (layers): ModuleList(\n","        (0-23): 24 x OPTDecoderLayer(\n","          (self_attn): OPTAttention(\n","            (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n","            (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n","            (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n","            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n","          )\n","          (activation_fn): ReLU()\n","          (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n","          (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n","          (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (lm_OPT_head): Linear(in_features=2048, out_features=50272, bias=False)\n",")"]},"metadata":{},"execution_count":46}],"source":["example_myOPT_CD_FT = myBaseOPT_CD_FT(load_model_name = model_name, device = device)\n","example_myOPT_CD_FT.half()\n","example_myOPT_CD_FT.to(device)\n","example_myOPT_CD_FT"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"eg7vX4IX9l68","executionInfo":{"status":"ok","timestamp":1714523790542,"user_tz":-120,"elapsed":14,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["for param in example_myOPT_CD_FT.parameters():\n","  if param.ndim <=2:\n","    param.data = param.data.to(torch.float32)\n"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"-8_2awqhUijw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523791405,"user_tz":-120,"elapsed":876,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"c09ad53d-2707-454c-d639-52575970fd1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["('coreOPT.decoder.embed_tokens.weight', Parameter containing:\n","tensor([[ 0.0175, -0.0312, -0.0176,  ..., -0.0374, -0.0247,  0.0100],\n","        [ 0.0168, -0.0312, -0.0161,  ..., -0.0373, -0.0273,  0.0114],\n","        [-0.0407,  0.0519,  0.0574,  ..., -0.0263, -0.0355, -0.0260],\n","        ...,\n","        [ 0.0182, -0.0312, -0.0163,  ..., -0.0359, -0.0312,  0.0133],\n","        [ 0.0189, -0.0312, -0.0171,  ..., -0.0371, -0.0230,  0.0085],\n","        [ 0.0182, -0.0312, -0.0193,  ..., -0.0365, -0.0280, -0.0224]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.embed_positions.weight', Parameter containing:\n","tensor([[-6.0654e-03, -5.9700e-04,  6.3324e-04,  ..., -6.5613e-03,\n","          6.4325e-04,  6.5327e-04],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00],\n","        [-8.1406e-03, -2.6221e-01,  6.0768e-03,  ...,  1.7273e-02,\n","         -5.0621e-03, -1.6220e-02],\n","        ...,\n","        [ 1.2657e-02, -1.1238e-02,  1.3676e-03,  ..., -1.0376e-02,\n","          2.5225e-04,  1.6983e-02],\n","        [ 1.4015e-02, -2.0538e-02,  1.6680e-03,  ..., -1.2383e-02,\n","          3.4618e-03,  1.0521e-02],\n","        [ 1.3672e-02, -3.1860e-02,  8.6746e-03,  ..., -1.5060e-02,\n","          9.3689e-03,  1.4214e-02]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.final_layer_norm.bias', Parameter containing:\n","tensor([ 0.0676,  0.1117,  0.0135,  ...,  0.0628,  0.0627, -0.1261],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.0.self_attn.k_proj.weight', Parameter containing:\n","tensor([[-7.6675e-03,  5.9557e-04, -4.7150e-03,  ...,  8.2588e-04,\n","          7.8087e-03, -4.7760e-03],\n","        [ 2.6321e-02, -3.8376e-03,  5.3406e-03,  ...,  5.8899e-03,\n","          1.0413e-04,  1.5221e-02],\n","        [ 2.9583e-03, -6.4011e-03, -7.6675e-03,  ..., -9.6359e-03,\n","         -1.1581e-02, -2.4452e-03],\n","        ...,\n","        [ 3.7537e-03, -6.2561e-04,  2.2449e-03,  ...,  2.4757e-03,\n","          2.0325e-02, -1.0357e-03],\n","        [ 1.3828e-03, -9.7198e-03, -1.6449e-02,  ...,  1.2321e-03,\n","          1.5327e-02, -4.7989e-03],\n","        [ 5.8353e-05,  8.8654e-03, -1.8936e-02,  ...,  8.0872e-03,\n","         -4.2534e-03,  7.2289e-03]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.0.self_attn.k_proj.bias', Parameter containing:\n","tensor([-2.3329e-04, -3.2597e-03,  1.1778e-03,  ...,  2.1756e-05,\n","         2.9278e-03,  4.9591e-04], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.0.self_attn.v_proj.weight', Parameter containing:\n","tensor([[ 0.0039,  0.0004,  0.0076,  ..., -0.0046, -0.0029,  0.0039],\n","        [ 0.0025, -0.0018,  0.0029,  ...,  0.0016, -0.0013,  0.0022],\n","        [-0.0068,  0.0092,  0.0009,  ...,  0.0024,  0.0026,  0.0100],\n","        ...,\n","        [-0.0006,  0.0017,  0.0016,  ...,  0.0074,  0.0003,  0.0006],\n","        [-0.0010,  0.0005, -0.0051,  ...,  0.0008,  0.0008, -0.0020],\n","        [ 0.0037, -0.0015,  0.0007,  ..., -0.0040,  0.0020, -0.0006]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.0.self_attn.v_proj.bias', Parameter containing:\n","tensor([ 0.0014,  0.0002, -0.0035,  ...,  0.0027,  0.0018, -0.0001],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.0.self_attn.q_proj.weight', Parameter containing:\n","tensor([[ 6.1464e-04,  6.9084e-03,  6.1646e-03,  ...,  1.9135e-02,\n","         -3.2845e-03,  1.6006e-02],\n","        [ 9.1400e-03, -3.7556e-03, -2.5597e-03,  ...,  2.4929e-03,\n","          1.0582e-02,  1.3893e-02],\n","        [-2.6493e-03,  2.4605e-03, -1.1749e-02,  ..., -1.5457e-02,\n","         -9.8877e-03,  7.7171e-03],\n","        ...,\n","        [-4.6234e-03, -1.3027e-03, -1.8967e-02,  ...,  1.1578e-03,\n","          1.0185e-02,  5.7983e-03],\n","        [-5.4240e-06, -1.1917e-02, -1.6220e-02,  ..., -8.8654e-03,\n","          1.7197e-02,  3.4668e-02],\n","        [-1.3313e-02, -7.6981e-03, -2.2446e-02,  ...,  6.1913e-03,\n","          8.7690e-04,  1.6632e-02]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.0.self_attn.q_proj.bias', Parameter containing:\n","tensor([-0.0407, -0.0028, -0.0199,  ..., -0.0168, -0.0078, -0.0042],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.0.self_attn.out_proj.weight', Parameter containing:\n","tensor([[-1.9007e-03,  3.3398e-03,  3.6697e-03,  ..., -3.1986e-03,\n","         -4.5853e-03,  3.7537e-03],\n","        [ 2.9259e-03, -2.5749e-03, -3.3641e-04,  ...,  1.6832e-03,\n","         -1.4162e-03, -2.4090e-03],\n","        [ 6.6223e-03, -2.8152e-03,  9.4032e-04,  ..., -5.1956e-03,\n","         -3.9711e-03,  3.0670e-03],\n","        ...,\n","        [-1.9913e-03, -1.4963e-03,  7.2098e-03,  ...,  4.8137e-04,\n","         -2.0275e-03, -7.7820e-03],\n","        [ 1.4079e-04,  2.1935e-03, -3.3112e-03,  ...,  6.1378e-03,\n","          7.6950e-05,  3.3798e-03],\n","        [-8.7166e-04, -3.2253e-03, -8.7357e-04,  ...,  3.9024e-03,\n","         -2.8687e-03, -1.4391e-03]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.0.self_attn.out_proj.bias', Parameter containing:\n","tensor([-0.0193, -0.0077,  0.0139,  ...,  0.0125,  0.0085,  0.0026],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.0.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.0.self_attn_layer_norm.bias', Parameter containing:\n","tensor([ 0.0638,  0.0932, -0.0633,  ..., -0.0454,  0.0674, -0.0422],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.0.fc1.weight', Parameter containing:\n","tensor([[ 1.8738e-02,  1.0843e-03, -1.0696e-02,  ...,  1.0307e-02,\n","          3.8757e-02,  9.0485e-03],\n","        [ 3.0937e-03,  1.2199e-02,  2.0157e-02,  ..., -3.6194e-02,\n","         -1.8280e-02, -4.5776e-03],\n","        [-1.3367e-02, -8.2703e-03,  1.1467e-02,  ..., -1.6800e-02,\n","          2.0003e-04,  1.5854e-02],\n","        ...,\n","        [ 2.5024e-02,  8.6670e-03, -1.1299e-02,  ...,  1.6724e-02,\n","         -1.4023e-02,  1.1345e-02],\n","        [-4.0092e-03,  6.2447e-03, -8.4534e-03,  ...,  1.1864e-02,\n","          7.6866e-03, -1.6495e-02],\n","        [-3.4103e-03, -5.4419e-05,  1.9089e-02,  ..., -9.5987e-04,\n","         -2.3499e-03,  5.8517e-03]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.0.fc1.bias', Parameter containing:\n","tensor([ 2.3782e-04, -4.9591e-03,  8.1003e-05,  ...,  6.3848e-04,\n","         3.2158e-03,  4.2000e-03], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.0.fc2.weight', Parameter containing:\n","tensor([[ 0.0038,  0.0018,  0.0036,  ...,  0.0076,  0.0043,  0.0104],\n","        [ 0.0041,  0.0049, -0.0276,  ..., -0.0034,  0.0320, -0.0198],\n","        [-0.0193, -0.0160, -0.0307,  ..., -0.0108,  0.0390, -0.0014],\n","        ...,\n","        [-0.0061, -0.0241, -0.0049,  ...,  0.0385,  0.0037, -0.0026],\n","        [-0.0042, -0.0240, -0.0065,  ...,  0.0050,  0.0098, -0.0070],\n","        [-0.0005,  0.0217,  0.0099,  ..., -0.0282, -0.0083,  0.0120]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.0.fc2.bias', Parameter containing:\n","tensor([-0.0102, -0.0209, -0.0010,  ...,  0.0006,  0.0116, -0.0040],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.0.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.0.final_layer_norm.bias', Parameter containing:\n","tensor([-0.1259, -0.1888,  0.1052,  ...,  0.1294, -0.0980,  0.1748],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.1.self_attn.k_proj.weight', Parameter containing:\n","tensor([[-0.0054, -0.0271,  0.0388,  ..., -0.0027,  0.0154, -0.0127],\n","        [ 0.0228, -0.0240, -0.0235,  ...,  0.0010, -0.0063,  0.0157],\n","        [ 0.0055,  0.0093, -0.0348,  ...,  0.0131, -0.0107,  0.0021],\n","        ...,\n","        [ 0.0018, -0.0160, -0.0211,  ...,  0.0054, -0.0133, -0.0023],\n","        [ 0.0136, -0.0370, -0.0150,  ...,  0.0168,  0.0039, -0.0160],\n","        [ 0.0126, -0.0784, -0.0037,  ...,  0.0123,  0.0047,  0.0002]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.1.self_attn.k_proj.bias', Parameter containing:\n","tensor([ 0.0646,  0.0315, -0.0313,  ..., -0.0344, -0.0191,  0.0400],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.1.self_attn.v_proj.weight', Parameter containing:\n","tensor([[-5.6803e-05,  1.0929e-03,  3.1643e-03,  ..., -2.1423e-02,\n","          3.0231e-03,  6.2180e-03],\n","        [ 1.2894e-02, -7.8812e-03, -5.2910e-03,  ...,  4.4556e-03,\n","         -3.4275e-03, -5.5599e-04],\n","        [-1.2989e-03,  3.3779e-03,  3.2978e-03,  ..., -6.6109e-03,\n","          8.5115e-04,  2.7390e-03],\n","        ...,\n","        [-3.8481e-04, -1.8015e-03,  4.7226e-03,  ..., -1.7214e-03,\n","          2.2526e-03, -9.1476e-03],\n","        [-2.4843e-04, -9.5654e-04, -2.9659e-03,  ...,  3.6182e-03,\n","         -7.4654e-03,  9.6989e-04],\n","        [-2.4891e-03,  5.1975e-04,  3.1853e-03,  ..., -4.6806e-03,\n","         -1.2527e-02,  1.3266e-03]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.1.self_attn.v_proj.bias', Parameter containing:\n","tensor([-0.0003, -0.0015,  0.0001,  ...,  0.0039, -0.0025, -0.0002],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.1.self_attn.q_proj.weight', Parameter containing:\n","tensor([[ 0.0224,  0.0103,  0.0079,  ...,  0.0318, -0.0258,  0.0089],\n","        [-0.0065, -0.0224, -0.0793,  ..., -0.0495,  0.0184, -0.0143],\n","        [-0.0171, -0.0305, -0.0382,  ..., -0.0192,  0.0150, -0.0015],\n","        ...,\n","        [ 0.0015,  0.0287, -0.0472,  ..., -0.0313, -0.0129, -0.0088],\n","        [-0.0092, -0.0202, -0.0023,  ..., -0.0142, -0.0108,  0.0020],\n","        [-0.0288, -0.0532, -0.0345,  ..., -0.0073,  0.0069, -0.0123]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.1.self_attn.q_proj.bias', Parameter containing:\n","tensor([-0.0526, -0.0192,  0.0028,  ..., -0.0495, -0.0811, -0.0967],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.1.self_attn.out_proj.weight', Parameter containing:\n","tensor([[-6.5193e-03, -6.8512e-03, -2.2354e-03,  ...,  6.9666e-04,\n","          1.3351e-05, -7.6294e-03],\n","        [-4.8566e-04,  1.3189e-03,  8.0395e-04,  ...,  3.2806e-03,\n","         -1.4532e-04,  3.7708e-03],\n","        [ 9.7847e-04, -1.2636e-03,  2.1000e-03,  ..., -6.3992e-04,\n","         -3.3131e-03,  6.6710e-04],\n","        ...,\n","        [ 3.0727e-03,  4.3678e-03, -5.9395e-03,  ..., -1.9016e-03,\n","          4.1199e-04,  3.5915e-03],\n","        [-7.3481e-04,  2.1324e-03,  9.6369e-04,  ..., -1.3103e-03,\n","          6.1188e-03,  3.0613e-03],\n","        [ 2.6836e-03, -1.5135e-03,  3.9673e-03,  ...,  4.2992e-03,\n","          2.3174e-03, -3.3531e-03]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.1.self_attn.out_proj.bias', Parameter containing:\n","tensor([ 0.0046, -0.0056, -0.0205,  ...,  0.0056, -0.0012,  0.0071],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.1.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.1.self_attn_layer_norm.bias', Parameter containing:\n","tensor([ 0.0301,  0.1770,  0.0273,  ..., -0.0341,  0.0184,  0.0019],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.1.fc1.weight', Parameter containing:\n","tensor([[ 0.0028,  0.0037,  0.0142,  ..., -0.0221, -0.0250, -0.0143],\n","        [-0.0048, -0.0070, -0.0055,  ...,  0.0135,  0.0098, -0.0084],\n","        [-0.0025, -0.0277,  0.0012,  ...,  0.0344,  0.0403, -0.0248],\n","        ...,\n","        [-0.0059,  0.0041,  0.0003,  ..., -0.0153,  0.0003, -0.0135],\n","        [-0.0048,  0.0064,  0.0007,  ..., -0.0163, -0.0145, -0.0486],\n","        [ 0.0023,  0.0059,  0.0043,  ...,  0.0057, -0.0017, -0.0178]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.1.fc1.bias', Parameter containing:\n","tensor([ 0.0054, -0.0059,  0.0102,  ..., -0.0068,  0.0111, -0.0089],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.1.fc2.weight', Parameter containing:\n","tensor([[ 0.0154,  0.0020,  0.0047,  ..., -0.0050, -0.0287, -0.0007],\n","        [ 0.0135, -0.0011, -0.0005,  ..., -0.0020, -0.0362,  0.0007],\n","        [ 0.0094, -0.0114,  0.0232,  ..., -0.0049, -0.0004, -0.0118],\n","        ...,\n","        [-0.0085, -0.0071,  0.0007,  ..., -0.0040, -0.0254, -0.0044],\n","        [-0.0223, -0.0033,  0.0100,  ...,  0.0089, -0.0115, -0.0051],\n","        [-0.0060, -0.0038,  0.0034,  ...,  0.0011,  0.0078, -0.0056]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.1.fc2.bias', Parameter containing:\n","tensor([-0.0104, -0.0071,  0.0224,  ..., -0.0039, -0.0054,  0.0032],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.1.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.1.final_layer_norm.bias', Parameter containing:\n","tensor([ 0.2498,  0.0013,  0.0277,  ...,  0.0335, -0.0989,  0.0435],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.2.self_attn.k_proj.weight', Parameter containing:\n","tensor([[ 0.0003, -0.0127, -0.0196,  ...,  0.0048, -0.0229,  0.0036],\n","        [-0.0344, -0.0041,  0.0249,  ..., -0.0124,  0.0182, -0.0143],\n","        [ 0.0117,  0.0195,  0.0190,  ...,  0.0014,  0.0108,  0.0071],\n","        ...,\n","        [ 0.0151,  0.0269,  0.0188,  ..., -0.0072,  0.0066,  0.0110],\n","        [-0.0194, -0.0148,  0.0026,  ...,  0.0278,  0.0333,  0.0230],\n","        [-0.0117,  0.0031,  0.0279,  ...,  0.0205,  0.0027,  0.0176]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.2.self_attn.k_proj.bias', Parameter containing:\n","tensor([-0.0939, -0.0233,  0.0461,  ...,  0.0096,  0.0064,  0.0458],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.2.self_attn.v_proj.weight', Parameter containing:\n","tensor([[ 0.0066,  0.0047, -0.0054,  ..., -0.0096,  0.0259,  0.0081],\n","        [ 0.0068, -0.0134,  0.0021,  ..., -0.0092,  0.0075,  0.0166],\n","        [-0.0075, -0.0004,  0.0037,  ..., -0.0080,  0.0172, -0.0002],\n","        ...,\n","        [ 0.0034, -0.0070, -0.0129,  ...,  0.0049, -0.0046, -0.0235],\n","        [-0.0004,  0.0137,  0.0063,  ...,  0.0153, -0.0051, -0.0067],\n","        [ 0.0092,  0.0039,  0.0012,  ...,  0.0058,  0.0116,  0.0103]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.2.self_attn.v_proj.bias', Parameter containing:\n","tensor([-0.0018,  0.0015, -0.0009,  ..., -0.0036,  0.0036, -0.0001],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.2.self_attn.q_proj.weight', Parameter containing:\n","tensor([[-0.0139, -0.0156, -0.0888,  ..., -0.0164,  0.0188,  0.0107],\n","        [ 0.0164, -0.0133, -0.0230,  ...,  0.0018, -0.0213, -0.0259],\n","        [ 0.0046, -0.0097,  0.0964,  ...,  0.0221, -0.0023, -0.0062],\n","        ...,\n","        [ 0.0306,  0.0005,  0.0245,  ..., -0.0091, -0.0028, -0.0149],\n","        [-0.0003,  0.0357,  0.0094,  ..., -0.0155, -0.0028, -0.0318],\n","        [ 0.0171,  0.0013, -0.0529,  ..., -0.0109,  0.0118,  0.0260]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.2.self_attn.q_proj.bias', Parameter containing:\n","tensor([-0.0432,  0.0178,  0.0253,  ...,  0.0119, -0.0151,  0.0107],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.2.self_attn.out_proj.weight', Parameter containing:\n","tensor([[ 2.3251e-03, -6.6223e-03,  3.3379e-03,  ...,  4.0970e-03,\n","         -7.2136e-03, -3.6030e-03],\n","        [-1.3222e-02, -1.9045e-03,  1.2577e-04,  ..., -1.3901e-02,\n","          2.5177e-03, -1.2836e-03],\n","        [-1.0971e-02,  1.0002e-02, -5.4779e-03,  ..., -5.5046e-03,\n","          4.5013e-03,  9.3842e-03],\n","        ...,\n","        [ 1.0155e-02, -7.7095e-03, -6.8207e-03,  ..., -1.7044e-02,\n","         -2.0905e-03,  3.0975e-03],\n","        [-2.0798e-02, -7.9575e-03, -1.4343e-03,  ..., -3.2365e-05,\n","          4.2534e-03, -1.2001e-02],\n","        [ 4.9782e-04,  2.1072e-02, -1.8911e-03,  ..., -1.2611e-02,\n","         -2.7132e-04, -2.2793e-03]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.2.self_attn.out_proj.bias', Parameter containing:\n","tensor([ 0.0002, -0.0098, -0.0223,  ...,  0.0199, -0.0076,  0.0153],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.2.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.2.self_attn_layer_norm.bias', Parameter containing:\n","tensor([ 0.0176,  0.1305,  0.0260,  ..., -0.0340,  0.0268, -0.0220],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.2.fc1.weight', Parameter containing:\n","tensor([[ 0.0041,  0.0225,  0.0241,  ...,  0.0026,  0.0119, -0.0125],\n","        [-0.0340, -0.0365, -0.0117,  ..., -0.0075, -0.0159, -0.0155],\n","        [-0.0037,  0.0014,  0.0058,  ..., -0.0363, -0.0177,  0.0087],\n","        ...,\n","        [-0.0054,  0.0136, -0.0195,  ...,  0.0139, -0.0118,  0.0037],\n","        [-0.0141, -0.0042,  0.0027,  ..., -0.0150, -0.0197, -0.0143],\n","        [-0.0039, -0.0062,  0.0214,  ...,  0.0378, -0.0029,  0.0143]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.2.fc1.bias', Parameter containing:\n","tensor([0.0004, 0.0028, 0.0061,  ..., 0.0038, 0.0058, 0.0020], device='cuda:0',\n","       requires_grad=True))\n","('coreOPT.decoder.layers.2.fc2.weight', Parameter containing:\n","tensor([[-0.0071, -0.0103,  0.0014,  ..., -0.0165, -0.0048, -0.0086],\n","        [-0.0065, -0.0031, -0.0043,  ..., -0.0105, -0.0132,  0.0385],\n","        [ 0.0040,  0.0109,  0.0323,  ...,  0.0103, -0.0051, -0.0375],\n","        ...,\n","        [-0.0042,  0.0191, -0.0193,  ...,  0.0127,  0.0066,  0.0182],\n","        [-0.0135, -0.0175, -0.0018,  ..., -0.0205,  0.0049,  0.0034],\n","        [-0.0231, -0.0079,  0.0084,  ...,  0.0015, -0.0066, -0.0172]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.2.fc2.bias', Parameter containing:\n","tensor([ 0.0015,  0.0043,  0.0071,  ..., -0.0183, -0.0098, -0.0075],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.2.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.2.final_layer_norm.bias', Parameter containing:\n","tensor([ 0.2021,  0.0653,  0.0674,  ...,  0.0460, -0.0118,  0.0234],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.3.self_attn.k_proj.weight', Parameter containing:\n","tensor([[-1.0658e-02, -8.2207e-04, -7.8354e-03,  ..., -1.0429e-02,\n","         -1.1215e-02,  8.0383e-02],\n","        [ 2.0386e-02, -2.7466e-02, -4.3854e-02,  ...,  1.2474e-02,\n","          8.8120e-03,  2.3422e-02],\n","        [ 1.5345e-03,  5.0316e-03,  2.5162e-02,  ..., -1.2451e-02,\n","          4.6310e-03,  1.0880e-02],\n","        ...,\n","        [ 2.4078e-02,  2.4185e-02,  2.6962e-02,  ...,  5.4352e-02,\n","         -9.7107e-02,  2.5696e-02],\n","        [ 5.2154e-05, -1.0773e-02,  7.5317e-02,  ..., -3.6865e-02,\n","          1.5388e-02, -1.1055e-02],\n","        [-3.1319e-03,  6.0081e-03, -6.5735e-02,  ...,  1.0548e-03,\n","          5.2124e-02,  4.4983e-02]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.3.self_attn.k_proj.bias', Parameter containing:\n","tensor([ 0.0947,  0.2500, -0.1283,  ...,  0.0177,  0.0242, -0.0313],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.3.self_attn.v_proj.weight', Parameter containing:\n","tensor([[-0.0025, -0.0133, -0.0145,  ..., -0.0013,  0.0086,  0.0222],\n","        [-0.0156,  0.0049, -0.0013,  ...,  0.0010,  0.0143, -0.0034],\n","        [-0.0122,  0.0055, -0.0024,  ..., -0.0277, -0.0202, -0.0008],\n","        ...,\n","        [-0.0021, -0.0036,  0.0012,  ...,  0.0116, -0.0112,  0.0175],\n","        [-0.0118, -0.0033,  0.0069,  ...,  0.0114,  0.0337, -0.0019],\n","        [ 0.0062,  0.0048, -0.0018,  ...,  0.0205,  0.0070,  0.0223]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.3.self_attn.v_proj.bias', Parameter containing:\n","tensor([-0.0009,  0.0010, -0.0009,  ...,  0.0014, -0.0008, -0.0006],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.3.self_attn.q_proj.weight', Parameter containing:\n","tensor([[ 0.0079,  0.0380,  0.0151,  ...,  0.0164,  0.0072,  0.0155],\n","        [-0.0100, -0.0254, -0.0361,  ..., -0.0083, -0.0044, -0.0272],\n","        [ 0.0105,  0.0278,  0.0184,  ...,  0.0236,  0.0222,  0.0141],\n","        ...,\n","        [-0.0356, -0.0864,  0.0124,  ..., -0.0481, -0.0462,  0.0148],\n","        [-0.0344, -0.0106,  0.0402,  ..., -0.0036, -0.0061,  0.0384],\n","        [-0.0061, -0.0235,  0.0475,  ..., -0.0341,  0.0170,  0.0015]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.3.self_attn.q_proj.bias', Parameter containing:\n","tensor([-0.0076, -0.0810,  0.0267,  ..., -0.0063, -0.0205,  0.0232],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.3.self_attn.out_proj.weight', Parameter containing:\n","tensor([[ 0.0018,  0.0001,  0.0073,  ...,  0.0040, -0.0189,  0.0154],\n","        [ 0.0215,  0.0053,  0.0063,  ...,  0.0027, -0.0168,  0.0090],\n","        [-0.0326, -0.0009,  0.0082,  ...,  0.0090, -0.0126,  0.0361],\n","        ...,\n","        [ 0.0188, -0.0068,  0.0008,  ..., -0.0080, -0.0079,  0.0095],\n","        [-0.0035, -0.0069, -0.0036,  ..., -0.0040,  0.0025, -0.0046],\n","        [ 0.0053,  0.0072, -0.0153,  ...,  0.0239,  0.0154,  0.0037]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.3.self_attn.out_proj.bias', Parameter containing:\n","tensor([ 0.0045, -0.0099, -0.0359,  ...,  0.0096,  0.0015,  0.0074],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.3.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.3.self_attn_layer_norm.bias', Parameter containing:\n","tensor([ 0.0128,  0.1276, -0.0034,  ..., -0.0327,  0.0308, -0.0424],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.3.fc1.weight', Parameter containing:\n","tensor([[-0.0121, -0.0037, -0.0229,  ...,  0.0040, -0.0337,  0.0114],\n","        [-0.0314, -0.0146,  0.0009,  ..., -0.0244,  0.0054,  0.0051],\n","        [-0.0241,  0.0656,  0.0055,  ..., -0.0296,  0.0096,  0.0170],\n","        ...,\n","        [-0.0015, -0.0122,  0.0053,  ..., -0.0055, -0.0037, -0.0004],\n","        [-0.0010,  0.0025,  0.0024,  ..., -0.0047,  0.0038, -0.0037],\n","        [-0.0086, -0.0081,  0.0175,  ..., -0.0106, -0.0284,  0.0369]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.3.fc1.bias', Parameter containing:\n","tensor([ 0.0027,  0.0004,  0.0052,  ..., -0.0042, -0.0060, -0.0005],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.3.fc2.weight', Parameter containing:\n","tensor([[-0.0078, -0.0015, -0.0033,  ...,  0.0050,  0.0017,  0.0195],\n","        [ 0.0142, -0.0341,  0.0378,  ...,  0.0028,  0.0021,  0.0071],\n","        [-0.0050, -0.0120,  0.0156,  ...,  0.0019,  0.0041,  0.0261],\n","        ...,\n","        [-0.0002, -0.0311,  0.0021,  ..., -0.0017,  0.0050, -0.0028],\n","        [-0.0018, -0.0114, -0.0091,  ..., -0.0008, -0.0006,  0.0030],\n","        [ 0.0097, -0.0237, -0.0210,  ...,  0.0006, -0.0010,  0.0205]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.3.fc2.bias', Parameter containing:\n","tensor([-0.0065, -0.0034,  0.0195,  ..., -0.0129, -0.0055, -0.0292],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.3.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.3.final_layer_norm.bias', Parameter containing:\n","tensor([0.1265, 0.0045, 0.0703,  ..., 0.0984, 0.0178, 0.0952], device='cuda:0',\n","       requires_grad=True))\n","('coreOPT.decoder.layers.4.self_attn.k_proj.weight', Parameter containing:\n","tensor([[-0.0056,  0.0081,  0.0091,  ...,  0.0002,  0.0097, -0.0163],\n","        [-0.0033, -0.0214, -0.0342,  ..., -0.0040, -0.0083, -0.0131],\n","        [-0.0055, -0.0161,  0.0070,  ..., -0.0178,  0.0001, -0.0037],\n","        ...,\n","        [-0.0085, -0.0102,  0.0246,  ..., -0.0073,  0.0026,  0.0017],\n","        [-0.0428,  0.0098,  0.0424,  ...,  0.0086, -0.0044, -0.0318],\n","        [ 0.0519, -0.0110, -0.0427,  ..., -0.0149,  0.0157,  0.0217]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.4.self_attn.k_proj.bias', Parameter containing:\n","tensor([-0.0156,  0.1256, -0.0146,  ..., -0.1289, -0.0548,  0.0627],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.4.self_attn.v_proj.weight', Parameter containing:\n","tensor([[-0.0041,  0.0027, -0.0009,  ...,  0.0018,  0.0095,  0.0014],\n","        [ 0.0184, -0.0046, -0.0007,  ...,  0.0245,  0.0027,  0.0054],\n","        [-0.0190, -0.0101, -0.0038,  ..., -0.0004,  0.0152, -0.0035],\n","        ...,\n","        [-0.0133, -0.0052, -0.0047,  ..., -0.0029, -0.0132,  0.0041],\n","        [ 0.0024, -0.0071,  0.0036,  ..., -0.0038, -0.0113,  0.0072],\n","        [ 0.0265,  0.0012,  0.0042,  ..., -0.0035,  0.0141,  0.0083]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.4.self_attn.v_proj.bias', Parameter containing:\n","tensor([ 3.5703e-05,  4.9782e-04, -4.1413e-04,  ...,  8.5950e-05,\n","         5.1260e-05,  3.6895e-05], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.4.self_attn.q_proj.weight', Parameter containing:\n","tensor([[-0.0079,  0.0093,  0.0016,  ..., -0.0079,  0.0087,  0.0004],\n","        [ 0.0022, -0.0021, -0.0038,  ...,  0.0005,  0.0050, -0.0080],\n","        [ 0.0128,  0.0032,  0.0022,  ...,  0.0039,  0.0155,  0.0051],\n","        ...,\n","        [ 0.0068,  0.0109, -0.0478,  ..., -0.0023,  0.0060,  0.0407],\n","        [-0.0028,  0.0161, -0.0221,  ..., -0.0149, -0.0126,  0.0048],\n","        [-0.0017, -0.0164,  0.0128,  ...,  0.0148,  0.0128,  0.0035]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.4.self_attn.q_proj.bias', Parameter containing:\n","tensor([ 0.0283, -0.1238,  0.0191,  ...,  0.1032,  0.0201, -0.0194],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.4.self_attn.out_proj.weight', Parameter containing:\n","tensor([[ 0.0056, -0.0085,  0.0072,  ...,  0.0023, -0.0041, -0.0045],\n","        [-0.0063,  0.0091,  0.0013,  ..., -0.0095,  0.0059, -0.0061],\n","        [-0.0028, -0.0063,  0.0064,  ...,  0.0029, -0.0015, -0.0140],\n","        ...,\n","        [-0.0002, -0.0129, -0.0048,  ...,  0.0029,  0.0064,  0.0067],\n","        [ 0.0002, -0.0002, -0.0019,  ..., -0.0010, -0.0004, -0.0137],\n","        [-0.0012,  0.0090,  0.0022,  ...,  0.0033, -0.0007,  0.0023]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.4.self_attn.out_proj.bias', Parameter containing:\n","tensor([-2.8496e-03, -3.4027e-03, -5.5695e-02,  ...,  1.2283e-02,\n","         6.0558e-05,  7.0877e-03], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.4.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.4.self_attn_layer_norm.bias', Parameter containing:\n","tensor([ 0.0147,  0.0918, -0.0123,  ..., -0.0252,  0.0276, -0.0586],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.4.fc1.weight', Parameter containing:\n","tensor([[-0.0352, -0.0327, -0.0004,  ..., -0.0176, -0.0075,  0.0053],\n","        [ 0.0018,  0.0079, -0.0032,  ...,  0.0008,  0.0042, -0.0027],\n","        [-0.0341,  0.0189,  0.0113,  ...,  0.0060, -0.0052,  0.0150],\n","        ...,\n","        [-0.0127,  0.0207, -0.0113,  ...,  0.0094,  0.0260, -0.0024],\n","        [ 0.0134, -0.0128, -0.0107,  ..., -0.0174,  0.0094,  0.0136],\n","        [-0.0362, -0.0013, -0.0035,  ..., -0.0039,  0.0370,  0.0158]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.4.fc1.bias', Parameter containing:\n","tensor([-0.0017, -0.0112,  0.0010,  ..., -0.0047, -0.0021, -0.0024],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.4.fc2.weight', Parameter containing:\n","tensor([[ 0.0337, -0.0088, -0.0171,  ..., -0.0118, -0.0071, -0.0208],\n","        [-0.0289,  0.0057,  0.0090,  ..., -0.0046, -0.0019, -0.0174],\n","        [-0.0254,  0.0007, -0.0081,  ..., -0.0288, -0.0077, -0.0345],\n","        ...,\n","        [ 0.0264,  0.0042,  0.0083,  ..., -0.0190,  0.0159, -0.0070],\n","        [-0.0222,  0.0049,  0.0004,  ...,  0.0078,  0.0035,  0.0050],\n","        [-0.0105,  0.0062,  0.0187,  ..., -0.0007,  0.0172, -0.0039]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.4.fc2.bias', Parameter containing:\n","tensor([-0.0040, -0.0031,  0.0262,  ..., -0.0160, -0.0043, -0.0228],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.4.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.4.final_layer_norm.bias', Parameter containing:\n","tensor([0.0881, 0.0592, 0.0757,  ..., 0.0941, 0.0424, 0.1259], device='cuda:0',\n","       requires_grad=True))\n","('coreOPT.decoder.layers.5.self_attn.k_proj.weight', Parameter containing:\n","tensor([[-0.0382, -0.0464,  0.0257,  ...,  0.0404, -0.0328, -0.0196],\n","        [-0.0277,  0.0360, -0.0470,  ..., -0.0338,  0.0171,  0.0368],\n","        [ 0.0622, -0.0060, -0.0182,  ...,  0.0176, -0.0133,  0.0334],\n","        ...,\n","        [ 0.0255, -0.0037, -0.0301,  ...,  0.0033, -0.0019,  0.0390],\n","        [ 0.0065,  0.0272, -0.0057,  ...,  0.0113, -0.0066, -0.0183],\n","        [-0.0144, -0.0134,  0.0641,  ...,  0.0160,  0.0037, -0.0131]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.5.self_attn.k_proj.bias', Parameter containing:\n","tensor([-0.2061,  0.2500,  0.2500,  ...,  0.1250,  0.0317, -0.1250],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.5.self_attn.v_proj.weight', Parameter containing:\n","tensor([[ 0.0043,  0.0222, -0.0002,  ..., -0.0181, -0.0219, -0.0165],\n","        [ 0.0073,  0.0021, -0.0064,  ..., -0.0286,  0.0125,  0.0062],\n","        [-0.0086,  0.0027,  0.0045,  ...,  0.0211,  0.0063,  0.0032],\n","        ...,\n","        [ 0.0350,  0.0107, -0.0080,  ..., -0.0316, -0.0055, -0.0012],\n","        [-0.0015,  0.0203,  0.0067,  ..., -0.0108,  0.0076,  0.0007],\n","        [ 0.0005, -0.0192, -0.0037,  ...,  0.0008,  0.0129,  0.0017]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.5.self_attn.v_proj.bias', Parameter containing:\n","tensor([-8.6367e-05, -6.6996e-04,  3.2043e-04,  ...,  6.1703e-04,\n","         6.5279e-04, -4.6039e-04], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.5.self_attn.q_proj.weight', Parameter containing:\n","tensor([[-0.0105, -0.0028,  0.0271,  ...,  0.0255, -0.0119,  0.0657],\n","        [-0.0212,  0.0181, -0.0649,  ...,  0.0074, -0.0135,  0.1307],\n","        [ 0.0072, -0.0340,  0.0022,  ..., -0.0198,  0.0594,  0.0670],\n","        ...,\n","        [ 0.0066,  0.0406, -0.1027,  ..., -0.0088, -0.0183,  0.0196],\n","        [ 0.0432,  0.0253, -0.0828,  ...,  0.0456, -0.0401, -0.0356],\n","        [-0.0104,  0.0174,  0.0195,  ...,  0.0021, -0.0494, -0.0424]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.5.self_attn.q_proj.bias', Parameter containing:\n","tensor([-0.0046,  0.0053,  0.0279,  ...,  0.0125, -0.0062,  0.0310],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.5.self_attn.out_proj.weight', Parameter containing:\n","tensor([[-0.0160, -0.0078,  0.0105,  ..., -0.0070,  0.0039, -0.0079],\n","        [-0.0044,  0.0041,  0.0016,  ...,  0.0145, -0.0113,  0.0104],\n","        [ 0.0047,  0.0157, -0.0012,  ...,  0.0555, -0.0087,  0.0009],\n","        ...,\n","        [-0.0084,  0.0078, -0.0192,  ...,  0.0223,  0.0080,  0.0039],\n","        [-0.0050, -0.0134,  0.0023,  ...,  0.0147, -0.0063,  0.0001],\n","        [ 0.0075, -0.0135,  0.0043,  ..., -0.0211, -0.0018,  0.0018]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.5.self_attn.out_proj.bias', Parameter containing:\n","tensor([-0.0028,  0.0152, -0.0562,  ...,  0.0009,  0.0040,  0.0145],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.5.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.5.self_attn_layer_norm.bias', Parameter containing:\n","tensor([ 0.0141,  0.0817,  0.0126,  ..., -0.0197,  0.0233, -0.0793],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.5.fc1.weight', Parameter containing:\n","tensor([[ 0.0519, -0.0056,  0.0095,  ..., -0.0512,  0.0102,  0.0118],\n","        [-0.0240,  0.0377, -0.0015,  ...,  0.0115,  0.0048, -0.0309],\n","        [ 0.0040,  0.0010,  0.0028,  ...,  0.0005, -0.0003, -0.0098],\n","        ...,\n","        [ 0.0167, -0.0496, -0.0070,  ..., -0.0070,  0.0276,  0.0039],\n","        [ 0.0098,  0.0149,  0.0131,  ..., -0.0090,  0.0143, -0.0499],\n","        [-0.0160, -0.0353,  0.0186,  ...,  0.0101, -0.0071,  0.0110]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.5.fc1.bias', Parameter containing:\n","tensor([-0.0068, -0.0052, -0.0086,  ..., -0.0034, -0.0025, -0.0030],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.5.fc2.weight', Parameter containing:\n","tensor([[ 0.0336, -0.0056,  0.0022,  ..., -0.0018,  0.0203,  0.0018],\n","        [ 0.0689,  0.0354,  0.0040,  ..., -0.0201,  0.0138, -0.0202],\n","        [-0.0026, -0.0074,  0.0052,  ...,  0.0057, -0.0091,  0.0019],\n","        ...,\n","        [-0.0247,  0.0095,  0.0041,  ...,  0.0020,  0.0006,  0.0001],\n","        [ 0.0059,  0.0216,  0.0037,  ..., -0.0132, -0.0036, -0.0051],\n","        [-0.0180,  0.0049,  0.0004,  ..., -0.0111, -0.0027, -0.0028]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.5.fc2.bias', Parameter containing:\n","tensor([-0.0104, -0.0068,  0.0190,  ..., -0.0075,  0.0099, -0.0219],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.5.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.5.final_layer_norm.bias', Parameter containing:\n","tensor([ 0.0404,  0.0878,  0.0636,  ...,  0.1022, -0.0493,  0.1467],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.6.self_attn.k_proj.weight', Parameter containing:\n","tensor([[-0.0288,  0.0699, -0.0195,  ..., -0.0039, -0.0528,  0.0247],\n","        [ 0.0626, -0.0020,  0.0964,  ...,  0.0181, -0.0115,  0.0157],\n","        [-0.0255,  0.0204,  0.0523,  ..., -0.0157,  0.0114, -0.0083],\n","        ...,\n","        [ 0.0055,  0.0141, -0.0136,  ..., -0.0396, -0.0174,  0.0383],\n","        [-0.0175,  0.0348,  0.0456,  ..., -0.0002, -0.0112,  0.0460],\n","        [-0.0300, -0.0232,  0.0538,  ..., -0.0264,  0.0047, -0.0028]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.6.self_attn.k_proj.bias', Parameter containing:\n","tensor([-0.0287,  0.0318,  0.0356,  ..., -0.0328, -0.0323, -0.0322],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.6.self_attn.v_proj.weight', Parameter containing:\n","tensor([[-1.4200e-03, -1.7563e-02, -5.7793e-03,  ..., -1.6083e-02,\n","          1.1284e-02, -8.3160e-03],\n","        [-2.9861e-02,  9.0332e-03,  6.9618e-03,  ...,  3.5667e-03,\n","         -4.5280e-03,  7.7820e-03],\n","        [-1.4656e-02, -1.2236e-03,  4.7760e-03,  ..., -6.7825e-03,\n","          1.3614e-04,  2.1992e-03],\n","        ...,\n","        [ 1.2274e-03,  3.4199e-03, -8.3876e-04,  ..., -1.5121e-02,\n","         -9.9487e-03, -6.0618e-05],\n","        [ 8.2636e-04, -1.0826e-02, -8.6670e-03,  ..., -9.9487e-03,\n","         -1.2344e-02, -1.1282e-03],\n","        [ 9.1476e-03,  2.6932e-03,  2.8000e-03,  ...,  1.0315e-02,\n","         -1.6846e-02, -8.2016e-04]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.6.self_attn.v_proj.bias', Parameter containing:\n","tensor([-0.0006,  0.0006,  0.0003,  ..., -0.0009, -0.0004,  0.0027],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.6.self_attn.q_proj.weight', Parameter containing:\n","tensor([[ 0.0480, -0.0163,  0.0528,  ...,  0.0346,  0.1030, -0.0285],\n","        [ 0.0294, -0.0374,  0.0229,  ...,  0.0014, -0.0334,  0.0122],\n","        [-0.0169, -0.0577,  0.0742,  ...,  0.0639, -0.0490,  0.0360],\n","        ...,\n","        [-0.0178, -0.0323,  0.0023,  ...,  0.0813,  0.0662, -0.0011],\n","        [ 0.0459,  0.0037,  0.0358,  ...,  0.0308, -0.0029, -0.0416],\n","        [ 0.0035, -0.0038,  0.0305,  ..., -0.0174, -0.0104,  0.0341]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.6.self_attn.q_proj.bias', Parameter containing:\n","tensor([0.0106, 0.0231, 0.0137,  ..., 0.0263, 0.0201, 0.0359], device='cuda:0',\n","       requires_grad=True))\n","('coreOPT.decoder.layers.6.self_attn.out_proj.weight', Parameter containing:\n","tensor([[ 1.2550e-03, -7.6866e-03,  1.2236e-03,  ...,  1.9653e-02,\n","         -5.4550e-03, -5.0278e-03],\n","        [-6.0234e-03,  1.5915e-02,  2.3880e-03,  ...,  1.7138e-03,\n","          5.3024e-03, -3.0637e-04],\n","        [ 1.5381e-02, -7.1182e-03, -6.9199e-03,  ...,  3.9215e-03,\n","         -4.9896e-03, -8.3828e-04],\n","        ...,\n","        [ 2.9327e-02, -1.9806e-02, -5.2872e-03,  ..., -4.2295e-04,\n","          9.3689e-03,  1.5327e-02],\n","        [-8.6212e-03,  6.0425e-03,  4.1656e-03,  ..., -5.1558e-05,\n","         -1.6479e-02,  1.1597e-02],\n","        [-5.3101e-03, -5.8517e-03,  1.2947e-02,  ..., -2.2449e-03,\n","          8.4381e-03, -9.6893e-03]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.6.self_attn.out_proj.bias', Parameter containing:\n","tensor([-0.0075,  0.0047, -0.0332,  ..., -0.0029,  0.0074,  0.0127],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.6.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.6.self_attn_layer_norm.bias', Parameter containing:\n","tensor([ 0.0097,  0.0704,  0.0016,  ..., -0.0171,  0.0199, -0.0915],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.6.fc1.weight', Parameter containing:\n","tensor([[ 3.7670e-05,  3.6888e-03,  3.0499e-03,  ...,  4.5662e-03,\n","          1.1108e-02, -6.8245e-03],\n","        [ 5.0068e-05,  2.7466e-03, -1.0788e-02,  ...,  1.1002e-02,\n","          4.7266e-05, -8.7662e-03],\n","        [ 4.5746e-02,  4.3732e-02,  3.8757e-02,  ..., -1.5549e-02,\n","         -1.5945e-02,  6.2981e-03],\n","        ...,\n","        [ 1.1581e-02, -3.8239e-02, -8.1482e-03,  ..., -7.6294e-03,\n","          1.3443e-02, -1.1345e-02],\n","        [ 5.2719e-03, -1.1406e-02,  2.3594e-03,  ..., -1.2390e-02,\n","          1.0117e-02,  1.5053e-02],\n","        [ 2.3308e-03, -2.0584e-02,  4.2572e-03,  ..., -1.8082e-03,\n","          1.1337e-02, -2.9640e-03]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.6.fc1.bias', Parameter containing:\n","tensor([-0.0081, -0.0049, -0.0045,  ..., -0.0075, -0.0047, -0.0052],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.6.fc2.weight', Parameter containing:\n","tensor([[-0.0026, -0.0017, -0.0103,  ..., -0.0178,  0.0209, -0.0105],\n","        [-0.0020, -0.0001, -0.0029,  ...,  0.0428, -0.0126, -0.0037],\n","        [ 0.0008, -0.0006, -0.0109,  ...,  0.0091,  0.0096, -0.0216],\n","        ...,\n","        [ 0.0022, -0.0020,  0.0066,  ..., -0.0139,  0.0116,  0.0065],\n","        [-0.0003,  0.0010, -0.0355,  ..., -0.0179, -0.0374,  0.0047],\n","        [-0.0001,  0.0017,  0.0163,  ..., -0.0022,  0.0062,  0.0090]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.6.fc2.bias', Parameter containing:\n","tensor([-0.0263,  0.0027,  0.0471,  ..., -0.0044, -0.0019, -0.0197],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.6.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.6.final_layer_norm.bias', Parameter containing:\n","tensor([ 0.0393, -0.0187, -0.0561,  ...,  0.0900, -0.0624,  0.1768],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.7.self_attn.k_proj.weight', Parameter containing:\n","tensor([[ 0.0107, -0.0251,  0.0219,  ..., -0.0454,  0.0278, -0.0170],\n","        [ 0.0613,  0.0146, -0.0125,  ...,  0.0063, -0.0024, -0.0183],\n","        [-0.0130,  0.0027, -0.0168,  ..., -0.0048,  0.0023,  0.0739],\n","        ...,\n","        [-0.0108, -0.0161,  0.0334,  ...,  0.0127,  0.0065, -0.0586],\n","        [-0.0067, -0.0050, -0.0389,  ...,  0.0071, -0.0127, -0.0547],\n","        [-0.0048,  0.0170,  0.0062,  ...,  0.0072, -0.0176,  0.0122]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.7.self_attn.k_proj.bias', Parameter containing:\n","tensor([-0.0625, -0.0643, -0.0625,  ...,  0.0166,  0.0134, -0.0066],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.7.self_attn.v_proj.weight', Parameter containing:\n","tensor([[ 0.0217,  0.0012, -0.0012,  ...,  0.0044,  0.0233, -0.0046],\n","        [-0.0517, -0.0012, -0.0096,  ...,  0.0105,  0.0105,  0.0055],\n","        [-0.0356, -0.0150, -0.0020,  ...,  0.0003, -0.0115, -0.0114],\n","        ...,\n","        [ 0.0057, -0.0054,  0.0065,  ..., -0.0048,  0.0004,  0.0059],\n","        [-0.0184, -0.0038, -0.0013,  ..., -0.0101, -0.0047, -0.0017],\n","        [-0.0088, -0.0022,  0.0059,  ...,  0.0069,  0.0082,  0.0038]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.7.self_attn.v_proj.bias', Parameter containing:\n","tensor([ 2.2566e-04,  1.3709e-06, -1.7509e-03,  ...,  1.1539e-03,\n","        -1.1215e-03,  4.1461e-04], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.7.self_attn.q_proj.weight', Parameter containing:\n","tensor([[-0.0011,  0.0150, -0.0005,  ..., -0.0128,  0.0345, -0.0160],\n","        [ 0.0157,  0.0110,  0.0392,  ...,  0.0173, -0.0174, -0.0305],\n","        [-0.0035, -0.0391,  0.1539,  ...,  0.0092, -0.0332, -0.0784],\n","        ...,\n","        [ 0.0281, -0.0113, -0.0399,  ...,  0.0156,  0.0107, -0.0445],\n","        [-0.0120,  0.0186, -0.0381,  ...,  0.0043, -0.0200,  0.0064],\n","        [-0.0276,  0.0094, -0.0162,  ..., -0.0318, -0.0865, -0.0373]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.7.self_attn.q_proj.bias', Parameter containing:\n","tensor([ 0.0072,  0.0032, -0.0345,  ..., -0.0139,  0.0002, -0.0063],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.7.self_attn.out_proj.weight', Parameter containing:\n","tensor([[ 7.2289e-03, -1.7197e-02,  1.4107e-02,  ..., -4.2992e-03,\n","          6.7291e-03,  4.5586e-03],\n","        [-5.9509e-04, -1.9485e-02, -1.8692e-02,  ..., -6.0310e-03,\n","         -3.4409e-03,  1.1658e-02],\n","        [ 1.5411e-02,  1.4389e-02, -3.8223e-03,  ..., -1.4820e-03,\n","         -2.3479e-03, -9.9869e-03],\n","        ...,\n","        [ 1.2268e-02,  5.6572e-03,  3.1452e-03,  ...,  1.0918e-02,\n","         -5.5265e-04, -1.2112e-03],\n","        [ 3.4332e-05,  1.2764e-02, -7.3624e-03,  ..., -9.0256e-03,\n","          2.7490e-04, -2.1248e-03],\n","        [-1.6052e-02, -1.2413e-02,  7.9572e-05,  ...,  2.7466e-03,\n","         -6.6032e-03,  5.8403e-03]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.7.self_attn.out_proj.bias', Parameter containing:\n","tensor([ 0.0082, -0.0096, -0.0326,  ..., -0.0013,  0.0023, -0.0021],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.7.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.7.self_attn_layer_norm.bias', Parameter containing:\n","tensor([ 0.0135,  0.0590,  0.0005,  ..., -0.0111,  0.0142, -0.0958],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.7.fc1.weight', Parameter containing:\n","tensor([[-0.0016, -0.0046,  0.0262,  ...,  0.0533, -0.0185, -0.0037],\n","        [ 0.0326,  0.0007, -0.0050,  ...,  0.0160, -0.0038, -0.0241],\n","        [ 0.0075,  0.0009, -0.0078,  ..., -0.0080,  0.0006,  0.0077],\n","        ...,\n","        [ 0.0043, -0.0010,  0.0014,  ..., -0.0038,  0.0004,  0.0012],\n","        [ 0.0052, -0.0231,  0.0091,  ..., -0.0302,  0.0099, -0.0115],\n","        [-0.0161,  0.0055, -0.0050,  ..., -0.0238, -0.0130,  0.0016]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.7.fc1.bias', Parameter containing:\n","tensor([-0.0050, -0.0058, -0.0109,  ..., -0.0057, -0.0135, -0.0102],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.7.fc2.weight', Parameter containing:\n","tensor([[ 0.0142, -0.0172,  0.0017,  ..., -0.0029, -0.0118,  0.0226],\n","        [-0.0017,  0.0124,  0.0063,  ..., -0.0004, -0.0251, -0.0132],\n","        [-0.0047, -0.0013, -0.0029,  ...,  0.0044,  0.0022,  0.0126],\n","        ...,\n","        [ 0.0022,  0.0093, -0.0029,  ..., -0.0010, -0.0246,  0.0559],\n","        [-0.0020, -0.0318,  0.0042,  ..., -0.0013,  0.0086, -0.0183],\n","        [-0.0108, -0.0045,  0.0053,  ..., -0.0005,  0.0111,  0.0252]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.7.fc2.bias', Parameter containing:\n","tensor([-0.0316, -0.0004,  0.0641,  ..., -0.0110, -0.0171, -0.0069],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.7.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.7.final_layer_norm.bias', Parameter containing:\n","tensor([ 0.0483, -0.0525, -0.0316,  ...,  0.0466,  0.0356,  0.1627],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.8.self_attn.k_proj.weight', Parameter containing:\n","tensor([[-0.0058, -0.0001,  0.0275,  ..., -0.0691, -0.0351, -0.0170],\n","        [ 0.0170, -0.0149,  0.0119,  ...,  0.0090, -0.0369, -0.0157],\n","        [-0.0080, -0.0084,  0.0136,  ...,  0.0215, -0.0382, -0.0214],\n","        ...,\n","        [-0.0109,  0.0213,  0.0611,  ..., -0.0059, -0.0042,  0.0043],\n","        [-0.0250, -0.0118, -0.0261,  ..., -0.0257,  0.0097,  0.0422],\n","        [ 0.0110,  0.0121, -0.0281,  ..., -0.0315,  0.0196,  0.0199]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.8.self_attn.k_proj.bias', Parameter containing:\n","tensor([-0.1210, -0.0625, -0.0857,  ...,  0.0241, -0.0327,  0.0239],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.8.self_attn.v_proj.weight', Parameter containing:\n","tensor([[ 0.0203, -0.0066,  0.0031,  ...,  0.0092, -0.0197,  0.0045],\n","        [-0.0055,  0.0058,  0.0025,  ...,  0.0105, -0.0031, -0.0050],\n","        [ 0.0158, -0.0033,  0.0036,  ...,  0.0058, -0.0194, -0.0003],\n","        ...,\n","        [ 0.0157, -0.0115, -0.0106,  ...,  0.0193,  0.0030, -0.0045],\n","        [-0.0163,  0.0082,  0.0081,  ..., -0.0138, -0.0222,  0.0037],\n","        [-0.0081,  0.0022, -0.0024,  ...,  0.0243, -0.0082, -0.0013]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.8.self_attn.v_proj.bias', Parameter containing:\n","tensor([-0.0006, -0.0015,  0.0007,  ...,  0.0020,  0.0036,  0.0009],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.8.self_attn.q_proj.weight', Parameter containing:\n","tensor([[ 0.0147, -0.0417, -0.0003,  ...,  0.0088,  0.0177,  0.0210],\n","        [ 0.0261,  0.0003,  0.0490,  ...,  0.0364,  0.0136, -0.0269],\n","        [-0.0641, -0.0152,  0.0481,  ..., -0.0634,  0.0195, -0.0142],\n","        ...,\n","        [ 0.0270,  0.0106, -0.0079,  ..., -0.0075,  0.0165,  0.0058],\n","        [-0.0182,  0.0201, -0.0043,  ..., -0.0454,  0.0433, -0.0144],\n","        [ 0.0081, -0.0103,  0.0181,  ...,  0.0331, -0.0095, -0.0045]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.8.self_attn.q_proj.bias', Parameter containing:\n","tensor([ 0.0080,  0.0177,  0.0035,  ...,  0.0202, -0.0109,  0.0085],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.8.self_attn.out_proj.weight', Parameter containing:\n","tensor([[ 0.0038,  0.0086, -0.0337,  ..., -0.0220,  0.0138,  0.0012],\n","        [ 0.0128,  0.0053, -0.0115,  ...,  0.0007, -0.0133, -0.0032],\n","        [-0.0092,  0.0095, -0.0189,  ..., -0.0002,  0.0093,  0.0039],\n","        ...,\n","        [ 0.0076,  0.0062, -0.0034,  ..., -0.0119,  0.0119, -0.0194],\n","        [ 0.0068, -0.0082,  0.0351,  ..., -0.0018,  0.0160,  0.0035],\n","        [-0.0104, -0.0020, -0.0003,  ...,  0.0110,  0.0109, -0.0003]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.8.self_attn.out_proj.bias', Parameter containing:\n","tensor([ 0.0059, -0.0067, -0.0122,  ..., -0.0069,  0.0100, -0.0152],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.8.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.8.self_attn_layer_norm.bias', Parameter containing:\n","tensor([ 0.0155,  0.0511,  0.0087,  ..., -0.0060,  0.0091, -0.1221],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.8.fc1.weight', Parameter containing:\n","tensor([[-0.0110, -0.0098,  0.0179,  ...,  0.0123, -0.0062, -0.0141],\n","        [-0.0122,  0.0505,  0.0027,  ..., -0.0067, -0.0798, -0.0003],\n","        [-0.0128,  0.0062, -0.0047,  ..., -0.0054, -0.0103, -0.0117],\n","        ...,\n","        [-0.0185, -0.0044,  0.0011,  ...,  0.0023, -0.0125,  0.0034],\n","        [-0.0366, -0.0079,  0.0236,  ...,  0.0099,  0.0141,  0.0434],\n","        [ 0.0221, -0.0245, -0.0057,  ...,  0.0175, -0.0293,  0.0122]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.8.fc1.bias', Parameter containing:\n","tensor([-0.0043, -0.0071, -0.0107,  ..., -0.0045, -0.0099, -0.0009],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.8.fc2.weight', Parameter containing:\n","tensor([[-1.1375e-02,  9.9869e-03,  1.5015e-02,  ...,  4.7577e-02,\n","          2.4338e-02,  9.4299e-03],\n","        [-3.3998e-04, -3.2288e-02,  1.4107e-02,  ...,  1.6632e-02,\n","         -3.1738e-02, -6.8474e-03],\n","        [-4.8256e-03, -6.7139e-03, -4.9683e-02,  ..., -8.9645e-03,\n","          1.2672e-02, -1.1620e-02],\n","        ...,\n","        [-1.1505e-02, -8.1635e-03,  4.7989e-03,  ...,  2.3880e-02,\n","         -1.6235e-02, -1.1192e-02],\n","        [ 9.0790e-03, -7.1287e-05,  4.4746e-03,  ...,  1.2299e-02,\n","         -2.0981e-02, -9.4986e-03],\n","        [ 1.3779e-02, -1.0414e-02,  2.1057e-03,  ..., -3.4275e-03,\n","          6.8420e-02,  1.8799e-02]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.8.fc2.bias', Parameter containing:\n","tensor([-0.0172, -0.0063,  0.0680,  ..., -0.0210, -0.0084, -0.0181],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.8.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.8.final_layer_norm.bias', Parameter containing:\n","tensor([ 0.0281, -0.0809, -0.0748,  ...,  0.0302,  0.0423,  0.1425],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.9.self_attn.k_proj.weight', Parameter containing:\n","tensor([[ 0.0230, -0.0196, -0.0193,  ...,  0.0192, -0.0114,  0.0047],\n","        [-0.0276,  0.0396, -0.0270,  ..., -0.0057, -0.0104, -0.0197],\n","        [ 0.0367,  0.0063, -0.0057,  ...,  0.0061, -0.0109, -0.0270],\n","        ...,\n","        [-0.0018, -0.0179,  0.0528,  ...,  0.0182,  0.0004,  0.0070],\n","        [ 0.0216,  0.0145,  0.0251,  ...,  0.0139,  0.0137,  0.0428],\n","        [ 0.0409,  0.0098, -0.0367,  ...,  0.0014,  0.0257,  0.0221]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.9.self_attn.k_proj.bias', Parameter containing:\n","tensor([-0.0013, -0.0226,  0.0282,  ..., -0.0157, -0.0149, -0.0199],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.9.self_attn.v_proj.weight', Parameter containing:\n","tensor([[ 2.2598e-02,  3.9062e-03,  1.2138e-02,  ...,  3.8605e-02,\n","         -5.1689e-03,  8.7204e-03],\n","        [-1.1909e-02,  6.2447e-03, -8.4829e-04,  ..., -1.0788e-02,\n","         -9.7351e-03,  1.1414e-02],\n","        [-1.3008e-02, -2.0921e-05, -5.7936e-04,  ..., -8.5754e-03,\n","         -2.0630e-02,  8.6021e-04],\n","        ...,\n","        [-3.9291e-03,  1.0765e-02, -4.5509e-03,  ..., -1.0933e-02,\n","          1.0292e-02,  2.9793e-03],\n","        [ 4.9973e-03,  1.8021e-02,  9.1553e-03,  ...,  1.8682e-03,\n","         -5.1193e-03,  7.0305e-03],\n","        [ 1.3191e-02, -3.4466e-03,  8.1444e-04,  ..., -1.7563e-02,\n","          1.4397e-02, -7.3586e-03]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.9.self_attn.v_proj.bias', Parameter containing:\n","tensor([-7.7128e-05, -5.0545e-05, -8.5545e-04,  ...,  1.4663e-04,\n","        -2.6894e-03, -3.1452e-03], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.9.self_attn.q_proj.weight', Parameter containing:\n","tensor([[-0.0020,  0.0052,  0.0012,  ..., -0.0040, -0.0194,  0.0213],\n","        [ 0.0044,  0.0178,  0.0137,  ..., -0.0262, -0.0030,  0.0160],\n","        [-0.0114, -0.0342, -0.0395,  ..., -0.0226, -0.0055,  0.0064],\n","        ...,\n","        [-0.0025,  0.0012,  0.0165,  ...,  0.0224,  0.0187,  0.0466],\n","        [-0.0136,  0.0059,  0.0840,  ...,  0.0182, -0.0057,  0.0139],\n","        [-0.0161, -0.0314, -0.0195,  ..., -0.0235, -0.0308,  0.0201]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.9.self_attn.q_proj.bias', Parameter containing:\n","tensor([ 0.0103,  0.0232, -0.0118,  ...,  0.1283, -0.0427, -0.0520],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.9.self_attn.out_proj.weight', Parameter containing:\n","tensor([[ 0.0006, -0.0009,  0.0077,  ..., -0.0059,  0.0041,  0.0115],\n","        [-0.0140, -0.0128, -0.0006,  ...,  0.0082, -0.0108,  0.0014],\n","        [-0.0379, -0.0019, -0.0079,  ...,  0.0008,  0.0172, -0.0338],\n","        ...,\n","        [-0.0347,  0.0114,  0.0130,  ..., -0.0120, -0.0079,  0.0013],\n","        [ 0.0020, -0.0070,  0.0324,  ...,  0.0104,  0.0048, -0.0051],\n","        [ 0.0059,  0.0017, -0.0026,  ...,  0.0059, -0.0168, -0.0143]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.9.self_attn.out_proj.bias', Parameter containing:\n","tensor([-2.9526e-03,  4.3945e-03, -1.3863e-02,  ..., -6.0005e-03,\n","         5.5432e-05, -2.2831e-03], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.9.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.9.self_attn_layer_norm.bias', Parameter containing:\n","tensor([ 0.0122,  0.0494,  0.0239,  ..., -0.0039,  0.0036, -0.1209],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.9.fc1.weight', Parameter containing:\n","tensor([[ 0.0096, -0.0055,  0.0278,  ..., -0.0445,  0.0266,  0.0076],\n","        [-0.0026, -0.0382,  0.0051,  ..., -0.0453,  0.0294,  0.0107],\n","        [-0.0108,  0.0389, -0.0120,  ..., -0.0131, -0.0360,  0.0052],\n","        ...,\n","        [-0.0228, -0.0184, -0.0095,  ..., -0.0226,  0.0237, -0.0119],\n","        [-0.0074, -0.0226, -0.0098,  ..., -0.0094,  0.0222,  0.0067],\n","        [-0.0252,  0.0266,  0.0180,  ..., -0.0026, -0.0086,  0.0328]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.9.fc1.bias', Parameter containing:\n","tensor([-0.0083, -0.0146, -0.0126,  ..., -0.0026, -0.0071, -0.0067],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.9.fc2.weight', Parameter containing:\n","tensor([[ 0.0167, -0.0305, -0.0140,  ...,  0.0292, -0.0002,  0.0116],\n","        [-0.0072, -0.0128,  0.0124,  ..., -0.0253,  0.0110, -0.0098],\n","        [-0.0078,  0.0370, -0.0006,  ...,  0.0032, -0.0028,  0.0025],\n","        ...,\n","        [-0.0103, -0.0267, -0.0145,  ...,  0.0042, -0.0048, -0.0195],\n","        [ 0.0010, -0.0053, -0.0033,  ...,  0.0206,  0.0332, -0.0006],\n","        [-0.0143, -0.0130,  0.0468,  ...,  0.0071, -0.0195, -0.0009]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.9.fc2.bias', Parameter containing:\n","tensor([-0.0141, -0.0174,  0.0455,  ..., -0.0164, -0.0089, -0.0095],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.9.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.9.final_layer_norm.bias', Parameter containing:\n","tensor([ 0.0233, -0.0845, -0.1223,  ...,  0.0696,  0.0743,  0.1597],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.10.self_attn.k_proj.weight', Parameter containing:\n","tensor([[ 0.0173, -0.0018,  0.0021,  ..., -0.0069, -0.0671, -0.0571],\n","        [-0.0174,  0.0397, -0.0197,  ...,  0.0244, -0.0172,  0.0253],\n","        [-0.0176, -0.0144, -0.0363,  ..., -0.0395, -0.0034,  0.0429],\n","        ...,\n","        [ 0.0213,  0.0147,  0.0011,  ..., -0.0020,  0.0252, -0.0075],\n","        [ 0.0400,  0.0033,  0.0042,  ...,  0.0203, -0.0218, -0.0300],\n","        [-0.0340, -0.0197,  0.1582,  ..., -0.0334,  0.0135,  0.0248]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.10.self_attn.k_proj.bias', Parameter containing:\n","tensor([ 0.0386, -0.0312, -0.0368,  ..., -0.0336,  0.0315,  0.0313],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.10.self_attn.v_proj.weight', Parameter containing:\n","tensor([[ 1.1082e-03, -2.9507e-03,  7.9803e-03,  ...,  2.0126e-02,\n","          2.7847e-02,  5.1994e-03],\n","        [-7.8964e-03, -8.7814e-03, -5.0049e-03,  ...,  2.5848e-02,\n","         -4.0863e-02, -1.2192e-02],\n","        [-2.3514e-02, -2.7603e-02, -1.9493e-03,  ...,  2.7878e-02,\n","          1.1696e-02, -7.3662e-03],\n","        ...,\n","        [ 1.8112e-02, -1.4648e-02,  1.7881e-05,  ...,  4.9171e-03,\n","         -2.5158e-03, -6.2904e-03],\n","        [ 6.6681e-03,  2.0889e-02, -5.3329e-03,  ..., -3.4618e-03,\n","         -5.5733e-03,  5.7554e-04],\n","        [ 3.1281e-02, -5.1842e-03,  1.3485e-03,  ..., -7.2479e-03,\n","          6.4430e-03, -1.3418e-03]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.10.self_attn.v_proj.bias', Parameter containing:\n","tensor([ 0.0002,  0.0005, -0.0010,  ..., -0.0026,  0.0017, -0.0004],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.10.self_attn.q_proj.weight', Parameter containing:\n","tensor([[ 0.0041, -0.0372,  0.0053,  ..., -0.0124, -0.0240, -0.0054],\n","        [ 0.0422,  0.0169,  0.0209,  ...,  0.0420,  0.0102, -0.0247],\n","        [-0.0240, -0.0035, -0.0518,  ..., -0.0165,  0.0014,  0.0787],\n","        ...,\n","        [-0.0442, -0.0031, -0.0222,  ..., -0.0327, -0.0269,  0.0228],\n","        [-0.0231,  0.0341, -0.0028,  ..., -0.0117, -0.0549,  0.0196],\n","        [ 0.0316, -0.0256,  0.0027,  ...,  0.0046, -0.0075,  0.0464]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.10.self_attn.q_proj.bias', Parameter containing:\n","tensor([-0.0157,  0.0179,  0.0019,  ..., -0.0136,  0.0152,  0.0089],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.10.self_attn.out_proj.weight', Parameter containing:\n","tensor([[ 0.0327,  0.0020,  0.0238,  ...,  0.0160,  0.0081, -0.0004],\n","        [-0.0007,  0.0149,  0.0256,  ...,  0.0010,  0.0039, -0.0019],\n","        [ 0.0003, -0.0052,  0.0084,  ..., -0.0115,  0.0058, -0.0030],\n","        ...,\n","        [ 0.0093, -0.0174, -0.0163,  ..., -0.0034, -0.0010, -0.0130],\n","        [-0.0222,  0.0209,  0.0025,  ...,  0.0026, -0.0085,  0.0041],\n","        [ 0.0117,  0.0159,  0.0354,  ..., -0.0020, -0.0080, -0.0077]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.10.self_attn.out_proj.bias', Parameter containing:\n","tensor([-0.0049, -0.0149,  0.0300,  ..., -0.0161, -0.0030, -0.0169],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.10.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.10.self_attn_layer_norm.bias', Parameter containing:\n","tensor([ 0.0127,  0.0385,  0.0323,  ..., -0.0036,  0.0007, -0.0959],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.10.fc1.weight', Parameter containing:\n","tensor([[-0.0085,  0.0213,  0.0289,  ..., -0.0315,  0.0231, -0.0355],\n","        [-0.0248, -0.0285,  0.0082,  ..., -0.0326, -0.0125,  0.0094],\n","        [ 0.0410, -0.0065,  0.0209,  ...,  0.0007,  0.0252, -0.0073],\n","        ...,\n","        [-0.0016,  0.0067, -0.0081,  ...,  0.0043,  0.0362, -0.0238],\n","        [-0.0369,  0.0020,  0.0078,  ..., -0.0108, -0.0157, -0.0145],\n","        [ 0.0029,  0.0259,  0.0015,  ...,  0.0271, -0.0035, -0.0258]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.10.fc1.bias', Parameter containing:\n","tensor([-0.0115, -0.0062, -0.0058,  ..., -0.0086, -0.0137, -0.0087],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.10.fc2.weight', Parameter containing:\n","tensor([[ 0.0113,  0.0170, -0.0234,  ..., -0.0175,  0.0105,  0.0209],\n","        [ 0.0074, -0.0288,  0.0123,  ..., -0.0030, -0.0031,  0.0135],\n","        [ 0.0136, -0.0082, -0.0034,  ..., -0.0033,  0.0060,  0.0022],\n","        ...,\n","        [ 0.0359, -0.0126,  0.0635,  ..., -0.0031, -0.0359,  0.0033],\n","        [-0.0032, -0.0314, -0.0090,  ..., -0.0097,  0.0145, -0.0266],\n","        [-0.0162,  0.0186,  0.0081,  ...,  0.0056, -0.0335, -0.0023]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.10.fc2.bias', Parameter containing:\n","tensor([-0.0074, -0.0162,  0.0462,  ..., -0.0092,  0.0008, -0.0106],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.10.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.10.final_layer_norm.bias', Parameter containing:\n","tensor([-0.0015, -0.0051, -0.1266,  ...,  0.0741,  0.0785,  0.1088],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.11.self_attn.k_proj.weight', Parameter containing:\n","tensor([[ 0.0023, -0.0336, -0.0423,  ...,  0.0037, -0.0040, -0.0012],\n","        [-0.0127, -0.0242,  0.0182,  ...,  0.0106, -0.0313,  0.0443],\n","        [ 0.0191, -0.0138, -0.0556,  ..., -0.0628, -0.0124, -0.0011],\n","        ...,\n","        [-0.0156,  0.0157,  0.0040,  ..., -0.0140,  0.0042,  0.0218],\n","        [ 0.0142,  0.0018,  0.0305,  ...,  0.0180, -0.0406, -0.0038],\n","        [-0.0081,  0.0250, -0.0130,  ..., -0.0469, -0.0205,  0.0070]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.11.self_attn.k_proj.bias', Parameter containing:\n","tensor([ 0.0053,  0.0156,  0.0328,  ...,  0.0238,  0.0332, -0.0317],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.11.self_attn.v_proj.weight', Parameter containing:\n","tensor([[ 0.0159, -0.0059, -0.0027,  ...,  0.0058, -0.0066, -0.0070],\n","        [-0.0121, -0.0014, -0.0134,  ..., -0.0250,  0.0177, -0.0079],\n","        [ 0.0165,  0.0037, -0.0014,  ...,  0.0051, -0.0132,  0.0078],\n","        ...,\n","        [ 0.0241, -0.0100,  0.0009,  ..., -0.0040,  0.0238,  0.0028],\n","        [ 0.0125, -0.0039,  0.0013,  ...,  0.0002,  0.0319,  0.0011],\n","        [-0.0166,  0.0043,  0.0040,  ..., -0.0014,  0.0146,  0.0168]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.11.self_attn.v_proj.bias', Parameter containing:\n","tensor([ 0.0069,  0.0013,  0.0004,  ..., -0.0019,  0.0003,  0.0011],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.11.self_attn.q_proj.weight', Parameter containing:\n","tensor([[-0.0460, -0.0100,  0.0071,  ...,  0.0436,  0.0141, -0.0135],\n","        [ 0.0043, -0.0425,  0.0341,  ...,  0.0226, -0.0062,  0.0152],\n","        [-0.0094, -0.0329, -0.0433,  ...,  0.0246, -0.0210, -0.0302],\n","        ...,\n","        [-0.0533,  0.0069,  0.0066,  ..., -0.0389,  0.0109, -0.0457],\n","        [-0.0147,  0.0021, -0.0205,  ...,  0.0347,  0.0206,  0.0497],\n","        [-0.0004,  0.0132, -0.0348,  ...,  0.0475,  0.0012, -0.0069]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.11.self_attn.q_proj.bias', Parameter containing:\n","tensor([-0.0162,  0.0011, -0.0030,  ...,  0.0042,  0.0155,  0.0002],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.11.self_attn.out_proj.weight', Parameter containing:\n","tensor([[ 0.0031,  0.0063, -0.0011,  ...,  0.0129, -0.0031,  0.0008],\n","        [-0.0125, -0.0086, -0.0143,  ..., -0.0146,  0.0131,  0.0133],\n","        [ 0.0073,  0.0013, -0.0016,  ...,  0.0063, -0.0199,  0.0118],\n","        ...,\n","        [-0.0056, -0.0027, -0.0202,  ..., -0.0007,  0.0038,  0.0275],\n","        [-0.0181, -0.0121, -0.0107,  ..., -0.0209, -0.0322, -0.0269],\n","        [ 0.0136, -0.0100, -0.0033,  ...,  0.0148, -0.0013, -0.0029]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.11.self_attn.out_proj.bias', Parameter containing:\n","tensor([ 0.0048, -0.0153,  0.0158,  ..., -0.0074, -0.0027, -0.0257],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.11.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.11.self_attn_layer_norm.bias', Parameter containing:\n","tensor([ 0.0176,  0.0388,  0.0479,  ..., -0.0002,  0.0004, -0.0865],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.11.fc1.weight', Parameter containing:\n","tensor([[-3.2425e-03, -2.2831e-03,  6.6605e-03,  ...,  4.6997e-03,\n","          1.5503e-02, -7.5455e-03],\n","        [ 5.2399e-02, -7.5378e-02, -2.9404e-02,  ..., -3.2635e-03,\n","         -1.1024e-02,  1.9760e-02],\n","        [-2.3723e-05, -3.3875e-02,  4.1351e-02,  ..., -2.1088e-02,\n","         -6.0822e-02, -8.1539e-04],\n","        ...,\n","        [-8.6060e-03,  3.1708e-02,  1.1120e-03,  ..., -2.2766e-02,\n","         -1.6281e-02, -8.6594e-04],\n","        [-8.3923e-03,  1.0330e-02, -2.3117e-03,  ...,  2.5482e-02,\n","          1.4366e-02, -5.8212e-03],\n","        [-2.8900e-02, -2.6276e-02, -6.3362e-03,  ..., -1.2856e-03,\n","          3.3455e-03,  1.2596e-02]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.11.fc1.bias', Parameter containing:\n","tensor([-0.0005, -0.0106, -0.0105,  ..., -0.0106, -0.0043, -0.0104],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.11.fc2.weight', Parameter containing:\n","tensor([[-0.0146, -0.0015,  0.0003,  ..., -0.0054,  0.0264, -0.0096],\n","        [-0.0105, -0.0522, -0.0267,  ..., -0.0073,  0.0258, -0.0103],\n","        [ 0.0001, -0.0077,  0.0226,  ...,  0.0026, -0.0014, -0.0226],\n","        ...,\n","        [ 0.0025,  0.0273,  0.0109,  ..., -0.0038, -0.0176,  0.0254],\n","        [-0.0007, -0.0177, -0.0028,  ..., -0.0076, -0.0005, -0.0153],\n","        [-0.0090,  0.0072,  0.0227,  ..., -0.0376,  0.0067,  0.0046]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.11.fc2.bias', Parameter containing:\n","tensor([-0.0018, -0.0194,  0.0630,  ..., -0.0081, -0.0065, -0.0064],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.11.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.11.final_layer_norm.bias', Parameter containing:\n","tensor([ 0.0160,  0.0302, -0.1274,  ...,  0.0460,  0.0654,  0.0141],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.12.self_attn.k_proj.weight', Parameter containing:\n","tensor([[ 0.0109,  0.0324, -0.0252,  ..., -0.0372, -0.0289,  0.0138],\n","        [-0.0316, -0.0385, -0.0503,  ..., -0.0404,  0.0204,  0.0004],\n","        [-0.0067, -0.0272,  0.0367,  ...,  0.0209,  0.0222,  0.0168],\n","        ...,\n","        [ 0.0162, -0.0201,  0.0994,  ..., -0.0121,  0.0033, -0.0039],\n","        [ 0.0110, -0.0253, -0.0496,  ..., -0.0395, -0.0189, -0.0356],\n","        [-0.0199, -0.0330,  0.0143,  ...,  0.0228, -0.0232, -0.0204]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.12.self_attn.k_proj.bias', Parameter containing:\n","tensor([ 0.0698, -0.0461, -0.0494,  ...,  0.0157, -0.0594,  0.0157],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.12.self_attn.v_proj.weight', Parameter containing:\n","tensor([[-0.0048, -0.0125, -0.0110,  ..., -0.0004, -0.0046, -0.0021],\n","        [-0.0092, -0.0073,  0.0094,  ...,  0.0023,  0.0022,  0.0010],\n","        [-0.0440, -0.0062,  0.0095,  ...,  0.0321,  0.0195, -0.0010],\n","        ...,\n","        [ 0.0030, -0.0015, -0.0002,  ..., -0.0239, -0.0063, -0.0118],\n","        [ 0.0128, -0.0202, -0.0022,  ...,  0.0016,  0.0067,  0.0104],\n","        [ 0.0071, -0.0009, -0.0042,  ...,  0.0136,  0.0058, -0.0084]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.12.self_attn.v_proj.bias', Parameter containing:\n","tensor([ 0.0014, -0.0001,  0.0030,  ..., -0.0010,  0.0042, -0.0025],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.12.self_attn.q_proj.weight', Parameter containing:\n","tensor([[ 0.0134,  0.0141, -0.0066,  ...,  0.0427, -0.0023, -0.0230],\n","        [-0.0111, -0.0318, -0.0728,  ..., -0.0270,  0.0294,  0.0064],\n","        [ 0.0002,  0.0315,  0.0431,  ..., -0.0340,  0.0718,  0.0081],\n","        ...,\n","        [-0.0251,  0.0203,  0.0199,  ..., -0.0177,  0.0076, -0.0406],\n","        [ 0.0274, -0.0435,  0.0104,  ..., -0.0623,  0.0113, -0.0353],\n","        [ 0.0267,  0.0001, -0.0525,  ...,  0.0063,  0.0033,  0.0160]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.12.self_attn.q_proj.bias', Parameter containing:\n","tensor([-0.0132, -0.0017,  0.0017,  ..., -0.0130, -0.0278, -0.0062],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.12.self_attn.out_proj.weight', Parameter containing:\n","tensor([[ 0.0145,  0.0031,  0.0063,  ..., -0.0118,  0.0067, -0.0032],\n","        [-0.0015, -0.0282,  0.0142,  ...,  0.0062,  0.0122, -0.0135],\n","        [-0.0091,  0.0010,  0.0111,  ...,  0.0023,  0.0097, -0.0027],\n","        ...,\n","        [-0.0072,  0.0226, -0.0102,  ..., -0.0093,  0.0110,  0.0180],\n","        [ 0.0108,  0.0121,  0.0149,  ..., -0.0099, -0.0185, -0.0042],\n","        [ 0.0026, -0.0117, -0.0243,  ..., -0.0025, -0.0002,  0.0067]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.12.self_attn.out_proj.bias', Parameter containing:\n","tensor([ 0.0021, -0.0144, -0.0314,  ..., -0.0060, -0.0040, -0.0198],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.12.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.12.self_attn_layer_norm.bias', Parameter containing:\n","tensor([ 1.2321e-02,  3.7384e-02,  6.2805e-02,  ..., -1.3292e-05,\n","        -4.5815e-03, -8.3313e-02], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.12.fc1.weight', Parameter containing:\n","tensor([[-0.0062, -0.0079, -0.0247,  ...,  0.0138, -0.0237,  0.0027],\n","        [-0.0104,  0.0122,  0.0056,  ...,  0.0074, -0.0118, -0.0047],\n","        [ 0.0218, -0.0117,  0.0156,  ...,  0.0024, -0.0112, -0.0070],\n","        ...,\n","        [-0.0018, -0.0194, -0.0137,  ..., -0.0056, -0.0327,  0.0217],\n","        [ 0.0042, -0.0191, -0.0037,  ..., -0.0111, -0.0164,  0.0014],\n","        [ 0.0165,  0.0360, -0.0115,  ..., -0.0030,  0.0061, -0.0074]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.12.fc1.bias', Parameter containing:\n","tensor([-0.0046, -0.0093,  0.0074,  ...,  0.0077, -0.0094,  0.0035],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.12.fc2.weight', Parameter containing:\n","tensor([[-0.0053, -0.0223, -0.0046,  ...,  0.0124,  0.0232, -0.0069],\n","        [ 0.0300,  0.0102,  0.0076,  ..., -0.0220,  0.0343,  0.0077],\n","        [-0.0198, -0.0043, -0.0005,  ..., -0.0145, -0.0058,  0.0061],\n","        ...,\n","        [ 0.0042,  0.0197,  0.0010,  ...,  0.0047,  0.0250,  0.0241],\n","        [-0.0190, -0.0363, -0.0099,  ..., -0.0019, -0.0090,  0.0036],\n","        [-0.0059,  0.0123, -0.0096,  ...,  0.0322,  0.0093,  0.0350]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.12.fc2.bias', Parameter containing:\n","tensor([-0.0117, -0.0141,  0.0495,  ..., -0.0086, -0.0091, -0.0060],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.12.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.12.final_layer_norm.bias', Parameter containing:\n","tensor([ 0.0251, -0.0077, -0.0899,  ...,  0.0526,  0.1113,  0.0756],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.13.self_attn.k_proj.weight', Parameter containing:\n","tensor([[-1.9331e-03,  6.5651e-03,  4.9408e-02,  ...,  4.2686e-03,\n","         -1.6571e-02,  8.0795e-03],\n","        [-3.8940e-02, -2.1271e-02,  3.4271e-02,  ...,  2.0325e-02,\n","         -2.8400e-03, -4.1656e-02],\n","        [-1.5007e-02,  2.6779e-02,  3.6560e-02,  ...,  3.4149e-02,\n","         -1.6190e-02,  3.0727e-03],\n","        ...,\n","        [-3.3142e-02, -3.6316e-02,  9.6512e-03,  ..., -8.3466e-03,\n","          3.1342e-02,  3.3813e-02],\n","        [ 1.7365e-02, -2.8152e-02,  2.5452e-02,  ...,  7.9346e-03,\n","         -2.4139e-02, -8.8348e-03],\n","        [-2.1835e-02,  3.4485e-02,  6.1095e-05,  ..., -3.6621e-02,\n","         -2.1835e-02,  9.1124e-04]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.13.self_attn.k_proj.bias', Parameter containing:\n","tensor([-0.1937, -0.1250, -0.1250,  ...,  0.1252,  0.0987, -0.1250],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.13.self_attn.v_proj.weight', Parameter containing:\n","tensor([[ 0.0014, -0.0223,  0.0070,  ..., -0.0105, -0.0015,  0.0003],\n","        [ 0.0275,  0.0222,  0.0006,  ...,  0.0090, -0.0131, -0.0060],\n","        [-0.0327,  0.0076, -0.0048,  ...,  0.0026,  0.0034,  0.0132],\n","        ...,\n","        [ 0.0205, -0.0056, -0.0067,  ..., -0.0004, -0.0252,  0.0165],\n","        [ 0.0071,  0.0248,  0.0027,  ..., -0.0117, -0.0023, -0.0040],\n","        [-0.0115,  0.0148, -0.0029,  ..., -0.0091, -0.0028,  0.0083]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.13.self_attn.v_proj.bias', Parameter containing:\n","tensor([-6.9904e-04, -3.2635e-03,  6.1929e-05,  ...,  2.6417e-04,\n","        -7.0047e-04,  9.4080e-04], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.13.self_attn.q_proj.weight', Parameter containing:\n","tensor([[ 4.6043e-03, -5.8708e-03,  6.4758e-02,  ...,  2.5131e-02,\n","          1.1261e-02, -3.5675e-02],\n","        [-5.3062e-03,  1.4580e-02,  1.8997e-02,  ...,  2.3026e-02,\n","          5.7259e-03,  1.0361e-02],\n","        [-9.8267e-03,  3.0151e-02,  1.8082e-02,  ..., -1.2131e-02,\n","          3.3398e-03,  5.2002e-02],\n","        ...,\n","        [-1.2398e-02,  4.6692e-02, -1.7328e-03,  ..., -1.7609e-02,\n","         -7.8082e-06, -2.4433e-03],\n","        [ 2.8782e-03, -5.7587e-02, -3.8757e-03,  ..., -3.4729e-02,\n","          2.2659e-02, -7.8583e-03],\n","        [ 5.0873e-02, -3.1128e-02, -1.4931e-02,  ...,  4.6783e-02,\n","         -3.7918e-03, -4.0474e-03]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.13.self_attn.q_proj.bias', Parameter containing:\n","tensor([ 0.0450,  0.0199,  0.0363,  ...,  0.0177,  0.0056, -0.0132],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.13.self_attn.out_proj.weight', Parameter containing:\n","tensor([[ 0.0056, -0.0257,  0.0298,  ..., -0.0026,  0.0481, -0.0150],\n","        [ 0.0074, -0.0094, -0.0110,  ..., -0.0176, -0.0014, -0.0158],\n","        [-0.0190, -0.0079,  0.0007,  ..., -0.0054, -0.0053, -0.0059],\n","        ...,\n","        [-0.0019, -0.0091, -0.0039,  ..., -0.0119, -0.0114, -0.0127],\n","        [ 0.0033,  0.0173,  0.0023,  ..., -0.0019,  0.0005,  0.0191],\n","        [-0.0064,  0.0054, -0.0111,  ...,  0.0052, -0.0047,  0.0008]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.13.self_attn.out_proj.bias', Parameter containing:\n","tensor([ 0.0058, -0.0119,  0.0139,  ..., -0.0072, -0.0033, -0.0193],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.13.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.13.self_attn_layer_norm.bias', Parameter containing:\n","tensor([ 0.0124,  0.0435,  0.0624,  ...,  0.0014, -0.0057, -0.0626],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.13.fc1.weight', Parameter containing:\n","tensor([[ 1.4275e-02,  1.4091e-02,  2.7985e-02,  ...,  2.7313e-03,\n","          6.8359e-03, -2.4155e-02],\n","        [-9.7656e-03,  1.6632e-02,  6.6147e-03,  ..., -9.0485e-03,\n","          8.4763e-03, -1.4069e-02],\n","        [-7.1678e-03,  3.1769e-02,  1.5335e-02,  ..., -2.5444e-03,\n","          1.5411e-02,  1.9409e-02],\n","        ...,\n","        [ 6.9389e-03,  1.1238e-02, -2.9583e-03,  ...,  6.8512e-03,\n","          2.2964e-02,  1.0948e-02],\n","        [-8.7280e-03,  4.8828e-02,  2.3773e-02,  ..., -6.8054e-03,\n","          6.7368e-03,  2.7180e-05],\n","        [ 1.1803e-02,  5.0392e-03,  1.4734e-04,  ..., -1.9958e-02,\n","         -5.0621e-03,  1.0719e-02]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.13.fc1.bias', Parameter containing:\n","tensor([-0.0092, -0.0117, -0.0067,  ..., -0.0068, -0.0172, -0.0027],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.13.fc2.weight', Parameter containing:\n","tensor([[ 0.0453,  0.0063, -0.0054,  ...,  0.0131,  0.0063,  0.0292],\n","        [-0.0119, -0.0197,  0.0023,  ..., -0.0170,  0.0689, -0.0337],\n","        [ 0.0031,  0.0152, -0.0074,  ..., -0.0052,  0.0065, -0.0028],\n","        ...,\n","        [-0.0222,  0.0233, -0.0331,  ..., -0.0012, -0.0004, -0.0064],\n","        [-0.0063, -0.0025,  0.0223,  ..., -0.0449,  0.0005,  0.0134],\n","        [ 0.0067, -0.0103,  0.0053,  ..., -0.0057,  0.0088, -0.0056]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.13.fc2.bias', Parameter containing:\n","tensor([-0.0187, -0.0211,  0.0705,  ..., -0.0094, -0.0037, -0.0130],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.13.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.13.final_layer_norm.bias', Parameter containing:\n","tensor([ 0.0544, -0.0045, -0.1124,  ...,  0.0966,  0.0963,  0.0832],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.14.self_attn.k_proj.weight', Parameter containing:\n","tensor([[ 0.0084,  0.0071, -0.0066,  ...,  0.0427,  0.0189,  0.0197],\n","        [-0.0093,  0.0166,  0.0323,  ..., -0.0120,  0.0280, -0.0220],\n","        [-0.0338, -0.0058, -0.0489,  ...,  0.0108,  0.0405, -0.0315],\n","        ...,\n","        [ 0.0390, -0.0133, -0.0580,  ...,  0.0226,  0.0033,  0.0278],\n","        [ 0.0026, -0.0019, -0.0662,  ..., -0.0294, -0.0190, -0.0073],\n","        [ 0.0027,  0.0304, -0.0308,  ..., -0.0144,  0.0353,  0.0060]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.14.self_attn.k_proj.bias', Parameter containing:\n","tensor([ 0.0080,  0.1076, -0.0338,  ...,  0.1678, -0.2285,  0.0473],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.14.self_attn.v_proj.weight', Parameter containing:\n","tensor([[-0.0020, -0.0128, -0.0067,  ...,  0.0032, -0.0003, -0.0015],\n","        [-0.0184,  0.0132,  0.0044,  ..., -0.0135, -0.0242, -0.0201],\n","        [ 0.0090, -0.0190,  0.0163,  ...,  0.0061,  0.0036, -0.0747],\n","        ...,\n","        [-0.0040,  0.0002, -0.0184,  ..., -0.0233, -0.0205, -0.0028],\n","        [ 0.0040,  0.0113, -0.0045,  ...,  0.0156,  0.0171,  0.0020],\n","        [ 0.0088,  0.0046, -0.0034,  ...,  0.0137, -0.0128,  0.0068]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.14.self_attn.v_proj.bias', Parameter containing:\n","tensor([ 0.0021,  0.0009,  0.0035,  ..., -0.0011,  0.0005,  0.0008],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.14.self_attn.q_proj.weight', Parameter containing:\n","tensor([[-4.6906e-02,  2.8362e-03,  7.8064e-02,  ..., -9.6436e-03,\n","         -1.9028e-02, -5.1453e-02],\n","        [-8.9340e-03,  4.8065e-02, -2.5120e-03,  ...,  2.1622e-02,\n","          2.8900e-02,  2.1637e-02],\n","        [-2.8491e-05,  2.5597e-03, -3.6804e-02,  ..., -3.8116e-02,\n","         -1.1086e-02,  2.9327e-02],\n","        ...,\n","        [ 1.1971e-02, -2.1790e-02,  2.5725e-04,  ..., -3.5950e-02,\n","         -3.8605e-02, -3.7170e-02],\n","        [-9.8953e-03, -1.6541e-02, -3.6987e-02,  ...,  3.6926e-02,\n","          2.2446e-02, -1.1452e-02],\n","        [ 2.2110e-02,  2.6962e-02, -3.7201e-02,  ..., -1.0696e-02,\n","          2.7451e-02,  1.5091e-02]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.14.self_attn.q_proj.bias', Parameter containing:\n","tensor([ 0.0009,  0.0601,  0.0247,  ...,  0.0153, -0.0043,  0.0035],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.14.self_attn.out_proj.weight', Parameter containing:\n","tensor([[ 2.2018e-02, -3.7813e-04, -1.2428e-02,  ..., -1.8631e-02,\n","          1.4740e-02,  4.8218e-03],\n","        [-1.2161e-02, -2.9190e-02, -4.0507e-04,  ..., -1.2985e-02,\n","          8.1100e-03, -4.9133e-03],\n","        [ 1.0834e-02,  2.9850e-03, -2.6917e-04,  ..., -3.2806e-02,\n","          1.2741e-02,  1.6651e-03],\n","        ...,\n","        [ 2.3102e-02,  7.2365e-03,  4.7836e-03,  ...,  7.6199e-04,\n","          6.9046e-03,  1.6205e-02],\n","        [-8.6060e-03,  7.1869e-03,  6.5842e-03,  ..., -6.8054e-03,\n","          1.3748e-02, -1.9608e-02],\n","        [ 1.3969e-02,  2.6169e-03, -5.4300e-05,  ...,  1.9283e-03,\n","          9.7122e-03,  1.6541e-02]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.14.self_attn.out_proj.bias', Parameter containing:\n","tensor([-0.0092, -0.0049, -0.0061,  ...,  0.0039, -0.0110, -0.0238],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.14.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.14.self_attn_layer_norm.bias', Parameter containing:\n","tensor([ 0.0145,  0.0436,  0.0617,  ..., -0.0038, -0.0037, -0.0247],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.14.fc1.weight', Parameter containing:\n","tensor([[ 0.0335,  0.0254,  0.0267,  ...,  0.0149,  0.0198, -0.0529],\n","        [-0.0508,  0.0187, -0.0098,  ..., -0.0150,  0.0028,  0.0061],\n","        [ 0.0004,  0.0121,  0.0251,  ..., -0.0464,  0.0036, -0.0095],\n","        ...,\n","        [-0.0008, -0.0360, -0.0072,  ...,  0.0284,  0.0065,  0.0279],\n","        [-0.0194,  0.0086,  0.0051,  ..., -0.0224, -0.0292, -0.0355],\n","        [ 0.0029, -0.0085,  0.0001,  ...,  0.0406,  0.0086, -0.0191]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.14.fc1.bias', Parameter containing:\n","tensor([-0.0189, -0.0133, -0.0140,  ..., -0.0174, -0.0139, -0.0183],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.14.fc2.weight', Parameter containing:\n","tensor([[ 0.0419,  0.0019,  0.0004,  ...,  0.0108,  0.0218,  0.0246],\n","        [-0.0025,  0.0018, -0.0449,  ...,  0.0089,  0.0211, -0.0333],\n","        [ 0.0147, -0.0035, -0.0215,  ..., -0.0018, -0.0061, -0.0121],\n","        ...,\n","        [ 0.0175,  0.0380,  0.0026,  ..., -0.0052,  0.0405,  0.0051],\n","        [ 0.0239, -0.0479,  0.0387,  ...,  0.0110, -0.0248,  0.0027],\n","        [-0.0280, -0.0132, -0.0178,  ..., -0.0014, -0.0133, -0.0017]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.14.fc2.bias', Parameter containing:\n","tensor([-0.0171, -0.0262,  0.0775,  ..., -0.0062, -0.0051, -0.0267],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.14.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.14.final_layer_norm.bias', Parameter containing:\n","tensor([ 0.0496, -0.0234, -0.0859,  ...,  0.1041,  0.0629,  0.0935],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.15.self_attn.k_proj.weight', Parameter containing:\n","tensor([[-0.0120, -0.0179,  0.0095,  ..., -0.0144,  0.0018,  0.0028],\n","        [ 0.0053,  0.0122, -0.0153,  ...,  0.0001,  0.0100, -0.0122],\n","        [-0.0004,  0.0365,  0.0106,  ...,  0.0093, -0.0117,  0.0064],\n","        ...,\n","        [ 0.0281, -0.0341,  0.0390,  ...,  0.0132, -0.0181,  0.0046],\n","        [-0.0259,  0.0030,  0.0090,  ...,  0.0020,  0.0113, -0.0101],\n","        [ 0.0380, -0.0076,  0.0146,  ..., -0.0257, -0.0233,  0.0109]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.15.self_attn.k_proj.bias', Parameter containing:\n","tensor([ 0.0625, -0.0233,  0.0250,  ...,  0.1250, -0.2286,  0.2081],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.15.self_attn.v_proj.weight', Parameter containing:\n","tensor([[-0.0167,  0.0202, -0.0067,  ...,  0.0241, -0.0116,  0.0003],\n","        [ 0.0062,  0.0154,  0.0008,  ...,  0.0074, -0.0064, -0.0044],\n","        [-0.0060,  0.0169,  0.0152,  ..., -0.0352,  0.0204,  0.0007],\n","        ...,\n","        [ 0.0398, -0.0253, -0.0084,  ..., -0.0122,  0.0237, -0.0091],\n","        [-0.0175, -0.0106,  0.0099,  ..., -0.0289, -0.0025,  0.0122],\n","        [ 0.0099,  0.0164,  0.0091,  ..., -0.0287,  0.0040, -0.0059]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.15.self_attn.v_proj.bias', Parameter containing:\n","tensor([-1.8196e-03, -1.7319e-03,  2.5392e-04,  ..., -3.3438e-05,\n","         8.8120e-04,  4.9543e-04], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.15.self_attn.q_proj.weight', Parameter containing:\n","tensor([[ 7.2250e-03,  7.3509e-03,  1.7609e-02,  ..., -1.2703e-02,\n","          6.7253e-03, -2.4704e-02],\n","        [-5.0211e-04,  1.4229e-02, -3.7323e-02,  ..., -7.6199e-04,\n","          2.3071e-02, -1.2260e-02],\n","        [-2.9221e-02,  1.8311e-02,  5.2124e-02,  ...,  2.5894e-02,\n","          8.1711e-03, -6.6299e-03],\n","        ...,\n","        [-2.2736e-02,  2.5681e-02,  4.2458e-03,  ..., -2.5665e-02,\n","         -5.8289e-03,  4.9095e-03],\n","        [-1.0391e-02,  1.6418e-02, -2.1408e-02,  ..., -1.5121e-02,\n","          1.9806e-02, -8.7509e-03],\n","        [-5.3894e-02,  5.2948e-03,  1.0376e-02,  ..., -1.0033e-02,\n","         -8.8215e-05, -8.1940e-03]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.15.self_attn.q_proj.bias', Parameter containing:\n","tensor([0.0069, 0.0330, 0.1123,  ..., 0.0056, 0.0002, 0.0033], device='cuda:0',\n","       requires_grad=True))\n","('coreOPT.decoder.layers.15.self_attn.out_proj.weight', Parameter containing:\n","tensor([[-0.0036, -0.0167,  0.0015,  ..., -0.0435,  0.0115, -0.0091],\n","        [-0.0033, -0.0140, -0.0042,  ...,  0.0158, -0.0043,  0.0215],\n","        [ 0.0407, -0.0199, -0.0353,  ..., -0.0014, -0.0204,  0.0086],\n","        ...,\n","        [-0.0131, -0.0009,  0.0218,  ..., -0.0015,  0.0061,  0.0261],\n","        [ 0.0140, -0.0306, -0.0322,  ..., -0.0043, -0.0179,  0.0204],\n","        [ 0.0060,  0.0105,  0.0077,  ...,  0.0277,  0.0175, -0.0028]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.15.self_attn.out_proj.bias', Parameter containing:\n","tensor([ 0.0041, -0.0096,  0.0372,  ...,  0.0011, -0.0077, -0.0209],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.15.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.15.self_attn_layer_norm.bias', Parameter containing:\n","tensor([0.0204, 0.0445, 0.0410,  ..., 0.0117, 0.0080, 0.0091], device='cuda:0',\n","       requires_grad=True))\n","('coreOPT.decoder.layers.15.fc1.weight', Parameter containing:\n","tensor([[-0.0166,  0.0171,  0.0039,  ..., -0.0067,  0.0159,  0.0097],\n","        [-0.0190, -0.0051,  0.0014,  ...,  0.0011, -0.0196, -0.0027],\n","        [-0.0194, -0.0024,  0.0115,  ..., -0.0303, -0.0022,  0.0158],\n","        ...,\n","        [-0.0132,  0.0066,  0.0049,  ...,  0.0077, -0.0061, -0.0009],\n","        [ 0.0158, -0.0183,  0.0096,  ..., -0.0198,  0.0067, -0.0055],\n","        [ 0.0066,  0.0103, -0.0208,  ..., -0.0110,  0.0111, -0.0121]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.15.fc1.bias', Parameter containing:\n","tensor([ 0.0046, -0.0102, -0.0056,  ..., -0.0151,  0.0005, -0.0147],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.15.fc2.weight', Parameter containing:\n","tensor([[-0.0028, -0.0042, -0.0030,  ..., -0.0024,  0.0024, -0.0007],\n","        [ 0.0150, -0.0107,  0.0141,  ...,  0.0133,  0.0262, -0.0153],\n","        [-0.0062, -0.0188,  0.0006,  ..., -0.0033,  0.0050,  0.0020],\n","        ...,\n","        [-0.0077,  0.0225,  0.0308,  ...,  0.0329,  0.0188,  0.0144],\n","        [ 0.0055,  0.0108, -0.0065,  ..., -0.0035,  0.0033, -0.0214],\n","        [ 0.0055, -0.0171, -0.0178,  ..., -0.0445,  0.0044, -0.0164]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.15.fc2.bias', Parameter containing:\n","tensor([-0.0108, -0.0217,  0.0955,  ...,  0.0106,  0.0077, -0.0197],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.15.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.15.final_layer_norm.bias', Parameter containing:\n","tensor([ 0.0291, -0.0258, -0.1172,  ...,  0.0956,  0.0532,  0.0698],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.16.self_attn.k_proj.weight', Parameter containing:\n","tensor([[ 0.0380,  0.0175,  0.0771,  ..., -0.0167, -0.0111,  0.0282],\n","        [-0.0097, -0.0175, -0.0149,  ..., -0.0184, -0.0022, -0.0148],\n","        [-0.0057, -0.0084,  0.0200,  ...,  0.0341,  0.0186,  0.0037],\n","        ...,\n","        [ 0.0115,  0.0025,  0.0083,  ..., -0.0015,  0.0053, -0.0386],\n","        [ 0.0406,  0.0122, -0.0085,  ..., -0.0147,  0.0161, -0.0004],\n","        [-0.0049, -0.0296,  0.0385,  ..., -0.0198, -0.0196, -0.0205]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.16.self_attn.k_proj.bias', Parameter containing:\n","tensor([-0.0022, -0.1250,  0.1431,  ...,  0.0870,  0.1260, -0.0612],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.16.self_attn.v_proj.weight', Parameter containing:\n","tensor([[ 0.0386, -0.0317, -0.0076,  ..., -0.0200,  0.0039,  0.0074],\n","        [ 0.0124,  0.0048, -0.0085,  ..., -0.0085, -0.0180,  0.0096],\n","        [-0.0271, -0.0083, -0.0080,  ..., -0.0305, -0.0117, -0.0088],\n","        ...,\n","        [-0.0135,  0.0058, -0.0008,  ...,  0.0085,  0.0064,  0.0153],\n","        [-0.0154,  0.0350, -0.0098,  ..., -0.0015,  0.0035, -0.0125],\n","        [-0.0156, -0.0054, -0.0040,  ...,  0.0174,  0.0043,  0.0138]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.16.self_attn.v_proj.bias', Parameter containing:\n","tensor([ 0.0010, -0.0003,  0.0014,  ..., -0.0017,  0.0004, -0.0017],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.16.self_attn.q_proj.weight', Parameter containing:\n","tensor([[-0.0165,  0.0120,  0.0106,  ..., -0.0264, -0.0157, -0.0092],\n","        [-0.0322, -0.0008, -0.0347,  ...,  0.0166, -0.0239, -0.0086],\n","        [-0.0038, -0.0118, -0.0040,  ...,  0.0067, -0.0118,  0.0474],\n","        ...,\n","        [-0.0196, -0.0081, -0.0500,  ...,  0.0231,  0.0219,  0.0253],\n","        [-0.0053, -0.0006,  0.0422,  ..., -0.0354,  0.0493,  0.0270],\n","        [-0.0021,  0.0329, -0.0219,  ..., -0.0197, -0.0086,  0.0313]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.16.self_attn.q_proj.bias', Parameter containing:\n","tensor([-0.0199,  0.0084,  0.0411,  ...,  0.0112, -0.0003, -0.0104],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.16.self_attn.out_proj.weight', Parameter containing:\n","tensor([[ 0.0057, -0.0026, -0.0263,  ..., -0.0025,  0.0021, -0.0063],\n","        [-0.0031, -0.0100,  0.0148,  ..., -0.0113,  0.0192,  0.0148],\n","        [-0.0272, -0.0045, -0.0073,  ...,  0.0058,  0.0002,  0.0122],\n","        ...,\n","        [-0.0158, -0.0082, -0.0010,  ..., -0.0215, -0.0267,  0.0142],\n","        [-0.0019,  0.0119, -0.0249,  ...,  0.0027,  0.0197, -0.0069],\n","        [ 0.0054,  0.0045,  0.0118,  ...,  0.0318,  0.0080, -0.0014]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.16.self_attn.out_proj.bias', Parameter containing:\n","tensor([ 0.0070, -0.0077, -0.0544,  ..., -0.0120, -0.0036, -0.0065],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.16.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.16.self_attn_layer_norm.bias', Parameter containing:\n","tensor([ 0.0143,  0.0487,  0.0395,  ...,  0.0050, -0.0015, -0.0074],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.16.fc1.weight', Parameter containing:\n","tensor([[ 0.0130, -0.0042, -0.0155,  ...,  0.0031,  0.0348,  0.0220],\n","        [-0.0179,  0.0056, -0.0120,  ..., -0.0176,  0.0006, -0.0168],\n","        [-0.0224, -0.0067,  0.0080,  ...,  0.0072,  0.0096, -0.0544],\n","        ...,\n","        [ 0.0298, -0.0050, -0.0065,  ...,  0.0199, -0.0110, -0.0402],\n","        [-0.0081, -0.0372, -0.0186,  ...,  0.0112, -0.0053, -0.0564],\n","        [-0.0215,  0.0237,  0.0278,  ...,  0.0446,  0.0234,  0.0145]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.16.fc1.bias', Parameter containing:\n","tensor([-0.0128, -0.0023, -0.0122,  ..., -0.0203, -0.0204, -0.0193],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.16.fc2.weight', Parameter containing:\n","tensor([[-0.0103,  0.0047,  0.0012,  ..., -0.0141, -0.0092, -0.0418],\n","        [-0.0468, -0.0203,  0.0251,  ...,  0.0418, -0.0087,  0.0310],\n","        [-0.0160, -0.0053, -0.0094,  ...,  0.0200, -0.0111, -0.0045],\n","        ...,\n","        [ 0.0256,  0.0022, -0.0102,  ...,  0.0033,  0.0445,  0.0104],\n","        [ 0.0418,  0.0067,  0.0179,  ...,  0.0249,  0.0171,  0.0248],\n","        [-0.0096,  0.0008,  0.0215,  ...,  0.0033, -0.0206, -0.0061]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.16.fc2.bias', Parameter containing:\n","tensor([-0.0098, -0.0266,  0.0737,  ...,  0.0054,  0.0110, -0.0176],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.16.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.16.final_layer_norm.bias', Parameter containing:\n","tensor([ 0.0467, -0.0229, -0.1343,  ...,  0.0677,  0.0836,  0.1102],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.17.self_attn.k_proj.weight', Parameter containing:\n","tensor([[ 0.0127, -0.0021, -0.0354,  ..., -0.0026, -0.0187,  0.0012],\n","        [-0.0033, -0.0077, -0.0487,  ...,  0.0169, -0.0085, -0.0206],\n","        [ 0.0092,  0.0263,  0.0016,  ..., -0.0287,  0.0410,  0.0071],\n","        ...,\n","        [-0.0159, -0.0087,  0.0060,  ...,  0.0501,  0.0321,  0.0121],\n","        [-0.0157, -0.0200,  0.0753,  ...,  0.0321,  0.0242, -0.0265],\n","        [-0.0179,  0.0245, -0.0047,  ...,  0.0397,  0.0391,  0.0102]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.17.self_attn.k_proj.bias', Parameter containing:\n","tensor([-0.1033, -0.1174,  0.0605,  ...,  0.1250,  0.0400, -0.0626],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.17.self_attn.v_proj.weight', Parameter containing:\n","tensor([[ 0.0029, -0.0291, -0.0174,  ..., -0.0319, -0.0159,  0.0126],\n","        [-0.0012, -0.0031, -0.0059,  ..., -0.0099, -0.0335, -0.0011],\n","        [-0.0058, -0.0218, -0.0126,  ..., -0.0096, -0.0274,  0.0277],\n","        ...,\n","        [-0.0106,  0.0049,  0.0086,  ..., -0.0073,  0.0067,  0.0022],\n","        [-0.0062,  0.0128,  0.0204,  ...,  0.0079,  0.0070,  0.0065],\n","        [-0.0240,  0.0027,  0.0086,  ...,  0.0018,  0.0148,  0.0178]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.17.self_attn.v_proj.bias', Parameter containing:\n","tensor([ 0.0008, -0.0006, -0.0017,  ...,  0.0008, -0.0006,  0.0022],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.17.self_attn.q_proj.weight', Parameter containing:\n","tensor([[-0.0019, -0.0019,  0.0067,  ...,  0.0498, -0.0449,  0.0222],\n","        [ 0.0018,  0.0086, -0.0552,  ...,  0.0092, -0.0173,  0.0390],\n","        [-0.0276, -0.0061,  0.0046,  ..., -0.0125,  0.0036, -0.0012],\n","        ...,\n","        [-0.0096, -0.0153, -0.0394,  ..., -0.0065,  0.0041,  0.0217],\n","        [ 0.0026, -0.0304,  0.0412,  ...,  0.0039,  0.0127, -0.0261],\n","        [-0.0511,  0.0249,  0.0101,  ..., -0.0151,  0.0034,  0.0511]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.17.self_attn.q_proj.bias', Parameter containing:\n","tensor([ 0.0348, -0.0008, -0.0025,  ...,  0.0174,  0.0144,  0.0149],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.17.self_attn.out_proj.weight', Parameter containing:\n","tensor([[ 0.0199,  0.0092, -0.0338,  ..., -0.0245, -0.0162, -0.0094],\n","        [-0.0017,  0.0127, -0.0152,  ...,  0.0173,  0.0086,  0.0304],\n","        [-0.0065, -0.0071, -0.0082,  ...,  0.0089,  0.0304,  0.0069],\n","        ...,\n","        [ 0.0030,  0.0289, -0.0045,  ...,  0.0002, -0.0057,  0.0041],\n","        [-0.0057, -0.0418,  0.0206,  ..., -0.0014,  0.0052,  0.0126],\n","        [-0.0262, -0.0036,  0.0010,  ..., -0.0133, -0.0163, -0.0035]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.17.self_attn.out_proj.bias', Parameter containing:\n","tensor([-0.0097, -0.0115,  0.0114,  ..., -0.0014, -0.0286, -0.0246],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.17.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.17.self_attn_layer_norm.bias', Parameter containing:\n","tensor([0.0222, 0.0638, 0.0607,  ..., 0.0239, 0.0112, 0.0082], device='cuda:0',\n","       requires_grad=True))\n","('coreOPT.decoder.layers.17.fc1.weight', Parameter containing:\n","tensor([[ 0.0126, -0.0060, -0.0381,  ...,  0.0115, -0.0155,  0.0065],\n","        [ 0.0032,  0.0050,  0.0080,  ...,  0.0269, -0.0222,  0.0025],\n","        [-0.0163, -0.0090,  0.0054,  ..., -0.0019, -0.0051, -0.0074],\n","        ...,\n","        [-0.0161,  0.0120,  0.0032,  ..., -0.0438, -0.0142, -0.0282],\n","        [ 0.0251, -0.0327, -0.0011,  ..., -0.0234, -0.0238, -0.0096],\n","        [ 0.0004, -0.0136, -0.0144,  ..., -0.0167, -0.0115, -0.0188]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.17.fc1.bias', Parameter containing:\n","tensor([-0.0100, -0.0076, -0.0111,  ..., -0.0107, -0.0178, -0.0051],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.17.fc2.weight', Parameter containing:\n","tensor([[ 0.0194,  0.0008,  0.0220,  ..., -0.0173,  0.0009, -0.0249],\n","        [ 0.0079,  0.0222,  0.0146,  ..., -0.0268, -0.0433, -0.0019],\n","        [-0.0484, -0.0141,  0.0172,  ...,  0.0126, -0.0139,  0.0008],\n","        ...,\n","        [ 0.0051,  0.0180,  0.0117,  ...,  0.0175, -0.0025, -0.0049],\n","        [-0.0222, -0.0107, -0.0154,  ..., -0.0102, -0.0164,  0.0039],\n","        [-0.0163, -0.0021, -0.0040,  ..., -0.0096, -0.0447,  0.0026]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.17.fc2.bias', Parameter containing:\n","tensor([-0.0161, -0.0088,  0.0718,  ...,  0.0025,  0.0122, -0.0261],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.17.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.17.final_layer_norm.bias', Parameter containing:\n","tensor([ 0.0371, -0.0552, -0.1136,  ...,  0.0746,  0.0457,  0.1041],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.18.self_attn.k_proj.weight', Parameter containing:\n","tensor([[ 0.0043, -0.0098,  0.0331,  ..., -0.0243,  0.0077, -0.0053],\n","        [ 0.0025,  0.0370,  0.0039,  ..., -0.0036,  0.0084,  0.0239],\n","        [ 0.0026,  0.0016, -0.0352,  ..., -0.0006, -0.0085,  0.0632],\n","        ...,\n","        [-0.0098, -0.0187,  0.0122,  ...,  0.0029, -0.0028,  0.0092],\n","        [ 0.0259, -0.0293, -0.0087,  ..., -0.0526, -0.0523, -0.0142],\n","        [ 0.0368, -0.0418,  0.0281,  ...,  0.0108,  0.0050, -0.0046]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.18.self_attn.k_proj.bias', Parameter containing:\n","tensor([ 0.1434, -0.1797,  0.1252,  ...,  0.0840, -0.1250, -0.1902],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.18.self_attn.v_proj.weight', Parameter containing:\n","tensor([[-0.0366,  0.0194,  0.0012,  ..., -0.0036,  0.0233, -0.0011],\n","        [-0.0141, -0.0346,  0.0006,  ..., -0.0267, -0.0295,  0.0040],\n","        [ 0.0027, -0.0573, -0.0068,  ...,  0.0182, -0.0005,  0.0145],\n","        ...,\n","        [-0.0068,  0.0038,  0.0055,  ...,  0.0098,  0.0038,  0.0036],\n","        [-0.0432,  0.0124,  0.0070,  ...,  0.0056, -0.0052,  0.0075],\n","        [-0.0237,  0.0046, -0.0091,  ...,  0.0106, -0.0146, -0.0193]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.18.self_attn.v_proj.bias', Parameter containing:\n","tensor([-0.0017,  0.0030,  0.0002,  ..., -0.0009,  0.0023, -0.0016],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.18.self_attn.q_proj.weight', Parameter containing:\n","tensor([[-0.0042, -0.0236,  0.0187,  ..., -0.0144, -0.0187,  0.0149],\n","        [ 0.0064,  0.0104, -0.0209,  ..., -0.0034,  0.0108, -0.0210],\n","        [ 0.0219,  0.0167, -0.0201,  ...,  0.0247, -0.0346,  0.0129],\n","        ...,\n","        [ 0.0131, -0.0322,  0.0180,  ...,  0.0082, -0.0142,  0.0220],\n","        [-0.0080, -0.0249, -0.0334,  ..., -0.0038,  0.0102,  0.0009],\n","        [ 0.0142, -0.0233,  0.0106,  ..., -0.0098, -0.0186,  0.0319]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.18.self_attn.q_proj.bias', Parameter containing:\n","tensor([-0.0083,  0.0025, -0.0085,  ..., -0.0148, -0.0066, -0.0191],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.18.self_attn.out_proj.weight', Parameter containing:\n","tensor([[-0.0086,  0.0525, -0.0240,  ...,  0.0089, -0.0255, -0.0062],\n","        [ 0.0684,  0.0032,  0.0153,  ..., -0.0430, -0.0229,  0.0192],\n","        [-0.0044, -0.0007,  0.0164,  ...,  0.0555, -0.0060, -0.0046],\n","        ...,\n","        [-0.0375, -0.0173,  0.0162,  ..., -0.0082, -0.0381,  0.0013],\n","        [-0.0073,  0.0126, -0.0200,  ...,  0.0030,  0.0218,  0.0092],\n","        [ 0.0257,  0.0238, -0.0013,  ..., -0.0290,  0.0157,  0.0033]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.18.self_attn.out_proj.bias', Parameter containing:\n","tensor([ 0.0195, -0.0073,  0.0553,  ...,  0.0151, -0.0127, -0.0192],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.18.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.18.self_attn_layer_norm.bias', Parameter containing:\n","tensor([0.0226, 0.0482, 0.0336,  ..., 0.0207, 0.0161, 0.0486], device='cuda:0',\n","       requires_grad=True))\n","('coreOPT.decoder.layers.18.fc1.weight', Parameter containing:\n","tensor([[-0.0275,  0.0158,  0.0138,  ..., -0.0268,  0.0077,  0.0217],\n","        [ 0.0044,  0.0003, -0.0008,  ..., -0.0201,  0.0365, -0.0321],\n","        [ 0.0320,  0.0006, -0.0317,  ...,  0.0076, -0.0026, -0.0143],\n","        ...,\n","        [-0.0091, -0.0150, -0.0173,  ..., -0.0037, -0.0151, -0.0241],\n","        [-0.0147, -0.0047,  0.0171,  ...,  0.0101, -0.0275, -0.0142],\n","        [-0.0391,  0.0035,  0.0021,  ...,  0.0151,  0.0046,  0.0415]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.18.fc1.bias', Parameter containing:\n","tensor([-0.0065, -0.0060, -0.0075,  ..., -0.0108, -0.0149, -0.0153],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.18.fc2.weight', Parameter containing:\n","tensor([[-1.8219e-02, -1.1650e-02, -3.6883e-04,  ..., -8.8272e-03,\n","         -1.3611e-02,  1.8661e-02],\n","        [-2.1744e-02,  2.8305e-02,  2.0325e-04,  ..., -5.2071e-03,\n","         -2.6855e-02,  1.9211e-02],\n","        [-6.7215e-03,  1.1997e-03,  9.8495e-03,  ...,  7.2212e-03,\n","         -2.9663e-02,  3.1292e-05],\n","        ...,\n","        [ 2.1194e-02, -4.5395e-03,  2.2324e-02,  ...,  1.2886e-02,\n","         -1.4091e-02,  2.8320e-02],\n","        [ 3.9978e-03,  2.4292e-02,  1.6693e-02,  ...,  7.0839e-03,\n","         -9.0256e-03,  2.3468e-02],\n","        [ 1.1536e-02, -5.3120e-04,  1.3580e-02,  ..., -2.4200e-02,\n","          1.8723e-02, -3.2684e-02]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.18.fc2.bias', Parameter containing:\n","tensor([-0.0243, -0.0028,  0.0577,  ...,  0.0052,  0.0101, -0.0122],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.18.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.18.final_layer_norm.bias', Parameter containing:\n","tensor([-0.0070, -0.1129, -0.0653,  ...,  0.0395,  0.0297,  0.1556],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.19.self_attn.k_proj.weight', Parameter containing:\n","tensor([[ 0.0160,  0.0120, -0.0135,  ...,  0.0012, -0.0027,  0.0126],\n","        [ 0.0432,  0.0069,  0.0341,  ..., -0.0479, -0.0134, -0.0239],\n","        [ 0.0130, -0.0196, -0.0087,  ..., -0.0007, -0.0293,  0.0025],\n","        ...,\n","        [-0.0188,  0.0035, -0.0172,  ..., -0.0194,  0.0017,  0.0016],\n","        [ 0.0263, -0.0117,  0.0194,  ...,  0.0025, -0.0046,  0.0093],\n","        [ 0.0285,  0.0136,  0.0226,  ...,  0.0260,  0.0051, -0.0242]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.19.self_attn.k_proj.bias', Parameter containing:\n","tensor([ 0.0946,  0.2500, -0.2500,  ..., -0.2500, -0.5000, -0.1687],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.19.self_attn.v_proj.weight', Parameter containing:\n","tensor([[-3.5675e-02,  1.0368e-02, -2.4368e-02,  ..., -7.3128e-03,\n","          9.1858e-03, -6.4850e-05],\n","        [-1.5129e-02, -3.3264e-02, -1.4830e-03,  ..., -3.4363e-02,\n","          9.5797e-04, -5.3444e-03],\n","        [ 1.5480e-02,  2.8473e-02,  3.9406e-03,  ..., -2.3613e-03,\n","         -4.7974e-02,  4.3564e-03],\n","        ...,\n","        [ 3.2593e-02, -1.1032e-02,  2.2945e-03,  ...,  2.8014e-04,\n","         -1.2360e-02,  1.7426e-02],\n","        [-6.7635e-03, -9.5673e-03,  1.9638e-02,  ...,  4.4861e-02,\n","          1.1501e-03,  1.0239e-02],\n","        [-5.0087e-03,  4.1412e-02, -1.7578e-02,  ...,  1.9196e-02,\n","         -2.0020e-02, -1.7731e-02]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.19.self_attn.v_proj.bias', Parameter containing:\n","tensor([-0.0048, -0.0019, -0.0070,  ...,  0.0037, -0.0022, -0.0006],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.19.self_attn.q_proj.weight', Parameter containing:\n","tensor([[-1.6891e-02,  1.2856e-03,  8.7662e-03,  ...,  3.5339e-02,\n","          3.0594e-02, -1.0133e-05],\n","        [ 3.2715e-02, -1.6260e-03, -1.5526e-03,  ..., -2.7359e-02,\n","          4.5624e-03, -2.4384e-02],\n","        [-7.5417e-03, -2.8336e-02,  1.9394e-02,  ..., -3.3264e-02,\n","          2.4612e-02, -1.5472e-02],\n","        ...,\n","        [-5.3833e-02, -1.2978e-02,  2.6230e-02,  ...,  1.4091e-02,\n","         -2.5375e-02, -1.6403e-02],\n","        [ 7.3357e-03, -6.1493e-03,  2.5314e-02,  ..., -1.1925e-02,\n","         -2.0660e-02,  3.3722e-02],\n","        [ 3.2013e-02,  1.9226e-02,  1.2665e-02,  ...,  1.7395e-02,\n","         -9.4223e-03,  6.6566e-03]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.19.self_attn.q_proj.bias', Parameter containing:\n","tensor([ 0.0285, -0.0241, -0.0002,  ...,  0.0095,  0.0985,  0.0288],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.19.self_attn.out_proj.weight', Parameter containing:\n","tensor([[-0.0204, -0.0082, -0.0247,  ...,  0.0005, -0.0231,  0.0149],\n","        [ 0.0150, -0.0046,  0.0327,  ..., -0.0121, -0.0041, -0.0184],\n","        [ 0.0054, -0.0124,  0.0135,  ..., -0.0054,  0.0164,  0.0092],\n","        ...,\n","        [ 0.0243, -0.0034,  0.0313,  ...,  0.0125, -0.0532, -0.0196],\n","        [ 0.0154, -0.0222,  0.0197,  ..., -0.0229, -0.0140, -0.0546],\n","        [-0.0237, -0.0260,  0.0024,  ..., -0.0205, -0.0042,  0.0277]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.19.self_attn.out_proj.bias', Parameter containing:\n","tensor([-0.0086, -0.0155,  0.0626,  ...,  0.0218, -0.0297, -0.0068],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.19.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.19.self_attn_layer_norm.bias', Parameter containing:\n","tensor([0.0250, 0.0412, 0.0267,  ..., 0.0316, 0.0245, 0.0624], device='cuda:0',\n","       requires_grad=True))\n","('coreOPT.decoder.layers.19.fc1.weight', Parameter containing:\n","tensor([[ 2.3041e-02, -3.0994e-03,  2.1820e-02,  ..., -3.7750e-02,\n","         -2.8114e-03, -1.9165e-02],\n","        [-5.6801e-03,  2.8152e-03,  7.8278e-03,  ..., -1.3191e-02,\n","         -1.3214e-02, -3.4698e-02],\n","        [ 1.0796e-02,  1.3054e-02, -2.0087e-05,  ...,  1.6418e-02,\n","          1.9287e-02, -7.8125e-03],\n","        ...,\n","        [ 1.7197e-02, -2.4857e-02,  2.9312e-02,  ..., -9.9258e-03,\n","          1.0323e-02, -7.1144e-04],\n","        [ 2.6398e-02,  1.6525e-02, -2.0340e-02,  ..., -2.2949e-02,\n","          1.5518e-02, -4.3762e-02],\n","        [-4.4647e-02,  2.3270e-02,  2.0905e-02,  ...,  8.0645e-05,\n","          2.2186e-02,  1.9592e-02]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.19.fc1.bias', Parameter containing:\n","tensor([-0.0076, -0.0110, -0.0090,  ..., -0.0101, -0.0103, -0.0071],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.19.fc2.weight', Parameter containing:\n","tensor([[-0.0221, -0.0151, -0.0025,  ...,  0.0540, -0.0032,  0.0388],\n","        [ 0.0180,  0.0190, -0.0245,  ..., -0.0090,  0.0231,  0.0254],\n","        [ 0.0406, -0.0169,  0.0342,  ..., -0.0136, -0.0176, -0.0482],\n","        ...,\n","        [-0.0275,  0.0023, -0.0179,  ..., -0.0090,  0.0015, -0.0080],\n","        [-0.0026, -0.0175, -0.0265,  ...,  0.0145,  0.0082, -0.0088],\n","        [-0.0096,  0.0012,  0.0055,  ..., -0.0073, -0.0088, -0.0153]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.19.fc2.bias', Parameter containing:\n","tensor([-0.0105,  0.0113,  0.0338,  ...,  0.0026,  0.0005, -0.0115],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.19.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.19.final_layer_norm.bias', Parameter containing:\n","tensor([-0.0066, -0.1278, -0.0135,  ...,  0.0754,  0.0518,  0.1599],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.20.self_attn.k_proj.weight', Parameter containing:\n","tensor([[ 0.0107, -0.0221, -0.0290,  ..., -0.0065, -0.0004,  0.0314],\n","        [ 0.0507,  0.0189, -0.0202,  ...,  0.0158,  0.0406, -0.0228],\n","        [-0.0041, -0.0050, -0.0271,  ..., -0.0100,  0.0225, -0.0138],\n","        ...,\n","        [ 0.0052, -0.0138,  0.0181,  ..., -0.0305, -0.0148,  0.0078],\n","        [ 0.0014,  0.0154,  0.0097,  ..., -0.0023,  0.0198, -0.0226],\n","        [ 0.0034, -0.0011, -0.0331,  ...,  0.0282,  0.0054, -0.0055]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.20.self_attn.k_proj.bias', Parameter containing:\n","tensor([-0.2500, -0.1682, -0.2500,  ...,  0.2537, -0.2500, -0.2500],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.20.self_attn.v_proj.weight', Parameter containing:\n","tensor([[-4.5959e-02,  8.5983e-03,  3.2806e-02,  ...,  5.1003e-03,\n","         -2.8549e-02, -2.5959e-03],\n","        [ 1.9073e-06,  3.6438e-02,  4.0588e-03,  ..., -1.4591e-03,\n","          7.2250e-03,  9.6664e-03],\n","        [-7.5684e-03,  1.9287e-02, -1.7380e-02,  ..., -5.0240e-03,\n","          2.5742e-02,  1.7609e-02],\n","        ...,\n","        [ 8.5526e-03,  1.9791e-02,  4.1870e-02,  ...,  2.5162e-02,\n","         -3.0350e-02,  1.3626e-02],\n","        [-1.2636e-03, -2.3361e-02,  5.3940e-03,  ...,  3.4618e-03,\n","         -6.1131e-04,  3.7201e-02],\n","        [ 1.7853e-02, -1.2331e-03,  3.4454e-02,  ..., -1.4435e-02,\n","         -6.6345e-02, -7.8735e-03]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.20.self_attn.v_proj.bias', Parameter containing:\n","tensor([ 0.0010, -0.0024, -0.0014,  ..., -0.0025, -0.0021,  0.0021],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.20.self_attn.q_proj.weight', Parameter containing:\n","tensor([[ 0.0206,  0.0064,  0.0438,  ...,  0.0151, -0.0406, -0.0006],\n","        [-0.0044, -0.0055, -0.0039,  ...,  0.0211, -0.0022,  0.0073],\n","        [-0.0017,  0.0022,  0.0354,  ...,  0.0239, -0.0083, -0.0035],\n","        ...,\n","        [ 0.0172, -0.0117, -0.0200,  ...,  0.0290, -0.0027,  0.0214],\n","        [ 0.0022, -0.0014,  0.0252,  ...,  0.0251,  0.0334,  0.0070],\n","        [-0.0055, -0.0026,  0.0062,  ...,  0.0234,  0.0185,  0.0171]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.20.self_attn.q_proj.bias', Parameter containing:\n","tensor([ 0.0202,  0.0058,  0.0117,  ..., -0.0347,  0.0090,  0.0091],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.20.self_attn.out_proj.weight', Parameter containing:\n","tensor([[-0.0548, -0.0138,  0.0018,  ...,  0.0377,  0.0169,  0.0038],\n","        [-0.0264, -0.0492,  0.0293,  ..., -0.0093, -0.0091,  0.0048],\n","        [ 0.0430, -0.0125, -0.0260,  ...,  0.0066,  0.0010,  0.0205],\n","        ...,\n","        [ 0.0173,  0.0254, -0.0067,  ..., -0.0260,  0.0281,  0.0055],\n","        [-0.0273,  0.0151, -0.0347,  ...,  0.0493, -0.0079, -0.0296],\n","        [-0.0046, -0.0090,  0.0336,  ...,  0.0322, -0.0001,  0.0007]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.20.self_attn.out_proj.bias', Parameter containing:\n","tensor([-0.0041, -0.0202,  0.0572,  ...,  0.0041,  0.0029,  0.0103],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.20.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.20.self_attn_layer_norm.bias', Parameter containing:\n","tensor([0.0257, 0.0370, 0.0097,  ..., 0.0313, 0.0254, 0.0660], device='cuda:0',\n","       requires_grad=True))\n","('coreOPT.decoder.layers.20.fc1.weight', Parameter containing:\n","tensor([[ 0.0180, -0.0276,  0.0487,  ...,  0.0280, -0.0411, -0.0273],\n","        [ 0.0015, -0.0022, -0.0336,  ..., -0.0257, -0.0302, -0.0264],\n","        [ 0.0021,  0.0448, -0.0118,  ...,  0.0108, -0.0571, -0.0064],\n","        ...,\n","        [-0.0204,  0.0162, -0.0234,  ...,  0.0158, -0.0127,  0.0074],\n","        [ 0.0185, -0.0313, -0.0095,  ...,  0.0070, -0.0055, -0.0259],\n","        [ 0.0158, -0.0030, -0.0310,  ..., -0.0279,  0.0028,  0.0040]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.20.fc1.bias', Parameter containing:\n","tensor([-0.0213,  0.0040, -0.0197,  ..., -0.0175, -0.0232, -0.0097],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.20.fc2.weight', Parameter containing:\n","tensor([[ 0.0087, -0.0117,  0.0218,  ...,  0.0011, -0.0062,  0.0468],\n","        [ 0.0112,  0.0034,  0.0005,  ...,  0.0259,  0.0204,  0.0156],\n","        [-0.0493,  0.0104,  0.0022,  ..., -0.0348,  0.0084, -0.0097],\n","        ...,\n","        [-0.0074, -0.0076,  0.0336,  ...,  0.0110,  0.0083,  0.0350],\n","        [ 0.0012, -0.0333, -0.0123,  ..., -0.0098, -0.0102, -0.0144],\n","        [ 0.0408, -0.0052, -0.0114,  ...,  0.0265,  0.0183,  0.0130]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.20.fc2.bias', Parameter containing:\n","tensor([-0.0074,  0.0119,  0.0255,  ...,  0.0074, -0.0047, -0.0193],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.20.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.20.final_layer_norm.bias', Parameter containing:\n","tensor([-0.0371, -0.1671,  0.0123,  ...,  0.0074,  0.0284,  0.1565],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.21.self_attn.k_proj.weight', Parameter containing:\n","tensor([[ 0.0022,  0.0184,  0.0092,  ...,  0.0204, -0.0010, -0.0169],\n","        [-0.0102,  0.0197, -0.0253,  ...,  0.0059,  0.0222, -0.0222],\n","        [ 0.0206, -0.0086, -0.0264,  ..., -0.0009, -0.0589, -0.0040],\n","        ...,\n","        [-0.0157, -0.0240,  0.0522,  ...,  0.0435,  0.0234, -0.0028],\n","        [-0.0023,  0.0128, -0.0130,  ...,  0.0034,  0.0068,  0.0020],\n","        [-0.0482,  0.0122,  0.0237,  ..., -0.0187, -0.0027,  0.0327]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.21.self_attn.k_proj.bias', Parameter containing:\n","tensor([ 0.5000, -0.5000, -0.5000,  ...,  0.4968, -0.3992,  0.3062],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.21.self_attn.v_proj.weight', Parameter containing:\n","tensor([[-0.0095,  0.0118, -0.0060,  ...,  0.0315,  0.0023,  0.0071],\n","        [-0.0024,  0.0081, -0.0103,  ...,  0.0145, -0.0133, -0.0087],\n","        [-0.0206,  0.0093,  0.0171,  ...,  0.0061,  0.0390, -0.0250],\n","        ...,\n","        [-0.0254,  0.0137, -0.0142,  ...,  0.0083,  0.0059,  0.0013],\n","        [-0.0405,  0.0155, -0.0017,  ...,  0.0167,  0.0011,  0.0660],\n","        [-0.0280, -0.0247, -0.0319,  ..., -0.0184, -0.0314, -0.0143]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.21.self_attn.v_proj.bias', Parameter containing:\n","tensor([-0.0073, -0.0034, -0.0027,  ..., -0.0010,  0.0043,  0.0008],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.21.self_attn.q_proj.weight', Parameter containing:\n","tensor([[-0.0213,  0.0198, -0.0157,  ...,  0.0099,  0.0176, -0.0179],\n","        [-0.0012,  0.0339, -0.0424,  ...,  0.0132,  0.0172,  0.0130],\n","        [-0.0180, -0.0123,  0.0233,  ...,  0.0157,  0.0087,  0.0289],\n","        ...,\n","        [ 0.0290, -0.0091,  0.0104,  ..., -0.0166, -0.0004,  0.0010],\n","        [-0.0034, -0.0171, -0.0022,  ...,  0.0161,  0.0240,  0.0225],\n","        [ 0.0076, -0.0255, -0.0105,  ..., -0.0441,  0.0026, -0.0234]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.21.self_attn.q_proj.bias', Parameter containing:\n","tensor([-0.0119,  0.0036,  0.0200,  ..., -0.0176, -0.0049,  0.0092],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.21.self_attn.out_proj.weight', Parameter containing:\n","tensor([[ 0.0101,  0.0045,  0.0002,  ...,  0.0114, -0.0017, -0.0265],\n","        [-0.0114,  0.0189, -0.0010,  ..., -0.0239,  0.0416,  0.0179],\n","        [ 0.0307, -0.0435,  0.0165,  ..., -0.0281, -0.0056, -0.0057],\n","        ...,\n","        [ 0.0084,  0.0282, -0.0015,  ..., -0.0124,  0.0100, -0.0211],\n","        [ 0.0044, -0.0078,  0.0079,  ...,  0.0344, -0.0120, -0.0081],\n","        [ 0.0153,  0.0099, -0.0397,  ..., -0.0111, -0.0446, -0.0359]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.21.self_attn.out_proj.bias', Parameter containing:\n","tensor([-0.0149, -0.0143,  0.0007,  ...,  0.0369, -0.0329, -0.0347],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.21.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.21.self_attn_layer_norm.bias', Parameter containing:\n","tensor([ 0.0125,  0.0288, -0.0045,  ...,  0.0414,  0.0259,  0.0988],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.21.fc1.weight', Parameter containing:\n","tensor([[-0.0128,  0.0084,  0.0216,  ..., -0.0356, -0.0040, -0.0085],\n","        [-0.0141, -0.0092, -0.0256,  ..., -0.0052, -0.0100, -0.0555],\n","        [ 0.0283, -0.0234, -0.0016,  ...,  0.0159,  0.0274, -0.0050],\n","        ...,\n","        [-0.0335, -0.0131, -0.0375,  ..., -0.0728, -0.0154, -0.0352],\n","        [ 0.0105, -0.0075, -0.0003,  ..., -0.0484,  0.0330, -0.0112],\n","        [-0.0054, -0.0043, -0.0060,  ..., -0.0085,  0.0573,  0.0177]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.21.fc1.bias', Parameter containing:\n","tensor([-0.0096, -0.0033, -0.0414,  ..., -0.0081, -0.0199, -0.0192],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.21.fc2.weight', Parameter containing:\n","tensor([[-0.0451,  0.0213, -0.0097,  ...,  0.0212,  0.0092,  0.0058],\n","        [-0.0205,  0.0837, -0.0328,  ...,  0.0387, -0.0261, -0.0093],\n","        [-0.0084, -0.0113,  0.0208,  ...,  0.0246,  0.0290, -0.0102],\n","        ...,\n","        [-0.0296, -0.0032,  0.0298,  ...,  0.0408, -0.0293,  0.0142],\n","        [-0.0053,  0.0235,  0.0169,  ...,  0.0004, -0.0057,  0.0342],\n","        [-0.0119,  0.0377, -0.0128,  ...,  0.0022, -0.0339, -0.0416]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.21.fc2.bias', Parameter containing:\n","tensor([-0.0236, -0.0093, -0.0131,  ...,  0.0351,  0.0293,  0.0239],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.21.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.21.final_layer_norm.bias', Parameter containing:\n","tensor([-0.0567, -0.1753,  0.1087,  ..., -0.0153,  0.0534,  0.1417],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.22.self_attn.k_proj.weight', Parameter containing:\n","tensor([[-0.0038,  0.0033,  0.0004,  ..., -0.0196,  0.0255, -0.0432],\n","        [ 0.0296, -0.0246,  0.0055,  ...,  0.0544,  0.0239,  0.0117],\n","        [ 0.0110, -0.0080, -0.0057,  ...,  0.0494,  0.0005,  0.0496],\n","        ...,\n","        [ 0.0022, -0.0106, -0.0186,  ..., -0.0145,  0.0134, -0.0167],\n","        [ 0.0310,  0.0144,  0.0033,  ..., -0.0247,  0.0045,  0.0124],\n","        [ 0.0056, -0.0197, -0.0104,  ..., -0.0334, -0.0569, -0.0146]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.22.self_attn.k_proj.bias', Parameter containing:\n","tensor([-0.5000,  0.5000,  0.5000,  ..., -0.5000,  0.5000, -0.5000],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.22.self_attn.v_proj.weight', Parameter containing:\n","tensor([[-3.9948e-02, -1.2695e-02, -6.6452e-03,  ..., -6.6895e-02,\n","          6.9094e-04,  1.7075e-02],\n","        [-8.6746e-03, -5.1994e-03, -5.4436e-03,  ...,  3.1494e-02,\n","         -1.5915e-02,  2.0966e-02],\n","        [ 4.8599e-03, -9.0182e-05, -1.9623e-02,  ...,  1.2260e-02,\n","         -3.5828e-02,  6.0310e-03],\n","        ...,\n","        [ 4.4586e-02, -2.9633e-02,  3.4542e-03,  ..., -1.1589e-02,\n","         -2.6810e-02,  4.0894e-02],\n","        [ 4.8332e-03,  6.5117e-03,  1.1215e-02,  ..., -6.2332e-03,\n","          3.2684e-02,  8.2932e-03],\n","        [ 6.3293e-02, -1.6153e-04,  7.9193e-03,  ..., -5.2643e-03,\n","         -4.1275e-03, -3.1799e-02]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.22.self_attn.v_proj.bias', Parameter containing:\n","tensor([ 0.0001,  0.0005,  0.0004,  ...,  0.0014, -0.0013, -0.0005],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.22.self_attn.q_proj.weight', Parameter containing:\n","tensor([[-0.0007,  0.0531,  0.0088,  ...,  0.0151,  0.0339, -0.0045],\n","        [ 0.0443,  0.0004, -0.0066,  ...,  0.0149,  0.0004,  0.0019],\n","        [-0.0057, -0.0297, -0.0434,  ...,  0.0049, -0.0221,  0.0580],\n","        ...,\n","        [ 0.0221, -0.0222,  0.0014,  ..., -0.0088,  0.0151,  0.0254],\n","        [-0.0273, -0.0117, -0.0199,  ..., -0.0745, -0.0414,  0.0203],\n","        [-0.0032, -0.0003, -0.0321,  ..., -0.0182, -0.0035, -0.0003]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.22.self_attn.q_proj.bias', Parameter containing:\n","tensor([-0.0046, -0.0143,  0.0204,  ...,  0.0036, -0.0085,  0.0225],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.22.self_attn.out_proj.weight', Parameter containing:\n","tensor([[-0.0133,  0.0150, -0.0137,  ..., -0.0138,  0.0187,  0.0026],\n","        [-0.0122,  0.0293,  0.0074,  ..., -0.0067,  0.0056,  0.0161],\n","        [ 0.0239, -0.0077,  0.0384,  ..., -0.0056,  0.0327, -0.0089],\n","        ...,\n","        [ 0.0106, -0.0137,  0.0002,  ..., -0.0361, -0.0350,  0.0381],\n","        [-0.0238, -0.0043, -0.0038,  ..., -0.0254,  0.0231,  0.0076],\n","        [ 0.0137, -0.0015, -0.0019,  ..., -0.0450,  0.0028, -0.0681]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.22.self_attn.out_proj.bias', Parameter containing:\n","tensor([ 0.0152, -0.0175,  0.0357,  ...,  0.0233,  0.0095, -0.0198],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.22.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.22.self_attn_layer_norm.bias', Parameter containing:\n","tensor([ 0.0054,  0.0559, -0.0005,  ...,  0.1224,  0.0790,  0.1417],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.22.fc1.weight', Parameter containing:\n","tensor([[-0.0026,  0.0260, -0.0197,  ..., -0.0130, -0.0055,  0.0060],\n","        [-0.0188, -0.0212,  0.0214,  ..., -0.0054, -0.0161,  0.0164],\n","        [ 0.0031, -0.0044,  0.0298,  ...,  0.0377,  0.0090,  0.0163],\n","        ...,\n","        [ 0.0500,  0.0156, -0.0028,  ...,  0.0173,  0.0128, -0.0018],\n","        [ 0.0274,  0.0107, -0.0121,  ...,  0.0076, -0.0228, -0.0172],\n","        [ 0.0410,  0.0111,  0.0057,  ..., -0.0001,  0.0165,  0.0253]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.22.fc1.bias', Parameter containing:\n","tensor([-0.0174,  0.0021, -0.0143,  ..., -0.0018, -0.0069, -0.0045],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.22.fc2.weight', Parameter containing:\n","tensor([[-1.6623e-03,  1.0117e-02, -2.4071e-03,  ..., -3.9093e-02,\n","         -1.2161e-02, -1.9484e-03],\n","        [-2.1072e-02,  4.8027e-03,  7.9117e-03,  ...,  1.1932e-02,\n","         -2.0172e-02,  2.3193e-02],\n","        [-9.5367e-06, -7.7934e-03,  2.5803e-02,  ..., -1.5671e-02,\n","          2.3804e-02,  3.3600e-02],\n","        ...,\n","        [ 3.0258e-02, -1.1549e-03,  1.1177e-02,  ..., -3.6133e-02,\n","          3.1647e-02,  1.4854e-02],\n","        [-2.1267e-03,  2.3071e-02,  1.4038e-03,  ...,  1.8082e-02,\n","         -3.8376e-03, -1.8539e-02],\n","        [ 1.5945e-02,  2.1057e-02,  4.4556e-02,  ..., -1.2291e-02,\n","         -1.5068e-03,  5.6496e-03]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.22.fc2.bias', Parameter containing:\n","tensor([-0.0154, -0.0059,  0.0047,  ...,  0.0424,  0.0193,  0.0171],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.22.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.22.final_layer_norm.bias', Parameter containing:\n","tensor([-0.0369, -0.1395,  0.1214,  ...,  0.0483,  0.1243,  0.1455],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.23.self_attn.k_proj.weight', Parameter containing:\n","tensor([[ 0.0280,  0.0198,  0.0012,  ...,  0.0221,  0.0142,  0.0119],\n","        [ 0.0145,  0.0021, -0.0067,  ...,  0.0071, -0.0017,  0.0168],\n","        [ 0.0154,  0.0410,  0.0362,  ...,  0.0135,  0.0256,  0.0408],\n","        ...,\n","        [-0.0527, -0.0559, -0.0263,  ..., -0.0085, -0.0149, -0.0388],\n","        [-0.0313,  0.0087, -0.0252,  ..., -0.0198, -0.0421, -0.0051],\n","        [-0.0248, -0.0134, -0.0109,  ..., -0.0590, -0.0138, -0.0056]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.23.self_attn.k_proj.bias', Parameter containing:\n","tensor([ 0.5000,  0.2671,  0.5000,  ..., -0.5000, -0.5000, -0.5000],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.23.self_attn.v_proj.weight', Parameter containing:\n","tensor([[ 0.0049, -0.0061,  0.0112,  ..., -0.0015, -0.0148,  0.0147],\n","        [ 0.0311, -0.0088,  0.0010,  ...,  0.0086, -0.0034, -0.0070],\n","        [-0.0034, -0.0076, -0.0219,  ..., -0.0055, -0.0029, -0.0085],\n","        ...,\n","        [ 0.0496,  0.0155, -0.0117,  ...,  0.0092, -0.0009, -0.0315],\n","        [ 0.0042,  0.0129, -0.0018,  ...,  0.0126,  0.0153,  0.0176],\n","        [-0.0048, -0.0036,  0.0021,  ..., -0.0320,  0.0053, -0.0083]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.23.self_attn.v_proj.bias', Parameter containing:\n","tensor([ 0.0017,  0.0011,  0.0008,  ...,  0.0001, -0.0001, -0.0004],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.23.self_attn.q_proj.weight', Parameter containing:\n","tensor([[ 0.0978, -0.0792, -0.0936,  ..., -0.0122, -0.0352, -0.0770],\n","        [ 0.0479, -0.0715, -0.0683,  ..., -0.0435, -0.0555, -0.0564],\n","        [ 0.0924, -0.0804, -0.0509,  ..., -0.0537, -0.0114, -0.0757],\n","        ...,\n","        [-0.0372,  0.0702,  0.0460,  ..., -0.0207,  0.0069, -0.0007],\n","        [-0.0403,  0.1151,  0.0609,  ..., -0.0173,  0.0698,  0.0578],\n","        [-0.0703,  0.1248,  0.1039,  ..., -0.0482, -0.0139,  0.0115]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.23.self_attn.q_proj.bias', Parameter containing:\n","tensor([-0.1006, -0.0660, -0.0880,  ...,  0.0307,  0.0307,  0.0311],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.23.self_attn.out_proj.weight', Parameter containing:\n","tensor([[-0.0163,  0.0115, -0.0222,  ..., -0.0369, -0.0248, -0.0194],\n","        [-0.0078, -0.0095, -0.0033,  ...,  0.0288,  0.0248,  0.0210],\n","        [ 0.0398,  0.0082, -0.0114,  ...,  0.0415, -0.0214,  0.0438],\n","        ...,\n","        [ 0.0201,  0.0037, -0.0196,  ...,  0.0406, -0.0413, -0.0342],\n","        [-0.0003,  0.0278,  0.0072,  ...,  0.0111, -0.0159, -0.0048],\n","        [ 0.0091,  0.0039,  0.0119,  ...,  0.0479,  0.0312, -0.0609]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.23.self_attn.out_proj.bias', Parameter containing:\n","tensor([ 0.0412,  0.0417,  0.0060,  ...,  0.0357, -0.0075, -0.0510],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.23.self_attn_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.23.self_attn_layer_norm.bias', Parameter containing:\n","tensor([0.1390, 0.2500, 0.2500,  ..., 0.2500, 0.2500, 0.2500], device='cuda:0',\n","       requires_grad=True))\n","('coreOPT.decoder.layers.23.fc1.weight', Parameter containing:\n","tensor([[ 1.1230e-02, -2.0126e-02,  1.4519e-02,  ...,  1.3380e-03,\n","         -1.2535e-02,  2.8442e-02],\n","        [ 4.5654e-02,  3.2063e-03, -1.9745e-02,  ...,  3.1113e-02,\n","          6.9809e-03,  1.6556e-02],\n","        [-5.5084e-03,  3.9062e-02, -3.4618e-03,  ...,  3.8719e-04,\n","         -3.4241e-02, -4.0131e-02],\n","        ...,\n","        [-1.9531e-02,  3.8635e-02, -7.2144e-02,  ...,  2.5604e-02,\n","          2.5314e-02,  3.3752e-02],\n","        [ 1.6418e-02, -8.9467e-05, -1.9943e-02,  ...,  1.3680e-02,\n","         -2.7695e-03, -7.3280e-03],\n","        [-2.4185e-02,  3.3997e-02, -2.1866e-02,  ...,  1.8084e-04,\n","         -1.5686e-02, -1.2077e-02]], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.23.fc1.bias', Parameter containing:\n","tensor([-0.0159, -0.0263, -0.0272,  ...,  0.0490, -0.0137, -0.0039],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.23.fc2.weight', Parameter containing:\n","tensor([[-0.0056, -0.0338, -0.0040,  ..., -0.0054, -0.0373,  0.0116],\n","        [-0.0107,  0.0353,  0.0192,  ..., -0.0020,  0.0484, -0.0063],\n","        [-0.0838,  0.0384, -0.0273,  ...,  0.0510, -0.0079, -0.0155],\n","        ...,\n","        [ 0.0407,  0.0206,  0.0088,  ..., -0.0103, -0.0120, -0.0161],\n","        [ 0.0276, -0.0456, -0.0094,  ..., -0.0146,  0.0399,  0.0058],\n","        [ 0.0055, -0.0074, -0.0679,  ...,  0.0019, -0.0140, -0.0136]],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.23.fc2.bias', Parameter containing:\n","tensor([-0.0096,  0.0027,  0.0209,  ...,  0.0467,  0.0269, -0.0206],\n","       device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.23.final_layer_norm.weight', Parameter containing:\n","tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True))\n","('coreOPT.decoder.layers.23.final_layer_norm.bias', Parameter containing:\n","tensor([-0.0145, -0.1015,  0.0997,  ...,  0.0743,  0.1257,  0.1272],\n","       device='cuda:0', requires_grad=True))\n","('lm_OPT_head.weight', Parameter containing:\n","tensor([[ 0.0175, -0.0312, -0.0176,  ..., -0.0374, -0.0247,  0.0100],\n","        [ 0.0168, -0.0312, -0.0161,  ..., -0.0373, -0.0273,  0.0114],\n","        [-0.0407,  0.0519,  0.0574,  ..., -0.0263, -0.0355, -0.0260],\n","        ...,\n","        [ 0.0182, -0.0312, -0.0163,  ..., -0.0359, -0.0312,  0.0133],\n","        [ 0.0189, -0.0312, -0.0171,  ..., -0.0371, -0.0230,  0.0085],\n","        [ 0.0182, -0.0312, -0.0193,  ..., -0.0365, -0.0280, -0.0224]],\n","       device='cuda:0', requires_grad=True))\n"]}],"source":["for param in example_myOPT_CD_FT.named_parameters():\n","  print(param)"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"d6HfGqaLbwY6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523791405,"user_tz":-120,"elapsed":39,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"3d39b674-2b1f-4bf7-dedf-c715527d028e"},"outputs":[{"output_type":"stream","name":"stdout","text":["YES token before training:     tensor([ 0.0097, -0.0088, -0.0440,  ..., -0.0301, -0.0121,  0.0087],\n","       device='cuda:0', grad_fn=<SelectBackward0>)\n","NO token before training:      tensor([-0.0151, -0.0090, -0.0768,  ..., -0.0016, -0.0118, -0.0248],\n","       device='cuda:0', grad_fn=<SelectBackward0>)\n"]}],"source":["print(\"YES token before training:    \", example_myOPT_CD_FT.coreOPT.decoder.embed_tokens.weight[9904])\n","print(\"NO token before training:     \", example_myOPT_CD_FT.coreOPT.decoder.embed_tokens.weight[3084])"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"r36cjWMRWmQZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523791405,"user_tz":-120,"elapsed":4,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"088400dc-6013-44f0-88ae-3b2ac95184ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["coreOPT.decoder.embed_tokens.weight is trainable\n"]}],"source":["for param in example_myOPT_CD_FT.parameters():\n","    param.requires_grad = False\n","for param in example_myOPT_CD_FT.coreOPT.decoder.embed_tokens.parameters():\n","    param.requires_grad = True\n","\n","for name, param in example_myOPT_CD_FT.named_parameters():\n","  if param.requires_grad:\n","    print(f\"{name} is {'trainable' if param.requires_grad else 'frozen'}\")"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"EyNBAkHqce50","executionInfo":{"status":"ok","timestamp":1714523792480,"user_tz":-120,"elapsed":1077,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["\n","learning_rate = 1e-4\n","num_epochs = 25\n","\n","# torch.use_deterministic_algorithms(False)\n","optimizer = torch.optim.Adam(example_myOPT_CD_FT.coreOPT.decoder.embed_tokens.parameters(), lr = learning_rate)\n","# model.new_weights = nn.Parameter(torch.randn_like(model.layer1.weight))\n","'''\n","optimizer = torch.optim.Adam([\n","    {'params': example_myOPT_CD_FT.coreOPT.decoder.embed_tokens.weight[9904], 'lr': learning_rate},\n","    {'params': example_myOPT_CD_FT.coreOPT.decoder.embed_tokens.weight[3084], 'lr': learning_rate}\n","])\n","'''\n","\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n","criterion = nn.KLDivLoss(reduction=\"batchmean\", log_target=True)"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"nD6TDdGvbyXX","executionInfo":{"status":"ok","timestamp":1714523792481,"user_tz":-120,"elapsed":3,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["def train_CD(num_epochs, data_loader, model, optimizer, criterion, scheduler, learning_rate=learning_rate):\n","  \"\"\"\n","  one epoch train function, one batch\n","  \"\"\"\n","\n","  #scaler = GradScaler()\n","  model.train()\n","\n","  all_loss = []\n","\n","  for t_step in range(num_epochs):\n","    # start = time.time()\n","    optimizer.zero_grad()\n","\n","\n","    batch_loss = []\n","\n","    for i, batch in enumerate(data_loader):\n","\n","      with torch.set_grad_enabled(True):\n","\n","\n","        with autocast():\n","          raw_output_scores = model.forward(batch['input_ids'].to(device), batch['attention_mask'].to(device))\n","\n","          scores_model = raw_output_scores[:,-1,:] # Select only the newly created (last one)\n","\n","\n","          smax_fn = nn.Softmax(dim=1) # perform softmax to obtain probabilities\n","          probs_model = smax_fn(scores_model) # perform softmax to obtain probabilities\n","          sel_model_probs = torch.gather(probs_model, 1, batch['OPT_idxs'].to(device))\n","          tot_prob = torch.unsqueeze(1-torch.sum(sel_model_probs, dim=1),1)\n","          model_probs = torch.cat((sel_model_probs, tot_prob), dim=1)\n","\n","\n","          loss =  criterion(torch.log(model_probs), torch.log(batch['OPT_probs'].detach().to(device)))\n","          loss.backward()\n","\n","          optimizer.step()\n","          optimizer.zero_grad()\n","\n","        #loss = torch.sum(model_probs - batch['OPT_probs'].detach().to(device))\n","        print(\"indiv Batch loss: \", loss)\n","\n","        batch_loss.append(loss)\n","\n","\n","    batch_loss_vals = [element.item() for element in batch_loss]\n","\n","    print(\"EPOCH: \", t_step, \"BATCH: \", i, \"avg batch loss: \", np.mean(batch_loss_vals), \"indiv batch loss: \", batch_loss_vals)\n","    all_loss.append(np.mean(batch_loss_vals))\n","  print(\"all_loss: \", all_loss)\n","  return all_loss"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"04J0pISkbyHr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7d184f7e-0f77-4b09-8ba6-d04021d3e91d","executionInfo":{"status":"ok","timestamp":1714523836231,"user_tz":-120,"elapsed":43753,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["indiv Batch loss:  tensor(6.5261, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(2.3843, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(3.0931, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(3.3505, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(2.8960, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.9177, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(2.7383, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(3.2913, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(3.2663, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(3.1909, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(3.8299, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(2.4488, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.9014, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(3.1869, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(2.1103, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(2.2117, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  0 BATCH:  15 avg batch loss:  3.0214811637997627 indiv batch loss:  [6.526092529296875, 2.3843443393707275, 3.0931077003479004, 3.3504695892333984, 2.896049976348877, 1.9177219867706299, 2.738346815109253, 3.2913362979888916, 3.2663369178771973, 3.1909432411193848, 3.829913377761841, 2.448805332183838, 1.9013596773147583, 3.186889886856079, 2.1103100776672363, 2.2116708755493164]\n","indiv Batch loss:  tensor(2.1177, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.7556, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(2.9970, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(2.0622, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.9318, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.9639, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.8215, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(2.2022, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.9847, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.7704, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.9885, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(2.0327, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.7752, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.9981, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(2.7903, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.8914, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  1 BATCH:  15 avg batch loss:  2.067703925073147 indiv batch loss:  [2.1177124977111816, 1.755639672279358, 2.996962785720825, 2.062217950820923, 1.9317611455917358, 1.9638551473617554, 1.8214852809906006, 2.2021639347076416, 1.9847360849380493, 1.770386815071106, 1.9884709119796753, 2.0327463150024414, 1.7752411365509033, 1.9981495141983032, 2.790346384048462, 1.8913872241973877]\n","indiv Batch loss:  tensor(1.6580, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.1079, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(2.2374, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.2581, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.4396, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.8288, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.7335, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.3386, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.1539, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.6928, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.5494, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.0496, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.0736, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.2786, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.3028, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.5065, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  2 BATCH:  15 avg batch loss:  1.4505601301789284 indiv batch loss:  [1.6579896211624146, 1.1078956127166748, 2.2373673915863037, 1.2580559253692627, 1.439557433128357, 1.8288239240646362, 1.7335001230239868, 1.3385893106460571, 1.1539288759231567, 1.692797303199768, 1.5493580102920532, 1.0495884418487549, 1.0736315250396729, 1.2785778045654297, 1.3028494119644165, 1.5064513683319092]\n","indiv Batch loss:  tensor(1.0860, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.9060, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(2.1153, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.1071, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.9202, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.8089, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.3163, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.4169, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.0364, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.4263, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.8254, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.6689, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.7550, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.8703, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.6782, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.3161, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  3 BATCH:  15 avg batch loss:  1.2033300288021564 indiv batch loss:  [1.0860178470611572, 0.9059605002403259, 2.1152923107147217, 1.107102870941162, 0.9201807379722595, 0.8088549971580505, 1.3163388967514038, 1.4169013500213623, 1.036417841911316, 1.4263343811035156, 1.8254002332687378, 0.6689198613166809, 0.7549837827682495, 0.8702659010887146, 1.6781914234161377, 1.316117525100708]\n","indiv Batch loss:  tensor(0.7349, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.5063, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.0532, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.9032, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.5357, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.8607, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.1151, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.0123, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.8451, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.0905, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.2954, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.7602, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.8563, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.6618, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.0331, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.7074, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  4 BATCH:  15 avg batch loss:  0.8731975220143795 indiv batch loss:  [0.7348581552505493, 0.5062558054924011, 1.0532323122024536, 0.9032191038131714, 0.535704493522644, 0.8607339262962341, 1.1151310205459595, 1.0122612714767456, 0.8450793623924255, 1.0905288457870483, 1.295438528060913, 0.7601594924926758, 0.8563166260719299, 0.6618279814720154, 1.0330528020858765, 0.7073606252670288]\n","indiv Batch loss:  tensor(0.5868, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3895, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.8938, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.7333, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.6676, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3864, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.5766, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.8824, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.5205, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.9076, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.9737, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3697, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.7033, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4422, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.3969, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.8085, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  5 BATCH:  15 avg batch loss:  0.7024157866835594 indiv batch loss:  [0.5867997407913208, 0.3894529640674591, 0.8938392996788025, 0.733327329158783, 0.6676404476165771, 0.38636836409568787, 0.5765627026557922, 0.8824286460876465, 0.5204716324806213, 0.9075719118118286, 0.9736509323120117, 0.36965212225914, 0.703300952911377, 0.44222429394721985, 1.39689040184021, 0.8084708452224731]\n","indiv Batch loss:  tensor(0.3220, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3615, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.6890, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.5785, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.6361, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.9124, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4392, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.6972, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4543, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.7169, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.6919, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3588, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3621, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(1.1457, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3670, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  6 BATCH:  15 avg batch loss:  0.5616678092628717 indiv batch loss:  [0.32204219698905945, 0.3615463376045227, 0.6890159249305725, 0.5784666538238525, 0.6360939145088196, 0.9123810529708862, 0.4391997754573822, 0.6971529722213745, 0.45431438088417053, 0.7169490456581116, 0.6918915510177612, 0.35884010791778564, 0.3621191084384918, 0.2539445459842682, 1.1456849575042725, 0.3670424222946167]\n","indiv Batch loss:  tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3498, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.5277, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.9975, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4820, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4331, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4152, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.5547, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4430, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.6220, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.5109, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.5080, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2741, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.6462, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.8038, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  7 BATCH:  15 avg batch loss:  0.5098177623003721 indiv batch loss:  [0.33151179552078247, 0.3497527539730072, 0.5277083516120911, 0.997524619102478, 0.48195359110832214, 0.4330924451351166, 0.4151533842086792, 0.5546655654907227, 0.4430142641067505, 0.621964156627655, 0.5108651518821716, 0.2578195631504059, 0.5080364942550659, 0.27406343817710876, 0.646187424659729, 0.8037711977958679]\n","indiv Batch loss:  tensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1996, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.5533, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4235, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3866, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4824, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3145, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4959, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3394, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.7342, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4687, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1348, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2888, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3703, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.5524, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.8082, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  8 BATCH:  15 avg batch loss:  0.4253794401884079 indiv batch loss:  [0.25355014204978943, 0.19963593780994415, 0.553312361240387, 0.4235072433948517, 0.38658270239830017, 0.48240652680397034, 0.3144720196723938, 0.49593013525009155, 0.33937615156173706, 0.7341583967208862, 0.46866941452026367, 0.13480938971042633, 0.2887648940086365, 0.37031200528144836, 0.5523678660392761, 0.808215856552124]\n","indiv Batch loss:  tensor(0.2024, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1806, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.5489, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3880, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4140, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3530, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4249, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3500, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3530, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4269, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3122, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3259, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2881, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.5210, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.6025, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  9 BATCH:  15 avg batch loss:  0.3721000161021948 indiv batch loss:  [0.2024349719285965, 0.18055705726146698, 0.5489122867584229, 0.38803309202194214, 0.41402941942214966, 0.2621287405490875, 0.3530103266239166, 0.42488744854927063, 0.3500353693962097, 0.35297876596450806, 0.42690613865852356, 0.31218603253364563, 0.3258710205554962, 0.2881399691104889, 0.520976722240448, 0.6025128960609436]\n","indiv Batch loss:  tensor(0.2292, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2136, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3619, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3179, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3365, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4762, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2999, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3099, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4797, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3920, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2186, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1807, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2161, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4018, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  10 BATCH:  15 avg batch loss:  0.30123920273035765 indiv batch loss:  [0.22923852503299713, 0.21361897885799408, 0.3619351387023926, 0.3179320991039276, 0.3365013897418976, 0.4762115180492401, 0.25181519985198975, 0.29990994930267334, 0.3098866939544678, 0.47968223690986633, 0.3920186758041382, 0.21858873963356018, 0.1807185560464859, 0.21614815294742584, 0.4017607867717743, 0.13386060297489166]\n","indiv Batch loss:  tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4351, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2934, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2452, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2957, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2132, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3017, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2964, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2243, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.6263, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.5961, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  11 BATCH:  15 avg batch loss:  0.3091424871236086 indiv batch loss:  [0.24347761273384094, 0.2230985313653946, 0.43507590889930725, 0.20064234733581543, 0.2934263050556183, 0.24520736932754517, 0.33844032883644104, 0.2957066297531128, 0.2131844162940979, 0.30167466402053833, 0.2963663339614868, 0.22428545355796814, 0.23922424018383026, 0.17408519983291626, 0.6262833476066589, 0.5961011052131653]\n","indiv Batch loss:  tensor(0.2272, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.5146, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3387, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2904, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1788, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2472, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2138, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3538, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4521, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2678, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1838, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3063, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2471, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  12 BATCH:  15 avg batch loss:  0.27257960941642523 indiv batch loss:  [0.22717319428920746, 0.13998596370220184, 0.5145570635795593, 0.3386940062046051, 0.290351539850235, 0.27245232462882996, 0.1788209080696106, 0.24719610810279846, 0.21382498741149902, 0.35378575325012207, 0.45211219787597656, 0.12738633155822754, 0.2678086459636688, 0.18379147350788116, 0.30627742409706116, 0.24705582857131958]\n","indiv Batch loss:  tensor(0.1359, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1859, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3731, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2802, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2355, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2180, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2488, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1772, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3628, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4144, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  13 BATCH:  15 avg batch loss:  0.23992471443489194 indiv batch loss:  [0.13585473597049713, 0.18592490255832672, 0.3731438219547272, 0.2801527678966522, 0.1276915967464447, 0.10665921121835709, 0.2355329543352127, 0.218017116189003, 0.21570995450019836, 0.2918124496936798, 0.24884521961212158, 0.21751759946346283, 0.24754896759986877, 0.17719753086566925, 0.36279532313346863, 0.41439127922058105]\n","indiv Batch loss:  tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1687, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1605, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2855, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4398, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1564, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2401, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3166, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1882, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0716, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1713, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2075, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  14 BATCH:  15 avg batch loss:  0.21145716030150652 indiv batch loss:  [0.08087345957756042, 0.1686895191669464, 0.20997416973114014, 0.16047166287899017, 0.15685875713825226, 0.28548726439476013, 0.43979591131210327, 0.15643948316574097, 0.2401166707277298, 0.3165988028049469, 0.2724730372428894, 0.18815065920352936, 0.07161195576190948, 0.17130254209041595, 0.25699564814567566, 0.20747502148151398]\n","indiv Batch loss:  tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2268, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1894, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1156, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2297, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1894, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2618, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3834, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2143, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  15 BATCH:  15 avg batch loss:  0.18457361171022058 indiv batch loss:  [0.14925917983055115, 0.14918740093708038, 0.22682172060012817, 0.18942071497440338, 0.11557634174823761, 0.08826526254415512, 0.22973525524139404, 0.16030248999595642, 0.1893671751022339, 0.256293386220932, 0.2617684006690979, 0.09350325167179108, 0.1249462440609932, 0.12101159244775772, 0.3834090530872345, 0.21431031823158264]\n","indiv Batch loss:  tensor(0.0910, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3052, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2005, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1072, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2401, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1639, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2351, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3119, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  16 BATCH:  15 avg batch loss:  0.18479177448898554 indiv batch loss:  [0.09100720286369324, 0.11279758810997009, 0.30519548058509827, 0.200515016913414, 0.15978746116161346, 0.10718924552202225, 0.24006208777427673, 0.25690585374832153, 0.1639421135187149, 0.26524031162261963, 0.23512732982635498, 0.09310706704854965, 0.07994665205478668, 0.08185644447803497, 0.2520941495895386, 0.31189438700675964]\n","indiv Batch loss:  tensor(0.1249, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4317, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1392, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0708, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.4003, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2127, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3513, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2711, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1108, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0954, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1567, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  17 BATCH:  15 avg batch loss:  0.1939887199550867 indiv batch loss:  [0.12494033575057983, 0.1259777992963791, 0.4317268431186676, 0.13918617367744446, 0.11690542101860046, 0.0708010122179985, 0.40025922656059265, 0.1519685983657837, 0.21265101432800293, 0.35131657123565674, 0.2710816264152527, 0.11076368391513824, 0.09539031237363815, 0.08086439967155457, 0.26327812671661377, 0.15670837461948395]\n","indiv Batch loss:  tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0808, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1313, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1765, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0640, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3189, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1157, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1807, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1797, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0969, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0510, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1261, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  18 BATCH:  15 avg batch loss:  0.15651854197494686 indiv batch loss:  [0.1416003406047821, 0.08077765256166458, 0.23666784167289734, 0.13131774961948395, 0.17649494111537933, 0.06398385763168335, 0.318879097700119, 0.115690216422081, 0.3451366722583771, 0.18069860339164734, 0.17970405519008636, 0.10599665343761444, 0.09685458242893219, 0.0510268397629261, 0.12608115375041962, 0.1533864140510559]\n","indiv Batch loss:  tensor(0.1362, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2109, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1080, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0484, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2015, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1276, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1067, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1644, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1307, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1008, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  19 BATCH:  15 avg batch loss:  0.1403273195028305 indiv batch loss:  [0.136172816157341, 0.21350178122520447, 0.21089379489421844, 0.10801149904727936, 0.1126304641366005, 0.04838068038225174, 0.20150037109851837, 0.12764115631580353, 0.1066591665148735, 0.16439631581306458, 0.13066521286964417, 0.08520922809839249, 0.21748676896095276, 0.10075706243515015, 0.16918569803237915, 0.11214509606361389]\n","indiv Batch loss:  tensor(0.1168, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0995, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0666, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2717, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1096, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1239, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2314, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1617, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  20 BATCH:  15 avg batch loss:  0.12774718506261706 indiv batch loss:  [0.11679346114397049, 0.08087261021137238, 0.14792418479919434, 0.1502513736486435, 0.09945421665906906, 0.06655276566743851, 0.2717452347278595, 0.11305750906467438, 0.1096406877040863, 0.09579727053642273, 0.12391950190067291, 0.2314263880252838, 0.08713182061910629, 0.08502192795276642, 0.16166189312934875, 0.10270411521196365]\n","indiv Batch loss:  tensor(0.1507, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1167, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0689, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0737, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  21 BATCH:  15 avg batch loss:  0.12434230605140328 indiv batch loss:  [0.1506548970937729, 0.08528485149145126, 0.2050994485616684, 0.08928854018449783, 0.08037439733743668, 0.09679281711578369, 0.14745394885540009, 0.11667747050523758, 0.14192911982536316, 0.17434996366500854, 0.2642950415611267, 0.06885328143835068, 0.07366631925106049, 0.10043840855360031, 0.09762551635503769, 0.09669287502765656]\n","indiv Batch loss:  tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1602, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0345, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1812, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0866, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0612, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  22 BATCH:  15 avg batch loss:  0.10547823016531765 indiv batch loss:  [0.10393499583005905, 0.06566165387630463, 0.18484623730182648, 0.16015826165676117, 0.09611760824918747, 0.08133556693792343, 0.1602291762828827, 0.03448990732431412, 0.18118396401405334, 0.08462078124284744, 0.10536566376686096, 0.0866352990269661, 0.06116301938891411, 0.07174977660179138, 0.13389533758163452, 0.07626443356275558]\n","indiv Batch loss:  tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1624, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1075, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0538, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1374, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1369, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0472, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1371, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  23 BATCH:  15 avg batch loss:  0.10307506914250553 indiv batch loss:  [0.06736302375793457, 0.13341739773750305, 0.16241970658302307, 0.10751552134752274, 0.053842708468437195, 0.09121308475732803, 0.12585538625717163, 0.08171071857213974, 0.07994219660758972, 0.1374131143093109, 0.13694758713245392, 0.08343862742185593, 0.08088858425617218, 0.04719305410981178, 0.12296348065137863, 0.13707691431045532]\n","indiv Batch loss:  tensor(0.1141, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0697, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0480, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0451, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1357, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0719, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0698, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0512, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.0556, device='cuda:0', grad_fn=<DivBackward0>)\n","indiv Batch loss:  tensor(0.1969, device='cuda:0', grad_fn=<DivBackward0>)\n","EPOCH:  24 BATCH:  15 avg batch loss:  0.09734512795694172 indiv batch loss:  [0.11414928734302521, 0.06966214627027512, 0.13039694726467133, 0.04799294099211693, 0.045112308114767075, 0.11001649498939514, 0.2505272328853607, 0.1356876939535141, 0.09939032793045044, 0.07186572253704071, 0.06977751851081848, 0.07286613434553146, 0.051225438714027405, 0.036326248198747635, 0.05558880418539047, 0.19693680107593536]\n","all_loss:  [3.0214811637997627, 2.067703925073147, 1.4505601301789284, 1.2033300288021564, 0.8731975220143795, 0.7024157866835594, 0.5616678092628717, 0.5098177623003721, 0.4253794401884079, 0.3721000161021948, 0.30123920273035765, 0.3091424871236086, 0.27257960941642523, 0.23992471443489194, 0.21145716030150652, 0.18457361171022058, 0.18479177448898554, 0.1939887199550867, 0.15651854197494686, 0.1403273195028305, 0.12774718506261706, 0.12434230605140328, 0.10547823016531765, 0.10307506914250553, 0.09734512795694172]\n"]}],"source":["\n","all_loss_results = train_CD(\n","                                        num_epochs =                        num_epochs,\n","                                        data_loader =                       dataloader_CD_probs_exp_CDTRAIN,\n","                                        model =                             example_myOPT_CD_FT,\n","                                        optimizer =                         optimizer,\n","                                        criterion =                         criterion,\n","                                        scheduler =                         scheduler\n","                                        )\n"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"-oY7L03hAnhc","colab":{"base_uri":"https://localhost:8080/","height":498},"executionInfo":{"status":"ok","timestamp":1714523836712,"user_tz":-120,"elapsed":491,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"80b2c114-4dc3-4a98-ab9d-9b8da3b74538"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# Plotting the results\n","vector_vals = np.array(all_loss_results)\n","\n","plt.figure(figsize=(8, 5))\n","plt.plot(range(1, len(vector_vals)+1), vector_vals, marker='o', linestyle='-')\n","plt.title(\"Loss Curve over Training\", fontsize=16)\n","plt.xlabel(\"Epochs\", fontsize=14)\n","plt.xticks(range(0, len(vector_vals) + 1, 5))\n","plt.ylabel(\"Training Loss\", fontsize=14)\n","plt.grid(True)\n","plt.tick_params(axis='x', labelsize=12)\n","plt.tick_params(axis='y', labelsize=12)\n","plt.show()\n"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"t9z8p50OVKd2","executionInfo":{"status":"ok","timestamp":1714523836712,"user_tz":-120,"elapsed":7,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Q1J4V4UKclHm"},"source":["# 6. IN-DOMAIN VALIDATION"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"ke4zvkHickGl","executionInfo":{"status":"ok","timestamp":1714523836712,"user_tz":-120,"elapsed":7,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["# format examples functions formats according to different types of formats for ICL both training and validation examples\n","\n","# select format to use here:\n","format_train_val = format_train_val # set it at the top of notebook in a common place\n","\n","\n","def format_examples_validation_VAL(example_val, format_val = format_train_val):\n","    if format_val== 'minimal':\n","      # \"minimal\" format\n","      return {'text': \"{\"  + example_val['premise'] + \"} {\" + example_val['hypothesis'] + \"}\" + \" ? Ġ\"}\n","    elif format_val== 'gpt3':\n","      # \"minimal\" format\n","      return {'text': \"{\"  + example_val['premise'] + \"} question: {\" + example_val['hypothesis'] + \"}\" + \" Yes or No? answer: Ġ\"}\n","\n","def create_combined_dataset_VAL(val_dataset, num_expts=num_experiments):\n","    combined_dataset = []\n","\n","\n","    for irep in range(num_expts):\n","      for val_ex in val_dataset:\n","\n","\n","            combined_ex = {'text': '', 'label': val_ex['label'], 'exp': irep+1}\n","\n","            # Way 1: set examples Yes, No, Yes, No, ...\n","            '''\n","            for idx_train in range(len(sampled_train_exs_yes)):\n","              # put order one Yes and another No consecutively\n","              combined_ex['text'] += sampled_train_exs_yes[idx_train]['text']\n","              combined_ex['text'] += sampled_train_exs_no[idx_train]['text']\n","            '''\n","\n","            # Way 2: set randomized\n","            #for idx_shuffled_list in range(len(shuffled_list)):\n","              # random option\n","            #  combined_ex['text'] += shuffled_list[idx_shuffled_list]['text']\n","\n","            # Add the example to predict (validation)\n","            combined_ex['text'] += val_ex['text']\n","\n","            # Append the new combined example to the combined dataset\n","            combined_dataset.append([combined_ex])\n","\n","    return combined_dataset\n","\n","\n","def dynamic_padding_collate_fn_VAL(batch):\n","    # This function is created to be able to tokenize dynamically to max length within each batch\n","    # Also, by modifying the tokenizer used, several other options are available\n","    # for example, if we set padding to a specified max_length, for example the model max_length, is also an option, not the default though\n","    # the default is the dynamic padding\n","\n","    batch = [item for sublist in batch for item in sublist]\n","\n","    texts = [item['text'] for item in batch]\n","    labels = [item['label'] for item in batch]\n","    exps = [item['exp'] for item in batch]\n","\n","    # choose option\n","    tokenized_inputs = OPT_tokenizer(texts, padding=\"longest\", truncation=True, return_tensors=\"pt\")\n","    # tokenized_inputs = OPT_tokenizer(texts, padding=\"max_length\", max_length = 2048, truncation=True, return_tensors=\"pt\")\n","\n","    labels_tensor = torch.tensor(labels, dtype=torch.long)\n","    exps_tensor = torch.tensor(exps, dtype=torch.long).to(device)\n","\n","    # return here the outputs desired\n","    # we have chosen the input_ids, attention_mask, label of the validation samples\n","    return {\n","        'input_ids': tokenized_inputs['input_ids'],\n","        'attention_mask': tokenized_inputs['attention_mask'],\n","        'labels': labels_tensor,\n","        'exps': exps_tensor\n","    }\n","\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, combined_dataset):\n","        self.dataset = combined_dataset\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        return self.dataset[idx]\n"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"5IvcUZPYckDr","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["98eec8c8c9f54cdc9b571396a72e55c3","8886b0ec30004646b5b1683744bf5f17","17b3b18c921f445ea8930af5957261e8","a34d75415f984687bd6c5b18680f4cf4","90fa18c6ef2e48c89d17f5574aa8e732","3bb0cb6161bf479fb8743876cf699272","b749e2f006e942879f0afbf0d81442a2","0d6aa790629c44a3a047347b8a3df61d","223ce77fd3c346d281150e6008e4f988","53616da3724e4efcb1eea5719e6ad8eb","d7e31382d8b6439790e634c0d5aa1882"]},"executionInfo":{"status":"ok","timestamp":1714523837439,"user_tz":-120,"elapsed":734,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"9f61b31c-1c9c-432d-d0a7-b6fb78c5f7a6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1024 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98eec8c8c9f54cdc9b571396a72e55c3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<__main__.CustomDataset object at 0x7a1e30a472e0>\n"]}],"source":["# First the samples are formatted according to selection above\n","# Important to check selection and re-run cell above so that it is taken by the mapping function correctly\n","'''\n","formatted_train_dataset_yes = train_dataset_yes.map(format_examples_train)\n","formatted_train_dataset_no = train_dataset_no.map(format_examples_train)\n","formatted_train_CD_dataset_yes = train_dataset_CD_yes.map(format_examples_CD_train)\n","formatted_train_CD_dataset_no = train_dataset_CD_no.map(format_examples_CD_train)\n","'''\n","formatted_val_dataset = val_dataset.map(format_examples_validation_VAL)\n","\n","# Initialize custom dataset with the combined dataset\n","# print result to check correctness\n","\n","combined_dataset_VAL = create_combined_dataset_VAL(\n","                                          val_dataset = formatted_val_dataset,\n","                                          num_expts=num_experiments\n","                                           )\n","\n","custom_dataset_VAL = CustomDataset(combined_dataset_VAL)\n","print(custom_dataset_VAL)\n","\n","custom_dataset_VAL_EXP = CustomDataset([item for item in custom_dataset_VAL if item[0]['exp'] == SEL_EXP_TRAIN_CD])\n","\n","# Last step, we create Dataloader passing the bx_size for inference (typically: 1, 4, 8, 16)\n","bx_size = bx_size # set it up at the beg of NB\n","dataloader_VAL = DataLoader(custom_dataset_VAL_EXP, batch_size=bx_size, collate_fn=dynamic_padding_collate_fn_VAL, shuffle=False) #shuffle=False for reproducibility"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"4cX3lmoTNeUb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523837439,"user_tz":-120,"elapsed":4,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"258927c5-8064-4f75-8da5-7c0a7a39dc32"},"outputs":[{"output_type":"stream","name":"stdout","text":["ORIGINAL:  0\n","TOKENIZE / DETOKENIZE:  [\"</s>{no it didn't} question: {Yes it did.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  1\n","TOKENIZE / DETOKENIZE:  [\"</s>{Who? asked Tommy.} question: {Tommy didn't know, who.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  2\n","TOKENIZE / DETOKENIZE:  ['</s>{Paroseas cave, reef, and wreck diving around its shores, giving the diver a wide range of environments to explore.} question: {The diver has no variety in places to explore, they are monotonous. } Yes or No? answer: Ġ']\n","ORIGINAL:  3\n","TOKENIZE / DETOKENIZE:  [\"</s>{um i've visited the Wyoming area i'm not sure exactly where Dances with Wolves was filmed} question: {I don't know even though I visited the area.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  4\n","TOKENIZE / DETOKENIZE:  [\"</s>{i think Buffalo is an up an coming team they're going to they're showing some real promise for the next uh few years} question: {Buffalo is showing some real promise for the next few years, I think they are an up and coming team.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  5\n","TOKENIZE / DETOKENIZE:  ['</s>{They did this to us.} question: {This was done by them.} Yes or No? answer: Ġ']\n","ORIGINAL:  6\n","TOKENIZE / DETOKENIZE:  ['</s>{uh-huh how about any matching programs} question: {What about matching programs? } Yes or No? answer: Ġ']\n","ORIGINAL:  7\n","TOKENIZE / DETOKENIZE:  ['</s>{MC2000-2, was initially considered and recommended by the Commission under the market test rules.} question: {MC2000-2 was recommended by the Commission.} Yes or No? answer: Ġ']\n","ORIGINAL:  8\n","TOKENIZE / DETOKENIZE:  ['</s>{Asked about abortion the other day on CNN, Republican National Committee Chairman Jim Nicholson also invoked what is apparently the party-line  inclusive party.} question: {The Republican National Committee Chairman freelanced on the topic of abortion when asked about it on CNN instead of reiterating the party-line.} Yes or No? answer: Ġ']\n","ORIGINAL:  9\n","TOKENIZE / DETOKENIZE:  ['</s>{It was like looking into a mirror, except infinitely more realistic.} question: {It was more realistic than looking in a mirror. } Yes or No? answer: Ġ']\n","ORIGINAL:  10\n","TOKENIZE / DETOKENIZE:  ['</s>{John Kasich dropped his presidential bid.} question: {John Kasich recommitted himself to the presidential bid and plans on winning.} Yes or No? answer: Ġ']\n","ORIGINAL:  11\n","TOKENIZE / DETOKENIZE:  [\"</s>{well that's good that's great} question: {Shit, that is bad, that is horrible.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  12\n","TOKENIZE / DETOKENIZE:  ['</s>{There were beads of perspiration on his brow.} question: {He was perfectly calm and dry as he waited.} Yes or No? answer: Ġ']\n","ORIGINAL:  13\n","TOKENIZE / DETOKENIZE:  ['</s>{Even the most aged and infirm travel here to die, for nothing is more blessed for a devout Hindu than to die in the great waters of the Varanasi and thus be released from the eternal cycle of rebirth.} question: {Devout Hindus believe that dying in the Varanasi frees a soul from the cycle of rebirth.} Yes or No? answer: Ġ']\n","ORIGINAL:  14\n","TOKENIZE / DETOKENIZE:  ['</s>{You and your friends are not welcome here, said Severn.} question: {Severn said the people were always welcome there.} Yes or No? answer: Ġ']\n","ORIGINAL:  15\n","TOKENIZE / DETOKENIZE:  ['</s>{Current Chinese leaders have distinctive characteristics that give them significant advantages over the United States in foreign policy.} question: {The us has advantages over China in foreign policy. } Yes or No? answer: Ġ']\n","ORIGINAL:  16\n","TOKENIZE / DETOKENIZE:  [\"</s>{The Chinese calendar was used to calculate the year of Japan's foundation by counting back the 1,260 years of the Chinese cosmological cycle.} question: {Japan's foundation was determined by using the Chinese calendar.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  17\n","TOKENIZE / DETOKENIZE:  [\"</s>{Two clues in the Pennsylvania  1) The boy had said, I'm going to go to the dinner dance and kill some people.} question: {There was only one clue in Pennsylvania and it had nothing to do with the boy.} Yes or No? answer: Ġ\"]\n","ORIGINAL:  18\n","TOKENIZE / DETOKENIZE:  ['</s>{8 A stoichiometry of 1.03 is typical when the FGD process is producing gypsum by-product, while a stoichiometry of 1.05 is needed to produce waste suitable for a landfill.} question: {A stoichiometry of 1.07 is typical when the FGD process is producing gypsum by-product} Yes or No? answer: Ġ']\n","ORIGINAL:  19\n","TOKENIZE / DETOKENIZE:  [\"</s>{oh yes yeah yeah yeah that's true too that's true} question: {It is true} Yes or No? answer: Ġ\"]\n"]}],"source":["for i, batch in enumerate(dataloader_VAL):\n","    if i<20:\n","      print(\"ORIGINAL: \", i,)\n","      print(\"TOKENIZE / DETOKENIZE: \", OPT_tokenizer.batch_decode(batch['input_ids']))\n","    else:\n","      break"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"OsF89ZvOedsc","executionInfo":{"status":"ok","timestamp":1714523837439,"user_tz":-120,"elapsed":3,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["# Set eval model for inference\n","# initialize to store results of model predictions and compare with ground-truth\n","# use generate text with only one token\n","# extract only the max score token YES (0 label) or NO (1 label)\n","\n","if SEL_EXP_TRAIN_CD == 1:\n","  example_myBaseOPT_CD.eval()\n","\n","  model_pred = torch.zeros(0, dtype=torch.long).to(device)\n","  ground_truth = torch.zeros(0, dtype=torch.long).to(device)\n","\n","  with torch.no_grad():\n","      for i, batch in enumerate(dataloader_VAL):\n","\n","          print(\"BATCH#: \", i, \"NUM EXPTS TOTAL: \", (i+1)*bx_size)\n","\n","          input_ids = batch['input_ids'].to(device)\n","          attention_mask = batch['attention_mask'].to(device)\n","\n","          gen_tokens = torch.tensor(1)\n","          gen_tokens = gen_tokens.to(device)\n","\n","\n","          # output only the binary yes/no,\n","          _, binary_yes_no, _ = example_myBaseOPT_CD.generate_text(input_ids, attention_mask, gen_tokens=gen_tokens)\n","          model_pred = torch.cat((model_pred, binary_yes_no), dim=0)\n","          ground_truth = torch.cat((ground_truth, batch['labels'].to(device)), dim=0)\n","\n","          print(\"BATCH#: \", i, \"NUM EXPTS TOTAL: \", (i+1)*bx_size, \"PREDICTION: \", binary_yes_no, \"TRUE LABELS: \", batch['labels'].detach())\n","\n","  accuracy_calc = (100*torch.sum(model_pred == ground_truth)/(model_pred.shape[0])).item()\n","  print(\"Average Train Exp Accuracy: \", accuracy_calc)"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"gntbpBSILmNl","executionInfo":{"status":"ok","timestamp":1714523837439,"user_tz":-120,"elapsed":3,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["# Evaluate results beyond accuracy:\n","if SEL_EXP_TRAIN_CD == 1:\n","  print(\"YES answer (%): \", ((torch.sum(model_pred==0))/len(model_pred)).item()*100)\n","  print(\"NO  answer (%): \", ((torch.sum(model_pred==1))/len(model_pred)).item()*100)"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"yJrvIVTgXMZ4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523843080,"user_tz":-120,"elapsed":5643,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"07d03132-c3a3-4b8c-a6e4-a9c2ae1bf4eb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['</s>A chat between a curious human and the Statue of Liberty.\\n\\nHuman: What is your name?\\nStatue: I am the Statue of Liberty.\\nHuman: Where do you live?\\nStatue: New York City.\\nHuman: How long have you lived there?\\nStatue: I have lived here for over 100 years.\\nHuman: What do you do?\\nStatue: I am a tourist attraction.\\nHuman: What do you do when you are not a tourist attraction?\\nStatue: I am a tourist attraction.\\nHuman: What do you do when you are not a tourist attraction?\\nStatue: I am a tourist attraction.\\nHuman: What do you do when you are not a tourist attraction?\\nStatue:']"]},"metadata":{},"execution_count":60}],"source":["# Check base model output correctness (from OPT HF example)\n","prompt_example = (\"A chat between a curious human and the Statue of Liberty.\\n\\nHuman: What is your name?\\nStatue: I am the \"\n","              \"Statue of Liberty.\\nHuman: Where do you live?\\nStatue: New York City.\\nHuman: How long have you lived \"\n","              \"there?\")\n","prompt_example_tokenized = OPT_tokenizer(prompt_example )\n","example_myBaseOPT_CD.eval()\n","outputs_ex_sp, binary_ex_sp, scores_ex_sp = example_myBaseOPT_CD.generate_text(src_inputs = torch.unsqueeze(torch.tensor(prompt_example_tokenized['input_ids']),0).to(device),\n","                                    src_attn = torch.unsqueeze(torch.tensor(prompt_example_tokenized['attention_mask']),0).to(device),\n","                                    gen_tokens=torch.tensor(100).to(device))\n","OPT_tokenizer.batch_decode(outputs_ex_sp)"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"kcG1Iekmedp6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523884762,"user_tz":-120,"elapsed":41696,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"28e0201c-8ca2-4fe6-847f-4c581eaf7f51"},"outputs":[{"output_type":"stream","name":"stdout","text":["BATCH#:  0 NUM EXPTS TOTAL:  1\n","BATCH#:  0 NUM EXPTS TOTAL:  1 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1 NUM EXPTS TOTAL:  2\n","BATCH#:  1 NUM EXPTS TOTAL:  2 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  2 NUM EXPTS TOTAL:  3\n","BATCH#:  2 NUM EXPTS TOTAL:  3 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  3 NUM EXPTS TOTAL:  4\n","BATCH#:  3 NUM EXPTS TOTAL:  4 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  4 NUM EXPTS TOTAL:  5\n","BATCH#:  4 NUM EXPTS TOTAL:  5 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  5 NUM EXPTS TOTAL:  6\n","BATCH#:  5 NUM EXPTS TOTAL:  6 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  6 NUM EXPTS TOTAL:  7\n","BATCH#:  6 NUM EXPTS TOTAL:  7 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  7 NUM EXPTS TOTAL:  8\n","BATCH#:  7 NUM EXPTS TOTAL:  8 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  8 NUM EXPTS TOTAL:  9\n","BATCH#:  8 NUM EXPTS TOTAL:  9 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  9 NUM EXPTS TOTAL:  10\n","BATCH#:  9 NUM EXPTS TOTAL:  10 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  10 NUM EXPTS TOTAL:  11\n","BATCH#:  10 NUM EXPTS TOTAL:  11 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  11 NUM EXPTS TOTAL:  12\n","BATCH#:  11 NUM EXPTS TOTAL:  12 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  12 NUM EXPTS TOTAL:  13\n","BATCH#:  12 NUM EXPTS TOTAL:  13 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  13 NUM EXPTS TOTAL:  14\n","BATCH#:  13 NUM EXPTS TOTAL:  14 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  14 NUM EXPTS TOTAL:  15\n","BATCH#:  14 NUM EXPTS TOTAL:  15 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  15 NUM EXPTS TOTAL:  16\n","BATCH#:  15 NUM EXPTS TOTAL:  16 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  16 NUM EXPTS TOTAL:  17\n","BATCH#:  16 NUM EXPTS TOTAL:  17 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  17 NUM EXPTS TOTAL:  18\n","BATCH#:  17 NUM EXPTS TOTAL:  18 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  18 NUM EXPTS TOTAL:  19\n","BATCH#:  18 NUM EXPTS TOTAL:  19 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  19 NUM EXPTS TOTAL:  20\n","BATCH#:  19 NUM EXPTS TOTAL:  20 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  20 NUM EXPTS TOTAL:  21\n","BATCH#:  20 NUM EXPTS TOTAL:  21 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  21 NUM EXPTS TOTAL:  22\n","BATCH#:  21 NUM EXPTS TOTAL:  22 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  22 NUM EXPTS TOTAL:  23\n","BATCH#:  22 NUM EXPTS TOTAL:  23 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  23 NUM EXPTS TOTAL:  24\n","BATCH#:  23 NUM EXPTS TOTAL:  24 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  24 NUM EXPTS TOTAL:  25\n","BATCH#:  24 NUM EXPTS TOTAL:  25 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  25 NUM EXPTS TOTAL:  26\n","BATCH#:  25 NUM EXPTS TOTAL:  26 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  26 NUM EXPTS TOTAL:  27\n","BATCH#:  26 NUM EXPTS TOTAL:  27 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  27 NUM EXPTS TOTAL:  28\n","BATCH#:  27 NUM EXPTS TOTAL:  28 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  28 NUM EXPTS TOTAL:  29\n","BATCH#:  28 NUM EXPTS TOTAL:  29 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  29 NUM EXPTS TOTAL:  30\n","BATCH#:  29 NUM EXPTS TOTAL:  30 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  30 NUM EXPTS TOTAL:  31\n","BATCH#:  30 NUM EXPTS TOTAL:  31 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  31 NUM EXPTS TOTAL:  32\n","BATCH#:  31 NUM EXPTS TOTAL:  32 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  32 NUM EXPTS TOTAL:  33\n","BATCH#:  32 NUM EXPTS TOTAL:  33 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  33 NUM EXPTS TOTAL:  34\n","BATCH#:  33 NUM EXPTS TOTAL:  34 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  34 NUM EXPTS TOTAL:  35\n","BATCH#:  34 NUM EXPTS TOTAL:  35 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  35 NUM EXPTS TOTAL:  36\n","BATCH#:  35 NUM EXPTS TOTAL:  36 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  36 NUM EXPTS TOTAL:  37\n","BATCH#:  36 NUM EXPTS TOTAL:  37 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  37 NUM EXPTS TOTAL:  38\n","BATCH#:  37 NUM EXPTS TOTAL:  38 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  38 NUM EXPTS TOTAL:  39\n","BATCH#:  38 NUM EXPTS TOTAL:  39 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  39 NUM EXPTS TOTAL:  40\n","BATCH#:  39 NUM EXPTS TOTAL:  40 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  40 NUM EXPTS TOTAL:  41\n","BATCH#:  40 NUM EXPTS TOTAL:  41 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  41 NUM EXPTS TOTAL:  42\n","BATCH#:  41 NUM EXPTS TOTAL:  42 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  42 NUM EXPTS TOTAL:  43\n","BATCH#:  42 NUM EXPTS TOTAL:  43 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  43 NUM EXPTS TOTAL:  44\n","BATCH#:  43 NUM EXPTS TOTAL:  44 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  44 NUM EXPTS TOTAL:  45\n","BATCH#:  44 NUM EXPTS TOTAL:  45 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  45 NUM EXPTS TOTAL:  46\n","BATCH#:  45 NUM EXPTS TOTAL:  46 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  46 NUM EXPTS TOTAL:  47\n","BATCH#:  46 NUM EXPTS TOTAL:  47 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  47 NUM EXPTS TOTAL:  48\n","BATCH#:  47 NUM EXPTS TOTAL:  48 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  48 NUM EXPTS TOTAL:  49\n","BATCH#:  48 NUM EXPTS TOTAL:  49 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  49 NUM EXPTS TOTAL:  50\n","BATCH#:  49 NUM EXPTS TOTAL:  50 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  50 NUM EXPTS TOTAL:  51\n","BATCH#:  50 NUM EXPTS TOTAL:  51 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  51 NUM EXPTS TOTAL:  52\n","BATCH#:  51 NUM EXPTS TOTAL:  52 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  52 NUM EXPTS TOTAL:  53\n","BATCH#:  52 NUM EXPTS TOTAL:  53 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  53 NUM EXPTS TOTAL:  54\n","BATCH#:  53 NUM EXPTS TOTAL:  54 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  54 NUM EXPTS TOTAL:  55\n","BATCH#:  54 NUM EXPTS TOTAL:  55 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  55 NUM EXPTS TOTAL:  56\n","BATCH#:  55 NUM EXPTS TOTAL:  56 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  56 NUM EXPTS TOTAL:  57\n","BATCH#:  56 NUM EXPTS TOTAL:  57 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  57 NUM EXPTS TOTAL:  58\n","BATCH#:  57 NUM EXPTS TOTAL:  58 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  58 NUM EXPTS TOTAL:  59\n","BATCH#:  58 NUM EXPTS TOTAL:  59 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  59 NUM EXPTS TOTAL:  60\n","BATCH#:  59 NUM EXPTS TOTAL:  60 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  60 NUM EXPTS TOTAL:  61\n","BATCH#:  60 NUM EXPTS TOTAL:  61 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  61 NUM EXPTS TOTAL:  62\n","BATCH#:  61 NUM EXPTS TOTAL:  62 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  62 NUM EXPTS TOTAL:  63\n","BATCH#:  62 NUM EXPTS TOTAL:  63 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  63 NUM EXPTS TOTAL:  64\n","BATCH#:  63 NUM EXPTS TOTAL:  64 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  64 NUM EXPTS TOTAL:  65\n","BATCH#:  64 NUM EXPTS TOTAL:  65 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  65 NUM EXPTS TOTAL:  66\n","BATCH#:  65 NUM EXPTS TOTAL:  66 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  66 NUM EXPTS TOTAL:  67\n","BATCH#:  66 NUM EXPTS TOTAL:  67 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  67 NUM EXPTS TOTAL:  68\n","BATCH#:  67 NUM EXPTS TOTAL:  68 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  68 NUM EXPTS TOTAL:  69\n","BATCH#:  68 NUM EXPTS TOTAL:  69 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  69 NUM EXPTS TOTAL:  70\n","BATCH#:  69 NUM EXPTS TOTAL:  70 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  70 NUM EXPTS TOTAL:  71\n","BATCH#:  70 NUM EXPTS TOTAL:  71 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  71 NUM EXPTS TOTAL:  72\n","BATCH#:  71 NUM EXPTS TOTAL:  72 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  72 NUM EXPTS TOTAL:  73\n","BATCH#:  72 NUM EXPTS TOTAL:  73 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  73 NUM EXPTS TOTAL:  74\n","BATCH#:  73 NUM EXPTS TOTAL:  74 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  74 NUM EXPTS TOTAL:  75\n","BATCH#:  74 NUM EXPTS TOTAL:  75 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  75 NUM EXPTS TOTAL:  76\n","BATCH#:  75 NUM EXPTS TOTAL:  76 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  76 NUM EXPTS TOTAL:  77\n","BATCH#:  76 NUM EXPTS TOTAL:  77 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  77 NUM EXPTS TOTAL:  78\n","BATCH#:  77 NUM EXPTS TOTAL:  78 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  78 NUM EXPTS TOTAL:  79\n","BATCH#:  78 NUM EXPTS TOTAL:  79 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  79 NUM EXPTS TOTAL:  80\n","BATCH#:  79 NUM EXPTS TOTAL:  80 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  80 NUM EXPTS TOTAL:  81\n","BATCH#:  80 NUM EXPTS TOTAL:  81 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  81 NUM EXPTS TOTAL:  82\n","BATCH#:  81 NUM EXPTS TOTAL:  82 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  82 NUM EXPTS TOTAL:  83\n","BATCH#:  82 NUM EXPTS TOTAL:  83 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  83 NUM EXPTS TOTAL:  84\n","BATCH#:  83 NUM EXPTS TOTAL:  84 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  84 NUM EXPTS TOTAL:  85\n","BATCH#:  84 NUM EXPTS TOTAL:  85 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  85 NUM EXPTS TOTAL:  86\n","BATCH#:  85 NUM EXPTS TOTAL:  86 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  86 NUM EXPTS TOTAL:  87\n","BATCH#:  86 NUM EXPTS TOTAL:  87 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  87 NUM EXPTS TOTAL:  88\n","BATCH#:  87 NUM EXPTS TOTAL:  88 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  88 NUM EXPTS TOTAL:  89\n","BATCH#:  88 NUM EXPTS TOTAL:  89 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  89 NUM EXPTS TOTAL:  90\n","BATCH#:  89 NUM EXPTS TOTAL:  90 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  90 NUM EXPTS TOTAL:  91\n","BATCH#:  90 NUM EXPTS TOTAL:  91 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  91 NUM EXPTS TOTAL:  92\n","BATCH#:  91 NUM EXPTS TOTAL:  92 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  92 NUM EXPTS TOTAL:  93\n","BATCH#:  92 NUM EXPTS TOTAL:  93 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  93 NUM EXPTS TOTAL:  94\n","BATCH#:  93 NUM EXPTS TOTAL:  94 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  94 NUM EXPTS TOTAL:  95\n","BATCH#:  94 NUM EXPTS TOTAL:  95 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  95 NUM EXPTS TOTAL:  96\n","BATCH#:  95 NUM EXPTS TOTAL:  96 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  96 NUM EXPTS TOTAL:  97\n","BATCH#:  96 NUM EXPTS TOTAL:  97 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  97 NUM EXPTS TOTAL:  98\n","BATCH#:  97 NUM EXPTS TOTAL:  98 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  98 NUM EXPTS TOTAL:  99\n","BATCH#:  98 NUM EXPTS TOTAL:  99 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  99 NUM EXPTS TOTAL:  100\n","BATCH#:  99 NUM EXPTS TOTAL:  100 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  100 NUM EXPTS TOTAL:  101\n","BATCH#:  100 NUM EXPTS TOTAL:  101 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  101 NUM EXPTS TOTAL:  102\n","BATCH#:  101 NUM EXPTS TOTAL:  102 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  102 NUM EXPTS TOTAL:  103\n","BATCH#:  102 NUM EXPTS TOTAL:  103 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  103 NUM EXPTS TOTAL:  104\n","BATCH#:  103 NUM EXPTS TOTAL:  104 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  104 NUM EXPTS TOTAL:  105\n","BATCH#:  104 NUM EXPTS TOTAL:  105 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  105 NUM EXPTS TOTAL:  106\n","BATCH#:  105 NUM EXPTS TOTAL:  106 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  106 NUM EXPTS TOTAL:  107\n","BATCH#:  106 NUM EXPTS TOTAL:  107 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  107 NUM EXPTS TOTAL:  108\n","BATCH#:  107 NUM EXPTS TOTAL:  108 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  108 NUM EXPTS TOTAL:  109\n","BATCH#:  108 NUM EXPTS TOTAL:  109 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  109 NUM EXPTS TOTAL:  110\n","BATCH#:  109 NUM EXPTS TOTAL:  110 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  110 NUM EXPTS TOTAL:  111\n","BATCH#:  110 NUM EXPTS TOTAL:  111 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  111 NUM EXPTS TOTAL:  112\n","BATCH#:  111 NUM EXPTS TOTAL:  112 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  112 NUM EXPTS TOTAL:  113\n","BATCH#:  112 NUM EXPTS TOTAL:  113 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  113 NUM EXPTS TOTAL:  114\n","BATCH#:  113 NUM EXPTS TOTAL:  114 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  114 NUM EXPTS TOTAL:  115\n","BATCH#:  114 NUM EXPTS TOTAL:  115 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  115 NUM EXPTS TOTAL:  116\n","BATCH#:  115 NUM EXPTS TOTAL:  116 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  116 NUM EXPTS TOTAL:  117\n","BATCH#:  116 NUM EXPTS TOTAL:  117 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  117 NUM EXPTS TOTAL:  118\n","BATCH#:  117 NUM EXPTS TOTAL:  118 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  118 NUM EXPTS TOTAL:  119\n","BATCH#:  118 NUM EXPTS TOTAL:  119 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  119 NUM EXPTS TOTAL:  120\n","BATCH#:  119 NUM EXPTS TOTAL:  120 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  120 NUM EXPTS TOTAL:  121\n","BATCH#:  120 NUM EXPTS TOTAL:  121 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  121 NUM EXPTS TOTAL:  122\n","BATCH#:  121 NUM EXPTS TOTAL:  122 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  122 NUM EXPTS TOTAL:  123\n","BATCH#:  122 NUM EXPTS TOTAL:  123 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  123 NUM EXPTS TOTAL:  124\n","BATCH#:  123 NUM EXPTS TOTAL:  124 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  124 NUM EXPTS TOTAL:  125\n","BATCH#:  124 NUM EXPTS TOTAL:  125 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  125 NUM EXPTS TOTAL:  126\n","BATCH#:  125 NUM EXPTS TOTAL:  126 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  126 NUM EXPTS TOTAL:  127\n","BATCH#:  126 NUM EXPTS TOTAL:  127 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  127 NUM EXPTS TOTAL:  128\n","BATCH#:  127 NUM EXPTS TOTAL:  128 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  128 NUM EXPTS TOTAL:  129\n","BATCH#:  128 NUM EXPTS TOTAL:  129 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  129 NUM EXPTS TOTAL:  130\n","BATCH#:  129 NUM EXPTS TOTAL:  130 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  130 NUM EXPTS TOTAL:  131\n","BATCH#:  130 NUM EXPTS TOTAL:  131 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  131 NUM EXPTS TOTAL:  132\n","BATCH#:  131 NUM EXPTS TOTAL:  132 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  132 NUM EXPTS TOTAL:  133\n","BATCH#:  132 NUM EXPTS TOTAL:  133 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  133 NUM EXPTS TOTAL:  134\n","BATCH#:  133 NUM EXPTS TOTAL:  134 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  134 NUM EXPTS TOTAL:  135\n","BATCH#:  134 NUM EXPTS TOTAL:  135 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  135 NUM EXPTS TOTAL:  136\n","BATCH#:  135 NUM EXPTS TOTAL:  136 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  136 NUM EXPTS TOTAL:  137\n","BATCH#:  136 NUM EXPTS TOTAL:  137 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  137 NUM EXPTS TOTAL:  138\n","BATCH#:  137 NUM EXPTS TOTAL:  138 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  138 NUM EXPTS TOTAL:  139\n","BATCH#:  138 NUM EXPTS TOTAL:  139 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  139 NUM EXPTS TOTAL:  140\n","BATCH#:  139 NUM EXPTS TOTAL:  140 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  140 NUM EXPTS TOTAL:  141\n","BATCH#:  140 NUM EXPTS TOTAL:  141 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  141 NUM EXPTS TOTAL:  142\n","BATCH#:  141 NUM EXPTS TOTAL:  142 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  142 NUM EXPTS TOTAL:  143\n","BATCH#:  142 NUM EXPTS TOTAL:  143 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  143 NUM EXPTS TOTAL:  144\n","BATCH#:  143 NUM EXPTS TOTAL:  144 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  144 NUM EXPTS TOTAL:  145\n","BATCH#:  144 NUM EXPTS TOTAL:  145 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  145 NUM EXPTS TOTAL:  146\n","BATCH#:  145 NUM EXPTS TOTAL:  146 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  146 NUM EXPTS TOTAL:  147\n","BATCH#:  146 NUM EXPTS TOTAL:  147 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  147 NUM EXPTS TOTAL:  148\n","BATCH#:  147 NUM EXPTS TOTAL:  148 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  148 NUM EXPTS TOTAL:  149\n","BATCH#:  148 NUM EXPTS TOTAL:  149 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  149 NUM EXPTS TOTAL:  150\n","BATCH#:  149 NUM EXPTS TOTAL:  150 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  150 NUM EXPTS TOTAL:  151\n","BATCH#:  150 NUM EXPTS TOTAL:  151 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  151 NUM EXPTS TOTAL:  152\n","BATCH#:  151 NUM EXPTS TOTAL:  152 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  152 NUM EXPTS TOTAL:  153\n","BATCH#:  152 NUM EXPTS TOTAL:  153 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  153 NUM EXPTS TOTAL:  154\n","BATCH#:  153 NUM EXPTS TOTAL:  154 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  154 NUM EXPTS TOTAL:  155\n","BATCH#:  154 NUM EXPTS TOTAL:  155 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  155 NUM EXPTS TOTAL:  156\n","BATCH#:  155 NUM EXPTS TOTAL:  156 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  156 NUM EXPTS TOTAL:  157\n","BATCH#:  156 NUM EXPTS TOTAL:  157 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  157 NUM EXPTS TOTAL:  158\n","BATCH#:  157 NUM EXPTS TOTAL:  158 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  158 NUM EXPTS TOTAL:  159\n","BATCH#:  158 NUM EXPTS TOTAL:  159 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  159 NUM EXPTS TOTAL:  160\n","BATCH#:  159 NUM EXPTS TOTAL:  160 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  160 NUM EXPTS TOTAL:  161\n","BATCH#:  160 NUM EXPTS TOTAL:  161 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  161 NUM EXPTS TOTAL:  162\n","BATCH#:  161 NUM EXPTS TOTAL:  162 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  162 NUM EXPTS TOTAL:  163\n","BATCH#:  162 NUM EXPTS TOTAL:  163 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  163 NUM EXPTS TOTAL:  164\n","BATCH#:  163 NUM EXPTS TOTAL:  164 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  164 NUM EXPTS TOTAL:  165\n","BATCH#:  164 NUM EXPTS TOTAL:  165 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  165 NUM EXPTS TOTAL:  166\n","BATCH#:  165 NUM EXPTS TOTAL:  166 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  166 NUM EXPTS TOTAL:  167\n","BATCH#:  166 NUM EXPTS TOTAL:  167 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  167 NUM EXPTS TOTAL:  168\n","BATCH#:  167 NUM EXPTS TOTAL:  168 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  168 NUM EXPTS TOTAL:  169\n","BATCH#:  168 NUM EXPTS TOTAL:  169 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  169 NUM EXPTS TOTAL:  170\n","BATCH#:  169 NUM EXPTS TOTAL:  170 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  170 NUM EXPTS TOTAL:  171\n","BATCH#:  170 NUM EXPTS TOTAL:  171 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  171 NUM EXPTS TOTAL:  172\n","BATCH#:  171 NUM EXPTS TOTAL:  172 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  172 NUM EXPTS TOTAL:  173\n","BATCH#:  172 NUM EXPTS TOTAL:  173 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  173 NUM EXPTS TOTAL:  174\n","BATCH#:  173 NUM EXPTS TOTAL:  174 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  174 NUM EXPTS TOTAL:  175\n","BATCH#:  174 NUM EXPTS TOTAL:  175 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  175 NUM EXPTS TOTAL:  176\n","BATCH#:  175 NUM EXPTS TOTAL:  176 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  176 NUM EXPTS TOTAL:  177\n","BATCH#:  176 NUM EXPTS TOTAL:  177 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  177 NUM EXPTS TOTAL:  178\n","BATCH#:  177 NUM EXPTS TOTAL:  178 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  178 NUM EXPTS TOTAL:  179\n","BATCH#:  178 NUM EXPTS TOTAL:  179 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  179 NUM EXPTS TOTAL:  180\n","BATCH#:  179 NUM EXPTS TOTAL:  180 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  180 NUM EXPTS TOTAL:  181\n","BATCH#:  180 NUM EXPTS TOTAL:  181 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  181 NUM EXPTS TOTAL:  182\n","BATCH#:  181 NUM EXPTS TOTAL:  182 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  182 NUM EXPTS TOTAL:  183\n","BATCH#:  182 NUM EXPTS TOTAL:  183 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  183 NUM EXPTS TOTAL:  184\n","BATCH#:  183 NUM EXPTS TOTAL:  184 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  184 NUM EXPTS TOTAL:  185\n","BATCH#:  184 NUM EXPTS TOTAL:  185 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  185 NUM EXPTS TOTAL:  186\n","BATCH#:  185 NUM EXPTS TOTAL:  186 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  186 NUM EXPTS TOTAL:  187\n","BATCH#:  186 NUM EXPTS TOTAL:  187 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  187 NUM EXPTS TOTAL:  188\n","BATCH#:  187 NUM EXPTS TOTAL:  188 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  188 NUM EXPTS TOTAL:  189\n","BATCH#:  188 NUM EXPTS TOTAL:  189 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  189 NUM EXPTS TOTAL:  190\n","BATCH#:  189 NUM EXPTS TOTAL:  190 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  190 NUM EXPTS TOTAL:  191\n","BATCH#:  190 NUM EXPTS TOTAL:  191 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  191 NUM EXPTS TOTAL:  192\n","BATCH#:  191 NUM EXPTS TOTAL:  192 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  192 NUM EXPTS TOTAL:  193\n","BATCH#:  192 NUM EXPTS TOTAL:  193 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  193 NUM EXPTS TOTAL:  194\n","BATCH#:  193 NUM EXPTS TOTAL:  194 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  194 NUM EXPTS TOTAL:  195\n","BATCH#:  194 NUM EXPTS TOTAL:  195 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  195 NUM EXPTS TOTAL:  196\n","BATCH#:  195 NUM EXPTS TOTAL:  196 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  196 NUM EXPTS TOTAL:  197\n","BATCH#:  196 NUM EXPTS TOTAL:  197 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  197 NUM EXPTS TOTAL:  198\n","BATCH#:  197 NUM EXPTS TOTAL:  198 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  198 NUM EXPTS TOTAL:  199\n","BATCH#:  198 NUM EXPTS TOTAL:  199 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  199 NUM EXPTS TOTAL:  200\n","BATCH#:  199 NUM EXPTS TOTAL:  200 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  200 NUM EXPTS TOTAL:  201\n","BATCH#:  200 NUM EXPTS TOTAL:  201 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  201 NUM EXPTS TOTAL:  202\n","BATCH#:  201 NUM EXPTS TOTAL:  202 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  202 NUM EXPTS TOTAL:  203\n","BATCH#:  202 NUM EXPTS TOTAL:  203 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  203 NUM EXPTS TOTAL:  204\n","BATCH#:  203 NUM EXPTS TOTAL:  204 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  204 NUM EXPTS TOTAL:  205\n","BATCH#:  204 NUM EXPTS TOTAL:  205 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  205 NUM EXPTS TOTAL:  206\n","BATCH#:  205 NUM EXPTS TOTAL:  206 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  206 NUM EXPTS TOTAL:  207\n","BATCH#:  206 NUM EXPTS TOTAL:  207 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  207 NUM EXPTS TOTAL:  208\n","BATCH#:  207 NUM EXPTS TOTAL:  208 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  208 NUM EXPTS TOTAL:  209\n","BATCH#:  208 NUM EXPTS TOTAL:  209 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  209 NUM EXPTS TOTAL:  210\n","BATCH#:  209 NUM EXPTS TOTAL:  210 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  210 NUM EXPTS TOTAL:  211\n","BATCH#:  210 NUM EXPTS TOTAL:  211 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  211 NUM EXPTS TOTAL:  212\n","BATCH#:  211 NUM EXPTS TOTAL:  212 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  212 NUM EXPTS TOTAL:  213\n","BATCH#:  212 NUM EXPTS TOTAL:  213 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  213 NUM EXPTS TOTAL:  214\n","BATCH#:  213 NUM EXPTS TOTAL:  214 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  214 NUM EXPTS TOTAL:  215\n","BATCH#:  214 NUM EXPTS TOTAL:  215 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  215 NUM EXPTS TOTAL:  216\n","BATCH#:  215 NUM EXPTS TOTAL:  216 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  216 NUM EXPTS TOTAL:  217\n","BATCH#:  216 NUM EXPTS TOTAL:  217 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  217 NUM EXPTS TOTAL:  218\n","BATCH#:  217 NUM EXPTS TOTAL:  218 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  218 NUM EXPTS TOTAL:  219\n","BATCH#:  218 NUM EXPTS TOTAL:  219 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  219 NUM EXPTS TOTAL:  220\n","BATCH#:  219 NUM EXPTS TOTAL:  220 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  220 NUM EXPTS TOTAL:  221\n","BATCH#:  220 NUM EXPTS TOTAL:  221 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  221 NUM EXPTS TOTAL:  222\n","BATCH#:  221 NUM EXPTS TOTAL:  222 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  222 NUM EXPTS TOTAL:  223\n","BATCH#:  222 NUM EXPTS TOTAL:  223 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  223 NUM EXPTS TOTAL:  224\n","BATCH#:  223 NUM EXPTS TOTAL:  224 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  224 NUM EXPTS TOTAL:  225\n","BATCH#:  224 NUM EXPTS TOTAL:  225 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  225 NUM EXPTS TOTAL:  226\n","BATCH#:  225 NUM EXPTS TOTAL:  226 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  226 NUM EXPTS TOTAL:  227\n","BATCH#:  226 NUM EXPTS TOTAL:  227 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  227 NUM EXPTS TOTAL:  228\n","BATCH#:  227 NUM EXPTS TOTAL:  228 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  228 NUM EXPTS TOTAL:  229\n","BATCH#:  228 NUM EXPTS TOTAL:  229 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  229 NUM EXPTS TOTAL:  230\n","BATCH#:  229 NUM EXPTS TOTAL:  230 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  230 NUM EXPTS TOTAL:  231\n","BATCH#:  230 NUM EXPTS TOTAL:  231 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  231 NUM EXPTS TOTAL:  232\n","BATCH#:  231 NUM EXPTS TOTAL:  232 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  232 NUM EXPTS TOTAL:  233\n","BATCH#:  232 NUM EXPTS TOTAL:  233 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  233 NUM EXPTS TOTAL:  234\n","BATCH#:  233 NUM EXPTS TOTAL:  234 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  234 NUM EXPTS TOTAL:  235\n","BATCH#:  234 NUM EXPTS TOTAL:  235 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  235 NUM EXPTS TOTAL:  236\n","BATCH#:  235 NUM EXPTS TOTAL:  236 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  236 NUM EXPTS TOTAL:  237\n","BATCH#:  236 NUM EXPTS TOTAL:  237 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  237 NUM EXPTS TOTAL:  238\n","BATCH#:  237 NUM EXPTS TOTAL:  238 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  238 NUM EXPTS TOTAL:  239\n","BATCH#:  238 NUM EXPTS TOTAL:  239 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  239 NUM EXPTS TOTAL:  240\n","BATCH#:  239 NUM EXPTS TOTAL:  240 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  240 NUM EXPTS TOTAL:  241\n","BATCH#:  240 NUM EXPTS TOTAL:  241 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  241 NUM EXPTS TOTAL:  242\n","BATCH#:  241 NUM EXPTS TOTAL:  242 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  242 NUM EXPTS TOTAL:  243\n","BATCH#:  242 NUM EXPTS TOTAL:  243 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  243 NUM EXPTS TOTAL:  244\n","BATCH#:  243 NUM EXPTS TOTAL:  244 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  244 NUM EXPTS TOTAL:  245\n","BATCH#:  244 NUM EXPTS TOTAL:  245 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  245 NUM EXPTS TOTAL:  246\n","BATCH#:  245 NUM EXPTS TOTAL:  246 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  246 NUM EXPTS TOTAL:  247\n","BATCH#:  246 NUM EXPTS TOTAL:  247 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  247 NUM EXPTS TOTAL:  248\n","BATCH#:  247 NUM EXPTS TOTAL:  248 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  248 NUM EXPTS TOTAL:  249\n","BATCH#:  248 NUM EXPTS TOTAL:  249 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  249 NUM EXPTS TOTAL:  250\n","BATCH#:  249 NUM EXPTS TOTAL:  250 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  250 NUM EXPTS TOTAL:  251\n","BATCH#:  250 NUM EXPTS TOTAL:  251 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  251 NUM EXPTS TOTAL:  252\n","BATCH#:  251 NUM EXPTS TOTAL:  252 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  252 NUM EXPTS TOTAL:  253\n","BATCH#:  252 NUM EXPTS TOTAL:  253 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  253 NUM EXPTS TOTAL:  254\n","BATCH#:  253 NUM EXPTS TOTAL:  254 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  254 NUM EXPTS TOTAL:  255\n","BATCH#:  254 NUM EXPTS TOTAL:  255 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  255 NUM EXPTS TOTAL:  256\n","BATCH#:  255 NUM EXPTS TOTAL:  256 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  256 NUM EXPTS TOTAL:  257\n","BATCH#:  256 NUM EXPTS TOTAL:  257 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  257 NUM EXPTS TOTAL:  258\n","BATCH#:  257 NUM EXPTS TOTAL:  258 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  258 NUM EXPTS TOTAL:  259\n","BATCH#:  258 NUM EXPTS TOTAL:  259 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  259 NUM EXPTS TOTAL:  260\n","BATCH#:  259 NUM EXPTS TOTAL:  260 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  260 NUM EXPTS TOTAL:  261\n","BATCH#:  260 NUM EXPTS TOTAL:  261 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  261 NUM EXPTS TOTAL:  262\n","BATCH#:  261 NUM EXPTS TOTAL:  262 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  262 NUM EXPTS TOTAL:  263\n","BATCH#:  262 NUM EXPTS TOTAL:  263 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  263 NUM EXPTS TOTAL:  264\n","BATCH#:  263 NUM EXPTS TOTAL:  264 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  264 NUM EXPTS TOTAL:  265\n","BATCH#:  264 NUM EXPTS TOTAL:  265 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  265 NUM EXPTS TOTAL:  266\n","BATCH#:  265 NUM EXPTS TOTAL:  266 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  266 NUM EXPTS TOTAL:  267\n","BATCH#:  266 NUM EXPTS TOTAL:  267 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  267 NUM EXPTS TOTAL:  268\n","BATCH#:  267 NUM EXPTS TOTAL:  268 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  268 NUM EXPTS TOTAL:  269\n","BATCH#:  268 NUM EXPTS TOTAL:  269 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  269 NUM EXPTS TOTAL:  270\n","BATCH#:  269 NUM EXPTS TOTAL:  270 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  270 NUM EXPTS TOTAL:  271\n","BATCH#:  270 NUM EXPTS TOTAL:  271 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  271 NUM EXPTS TOTAL:  272\n","BATCH#:  271 NUM EXPTS TOTAL:  272 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  272 NUM EXPTS TOTAL:  273\n","BATCH#:  272 NUM EXPTS TOTAL:  273 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  273 NUM EXPTS TOTAL:  274\n","BATCH#:  273 NUM EXPTS TOTAL:  274 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  274 NUM EXPTS TOTAL:  275\n","BATCH#:  274 NUM EXPTS TOTAL:  275 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  275 NUM EXPTS TOTAL:  276\n","BATCH#:  275 NUM EXPTS TOTAL:  276 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  276 NUM EXPTS TOTAL:  277\n","BATCH#:  276 NUM EXPTS TOTAL:  277 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  277 NUM EXPTS TOTAL:  278\n","BATCH#:  277 NUM EXPTS TOTAL:  278 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  278 NUM EXPTS TOTAL:  279\n","BATCH#:  278 NUM EXPTS TOTAL:  279 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  279 NUM EXPTS TOTAL:  280\n","BATCH#:  279 NUM EXPTS TOTAL:  280 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  280 NUM EXPTS TOTAL:  281\n","BATCH#:  280 NUM EXPTS TOTAL:  281 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  281 NUM EXPTS TOTAL:  282\n","BATCH#:  281 NUM EXPTS TOTAL:  282 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  282 NUM EXPTS TOTAL:  283\n","BATCH#:  282 NUM EXPTS TOTAL:  283 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  283 NUM EXPTS TOTAL:  284\n","BATCH#:  283 NUM EXPTS TOTAL:  284 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  284 NUM EXPTS TOTAL:  285\n","BATCH#:  284 NUM EXPTS TOTAL:  285 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  285 NUM EXPTS TOTAL:  286\n","BATCH#:  285 NUM EXPTS TOTAL:  286 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  286 NUM EXPTS TOTAL:  287\n","BATCH#:  286 NUM EXPTS TOTAL:  287 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  287 NUM EXPTS TOTAL:  288\n","BATCH#:  287 NUM EXPTS TOTAL:  288 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  288 NUM EXPTS TOTAL:  289\n","BATCH#:  288 NUM EXPTS TOTAL:  289 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  289 NUM EXPTS TOTAL:  290\n","BATCH#:  289 NUM EXPTS TOTAL:  290 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  290 NUM EXPTS TOTAL:  291\n","BATCH#:  290 NUM EXPTS TOTAL:  291 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  291 NUM EXPTS TOTAL:  292\n","BATCH#:  291 NUM EXPTS TOTAL:  292 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  292 NUM EXPTS TOTAL:  293\n","BATCH#:  292 NUM EXPTS TOTAL:  293 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  293 NUM EXPTS TOTAL:  294\n","BATCH#:  293 NUM EXPTS TOTAL:  294 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  294 NUM EXPTS TOTAL:  295\n","BATCH#:  294 NUM EXPTS TOTAL:  295 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  295 NUM EXPTS TOTAL:  296\n","BATCH#:  295 NUM EXPTS TOTAL:  296 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  296 NUM EXPTS TOTAL:  297\n","BATCH#:  296 NUM EXPTS TOTAL:  297 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  297 NUM EXPTS TOTAL:  298\n","BATCH#:  297 NUM EXPTS TOTAL:  298 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  298 NUM EXPTS TOTAL:  299\n","BATCH#:  298 NUM EXPTS TOTAL:  299 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  299 NUM EXPTS TOTAL:  300\n","BATCH#:  299 NUM EXPTS TOTAL:  300 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  300 NUM EXPTS TOTAL:  301\n","BATCH#:  300 NUM EXPTS TOTAL:  301 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  301 NUM EXPTS TOTAL:  302\n","BATCH#:  301 NUM EXPTS TOTAL:  302 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  302 NUM EXPTS TOTAL:  303\n","BATCH#:  302 NUM EXPTS TOTAL:  303 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  303 NUM EXPTS TOTAL:  304\n","BATCH#:  303 NUM EXPTS TOTAL:  304 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  304 NUM EXPTS TOTAL:  305\n","BATCH#:  304 NUM EXPTS TOTAL:  305 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  305 NUM EXPTS TOTAL:  306\n","BATCH#:  305 NUM EXPTS TOTAL:  306 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  306 NUM EXPTS TOTAL:  307\n","BATCH#:  306 NUM EXPTS TOTAL:  307 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  307 NUM EXPTS TOTAL:  308\n","BATCH#:  307 NUM EXPTS TOTAL:  308 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  308 NUM EXPTS TOTAL:  309\n","BATCH#:  308 NUM EXPTS TOTAL:  309 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  309 NUM EXPTS TOTAL:  310\n","BATCH#:  309 NUM EXPTS TOTAL:  310 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  310 NUM EXPTS TOTAL:  311\n","BATCH#:  310 NUM EXPTS TOTAL:  311 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  311 NUM EXPTS TOTAL:  312\n","BATCH#:  311 NUM EXPTS TOTAL:  312 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  312 NUM EXPTS TOTAL:  313\n","BATCH#:  312 NUM EXPTS TOTAL:  313 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  313 NUM EXPTS TOTAL:  314\n","BATCH#:  313 NUM EXPTS TOTAL:  314 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  314 NUM EXPTS TOTAL:  315\n","BATCH#:  314 NUM EXPTS TOTAL:  315 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  315 NUM EXPTS TOTAL:  316\n","BATCH#:  315 NUM EXPTS TOTAL:  316 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  316 NUM EXPTS TOTAL:  317\n","BATCH#:  316 NUM EXPTS TOTAL:  317 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  317 NUM EXPTS TOTAL:  318\n","BATCH#:  317 NUM EXPTS TOTAL:  318 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  318 NUM EXPTS TOTAL:  319\n","BATCH#:  318 NUM EXPTS TOTAL:  319 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  319 NUM EXPTS TOTAL:  320\n","BATCH#:  319 NUM EXPTS TOTAL:  320 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  320 NUM EXPTS TOTAL:  321\n","BATCH#:  320 NUM EXPTS TOTAL:  321 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  321 NUM EXPTS TOTAL:  322\n","BATCH#:  321 NUM EXPTS TOTAL:  322 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  322 NUM EXPTS TOTAL:  323\n","BATCH#:  322 NUM EXPTS TOTAL:  323 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  323 NUM EXPTS TOTAL:  324\n","BATCH#:  323 NUM EXPTS TOTAL:  324 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  324 NUM EXPTS TOTAL:  325\n","BATCH#:  324 NUM EXPTS TOTAL:  325 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  325 NUM EXPTS TOTAL:  326\n","BATCH#:  325 NUM EXPTS TOTAL:  326 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  326 NUM EXPTS TOTAL:  327\n","BATCH#:  326 NUM EXPTS TOTAL:  327 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  327 NUM EXPTS TOTAL:  328\n","BATCH#:  327 NUM EXPTS TOTAL:  328 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  328 NUM EXPTS TOTAL:  329\n","BATCH#:  328 NUM EXPTS TOTAL:  329 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  329 NUM EXPTS TOTAL:  330\n","BATCH#:  329 NUM EXPTS TOTAL:  330 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  330 NUM EXPTS TOTAL:  331\n","BATCH#:  330 NUM EXPTS TOTAL:  331 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  331 NUM EXPTS TOTAL:  332\n","BATCH#:  331 NUM EXPTS TOTAL:  332 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  332 NUM EXPTS TOTAL:  333\n","BATCH#:  332 NUM EXPTS TOTAL:  333 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  333 NUM EXPTS TOTAL:  334\n","BATCH#:  333 NUM EXPTS TOTAL:  334 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  334 NUM EXPTS TOTAL:  335\n","BATCH#:  334 NUM EXPTS TOTAL:  335 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  335 NUM EXPTS TOTAL:  336\n","BATCH#:  335 NUM EXPTS TOTAL:  336 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  336 NUM EXPTS TOTAL:  337\n","BATCH#:  336 NUM EXPTS TOTAL:  337 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  337 NUM EXPTS TOTAL:  338\n","BATCH#:  337 NUM EXPTS TOTAL:  338 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  338 NUM EXPTS TOTAL:  339\n","BATCH#:  338 NUM EXPTS TOTAL:  339 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  339 NUM EXPTS TOTAL:  340\n","BATCH#:  339 NUM EXPTS TOTAL:  340 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  340 NUM EXPTS TOTAL:  341\n","BATCH#:  340 NUM EXPTS TOTAL:  341 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  341 NUM EXPTS TOTAL:  342\n","BATCH#:  341 NUM EXPTS TOTAL:  342 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  342 NUM EXPTS TOTAL:  343\n","BATCH#:  342 NUM EXPTS TOTAL:  343 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  343 NUM EXPTS TOTAL:  344\n","BATCH#:  343 NUM EXPTS TOTAL:  344 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  344 NUM EXPTS TOTAL:  345\n","BATCH#:  344 NUM EXPTS TOTAL:  345 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  345 NUM EXPTS TOTAL:  346\n","BATCH#:  345 NUM EXPTS TOTAL:  346 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  346 NUM EXPTS TOTAL:  347\n","BATCH#:  346 NUM EXPTS TOTAL:  347 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  347 NUM EXPTS TOTAL:  348\n","BATCH#:  347 NUM EXPTS TOTAL:  348 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  348 NUM EXPTS TOTAL:  349\n","BATCH#:  348 NUM EXPTS TOTAL:  349 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  349 NUM EXPTS TOTAL:  350\n","BATCH#:  349 NUM EXPTS TOTAL:  350 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  350 NUM EXPTS TOTAL:  351\n","BATCH#:  350 NUM EXPTS TOTAL:  351 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  351 NUM EXPTS TOTAL:  352\n","BATCH#:  351 NUM EXPTS TOTAL:  352 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  352 NUM EXPTS TOTAL:  353\n","BATCH#:  352 NUM EXPTS TOTAL:  353 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  353 NUM EXPTS TOTAL:  354\n","BATCH#:  353 NUM EXPTS TOTAL:  354 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  354 NUM EXPTS TOTAL:  355\n","BATCH#:  354 NUM EXPTS TOTAL:  355 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  355 NUM EXPTS TOTAL:  356\n","BATCH#:  355 NUM EXPTS TOTAL:  356 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  356 NUM EXPTS TOTAL:  357\n","BATCH#:  356 NUM EXPTS TOTAL:  357 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  357 NUM EXPTS TOTAL:  358\n","BATCH#:  357 NUM EXPTS TOTAL:  358 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  358 NUM EXPTS TOTAL:  359\n","BATCH#:  358 NUM EXPTS TOTAL:  359 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  359 NUM EXPTS TOTAL:  360\n","BATCH#:  359 NUM EXPTS TOTAL:  360 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  360 NUM EXPTS TOTAL:  361\n","BATCH#:  360 NUM EXPTS TOTAL:  361 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  361 NUM EXPTS TOTAL:  362\n","BATCH#:  361 NUM EXPTS TOTAL:  362 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  362 NUM EXPTS TOTAL:  363\n","BATCH#:  362 NUM EXPTS TOTAL:  363 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  363 NUM EXPTS TOTAL:  364\n","BATCH#:  363 NUM EXPTS TOTAL:  364 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  364 NUM EXPTS TOTAL:  365\n","BATCH#:  364 NUM EXPTS TOTAL:  365 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  365 NUM EXPTS TOTAL:  366\n","BATCH#:  365 NUM EXPTS TOTAL:  366 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  366 NUM EXPTS TOTAL:  367\n","BATCH#:  366 NUM EXPTS TOTAL:  367 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  367 NUM EXPTS TOTAL:  368\n","BATCH#:  367 NUM EXPTS TOTAL:  368 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  368 NUM EXPTS TOTAL:  369\n","BATCH#:  368 NUM EXPTS TOTAL:  369 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  369 NUM EXPTS TOTAL:  370\n","BATCH#:  369 NUM EXPTS TOTAL:  370 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  370 NUM EXPTS TOTAL:  371\n","BATCH#:  370 NUM EXPTS TOTAL:  371 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  371 NUM EXPTS TOTAL:  372\n","BATCH#:  371 NUM EXPTS TOTAL:  372 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  372 NUM EXPTS TOTAL:  373\n","BATCH#:  372 NUM EXPTS TOTAL:  373 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  373 NUM EXPTS TOTAL:  374\n","BATCH#:  373 NUM EXPTS TOTAL:  374 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  374 NUM EXPTS TOTAL:  375\n","BATCH#:  374 NUM EXPTS TOTAL:  375 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  375 NUM EXPTS TOTAL:  376\n","BATCH#:  375 NUM EXPTS TOTAL:  376 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  376 NUM EXPTS TOTAL:  377\n","BATCH#:  376 NUM EXPTS TOTAL:  377 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  377 NUM EXPTS TOTAL:  378\n","BATCH#:  377 NUM EXPTS TOTAL:  378 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  378 NUM EXPTS TOTAL:  379\n","BATCH#:  378 NUM EXPTS TOTAL:  379 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  379 NUM EXPTS TOTAL:  380\n","BATCH#:  379 NUM EXPTS TOTAL:  380 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  380 NUM EXPTS TOTAL:  381\n","BATCH#:  380 NUM EXPTS TOTAL:  381 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  381 NUM EXPTS TOTAL:  382\n","BATCH#:  381 NUM EXPTS TOTAL:  382 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  382 NUM EXPTS TOTAL:  383\n","BATCH#:  382 NUM EXPTS TOTAL:  383 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  383 NUM EXPTS TOTAL:  384\n","BATCH#:  383 NUM EXPTS TOTAL:  384 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  384 NUM EXPTS TOTAL:  385\n","BATCH#:  384 NUM EXPTS TOTAL:  385 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  385 NUM EXPTS TOTAL:  386\n","BATCH#:  385 NUM EXPTS TOTAL:  386 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  386 NUM EXPTS TOTAL:  387\n","BATCH#:  386 NUM EXPTS TOTAL:  387 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  387 NUM EXPTS TOTAL:  388\n","BATCH#:  387 NUM EXPTS TOTAL:  388 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  388 NUM EXPTS TOTAL:  389\n","BATCH#:  388 NUM EXPTS TOTAL:  389 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  389 NUM EXPTS TOTAL:  390\n","BATCH#:  389 NUM EXPTS TOTAL:  390 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  390 NUM EXPTS TOTAL:  391\n","BATCH#:  390 NUM EXPTS TOTAL:  391 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  391 NUM EXPTS TOTAL:  392\n","BATCH#:  391 NUM EXPTS TOTAL:  392 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  392 NUM EXPTS TOTAL:  393\n","BATCH#:  392 NUM EXPTS TOTAL:  393 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  393 NUM EXPTS TOTAL:  394\n","BATCH#:  393 NUM EXPTS TOTAL:  394 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  394 NUM EXPTS TOTAL:  395\n","BATCH#:  394 NUM EXPTS TOTAL:  395 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  395 NUM EXPTS TOTAL:  396\n","BATCH#:  395 NUM EXPTS TOTAL:  396 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  396 NUM EXPTS TOTAL:  397\n","BATCH#:  396 NUM EXPTS TOTAL:  397 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  397 NUM EXPTS TOTAL:  398\n","BATCH#:  397 NUM EXPTS TOTAL:  398 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  398 NUM EXPTS TOTAL:  399\n","BATCH#:  398 NUM EXPTS TOTAL:  399 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  399 NUM EXPTS TOTAL:  400\n","BATCH#:  399 NUM EXPTS TOTAL:  400 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  400 NUM EXPTS TOTAL:  401\n","BATCH#:  400 NUM EXPTS TOTAL:  401 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  401 NUM EXPTS TOTAL:  402\n","BATCH#:  401 NUM EXPTS TOTAL:  402 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  402 NUM EXPTS TOTAL:  403\n","BATCH#:  402 NUM EXPTS TOTAL:  403 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  403 NUM EXPTS TOTAL:  404\n","BATCH#:  403 NUM EXPTS TOTAL:  404 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  404 NUM EXPTS TOTAL:  405\n","BATCH#:  404 NUM EXPTS TOTAL:  405 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  405 NUM EXPTS TOTAL:  406\n","BATCH#:  405 NUM EXPTS TOTAL:  406 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  406 NUM EXPTS TOTAL:  407\n","BATCH#:  406 NUM EXPTS TOTAL:  407 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  407 NUM EXPTS TOTAL:  408\n","BATCH#:  407 NUM EXPTS TOTAL:  408 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  408 NUM EXPTS TOTAL:  409\n","BATCH#:  408 NUM EXPTS TOTAL:  409 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  409 NUM EXPTS TOTAL:  410\n","BATCH#:  409 NUM EXPTS TOTAL:  410 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  410 NUM EXPTS TOTAL:  411\n","BATCH#:  410 NUM EXPTS TOTAL:  411 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  411 NUM EXPTS TOTAL:  412\n","BATCH#:  411 NUM EXPTS TOTAL:  412 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  412 NUM EXPTS TOTAL:  413\n","BATCH#:  412 NUM EXPTS TOTAL:  413 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  413 NUM EXPTS TOTAL:  414\n","BATCH#:  413 NUM EXPTS TOTAL:  414 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  414 NUM EXPTS TOTAL:  415\n","BATCH#:  414 NUM EXPTS TOTAL:  415 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  415 NUM EXPTS TOTAL:  416\n","BATCH#:  415 NUM EXPTS TOTAL:  416 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  416 NUM EXPTS TOTAL:  417\n","BATCH#:  416 NUM EXPTS TOTAL:  417 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  417 NUM EXPTS TOTAL:  418\n","BATCH#:  417 NUM EXPTS TOTAL:  418 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  418 NUM EXPTS TOTAL:  419\n","BATCH#:  418 NUM EXPTS TOTAL:  419 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  419 NUM EXPTS TOTAL:  420\n","BATCH#:  419 NUM EXPTS TOTAL:  420 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  420 NUM EXPTS TOTAL:  421\n","BATCH#:  420 NUM EXPTS TOTAL:  421 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  421 NUM EXPTS TOTAL:  422\n","BATCH#:  421 NUM EXPTS TOTAL:  422 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  422 NUM EXPTS TOTAL:  423\n","BATCH#:  422 NUM EXPTS TOTAL:  423 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  423 NUM EXPTS TOTAL:  424\n","BATCH#:  423 NUM EXPTS TOTAL:  424 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  424 NUM EXPTS TOTAL:  425\n","BATCH#:  424 NUM EXPTS TOTAL:  425 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  425 NUM EXPTS TOTAL:  426\n","BATCH#:  425 NUM EXPTS TOTAL:  426 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  426 NUM EXPTS TOTAL:  427\n","BATCH#:  426 NUM EXPTS TOTAL:  427 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  427 NUM EXPTS TOTAL:  428\n","BATCH#:  427 NUM EXPTS TOTAL:  428 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  428 NUM EXPTS TOTAL:  429\n","BATCH#:  428 NUM EXPTS TOTAL:  429 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  429 NUM EXPTS TOTAL:  430\n","BATCH#:  429 NUM EXPTS TOTAL:  430 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  430 NUM EXPTS TOTAL:  431\n","BATCH#:  430 NUM EXPTS TOTAL:  431 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  431 NUM EXPTS TOTAL:  432\n","BATCH#:  431 NUM EXPTS TOTAL:  432 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  432 NUM EXPTS TOTAL:  433\n","BATCH#:  432 NUM EXPTS TOTAL:  433 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  433 NUM EXPTS TOTAL:  434\n","BATCH#:  433 NUM EXPTS TOTAL:  434 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  434 NUM EXPTS TOTAL:  435\n","BATCH#:  434 NUM EXPTS TOTAL:  435 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  435 NUM EXPTS TOTAL:  436\n","BATCH#:  435 NUM EXPTS TOTAL:  436 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  436 NUM EXPTS TOTAL:  437\n","BATCH#:  436 NUM EXPTS TOTAL:  437 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  437 NUM EXPTS TOTAL:  438\n","BATCH#:  437 NUM EXPTS TOTAL:  438 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  438 NUM EXPTS TOTAL:  439\n","BATCH#:  438 NUM EXPTS TOTAL:  439 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  439 NUM EXPTS TOTAL:  440\n","BATCH#:  439 NUM EXPTS TOTAL:  440 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  440 NUM EXPTS TOTAL:  441\n","BATCH#:  440 NUM EXPTS TOTAL:  441 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  441 NUM EXPTS TOTAL:  442\n","BATCH#:  441 NUM EXPTS TOTAL:  442 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  442 NUM EXPTS TOTAL:  443\n","BATCH#:  442 NUM EXPTS TOTAL:  443 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  443 NUM EXPTS TOTAL:  444\n","BATCH#:  443 NUM EXPTS TOTAL:  444 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  444 NUM EXPTS TOTAL:  445\n","BATCH#:  444 NUM EXPTS TOTAL:  445 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  445 NUM EXPTS TOTAL:  446\n","BATCH#:  445 NUM EXPTS TOTAL:  446 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  446 NUM EXPTS TOTAL:  447\n","BATCH#:  446 NUM EXPTS TOTAL:  447 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  447 NUM EXPTS TOTAL:  448\n","BATCH#:  447 NUM EXPTS TOTAL:  448 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  448 NUM EXPTS TOTAL:  449\n","BATCH#:  448 NUM EXPTS TOTAL:  449 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  449 NUM EXPTS TOTAL:  450\n","BATCH#:  449 NUM EXPTS TOTAL:  450 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  450 NUM EXPTS TOTAL:  451\n","BATCH#:  450 NUM EXPTS TOTAL:  451 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  451 NUM EXPTS TOTAL:  452\n","BATCH#:  451 NUM EXPTS TOTAL:  452 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  452 NUM EXPTS TOTAL:  453\n","BATCH#:  452 NUM EXPTS TOTAL:  453 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  453 NUM EXPTS TOTAL:  454\n","BATCH#:  453 NUM EXPTS TOTAL:  454 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  454 NUM EXPTS TOTAL:  455\n","BATCH#:  454 NUM EXPTS TOTAL:  455 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  455 NUM EXPTS TOTAL:  456\n","BATCH#:  455 NUM EXPTS TOTAL:  456 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  456 NUM EXPTS TOTAL:  457\n","BATCH#:  456 NUM EXPTS TOTAL:  457 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  457 NUM EXPTS TOTAL:  458\n","BATCH#:  457 NUM EXPTS TOTAL:  458 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  458 NUM EXPTS TOTAL:  459\n","BATCH#:  458 NUM EXPTS TOTAL:  459 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  459 NUM EXPTS TOTAL:  460\n","BATCH#:  459 NUM EXPTS TOTAL:  460 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  460 NUM EXPTS TOTAL:  461\n","BATCH#:  460 NUM EXPTS TOTAL:  461 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  461 NUM EXPTS TOTAL:  462\n","BATCH#:  461 NUM EXPTS TOTAL:  462 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  462 NUM EXPTS TOTAL:  463\n","BATCH#:  462 NUM EXPTS TOTAL:  463 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  463 NUM EXPTS TOTAL:  464\n","BATCH#:  463 NUM EXPTS TOTAL:  464 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  464 NUM EXPTS TOTAL:  465\n","BATCH#:  464 NUM EXPTS TOTAL:  465 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  465 NUM EXPTS TOTAL:  466\n","BATCH#:  465 NUM EXPTS TOTAL:  466 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  466 NUM EXPTS TOTAL:  467\n","BATCH#:  466 NUM EXPTS TOTAL:  467 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  467 NUM EXPTS TOTAL:  468\n","BATCH#:  467 NUM EXPTS TOTAL:  468 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  468 NUM EXPTS TOTAL:  469\n","BATCH#:  468 NUM EXPTS TOTAL:  469 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  469 NUM EXPTS TOTAL:  470\n","BATCH#:  469 NUM EXPTS TOTAL:  470 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  470 NUM EXPTS TOTAL:  471\n","BATCH#:  470 NUM EXPTS TOTAL:  471 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  471 NUM EXPTS TOTAL:  472\n","BATCH#:  471 NUM EXPTS TOTAL:  472 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  472 NUM EXPTS TOTAL:  473\n","BATCH#:  472 NUM EXPTS TOTAL:  473 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  473 NUM EXPTS TOTAL:  474\n","BATCH#:  473 NUM EXPTS TOTAL:  474 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  474 NUM EXPTS TOTAL:  475\n","BATCH#:  474 NUM EXPTS TOTAL:  475 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  475 NUM EXPTS TOTAL:  476\n","BATCH#:  475 NUM EXPTS TOTAL:  476 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  476 NUM EXPTS TOTAL:  477\n","BATCH#:  476 NUM EXPTS TOTAL:  477 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  477 NUM EXPTS TOTAL:  478\n","BATCH#:  477 NUM EXPTS TOTAL:  478 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  478 NUM EXPTS TOTAL:  479\n","BATCH#:  478 NUM EXPTS TOTAL:  479 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  479 NUM EXPTS TOTAL:  480\n","BATCH#:  479 NUM EXPTS TOTAL:  480 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  480 NUM EXPTS TOTAL:  481\n","BATCH#:  480 NUM EXPTS TOTAL:  481 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  481 NUM EXPTS TOTAL:  482\n","BATCH#:  481 NUM EXPTS TOTAL:  482 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  482 NUM EXPTS TOTAL:  483\n","BATCH#:  482 NUM EXPTS TOTAL:  483 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  483 NUM EXPTS TOTAL:  484\n","BATCH#:  483 NUM EXPTS TOTAL:  484 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  484 NUM EXPTS TOTAL:  485\n","BATCH#:  484 NUM EXPTS TOTAL:  485 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  485 NUM EXPTS TOTAL:  486\n","BATCH#:  485 NUM EXPTS TOTAL:  486 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  486 NUM EXPTS TOTAL:  487\n","BATCH#:  486 NUM EXPTS TOTAL:  487 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  487 NUM EXPTS TOTAL:  488\n","BATCH#:  487 NUM EXPTS TOTAL:  488 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  488 NUM EXPTS TOTAL:  489\n","BATCH#:  488 NUM EXPTS TOTAL:  489 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  489 NUM EXPTS TOTAL:  490\n","BATCH#:  489 NUM EXPTS TOTAL:  490 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  490 NUM EXPTS TOTAL:  491\n","BATCH#:  490 NUM EXPTS TOTAL:  491 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  491 NUM EXPTS TOTAL:  492\n","BATCH#:  491 NUM EXPTS TOTAL:  492 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  492 NUM EXPTS TOTAL:  493\n","BATCH#:  492 NUM EXPTS TOTAL:  493 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  493 NUM EXPTS TOTAL:  494\n","BATCH#:  493 NUM EXPTS TOTAL:  494 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  494 NUM EXPTS TOTAL:  495\n","BATCH#:  494 NUM EXPTS TOTAL:  495 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  495 NUM EXPTS TOTAL:  496\n","BATCH#:  495 NUM EXPTS TOTAL:  496 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  496 NUM EXPTS TOTAL:  497\n","BATCH#:  496 NUM EXPTS TOTAL:  497 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  497 NUM EXPTS TOTAL:  498\n","BATCH#:  497 NUM EXPTS TOTAL:  498 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  498 NUM EXPTS TOTAL:  499\n","BATCH#:  498 NUM EXPTS TOTAL:  499 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  499 NUM EXPTS TOTAL:  500\n","BATCH#:  499 NUM EXPTS TOTAL:  500 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  500 NUM EXPTS TOTAL:  501\n","BATCH#:  500 NUM EXPTS TOTAL:  501 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  501 NUM EXPTS TOTAL:  502\n","BATCH#:  501 NUM EXPTS TOTAL:  502 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  502 NUM EXPTS TOTAL:  503\n","BATCH#:  502 NUM EXPTS TOTAL:  503 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  503 NUM EXPTS TOTAL:  504\n","BATCH#:  503 NUM EXPTS TOTAL:  504 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  504 NUM EXPTS TOTAL:  505\n","BATCH#:  504 NUM EXPTS TOTAL:  505 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  505 NUM EXPTS TOTAL:  506\n","BATCH#:  505 NUM EXPTS TOTAL:  506 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  506 NUM EXPTS TOTAL:  507\n","BATCH#:  506 NUM EXPTS TOTAL:  507 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  507 NUM EXPTS TOTAL:  508\n","BATCH#:  507 NUM EXPTS TOTAL:  508 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  508 NUM EXPTS TOTAL:  509\n","BATCH#:  508 NUM EXPTS TOTAL:  509 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  509 NUM EXPTS TOTAL:  510\n","BATCH#:  509 NUM EXPTS TOTAL:  510 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  510 NUM EXPTS TOTAL:  511\n","BATCH#:  510 NUM EXPTS TOTAL:  511 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  511 NUM EXPTS TOTAL:  512\n","BATCH#:  511 NUM EXPTS TOTAL:  512 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  512 NUM EXPTS TOTAL:  513\n","BATCH#:  512 NUM EXPTS TOTAL:  513 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  513 NUM EXPTS TOTAL:  514\n","BATCH#:  513 NUM EXPTS TOTAL:  514 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  514 NUM EXPTS TOTAL:  515\n","BATCH#:  514 NUM EXPTS TOTAL:  515 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  515 NUM EXPTS TOTAL:  516\n","BATCH#:  515 NUM EXPTS TOTAL:  516 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  516 NUM EXPTS TOTAL:  517\n","BATCH#:  516 NUM EXPTS TOTAL:  517 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  517 NUM EXPTS TOTAL:  518\n","BATCH#:  517 NUM EXPTS TOTAL:  518 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  518 NUM EXPTS TOTAL:  519\n","BATCH#:  518 NUM EXPTS TOTAL:  519 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  519 NUM EXPTS TOTAL:  520\n","BATCH#:  519 NUM EXPTS TOTAL:  520 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  520 NUM EXPTS TOTAL:  521\n","BATCH#:  520 NUM EXPTS TOTAL:  521 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  521 NUM EXPTS TOTAL:  522\n","BATCH#:  521 NUM EXPTS TOTAL:  522 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  522 NUM EXPTS TOTAL:  523\n","BATCH#:  522 NUM EXPTS TOTAL:  523 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  523 NUM EXPTS TOTAL:  524\n","BATCH#:  523 NUM EXPTS TOTAL:  524 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  524 NUM EXPTS TOTAL:  525\n","BATCH#:  524 NUM EXPTS TOTAL:  525 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  525 NUM EXPTS TOTAL:  526\n","BATCH#:  525 NUM EXPTS TOTAL:  526 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  526 NUM EXPTS TOTAL:  527\n","BATCH#:  526 NUM EXPTS TOTAL:  527 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  527 NUM EXPTS TOTAL:  528\n","BATCH#:  527 NUM EXPTS TOTAL:  528 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  528 NUM EXPTS TOTAL:  529\n","BATCH#:  528 NUM EXPTS TOTAL:  529 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  529 NUM EXPTS TOTAL:  530\n","BATCH#:  529 NUM EXPTS TOTAL:  530 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  530 NUM EXPTS TOTAL:  531\n","BATCH#:  530 NUM EXPTS TOTAL:  531 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  531 NUM EXPTS TOTAL:  532\n","BATCH#:  531 NUM EXPTS TOTAL:  532 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  532 NUM EXPTS TOTAL:  533\n","BATCH#:  532 NUM EXPTS TOTAL:  533 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  533 NUM EXPTS TOTAL:  534\n","BATCH#:  533 NUM EXPTS TOTAL:  534 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  534 NUM EXPTS TOTAL:  535\n","BATCH#:  534 NUM EXPTS TOTAL:  535 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  535 NUM EXPTS TOTAL:  536\n","BATCH#:  535 NUM EXPTS TOTAL:  536 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  536 NUM EXPTS TOTAL:  537\n","BATCH#:  536 NUM EXPTS TOTAL:  537 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  537 NUM EXPTS TOTAL:  538\n","BATCH#:  537 NUM EXPTS TOTAL:  538 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  538 NUM EXPTS TOTAL:  539\n","BATCH#:  538 NUM EXPTS TOTAL:  539 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  539 NUM EXPTS TOTAL:  540\n","BATCH#:  539 NUM EXPTS TOTAL:  540 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  540 NUM EXPTS TOTAL:  541\n","BATCH#:  540 NUM EXPTS TOTAL:  541 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  541 NUM EXPTS TOTAL:  542\n","BATCH#:  541 NUM EXPTS TOTAL:  542 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  542 NUM EXPTS TOTAL:  543\n","BATCH#:  542 NUM EXPTS TOTAL:  543 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  543 NUM EXPTS TOTAL:  544\n","BATCH#:  543 NUM EXPTS TOTAL:  544 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  544 NUM EXPTS TOTAL:  545\n","BATCH#:  544 NUM EXPTS TOTAL:  545 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  545 NUM EXPTS TOTAL:  546\n","BATCH#:  545 NUM EXPTS TOTAL:  546 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  546 NUM EXPTS TOTAL:  547\n","BATCH#:  546 NUM EXPTS TOTAL:  547 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  547 NUM EXPTS TOTAL:  548\n","BATCH#:  547 NUM EXPTS TOTAL:  548 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  548 NUM EXPTS TOTAL:  549\n","BATCH#:  548 NUM EXPTS TOTAL:  549 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  549 NUM EXPTS TOTAL:  550\n","BATCH#:  549 NUM EXPTS TOTAL:  550 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  550 NUM EXPTS TOTAL:  551\n","BATCH#:  550 NUM EXPTS TOTAL:  551 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  551 NUM EXPTS TOTAL:  552\n","BATCH#:  551 NUM EXPTS TOTAL:  552 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  552 NUM EXPTS TOTAL:  553\n","BATCH#:  552 NUM EXPTS TOTAL:  553 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  553 NUM EXPTS TOTAL:  554\n","BATCH#:  553 NUM EXPTS TOTAL:  554 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  554 NUM EXPTS TOTAL:  555\n","BATCH#:  554 NUM EXPTS TOTAL:  555 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  555 NUM EXPTS TOTAL:  556\n","BATCH#:  555 NUM EXPTS TOTAL:  556 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  556 NUM EXPTS TOTAL:  557\n","BATCH#:  556 NUM EXPTS TOTAL:  557 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  557 NUM EXPTS TOTAL:  558\n","BATCH#:  557 NUM EXPTS TOTAL:  558 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  558 NUM EXPTS TOTAL:  559\n","BATCH#:  558 NUM EXPTS TOTAL:  559 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  559 NUM EXPTS TOTAL:  560\n","BATCH#:  559 NUM EXPTS TOTAL:  560 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  560 NUM EXPTS TOTAL:  561\n","BATCH#:  560 NUM EXPTS TOTAL:  561 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  561 NUM EXPTS TOTAL:  562\n","BATCH#:  561 NUM EXPTS TOTAL:  562 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  562 NUM EXPTS TOTAL:  563\n","BATCH#:  562 NUM EXPTS TOTAL:  563 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  563 NUM EXPTS TOTAL:  564\n","BATCH#:  563 NUM EXPTS TOTAL:  564 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  564 NUM EXPTS TOTAL:  565\n","BATCH#:  564 NUM EXPTS TOTAL:  565 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  565 NUM EXPTS TOTAL:  566\n","BATCH#:  565 NUM EXPTS TOTAL:  566 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  566 NUM EXPTS TOTAL:  567\n","BATCH#:  566 NUM EXPTS TOTAL:  567 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  567 NUM EXPTS TOTAL:  568\n","BATCH#:  567 NUM EXPTS TOTAL:  568 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  568 NUM EXPTS TOTAL:  569\n","BATCH#:  568 NUM EXPTS TOTAL:  569 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  569 NUM EXPTS TOTAL:  570\n","BATCH#:  569 NUM EXPTS TOTAL:  570 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  570 NUM EXPTS TOTAL:  571\n","BATCH#:  570 NUM EXPTS TOTAL:  571 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  571 NUM EXPTS TOTAL:  572\n","BATCH#:  571 NUM EXPTS TOTAL:  572 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  572 NUM EXPTS TOTAL:  573\n","BATCH#:  572 NUM EXPTS TOTAL:  573 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  573 NUM EXPTS TOTAL:  574\n","BATCH#:  573 NUM EXPTS TOTAL:  574 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  574 NUM EXPTS TOTAL:  575\n","BATCH#:  574 NUM EXPTS TOTAL:  575 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  575 NUM EXPTS TOTAL:  576\n","BATCH#:  575 NUM EXPTS TOTAL:  576 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  576 NUM EXPTS TOTAL:  577\n","BATCH#:  576 NUM EXPTS TOTAL:  577 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  577 NUM EXPTS TOTAL:  578\n","BATCH#:  577 NUM EXPTS TOTAL:  578 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  578 NUM EXPTS TOTAL:  579\n","BATCH#:  578 NUM EXPTS TOTAL:  579 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  579 NUM EXPTS TOTAL:  580\n","BATCH#:  579 NUM EXPTS TOTAL:  580 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  580 NUM EXPTS TOTAL:  581\n","BATCH#:  580 NUM EXPTS TOTAL:  581 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  581 NUM EXPTS TOTAL:  582\n","BATCH#:  581 NUM EXPTS TOTAL:  582 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  582 NUM EXPTS TOTAL:  583\n","BATCH#:  582 NUM EXPTS TOTAL:  583 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  583 NUM EXPTS TOTAL:  584\n","BATCH#:  583 NUM EXPTS TOTAL:  584 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  584 NUM EXPTS TOTAL:  585\n","BATCH#:  584 NUM EXPTS TOTAL:  585 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  585 NUM EXPTS TOTAL:  586\n","BATCH#:  585 NUM EXPTS TOTAL:  586 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  586 NUM EXPTS TOTAL:  587\n","BATCH#:  586 NUM EXPTS TOTAL:  587 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  587 NUM EXPTS TOTAL:  588\n","BATCH#:  587 NUM EXPTS TOTAL:  588 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  588 NUM EXPTS TOTAL:  589\n","BATCH#:  588 NUM EXPTS TOTAL:  589 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  589 NUM EXPTS TOTAL:  590\n","BATCH#:  589 NUM EXPTS TOTAL:  590 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  590 NUM EXPTS TOTAL:  591\n","BATCH#:  590 NUM EXPTS TOTAL:  591 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  591 NUM EXPTS TOTAL:  592\n","BATCH#:  591 NUM EXPTS TOTAL:  592 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  592 NUM EXPTS TOTAL:  593\n","BATCH#:  592 NUM EXPTS TOTAL:  593 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  593 NUM EXPTS TOTAL:  594\n","BATCH#:  593 NUM EXPTS TOTAL:  594 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  594 NUM EXPTS TOTAL:  595\n","BATCH#:  594 NUM EXPTS TOTAL:  595 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  595 NUM EXPTS TOTAL:  596\n","BATCH#:  595 NUM EXPTS TOTAL:  596 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  596 NUM EXPTS TOTAL:  597\n","BATCH#:  596 NUM EXPTS TOTAL:  597 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  597 NUM EXPTS TOTAL:  598\n","BATCH#:  597 NUM EXPTS TOTAL:  598 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  598 NUM EXPTS TOTAL:  599\n","BATCH#:  598 NUM EXPTS TOTAL:  599 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  599 NUM EXPTS TOTAL:  600\n","BATCH#:  599 NUM EXPTS TOTAL:  600 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  600 NUM EXPTS TOTAL:  601\n","BATCH#:  600 NUM EXPTS TOTAL:  601 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  601 NUM EXPTS TOTAL:  602\n","BATCH#:  601 NUM EXPTS TOTAL:  602 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  602 NUM EXPTS TOTAL:  603\n","BATCH#:  602 NUM EXPTS TOTAL:  603 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  603 NUM EXPTS TOTAL:  604\n","BATCH#:  603 NUM EXPTS TOTAL:  604 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  604 NUM EXPTS TOTAL:  605\n","BATCH#:  604 NUM EXPTS TOTAL:  605 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  605 NUM EXPTS TOTAL:  606\n","BATCH#:  605 NUM EXPTS TOTAL:  606 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  606 NUM EXPTS TOTAL:  607\n","BATCH#:  606 NUM EXPTS TOTAL:  607 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  607 NUM EXPTS TOTAL:  608\n","BATCH#:  607 NUM EXPTS TOTAL:  608 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  608 NUM EXPTS TOTAL:  609\n","BATCH#:  608 NUM EXPTS TOTAL:  609 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  609 NUM EXPTS TOTAL:  610\n","BATCH#:  609 NUM EXPTS TOTAL:  610 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  610 NUM EXPTS TOTAL:  611\n","BATCH#:  610 NUM EXPTS TOTAL:  611 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  611 NUM EXPTS TOTAL:  612\n","BATCH#:  611 NUM EXPTS TOTAL:  612 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  612 NUM EXPTS TOTAL:  613\n","BATCH#:  612 NUM EXPTS TOTAL:  613 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  613 NUM EXPTS TOTAL:  614\n","BATCH#:  613 NUM EXPTS TOTAL:  614 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  614 NUM EXPTS TOTAL:  615\n","BATCH#:  614 NUM EXPTS TOTAL:  615 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  615 NUM EXPTS TOTAL:  616\n","BATCH#:  615 NUM EXPTS TOTAL:  616 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  616 NUM EXPTS TOTAL:  617\n","BATCH#:  616 NUM EXPTS TOTAL:  617 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  617 NUM EXPTS TOTAL:  618\n","BATCH#:  617 NUM EXPTS TOTAL:  618 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  618 NUM EXPTS TOTAL:  619\n","BATCH#:  618 NUM EXPTS TOTAL:  619 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  619 NUM EXPTS TOTAL:  620\n","BATCH#:  619 NUM EXPTS TOTAL:  620 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  620 NUM EXPTS TOTAL:  621\n","BATCH#:  620 NUM EXPTS TOTAL:  621 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  621 NUM EXPTS TOTAL:  622\n","BATCH#:  621 NUM EXPTS TOTAL:  622 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  622 NUM EXPTS TOTAL:  623\n","BATCH#:  622 NUM EXPTS TOTAL:  623 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  623 NUM EXPTS TOTAL:  624\n","BATCH#:  623 NUM EXPTS TOTAL:  624 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  624 NUM EXPTS TOTAL:  625\n","BATCH#:  624 NUM EXPTS TOTAL:  625 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  625 NUM EXPTS TOTAL:  626\n","BATCH#:  625 NUM EXPTS TOTAL:  626 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  626 NUM EXPTS TOTAL:  627\n","BATCH#:  626 NUM EXPTS TOTAL:  627 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  627 NUM EXPTS TOTAL:  628\n","BATCH#:  627 NUM EXPTS TOTAL:  628 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  628 NUM EXPTS TOTAL:  629\n","BATCH#:  628 NUM EXPTS TOTAL:  629 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  629 NUM EXPTS TOTAL:  630\n","BATCH#:  629 NUM EXPTS TOTAL:  630 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  630 NUM EXPTS TOTAL:  631\n","BATCH#:  630 NUM EXPTS TOTAL:  631 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  631 NUM EXPTS TOTAL:  632\n","BATCH#:  631 NUM EXPTS TOTAL:  632 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  632 NUM EXPTS TOTAL:  633\n","BATCH#:  632 NUM EXPTS TOTAL:  633 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  633 NUM EXPTS TOTAL:  634\n","BATCH#:  633 NUM EXPTS TOTAL:  634 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  634 NUM EXPTS TOTAL:  635\n","BATCH#:  634 NUM EXPTS TOTAL:  635 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  635 NUM EXPTS TOTAL:  636\n","BATCH#:  635 NUM EXPTS TOTAL:  636 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  636 NUM EXPTS TOTAL:  637\n","BATCH#:  636 NUM EXPTS TOTAL:  637 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  637 NUM EXPTS TOTAL:  638\n","BATCH#:  637 NUM EXPTS TOTAL:  638 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  638 NUM EXPTS TOTAL:  639\n","BATCH#:  638 NUM EXPTS TOTAL:  639 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  639 NUM EXPTS TOTAL:  640\n","BATCH#:  639 NUM EXPTS TOTAL:  640 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  640 NUM EXPTS TOTAL:  641\n","BATCH#:  640 NUM EXPTS TOTAL:  641 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  641 NUM EXPTS TOTAL:  642\n","BATCH#:  641 NUM EXPTS TOTAL:  642 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  642 NUM EXPTS TOTAL:  643\n","BATCH#:  642 NUM EXPTS TOTAL:  643 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  643 NUM EXPTS TOTAL:  644\n","BATCH#:  643 NUM EXPTS TOTAL:  644 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  644 NUM EXPTS TOTAL:  645\n","BATCH#:  644 NUM EXPTS TOTAL:  645 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  645 NUM EXPTS TOTAL:  646\n","BATCH#:  645 NUM EXPTS TOTAL:  646 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  646 NUM EXPTS TOTAL:  647\n","BATCH#:  646 NUM EXPTS TOTAL:  647 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  647 NUM EXPTS TOTAL:  648\n","BATCH#:  647 NUM EXPTS TOTAL:  648 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  648 NUM EXPTS TOTAL:  649\n","BATCH#:  648 NUM EXPTS TOTAL:  649 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  649 NUM EXPTS TOTAL:  650\n","BATCH#:  649 NUM EXPTS TOTAL:  650 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  650 NUM EXPTS TOTAL:  651\n","BATCH#:  650 NUM EXPTS TOTAL:  651 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  651 NUM EXPTS TOTAL:  652\n","BATCH#:  651 NUM EXPTS TOTAL:  652 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  652 NUM EXPTS TOTAL:  653\n","BATCH#:  652 NUM EXPTS TOTAL:  653 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  653 NUM EXPTS TOTAL:  654\n","BATCH#:  653 NUM EXPTS TOTAL:  654 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  654 NUM EXPTS TOTAL:  655\n","BATCH#:  654 NUM EXPTS TOTAL:  655 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  655 NUM EXPTS TOTAL:  656\n","BATCH#:  655 NUM EXPTS TOTAL:  656 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  656 NUM EXPTS TOTAL:  657\n","BATCH#:  656 NUM EXPTS TOTAL:  657 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  657 NUM EXPTS TOTAL:  658\n","BATCH#:  657 NUM EXPTS TOTAL:  658 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  658 NUM EXPTS TOTAL:  659\n","BATCH#:  658 NUM EXPTS TOTAL:  659 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  659 NUM EXPTS TOTAL:  660\n","BATCH#:  659 NUM EXPTS TOTAL:  660 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  660 NUM EXPTS TOTAL:  661\n","BATCH#:  660 NUM EXPTS TOTAL:  661 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  661 NUM EXPTS TOTAL:  662\n","BATCH#:  661 NUM EXPTS TOTAL:  662 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  662 NUM EXPTS TOTAL:  663\n","BATCH#:  662 NUM EXPTS TOTAL:  663 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  663 NUM EXPTS TOTAL:  664\n","BATCH#:  663 NUM EXPTS TOTAL:  664 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  664 NUM EXPTS TOTAL:  665\n","BATCH#:  664 NUM EXPTS TOTAL:  665 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  665 NUM EXPTS TOTAL:  666\n","BATCH#:  665 NUM EXPTS TOTAL:  666 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  666 NUM EXPTS TOTAL:  667\n","BATCH#:  666 NUM EXPTS TOTAL:  667 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  667 NUM EXPTS TOTAL:  668\n","BATCH#:  667 NUM EXPTS TOTAL:  668 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  668 NUM EXPTS TOTAL:  669\n","BATCH#:  668 NUM EXPTS TOTAL:  669 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  669 NUM EXPTS TOTAL:  670\n","BATCH#:  669 NUM EXPTS TOTAL:  670 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  670 NUM EXPTS TOTAL:  671\n","BATCH#:  670 NUM EXPTS TOTAL:  671 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  671 NUM EXPTS TOTAL:  672\n","BATCH#:  671 NUM EXPTS TOTAL:  672 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  672 NUM EXPTS TOTAL:  673\n","BATCH#:  672 NUM EXPTS TOTAL:  673 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  673 NUM EXPTS TOTAL:  674\n","BATCH#:  673 NUM EXPTS TOTAL:  674 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  674 NUM EXPTS TOTAL:  675\n","BATCH#:  674 NUM EXPTS TOTAL:  675 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  675 NUM EXPTS TOTAL:  676\n","BATCH#:  675 NUM EXPTS TOTAL:  676 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  676 NUM EXPTS TOTAL:  677\n","BATCH#:  676 NUM EXPTS TOTAL:  677 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  677 NUM EXPTS TOTAL:  678\n","BATCH#:  677 NUM EXPTS TOTAL:  678 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  678 NUM EXPTS TOTAL:  679\n","BATCH#:  678 NUM EXPTS TOTAL:  679 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  679 NUM EXPTS TOTAL:  680\n","BATCH#:  679 NUM EXPTS TOTAL:  680 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  680 NUM EXPTS TOTAL:  681\n","BATCH#:  680 NUM EXPTS TOTAL:  681 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  681 NUM EXPTS TOTAL:  682\n","BATCH#:  681 NUM EXPTS TOTAL:  682 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  682 NUM EXPTS TOTAL:  683\n","BATCH#:  682 NUM EXPTS TOTAL:  683 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  683 NUM EXPTS TOTAL:  684\n","BATCH#:  683 NUM EXPTS TOTAL:  684 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  684 NUM EXPTS TOTAL:  685\n","BATCH#:  684 NUM EXPTS TOTAL:  685 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  685 NUM EXPTS TOTAL:  686\n","BATCH#:  685 NUM EXPTS TOTAL:  686 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  686 NUM EXPTS TOTAL:  687\n","BATCH#:  686 NUM EXPTS TOTAL:  687 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  687 NUM EXPTS TOTAL:  688\n","BATCH#:  687 NUM EXPTS TOTAL:  688 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  688 NUM EXPTS TOTAL:  689\n","BATCH#:  688 NUM EXPTS TOTAL:  689 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  689 NUM EXPTS TOTAL:  690\n","BATCH#:  689 NUM EXPTS TOTAL:  690 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  690 NUM EXPTS TOTAL:  691\n","BATCH#:  690 NUM EXPTS TOTAL:  691 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  691 NUM EXPTS TOTAL:  692\n","BATCH#:  691 NUM EXPTS TOTAL:  692 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  692 NUM EXPTS TOTAL:  693\n","BATCH#:  692 NUM EXPTS TOTAL:  693 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  693 NUM EXPTS TOTAL:  694\n","BATCH#:  693 NUM EXPTS TOTAL:  694 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  694 NUM EXPTS TOTAL:  695\n","BATCH#:  694 NUM EXPTS TOTAL:  695 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  695 NUM EXPTS TOTAL:  696\n","BATCH#:  695 NUM EXPTS TOTAL:  696 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  696 NUM EXPTS TOTAL:  697\n","BATCH#:  696 NUM EXPTS TOTAL:  697 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  697 NUM EXPTS TOTAL:  698\n","BATCH#:  697 NUM EXPTS TOTAL:  698 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  698 NUM EXPTS TOTAL:  699\n","BATCH#:  698 NUM EXPTS TOTAL:  699 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  699 NUM EXPTS TOTAL:  700\n","BATCH#:  699 NUM EXPTS TOTAL:  700 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  700 NUM EXPTS TOTAL:  701\n","BATCH#:  700 NUM EXPTS TOTAL:  701 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  701 NUM EXPTS TOTAL:  702\n","BATCH#:  701 NUM EXPTS TOTAL:  702 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  702 NUM EXPTS TOTAL:  703\n","BATCH#:  702 NUM EXPTS TOTAL:  703 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  703 NUM EXPTS TOTAL:  704\n","BATCH#:  703 NUM EXPTS TOTAL:  704 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  704 NUM EXPTS TOTAL:  705\n","BATCH#:  704 NUM EXPTS TOTAL:  705 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  705 NUM EXPTS TOTAL:  706\n","BATCH#:  705 NUM EXPTS TOTAL:  706 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  706 NUM EXPTS TOTAL:  707\n","BATCH#:  706 NUM EXPTS TOTAL:  707 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  707 NUM EXPTS TOTAL:  708\n","BATCH#:  707 NUM EXPTS TOTAL:  708 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  708 NUM EXPTS TOTAL:  709\n","BATCH#:  708 NUM EXPTS TOTAL:  709 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  709 NUM EXPTS TOTAL:  710\n","BATCH#:  709 NUM EXPTS TOTAL:  710 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  710 NUM EXPTS TOTAL:  711\n","BATCH#:  710 NUM EXPTS TOTAL:  711 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  711 NUM EXPTS TOTAL:  712\n","BATCH#:  711 NUM EXPTS TOTAL:  712 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  712 NUM EXPTS TOTAL:  713\n","BATCH#:  712 NUM EXPTS TOTAL:  713 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  713 NUM EXPTS TOTAL:  714\n","BATCH#:  713 NUM EXPTS TOTAL:  714 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  714 NUM EXPTS TOTAL:  715\n","BATCH#:  714 NUM EXPTS TOTAL:  715 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  715 NUM EXPTS TOTAL:  716\n","BATCH#:  715 NUM EXPTS TOTAL:  716 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  716 NUM EXPTS TOTAL:  717\n","BATCH#:  716 NUM EXPTS TOTAL:  717 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  717 NUM EXPTS TOTAL:  718\n","BATCH#:  717 NUM EXPTS TOTAL:  718 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  718 NUM EXPTS TOTAL:  719\n","BATCH#:  718 NUM EXPTS TOTAL:  719 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  719 NUM EXPTS TOTAL:  720\n","BATCH#:  719 NUM EXPTS TOTAL:  720 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  720 NUM EXPTS TOTAL:  721\n","BATCH#:  720 NUM EXPTS TOTAL:  721 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  721 NUM EXPTS TOTAL:  722\n","BATCH#:  721 NUM EXPTS TOTAL:  722 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  722 NUM EXPTS TOTAL:  723\n","BATCH#:  722 NUM EXPTS TOTAL:  723 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  723 NUM EXPTS TOTAL:  724\n","BATCH#:  723 NUM EXPTS TOTAL:  724 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  724 NUM EXPTS TOTAL:  725\n","BATCH#:  724 NUM EXPTS TOTAL:  725 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  725 NUM EXPTS TOTAL:  726\n","BATCH#:  725 NUM EXPTS TOTAL:  726 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  726 NUM EXPTS TOTAL:  727\n","BATCH#:  726 NUM EXPTS TOTAL:  727 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  727 NUM EXPTS TOTAL:  728\n","BATCH#:  727 NUM EXPTS TOTAL:  728 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  728 NUM EXPTS TOTAL:  729\n","BATCH#:  728 NUM EXPTS TOTAL:  729 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  729 NUM EXPTS TOTAL:  730\n","BATCH#:  729 NUM EXPTS TOTAL:  730 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  730 NUM EXPTS TOTAL:  731\n","BATCH#:  730 NUM EXPTS TOTAL:  731 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  731 NUM EXPTS TOTAL:  732\n","BATCH#:  731 NUM EXPTS TOTAL:  732 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  732 NUM EXPTS TOTAL:  733\n","BATCH#:  732 NUM EXPTS TOTAL:  733 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  733 NUM EXPTS TOTAL:  734\n","BATCH#:  733 NUM EXPTS TOTAL:  734 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  734 NUM EXPTS TOTAL:  735\n","BATCH#:  734 NUM EXPTS TOTAL:  735 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  735 NUM EXPTS TOTAL:  736\n","BATCH#:  735 NUM EXPTS TOTAL:  736 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  736 NUM EXPTS TOTAL:  737\n","BATCH#:  736 NUM EXPTS TOTAL:  737 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  737 NUM EXPTS TOTAL:  738\n","BATCH#:  737 NUM EXPTS TOTAL:  738 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  738 NUM EXPTS TOTAL:  739\n","BATCH#:  738 NUM EXPTS TOTAL:  739 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  739 NUM EXPTS TOTAL:  740\n","BATCH#:  739 NUM EXPTS TOTAL:  740 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  740 NUM EXPTS TOTAL:  741\n","BATCH#:  740 NUM EXPTS TOTAL:  741 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  741 NUM EXPTS TOTAL:  742\n","BATCH#:  741 NUM EXPTS TOTAL:  742 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  742 NUM EXPTS TOTAL:  743\n","BATCH#:  742 NUM EXPTS TOTAL:  743 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  743 NUM EXPTS TOTAL:  744\n","BATCH#:  743 NUM EXPTS TOTAL:  744 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  744 NUM EXPTS TOTAL:  745\n","BATCH#:  744 NUM EXPTS TOTAL:  745 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  745 NUM EXPTS TOTAL:  746\n","BATCH#:  745 NUM EXPTS TOTAL:  746 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  746 NUM EXPTS TOTAL:  747\n","BATCH#:  746 NUM EXPTS TOTAL:  747 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  747 NUM EXPTS TOTAL:  748\n","BATCH#:  747 NUM EXPTS TOTAL:  748 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  748 NUM EXPTS TOTAL:  749\n","BATCH#:  748 NUM EXPTS TOTAL:  749 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  749 NUM EXPTS TOTAL:  750\n","BATCH#:  749 NUM EXPTS TOTAL:  750 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  750 NUM EXPTS TOTAL:  751\n","BATCH#:  750 NUM EXPTS TOTAL:  751 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  751 NUM EXPTS TOTAL:  752\n","BATCH#:  751 NUM EXPTS TOTAL:  752 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  752 NUM EXPTS TOTAL:  753\n","BATCH#:  752 NUM EXPTS TOTAL:  753 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  753 NUM EXPTS TOTAL:  754\n","BATCH#:  753 NUM EXPTS TOTAL:  754 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  754 NUM EXPTS TOTAL:  755\n","BATCH#:  754 NUM EXPTS TOTAL:  755 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  755 NUM EXPTS TOTAL:  756\n","BATCH#:  755 NUM EXPTS TOTAL:  756 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  756 NUM EXPTS TOTAL:  757\n","BATCH#:  756 NUM EXPTS TOTAL:  757 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  757 NUM EXPTS TOTAL:  758\n","BATCH#:  757 NUM EXPTS TOTAL:  758 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  758 NUM EXPTS TOTAL:  759\n","BATCH#:  758 NUM EXPTS TOTAL:  759 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  759 NUM EXPTS TOTAL:  760\n","BATCH#:  759 NUM EXPTS TOTAL:  760 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  760 NUM EXPTS TOTAL:  761\n","BATCH#:  760 NUM EXPTS TOTAL:  761 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  761 NUM EXPTS TOTAL:  762\n","BATCH#:  761 NUM EXPTS TOTAL:  762 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  762 NUM EXPTS TOTAL:  763\n","BATCH#:  762 NUM EXPTS TOTAL:  763 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  763 NUM EXPTS TOTAL:  764\n","BATCH#:  763 NUM EXPTS TOTAL:  764 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  764 NUM EXPTS TOTAL:  765\n","BATCH#:  764 NUM EXPTS TOTAL:  765 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  765 NUM EXPTS TOTAL:  766\n","BATCH#:  765 NUM EXPTS TOTAL:  766 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  766 NUM EXPTS TOTAL:  767\n","BATCH#:  766 NUM EXPTS TOTAL:  767 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  767 NUM EXPTS TOTAL:  768\n","BATCH#:  767 NUM EXPTS TOTAL:  768 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  768 NUM EXPTS TOTAL:  769\n","BATCH#:  768 NUM EXPTS TOTAL:  769 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  769 NUM EXPTS TOTAL:  770\n","BATCH#:  769 NUM EXPTS TOTAL:  770 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  770 NUM EXPTS TOTAL:  771\n","BATCH#:  770 NUM EXPTS TOTAL:  771 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  771 NUM EXPTS TOTAL:  772\n","BATCH#:  771 NUM EXPTS TOTAL:  772 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  772 NUM EXPTS TOTAL:  773\n","BATCH#:  772 NUM EXPTS TOTAL:  773 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  773 NUM EXPTS TOTAL:  774\n","BATCH#:  773 NUM EXPTS TOTAL:  774 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  774 NUM EXPTS TOTAL:  775\n","BATCH#:  774 NUM EXPTS TOTAL:  775 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  775 NUM EXPTS TOTAL:  776\n","BATCH#:  775 NUM EXPTS TOTAL:  776 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  776 NUM EXPTS TOTAL:  777\n","BATCH#:  776 NUM EXPTS TOTAL:  777 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  777 NUM EXPTS TOTAL:  778\n","BATCH#:  777 NUM EXPTS TOTAL:  778 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  778 NUM EXPTS TOTAL:  779\n","BATCH#:  778 NUM EXPTS TOTAL:  779 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  779 NUM EXPTS TOTAL:  780\n","BATCH#:  779 NUM EXPTS TOTAL:  780 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  780 NUM EXPTS TOTAL:  781\n","BATCH#:  780 NUM EXPTS TOTAL:  781 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  781 NUM EXPTS TOTAL:  782\n","BATCH#:  781 NUM EXPTS TOTAL:  782 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  782 NUM EXPTS TOTAL:  783\n","BATCH#:  782 NUM EXPTS TOTAL:  783 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  783 NUM EXPTS TOTAL:  784\n","BATCH#:  783 NUM EXPTS TOTAL:  784 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  784 NUM EXPTS TOTAL:  785\n","BATCH#:  784 NUM EXPTS TOTAL:  785 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  785 NUM EXPTS TOTAL:  786\n","BATCH#:  785 NUM EXPTS TOTAL:  786 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  786 NUM EXPTS TOTAL:  787\n","BATCH#:  786 NUM EXPTS TOTAL:  787 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  787 NUM EXPTS TOTAL:  788\n","BATCH#:  787 NUM EXPTS TOTAL:  788 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  788 NUM EXPTS TOTAL:  789\n","BATCH#:  788 NUM EXPTS TOTAL:  789 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  789 NUM EXPTS TOTAL:  790\n","BATCH#:  789 NUM EXPTS TOTAL:  790 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  790 NUM EXPTS TOTAL:  791\n","BATCH#:  790 NUM EXPTS TOTAL:  791 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  791 NUM EXPTS TOTAL:  792\n","BATCH#:  791 NUM EXPTS TOTAL:  792 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  792 NUM EXPTS TOTAL:  793\n","BATCH#:  792 NUM EXPTS TOTAL:  793 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  793 NUM EXPTS TOTAL:  794\n","BATCH#:  793 NUM EXPTS TOTAL:  794 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  794 NUM EXPTS TOTAL:  795\n","BATCH#:  794 NUM EXPTS TOTAL:  795 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  795 NUM EXPTS TOTAL:  796\n","BATCH#:  795 NUM EXPTS TOTAL:  796 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  796 NUM EXPTS TOTAL:  797\n","BATCH#:  796 NUM EXPTS TOTAL:  797 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  797 NUM EXPTS TOTAL:  798\n","BATCH#:  797 NUM EXPTS TOTAL:  798 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  798 NUM EXPTS TOTAL:  799\n","BATCH#:  798 NUM EXPTS TOTAL:  799 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  799 NUM EXPTS TOTAL:  800\n","BATCH#:  799 NUM EXPTS TOTAL:  800 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  800 NUM EXPTS TOTAL:  801\n","BATCH#:  800 NUM EXPTS TOTAL:  801 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  801 NUM EXPTS TOTAL:  802\n","BATCH#:  801 NUM EXPTS TOTAL:  802 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  802 NUM EXPTS TOTAL:  803\n","BATCH#:  802 NUM EXPTS TOTAL:  803 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  803 NUM EXPTS TOTAL:  804\n","BATCH#:  803 NUM EXPTS TOTAL:  804 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  804 NUM EXPTS TOTAL:  805\n","BATCH#:  804 NUM EXPTS TOTAL:  805 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  805 NUM EXPTS TOTAL:  806\n","BATCH#:  805 NUM EXPTS TOTAL:  806 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  806 NUM EXPTS TOTAL:  807\n","BATCH#:  806 NUM EXPTS TOTAL:  807 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  807 NUM EXPTS TOTAL:  808\n","BATCH#:  807 NUM EXPTS TOTAL:  808 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  808 NUM EXPTS TOTAL:  809\n","BATCH#:  808 NUM EXPTS TOTAL:  809 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  809 NUM EXPTS TOTAL:  810\n","BATCH#:  809 NUM EXPTS TOTAL:  810 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  810 NUM EXPTS TOTAL:  811\n","BATCH#:  810 NUM EXPTS TOTAL:  811 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  811 NUM EXPTS TOTAL:  812\n","BATCH#:  811 NUM EXPTS TOTAL:  812 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  812 NUM EXPTS TOTAL:  813\n","BATCH#:  812 NUM EXPTS TOTAL:  813 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  813 NUM EXPTS TOTAL:  814\n","BATCH#:  813 NUM EXPTS TOTAL:  814 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  814 NUM EXPTS TOTAL:  815\n","BATCH#:  814 NUM EXPTS TOTAL:  815 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  815 NUM EXPTS TOTAL:  816\n","BATCH#:  815 NUM EXPTS TOTAL:  816 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  816 NUM EXPTS TOTAL:  817\n","BATCH#:  816 NUM EXPTS TOTAL:  817 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  817 NUM EXPTS TOTAL:  818\n","BATCH#:  817 NUM EXPTS TOTAL:  818 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  818 NUM EXPTS TOTAL:  819\n","BATCH#:  818 NUM EXPTS TOTAL:  819 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  819 NUM EXPTS TOTAL:  820\n","BATCH#:  819 NUM EXPTS TOTAL:  820 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  820 NUM EXPTS TOTAL:  821\n","BATCH#:  820 NUM EXPTS TOTAL:  821 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  821 NUM EXPTS TOTAL:  822\n","BATCH#:  821 NUM EXPTS TOTAL:  822 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  822 NUM EXPTS TOTAL:  823\n","BATCH#:  822 NUM EXPTS TOTAL:  823 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  823 NUM EXPTS TOTAL:  824\n","BATCH#:  823 NUM EXPTS TOTAL:  824 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  824 NUM EXPTS TOTAL:  825\n","BATCH#:  824 NUM EXPTS TOTAL:  825 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  825 NUM EXPTS TOTAL:  826\n","BATCH#:  825 NUM EXPTS TOTAL:  826 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  826 NUM EXPTS TOTAL:  827\n","BATCH#:  826 NUM EXPTS TOTAL:  827 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  827 NUM EXPTS TOTAL:  828\n","BATCH#:  827 NUM EXPTS TOTAL:  828 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  828 NUM EXPTS TOTAL:  829\n","BATCH#:  828 NUM EXPTS TOTAL:  829 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  829 NUM EXPTS TOTAL:  830\n","BATCH#:  829 NUM EXPTS TOTAL:  830 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  830 NUM EXPTS TOTAL:  831\n","BATCH#:  830 NUM EXPTS TOTAL:  831 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  831 NUM EXPTS TOTAL:  832\n","BATCH#:  831 NUM EXPTS TOTAL:  832 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  832 NUM EXPTS TOTAL:  833\n","BATCH#:  832 NUM EXPTS TOTAL:  833 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  833 NUM EXPTS TOTAL:  834\n","BATCH#:  833 NUM EXPTS TOTAL:  834 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  834 NUM EXPTS TOTAL:  835\n","BATCH#:  834 NUM EXPTS TOTAL:  835 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  835 NUM EXPTS TOTAL:  836\n","BATCH#:  835 NUM EXPTS TOTAL:  836 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  836 NUM EXPTS TOTAL:  837\n","BATCH#:  836 NUM EXPTS TOTAL:  837 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  837 NUM EXPTS TOTAL:  838\n","BATCH#:  837 NUM EXPTS TOTAL:  838 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  838 NUM EXPTS TOTAL:  839\n","BATCH#:  838 NUM EXPTS TOTAL:  839 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  839 NUM EXPTS TOTAL:  840\n","BATCH#:  839 NUM EXPTS TOTAL:  840 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  840 NUM EXPTS TOTAL:  841\n","BATCH#:  840 NUM EXPTS TOTAL:  841 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  841 NUM EXPTS TOTAL:  842\n","BATCH#:  841 NUM EXPTS TOTAL:  842 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  842 NUM EXPTS TOTAL:  843\n","BATCH#:  842 NUM EXPTS TOTAL:  843 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  843 NUM EXPTS TOTAL:  844\n","BATCH#:  843 NUM EXPTS TOTAL:  844 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  844 NUM EXPTS TOTAL:  845\n","BATCH#:  844 NUM EXPTS TOTAL:  845 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  845 NUM EXPTS TOTAL:  846\n","BATCH#:  845 NUM EXPTS TOTAL:  846 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  846 NUM EXPTS TOTAL:  847\n","BATCH#:  846 NUM EXPTS TOTAL:  847 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  847 NUM EXPTS TOTAL:  848\n","BATCH#:  847 NUM EXPTS TOTAL:  848 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  848 NUM EXPTS TOTAL:  849\n","BATCH#:  848 NUM EXPTS TOTAL:  849 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  849 NUM EXPTS TOTAL:  850\n","BATCH#:  849 NUM EXPTS TOTAL:  850 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  850 NUM EXPTS TOTAL:  851\n","BATCH#:  850 NUM EXPTS TOTAL:  851 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  851 NUM EXPTS TOTAL:  852\n","BATCH#:  851 NUM EXPTS TOTAL:  852 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  852 NUM EXPTS TOTAL:  853\n","BATCH#:  852 NUM EXPTS TOTAL:  853 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  853 NUM EXPTS TOTAL:  854\n","BATCH#:  853 NUM EXPTS TOTAL:  854 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  854 NUM EXPTS TOTAL:  855\n","BATCH#:  854 NUM EXPTS TOTAL:  855 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  855 NUM EXPTS TOTAL:  856\n","BATCH#:  855 NUM EXPTS TOTAL:  856 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  856 NUM EXPTS TOTAL:  857\n","BATCH#:  856 NUM EXPTS TOTAL:  857 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  857 NUM EXPTS TOTAL:  858\n","BATCH#:  857 NUM EXPTS TOTAL:  858 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  858 NUM EXPTS TOTAL:  859\n","BATCH#:  858 NUM EXPTS TOTAL:  859 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  859 NUM EXPTS TOTAL:  860\n","BATCH#:  859 NUM EXPTS TOTAL:  860 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  860 NUM EXPTS TOTAL:  861\n","BATCH#:  860 NUM EXPTS TOTAL:  861 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  861 NUM EXPTS TOTAL:  862\n","BATCH#:  861 NUM EXPTS TOTAL:  862 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  862 NUM EXPTS TOTAL:  863\n","BATCH#:  862 NUM EXPTS TOTAL:  863 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  863 NUM EXPTS TOTAL:  864\n","BATCH#:  863 NUM EXPTS TOTAL:  864 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  864 NUM EXPTS TOTAL:  865\n","BATCH#:  864 NUM EXPTS TOTAL:  865 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  865 NUM EXPTS TOTAL:  866\n","BATCH#:  865 NUM EXPTS TOTAL:  866 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  866 NUM EXPTS TOTAL:  867\n","BATCH#:  866 NUM EXPTS TOTAL:  867 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  867 NUM EXPTS TOTAL:  868\n","BATCH#:  867 NUM EXPTS TOTAL:  868 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  868 NUM EXPTS TOTAL:  869\n","BATCH#:  868 NUM EXPTS TOTAL:  869 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  869 NUM EXPTS TOTAL:  870\n","BATCH#:  869 NUM EXPTS TOTAL:  870 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  870 NUM EXPTS TOTAL:  871\n","BATCH#:  870 NUM EXPTS TOTAL:  871 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  871 NUM EXPTS TOTAL:  872\n","BATCH#:  871 NUM EXPTS TOTAL:  872 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  872 NUM EXPTS TOTAL:  873\n","BATCH#:  872 NUM EXPTS TOTAL:  873 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  873 NUM EXPTS TOTAL:  874\n","BATCH#:  873 NUM EXPTS TOTAL:  874 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  874 NUM EXPTS TOTAL:  875\n","BATCH#:  874 NUM EXPTS TOTAL:  875 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  875 NUM EXPTS TOTAL:  876\n","BATCH#:  875 NUM EXPTS TOTAL:  876 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  876 NUM EXPTS TOTAL:  877\n","BATCH#:  876 NUM EXPTS TOTAL:  877 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  877 NUM EXPTS TOTAL:  878\n","BATCH#:  877 NUM EXPTS TOTAL:  878 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  878 NUM EXPTS TOTAL:  879\n","BATCH#:  878 NUM EXPTS TOTAL:  879 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  879 NUM EXPTS TOTAL:  880\n","BATCH#:  879 NUM EXPTS TOTAL:  880 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  880 NUM EXPTS TOTAL:  881\n","BATCH#:  880 NUM EXPTS TOTAL:  881 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  881 NUM EXPTS TOTAL:  882\n","BATCH#:  881 NUM EXPTS TOTAL:  882 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  882 NUM EXPTS TOTAL:  883\n","BATCH#:  882 NUM EXPTS TOTAL:  883 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  883 NUM EXPTS TOTAL:  884\n","BATCH#:  883 NUM EXPTS TOTAL:  884 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  884 NUM EXPTS TOTAL:  885\n","BATCH#:  884 NUM EXPTS TOTAL:  885 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  885 NUM EXPTS TOTAL:  886\n","BATCH#:  885 NUM EXPTS TOTAL:  886 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  886 NUM EXPTS TOTAL:  887\n","BATCH#:  886 NUM EXPTS TOTAL:  887 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  887 NUM EXPTS TOTAL:  888\n","BATCH#:  887 NUM EXPTS TOTAL:  888 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  888 NUM EXPTS TOTAL:  889\n","BATCH#:  888 NUM EXPTS TOTAL:  889 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  889 NUM EXPTS TOTAL:  890\n","BATCH#:  889 NUM EXPTS TOTAL:  890 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  890 NUM EXPTS TOTAL:  891\n","BATCH#:  890 NUM EXPTS TOTAL:  891 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  891 NUM EXPTS TOTAL:  892\n","BATCH#:  891 NUM EXPTS TOTAL:  892 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  892 NUM EXPTS TOTAL:  893\n","BATCH#:  892 NUM EXPTS TOTAL:  893 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  893 NUM EXPTS TOTAL:  894\n","BATCH#:  893 NUM EXPTS TOTAL:  894 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  894 NUM EXPTS TOTAL:  895\n","BATCH#:  894 NUM EXPTS TOTAL:  895 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  895 NUM EXPTS TOTAL:  896\n","BATCH#:  895 NUM EXPTS TOTAL:  896 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  896 NUM EXPTS TOTAL:  897\n","BATCH#:  896 NUM EXPTS TOTAL:  897 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  897 NUM EXPTS TOTAL:  898\n","BATCH#:  897 NUM EXPTS TOTAL:  898 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  898 NUM EXPTS TOTAL:  899\n","BATCH#:  898 NUM EXPTS TOTAL:  899 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  899 NUM EXPTS TOTAL:  900\n","BATCH#:  899 NUM EXPTS TOTAL:  900 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  900 NUM EXPTS TOTAL:  901\n","BATCH#:  900 NUM EXPTS TOTAL:  901 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  901 NUM EXPTS TOTAL:  902\n","BATCH#:  901 NUM EXPTS TOTAL:  902 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  902 NUM EXPTS TOTAL:  903\n","BATCH#:  902 NUM EXPTS TOTAL:  903 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  903 NUM EXPTS TOTAL:  904\n","BATCH#:  903 NUM EXPTS TOTAL:  904 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  904 NUM EXPTS TOTAL:  905\n","BATCH#:  904 NUM EXPTS TOTAL:  905 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  905 NUM EXPTS TOTAL:  906\n","BATCH#:  905 NUM EXPTS TOTAL:  906 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  906 NUM EXPTS TOTAL:  907\n","BATCH#:  906 NUM EXPTS TOTAL:  907 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  907 NUM EXPTS TOTAL:  908\n","BATCH#:  907 NUM EXPTS TOTAL:  908 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  908 NUM EXPTS TOTAL:  909\n","BATCH#:  908 NUM EXPTS TOTAL:  909 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  909 NUM EXPTS TOTAL:  910\n","BATCH#:  909 NUM EXPTS TOTAL:  910 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  910 NUM EXPTS TOTAL:  911\n","BATCH#:  910 NUM EXPTS TOTAL:  911 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  911 NUM EXPTS TOTAL:  912\n","BATCH#:  911 NUM EXPTS TOTAL:  912 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  912 NUM EXPTS TOTAL:  913\n","BATCH#:  912 NUM EXPTS TOTAL:  913 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  913 NUM EXPTS TOTAL:  914\n","BATCH#:  913 NUM EXPTS TOTAL:  914 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  914 NUM EXPTS TOTAL:  915\n","BATCH#:  914 NUM EXPTS TOTAL:  915 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  915 NUM EXPTS TOTAL:  916\n","BATCH#:  915 NUM EXPTS TOTAL:  916 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  916 NUM EXPTS TOTAL:  917\n","BATCH#:  916 NUM EXPTS TOTAL:  917 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  917 NUM EXPTS TOTAL:  918\n","BATCH#:  917 NUM EXPTS TOTAL:  918 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  918 NUM EXPTS TOTAL:  919\n","BATCH#:  918 NUM EXPTS TOTAL:  919 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  919 NUM EXPTS TOTAL:  920\n","BATCH#:  919 NUM EXPTS TOTAL:  920 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  920 NUM EXPTS TOTAL:  921\n","BATCH#:  920 NUM EXPTS TOTAL:  921 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  921 NUM EXPTS TOTAL:  922\n","BATCH#:  921 NUM EXPTS TOTAL:  922 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  922 NUM EXPTS TOTAL:  923\n","BATCH#:  922 NUM EXPTS TOTAL:  923 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  923 NUM EXPTS TOTAL:  924\n","BATCH#:  923 NUM EXPTS TOTAL:  924 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  924 NUM EXPTS TOTAL:  925\n","BATCH#:  924 NUM EXPTS TOTAL:  925 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  925 NUM EXPTS TOTAL:  926\n","BATCH#:  925 NUM EXPTS TOTAL:  926 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  926 NUM EXPTS TOTAL:  927\n","BATCH#:  926 NUM EXPTS TOTAL:  927 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  927 NUM EXPTS TOTAL:  928\n","BATCH#:  927 NUM EXPTS TOTAL:  928 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  928 NUM EXPTS TOTAL:  929\n","BATCH#:  928 NUM EXPTS TOTAL:  929 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  929 NUM EXPTS TOTAL:  930\n","BATCH#:  929 NUM EXPTS TOTAL:  930 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  930 NUM EXPTS TOTAL:  931\n","BATCH#:  930 NUM EXPTS TOTAL:  931 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  931 NUM EXPTS TOTAL:  932\n","BATCH#:  931 NUM EXPTS TOTAL:  932 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  932 NUM EXPTS TOTAL:  933\n","BATCH#:  932 NUM EXPTS TOTAL:  933 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  933 NUM EXPTS TOTAL:  934\n","BATCH#:  933 NUM EXPTS TOTAL:  934 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  934 NUM EXPTS TOTAL:  935\n","BATCH#:  934 NUM EXPTS TOTAL:  935 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  935 NUM EXPTS TOTAL:  936\n","BATCH#:  935 NUM EXPTS TOTAL:  936 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  936 NUM EXPTS TOTAL:  937\n","BATCH#:  936 NUM EXPTS TOTAL:  937 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  937 NUM EXPTS TOTAL:  938\n","BATCH#:  937 NUM EXPTS TOTAL:  938 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  938 NUM EXPTS TOTAL:  939\n","BATCH#:  938 NUM EXPTS TOTAL:  939 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  939 NUM EXPTS TOTAL:  940\n","BATCH#:  939 NUM EXPTS TOTAL:  940 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  940 NUM EXPTS TOTAL:  941\n","BATCH#:  940 NUM EXPTS TOTAL:  941 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  941 NUM EXPTS TOTAL:  942\n","BATCH#:  941 NUM EXPTS TOTAL:  942 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  942 NUM EXPTS TOTAL:  943\n","BATCH#:  942 NUM EXPTS TOTAL:  943 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  943 NUM EXPTS TOTAL:  944\n","BATCH#:  943 NUM EXPTS TOTAL:  944 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  944 NUM EXPTS TOTAL:  945\n","BATCH#:  944 NUM EXPTS TOTAL:  945 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  945 NUM EXPTS TOTAL:  946\n","BATCH#:  945 NUM EXPTS TOTAL:  946 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  946 NUM EXPTS TOTAL:  947\n","BATCH#:  946 NUM EXPTS TOTAL:  947 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  947 NUM EXPTS TOTAL:  948\n","BATCH#:  947 NUM EXPTS TOTAL:  948 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  948 NUM EXPTS TOTAL:  949\n","BATCH#:  948 NUM EXPTS TOTAL:  949 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  949 NUM EXPTS TOTAL:  950\n","BATCH#:  949 NUM EXPTS TOTAL:  950 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  950 NUM EXPTS TOTAL:  951\n","BATCH#:  950 NUM EXPTS TOTAL:  951 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  951 NUM EXPTS TOTAL:  952\n","BATCH#:  951 NUM EXPTS TOTAL:  952 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  952 NUM EXPTS TOTAL:  953\n","BATCH#:  952 NUM EXPTS TOTAL:  953 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  953 NUM EXPTS TOTAL:  954\n","BATCH#:  953 NUM EXPTS TOTAL:  954 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  954 NUM EXPTS TOTAL:  955\n","BATCH#:  954 NUM EXPTS TOTAL:  955 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  955 NUM EXPTS TOTAL:  956\n","BATCH#:  955 NUM EXPTS TOTAL:  956 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  956 NUM EXPTS TOTAL:  957\n","BATCH#:  956 NUM EXPTS TOTAL:  957 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  957 NUM EXPTS TOTAL:  958\n","BATCH#:  957 NUM EXPTS TOTAL:  958 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  958 NUM EXPTS TOTAL:  959\n","BATCH#:  958 NUM EXPTS TOTAL:  959 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  959 NUM EXPTS TOTAL:  960\n","BATCH#:  959 NUM EXPTS TOTAL:  960 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  960 NUM EXPTS TOTAL:  961\n","BATCH#:  960 NUM EXPTS TOTAL:  961 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  961 NUM EXPTS TOTAL:  962\n","BATCH#:  961 NUM EXPTS TOTAL:  962 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  962 NUM EXPTS TOTAL:  963\n","BATCH#:  962 NUM EXPTS TOTAL:  963 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  963 NUM EXPTS TOTAL:  964\n","BATCH#:  963 NUM EXPTS TOTAL:  964 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  964 NUM EXPTS TOTAL:  965\n","BATCH#:  964 NUM EXPTS TOTAL:  965 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  965 NUM EXPTS TOTAL:  966\n","BATCH#:  965 NUM EXPTS TOTAL:  966 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  966 NUM EXPTS TOTAL:  967\n","BATCH#:  966 NUM EXPTS TOTAL:  967 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  967 NUM EXPTS TOTAL:  968\n","BATCH#:  967 NUM EXPTS TOTAL:  968 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  968 NUM EXPTS TOTAL:  969\n","BATCH#:  968 NUM EXPTS TOTAL:  969 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  969 NUM EXPTS TOTAL:  970\n","BATCH#:  969 NUM EXPTS TOTAL:  970 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  970 NUM EXPTS TOTAL:  971\n","BATCH#:  970 NUM EXPTS TOTAL:  971 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  971 NUM EXPTS TOTAL:  972\n","BATCH#:  971 NUM EXPTS TOTAL:  972 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  972 NUM EXPTS TOTAL:  973\n","BATCH#:  972 NUM EXPTS TOTAL:  973 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  973 NUM EXPTS TOTAL:  974\n","BATCH#:  973 NUM EXPTS TOTAL:  974 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  974 NUM EXPTS TOTAL:  975\n","BATCH#:  974 NUM EXPTS TOTAL:  975 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  975 NUM EXPTS TOTAL:  976\n","BATCH#:  975 NUM EXPTS TOTAL:  976 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  976 NUM EXPTS TOTAL:  977\n","BATCH#:  976 NUM EXPTS TOTAL:  977 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  977 NUM EXPTS TOTAL:  978\n","BATCH#:  977 NUM EXPTS TOTAL:  978 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  978 NUM EXPTS TOTAL:  979\n","BATCH#:  978 NUM EXPTS TOTAL:  979 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  979 NUM EXPTS TOTAL:  980\n","BATCH#:  979 NUM EXPTS TOTAL:  980 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  980 NUM EXPTS TOTAL:  981\n","BATCH#:  980 NUM EXPTS TOTAL:  981 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  981 NUM EXPTS TOTAL:  982\n","BATCH#:  981 NUM EXPTS TOTAL:  982 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  982 NUM EXPTS TOTAL:  983\n","BATCH#:  982 NUM EXPTS TOTAL:  983 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  983 NUM EXPTS TOTAL:  984\n","BATCH#:  983 NUM EXPTS TOTAL:  984 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  984 NUM EXPTS TOTAL:  985\n","BATCH#:  984 NUM EXPTS TOTAL:  985 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  985 NUM EXPTS TOTAL:  986\n","BATCH#:  985 NUM EXPTS TOTAL:  986 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  986 NUM EXPTS TOTAL:  987\n","BATCH#:  986 NUM EXPTS TOTAL:  987 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  987 NUM EXPTS TOTAL:  988\n","BATCH#:  987 NUM EXPTS TOTAL:  988 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  988 NUM EXPTS TOTAL:  989\n","BATCH#:  988 NUM EXPTS TOTAL:  989 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  989 NUM EXPTS TOTAL:  990\n","BATCH#:  989 NUM EXPTS TOTAL:  990 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  990 NUM EXPTS TOTAL:  991\n","BATCH#:  990 NUM EXPTS TOTAL:  991 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  991 NUM EXPTS TOTAL:  992\n","BATCH#:  991 NUM EXPTS TOTAL:  992 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  992 NUM EXPTS TOTAL:  993\n","BATCH#:  992 NUM EXPTS TOTAL:  993 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  993 NUM EXPTS TOTAL:  994\n","BATCH#:  993 NUM EXPTS TOTAL:  994 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  994 NUM EXPTS TOTAL:  995\n","BATCH#:  994 NUM EXPTS TOTAL:  995 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  995 NUM EXPTS TOTAL:  996\n","BATCH#:  995 NUM EXPTS TOTAL:  996 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  996 NUM EXPTS TOTAL:  997\n","BATCH#:  996 NUM EXPTS TOTAL:  997 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  997 NUM EXPTS TOTAL:  998\n","BATCH#:  997 NUM EXPTS TOTAL:  998 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  998 NUM EXPTS TOTAL:  999\n","BATCH#:  998 NUM EXPTS TOTAL:  999 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  999 NUM EXPTS TOTAL:  1000\n","BATCH#:  999 NUM EXPTS TOTAL:  1000 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1000 NUM EXPTS TOTAL:  1001\n","BATCH#:  1000 NUM EXPTS TOTAL:  1001 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1001 NUM EXPTS TOTAL:  1002\n","BATCH#:  1001 NUM EXPTS TOTAL:  1002 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1002 NUM EXPTS TOTAL:  1003\n","BATCH#:  1002 NUM EXPTS TOTAL:  1003 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1003 NUM EXPTS TOTAL:  1004\n","BATCH#:  1003 NUM EXPTS TOTAL:  1004 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1004 NUM EXPTS TOTAL:  1005\n","BATCH#:  1004 NUM EXPTS TOTAL:  1005 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1005 NUM EXPTS TOTAL:  1006\n","BATCH#:  1005 NUM EXPTS TOTAL:  1006 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1006 NUM EXPTS TOTAL:  1007\n","BATCH#:  1006 NUM EXPTS TOTAL:  1007 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1007 NUM EXPTS TOTAL:  1008\n","BATCH#:  1007 NUM EXPTS TOTAL:  1008 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1008 NUM EXPTS TOTAL:  1009\n","BATCH#:  1008 NUM EXPTS TOTAL:  1009 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1009 NUM EXPTS TOTAL:  1010\n","BATCH#:  1009 NUM EXPTS TOTAL:  1010 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1010 NUM EXPTS TOTAL:  1011\n","BATCH#:  1010 NUM EXPTS TOTAL:  1011 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1011 NUM EXPTS TOTAL:  1012\n","BATCH#:  1011 NUM EXPTS TOTAL:  1012 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1012 NUM EXPTS TOTAL:  1013\n","BATCH#:  1012 NUM EXPTS TOTAL:  1013 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1013 NUM EXPTS TOTAL:  1014\n","BATCH#:  1013 NUM EXPTS TOTAL:  1014 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1014 NUM EXPTS TOTAL:  1015\n","BATCH#:  1014 NUM EXPTS TOTAL:  1015 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1015 NUM EXPTS TOTAL:  1016\n","BATCH#:  1015 NUM EXPTS TOTAL:  1016 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1016 NUM EXPTS TOTAL:  1017\n","BATCH#:  1016 NUM EXPTS TOTAL:  1017 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1017 NUM EXPTS TOTAL:  1018\n","BATCH#:  1017 NUM EXPTS TOTAL:  1018 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1018 NUM EXPTS TOTAL:  1019\n","BATCH#:  1018 NUM EXPTS TOTAL:  1019 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1019 NUM EXPTS TOTAL:  1020\n","BATCH#:  1019 NUM EXPTS TOTAL:  1020 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1020 NUM EXPTS TOTAL:  1021\n","BATCH#:  1020 NUM EXPTS TOTAL:  1021 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1021 NUM EXPTS TOTAL:  1022\n","BATCH#:  1021 NUM EXPTS TOTAL:  1022 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1022 NUM EXPTS TOTAL:  1023\n","BATCH#:  1022 NUM EXPTS TOTAL:  1023 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1023 NUM EXPTS TOTAL:  1024\n","BATCH#:  1023 NUM EXPTS TOTAL:  1024 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","Average Train Exp Accuracy:  52.734375\n"]}],"source":["\n","\n","example_myOPT_CD_FT.eval()\n","\n","model_pred = torch.zeros(0, dtype=torch.long).to(device)\n","ground_truth = torch.zeros(0, dtype=torch.long).to(device)\n","\n","with torch.no_grad():\n","    for i, batch in enumerate(dataloader_VAL):\n","\n","        print(\"BATCH#: \", i, \"NUM EXPTS TOTAL: \", (i+1)*bx_size)\n","\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","\n","        gen_tokens = torch.tensor(1)\n","        gen_tokens = gen_tokens.to(device)\n","\n","\n","        # output only the binary yes/no,\n","        _, binary_yes_no, _ = example_myOPT_CD_FT.generate_text(input_ids, attention_mask, gen_tokens=gen_tokens)\n","        model_pred = torch.cat((model_pred, binary_yes_no), dim=0)\n","        ground_truth = torch.cat((ground_truth, batch['labels'].to(device)), dim=0)\n","\n","        print(\"BATCH#: \", i, \"NUM EXPTS TOTAL: \", (i+1)*bx_size, \"PREDICTION: \", binary_yes_no, \"TRUE LABELS: \", batch['labels'].detach())\n","\n","accuracy_calc = (100*torch.sum(model_pred == ground_truth)/(model_pred.shape[0])).item()\n","print(\"Average Train Exp Accuracy: \", accuracy_calc)"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"wUJQ6GaMednd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523884762,"user_tz":-120,"elapsed":36,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"f018d4a2-5899-4be2-8d2e-2f2fdaa5a5d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["YES answer (%):  35.9375\n","NO  answer (%):  64.0625\n"]}],"source":["# Evaluate results beyond accuracy:\n","\n","print(\"YES answer (%): \", ((torch.sum(model_pred==0))/len(model_pred)).item()*100)\n","print(\"NO  answer (%): \", ((torch.sum(model_pred==1))/len(model_pred)).item()*100)"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"HhdrTEIoMWWb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523884762,"user_tz":-120,"elapsed":11,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"956348b2-a99d-4cd0-c19b-dcc6dc3984bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0]\n","YES TRAIN answer (%):  56.25\n","NO  TRAIN answer (%):  43.75\n"]}],"source":["\n","list_labels_train = []\n","\n","for i, batch in enumerate(dataloader_CD_probs_exp_CDTRAIN):\n","\n","    #print(batch['OPT_probs'][0])\n","    #print(batch['OPT_idxs'][0])\n","    if 9904 in list(batch['OPT_idxs'][0]):\n","      yes_prob = batch['OPT_probs'][0][(batch['OPT_idxs'][0]==9904).nonzero(as_tuple=True)].item()\n","    else:\n","      yes_prob = 0\n","    if 3084 in list(batch['OPT_idxs'][0]):\n","      no_prob = batch['OPT_probs'][0][(batch['OPT_idxs'][0]==3084).nonzero(as_tuple=True)].item()\n","    else:\n","      no_prob = 0\n","\n","    if yes_prob!=0 and no_prob!=0:\n","      result_to_train = ((no_prob - yes_prob)>0)*1\n","    else:\n","      result_to_train = 0.5\n","\n","    list_labels_train.append(result_to_train)\n","print(list_labels_train)\n","\n","print(\"YES TRAIN answer (%): \", ((torch.sum(torch.tensor(list_labels_train)==0))/len(list_labels_train)).item()*100)\n","print(\"NO  TRAIN answer (%): \", ((torch.sum(torch.tensor(list_labels_train)==1))/len(list_labels_train)).item()*100)"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"q4SIvgpbedkb","executionInfo":{"status":"ok","timestamp":1714523890259,"user_tz":-120,"elapsed":5507,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f996e448-8a38-43fb-921d-6cc1d0e003a5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['</s>A chat between a curious human and the Statue of Liberty.\\n\\nHuman: What is your name?\\nStatue: I am the Statue of Liberty.\\nHuman: Where do you live?\\nStatue: New York City.\\nHuman: How long have you lived there?\\nStatue: I have lived here for over 100 years.\\nHuman: What do you do?\\nStatue: I am a tourist attraction.\\nHuman: What do you do when you are not a tourist attraction?\\nStatue: I am a tourist attraction.\\nHuman: What do you do when you are not a tourist attraction?\\nStatue: I am a tourist attraction.\\nHuman: What do you do when you are not a tourist attraction?\\nStatue:']"]},"metadata":{},"execution_count":64}],"source":["# Check base model output correctness (from OPT HF example)\n","prompt_example = (\"A chat between a curious human and the Statue of Liberty.\\n\\nHuman: What is your name?\\nStatue: I am the \"\n","              \"Statue of Liberty.\\nHuman: Where do you live?\\nStatue: New York City.\\nHuman: How long have you lived \"\n","              \"there?\")\n","prompt_example_tokenized = OPT_tokenizer(prompt_example )\n","example_myOPT_CD_FT.eval()\n","outputs_ex_sp, binary_ex_sp, scores_ex_sp = example_myOPT_CD_FT.generate_text(src_inputs = torch.unsqueeze(torch.tensor(prompt_example_tokenized['input_ids']),0).to(device),\n","                                    src_attn = torch.unsqueeze(torch.tensor(prompt_example_tokenized['attention_mask']),0).to(device),\n","                                    gen_tokens=torch.tensor(100).to(device))\n","OPT_tokenizer.batch_decode(outputs_ex_sp)"]},{"cell_type":"markdown","metadata":{"id":"7TrCMgPqwnH-"},"source":["# 7. OUT OF DOMAIN VALIDATION"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"i7DXLZYPedey","colab":{"base_uri":"https://localhost:8080/","height":353,"referenced_widgets":["e815468c3e9d480f853757c5a8d534a6","a90eac8b75e94a619f2c5ca95a6fe24a","8dee333e3fe143d5928a04366a551841","5fcea17a3c9f483f84f444bf846754e7","a213a54abb6344209ded5534a0c9e580","b422d529a24f49868aee0a6c74645226","43f49bf0403f4f02a87b54715f764f92","dbfddeaf8fe94ccbb5d77e3b2c5ad68e","300db2731aad43a0af2c6b6dacf698f0","5268142df9ab445e8e521beef33eaacf","971bbcf5801b429e9cdb4dcc71e9793c","416182fe882c432a90fc24c4d77b445a","99a63d8e9b754ad8a7500139ce298e5e","1e5d4b23c3f8470c9aebc3b9a5c253db","1487f683d1124a829cc02e1c33c1ff4d","5f86887f9ffb4bc3b2ecf7af63e8a722","eb09763048c142a9bc997d97a4a00c76","18789117dedf47c5846d204aa732de8e","baad8b8d4ad04554911979b86d71df7e","366a7af4e9a14782948c90bf461c2866","75159a4e3430479199f348269ba01cc3","addaad64db134f3dbd3396708803c666","272fbe610d3b49bbb7503ce05d76b31a","968843910cb647eabe74e00786c39d5f","2f4ba675d8b94a31ad01e4220221b221","fd8e610fb7c74ac58e0f7805bd9e59d4","6c8aa005860741aca3a2fe707dc7476a","0c5d54279af8410fa08f6437a73a951f","834291d71c93429894acf5f1bfa64e8f","655f16aa65c14362a2f293621e3f237c","71a039ad1f154134afd905df5da89f60","4d358b5597804179a301e7acd3bff3b4","2a2e3ee0c18c43668227fe5352c02821","3c088451519744bcb0b8e3665c4ab18f","10d1a77d35f44abcb3cde1ea7820ac3b","84f6ff00483c4a349e140573618a6c47","e725016bfd25408ca0f6fc3048c806fd","12d7648b8790413992f33144b7a7d9de","4a9e5548d3f942a2bbfea7edd4d7e55c","a1d3da4dc1b04ad98edf49859ea32b61","fbc8ea3c152546248ecb4df39d2586b5","8fd65ba133314e22adbf857f4952ec84","b8f18bf97d0f41449a42d7726423d479","17e752e5e935459e8cd5169dc8e8b25b"]},"executionInfo":{"status":"ok","timestamp":1714523893315,"user_tz":-120,"elapsed":3067,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"19bee6f3-1eee-40e2-85c3-fc4b2c2d2431"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/3.14M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e815468c3e9d480f853757c5a8d534a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/3.14M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"416182fe882c432a90fc24c4d77b445a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/30000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"272fbe610d3b49bbb7503ce05d76b31a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/30000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c088451519744bcb0b8e3665c4ab18f"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'parse_premise', 'parse_hypothesis', 'binary_parse_premise', 'binary_parse_hypothesis', 'heuristic', 'subcase', 'template'],\n","        num_rows: 30000\n","    })\n","    validation: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'parse_premise', 'parse_hypothesis', 'binary_parse_premise', 'binary_parse_hypothesis', 'heuristic', 'subcase', 'template'],\n","        num_rows: 30000\n","    })\n","})"]},"metadata":{},"execution_count":65}],"source":["dataset_ood = load_dataset(\"hans\")\n","dataset_ood"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"oAFcefWkwmPs","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["3d0e6b604743450cb14a7803f19112a2","0e09e2bcc0df4691b03f708104c74233","c0bd42af1e2741989ac52a8b9f6d80c3","b3b153ab20054c1d9924e751e653ab87","889c0bec65f44c8f9d2c1acee93a3c19","7d733c18de6f424b897df3a7bb562ce2","6364556479854c35ae353527d159c66a","ac5f05581573444c8d3fd66b8807d7d4","e3118c0ce4734a3ea39bc7d8a5827e09","0ad0603114184b868e9e222be3d4a4b2","17c425d0f77e4dd19420e5f43a0c20fd"]},"executionInfo":{"status":"ok","timestamp":1714523893651,"user_tz":-120,"elapsed":342,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"58cfd85b-8da9-4574-914c-fb616c6bc1a8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/30000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d0e6b604743450cb14a7803f19112a2"}},"metadata":{}}],"source":["dataset_ood_val = (dataset_ood['validation']).filter(lambda example: example[\"heuristic\"] == 'lexical_overlap')"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"Jn4ufgMzwmNS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523894062,"user_tz":-120,"elapsed":412,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"95a5387d-a5db-405c-82ea-a5ecf2796753"},"outputs":[{"output_type":"stream","name":"stdout","text":["indices_ood_val:  [6252 4684 1731 ... 9410 1671  474]\n"]},{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['premise', 'hypothesis', 'label', 'parse_premise', 'parse_hypothesis', 'binary_parse_premise', 'binary_parse_hypothesis', 'heuristic', 'subcase', 'template'],\n","    num_rows: 1024\n","})"]},"metadata":{},"execution_count":67}],"source":["# Perform the filters and splits from the original datasets\n","\n","\n","random_split_seed_ood = 42 # set above, equal to 42\n","\n","examples_per_exp =  examples_per_exp # 16\n","num_experiments = num_experiments # 10\n","num_validations = num_validations # 16*64 #64*16 = 1024 #6692\n","\n","np.random.seed(random_split_seed_ood)\n","indices_ood_val = np.random.choice(range(len(dataset_ood_val)), size=num_validations, replace=False)\n","print(\"indices_ood_val: \", indices_ood_val)\n","\n","dataset_ood_val_sel = dataset_ood_val.select(indices_ood_val)\n","dataset_ood_val_sel"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"3aAqJWOqwmKR","executionInfo":{"status":"ok","timestamp":1714523894062,"user_tz":-120,"elapsed":5,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"outputs":[],"source":["# format examples functions formats according to different types of formats for ICL both training and validation examples\n","\n","# select format to use here:\n","format_train_val = format_train_val # set it at the top of notebook in a common place\n","\n","\n","def format_examples_validation_VALOOD(example_val, format_val = format_train_val):\n","    if format_val== 'minimal':\n","      # \"minimal\" format\n","      return {'text': \"{\"  + example_val['premise'] + \"} {\" + example_val['hypothesis'] + \"}\" + \" ? Ġ\"}\n","    elif format_val== 'gpt3':\n","      # \"minimal\" format\n","      return {'text': \"{\"  + example_val['premise'] + \"} question: {\" + example_val['hypothesis'] + \"}\" + \" Yes or No? answer: Ġ\"}\n","\n","def create_combined_dataset_VALOOD(val_dataset, num_expts=num_experiments):\n","    combined_dataset = []\n","    #train_examples_yes = [example for example in train_ds_yes]\n","    #train_examples_no = [example for example in train_ds_no]\n","\n","    for irep in range(num_expts):\n","      for val_ex in val_dataset:\n","\n","            combined_ex = {'text': '', 'label': val_ex['label'], 'exp': irep+1}\n","\n","            # Add the example to predict (validation)\n","            combined_ex['text'] += val_ex['text']\n","\n","            # Append the new combined example to the combined dataset\n","            combined_dataset.append([combined_ex])\n","\n","    return combined_dataset\n","\n","\n","def dynamic_padding_collate_fn_VALOOD(batch):\n","    # This function is created to be able to tokenize dynamically to max length within each batch\n","    # Also, by modifying the tokenizer used, several other options are available\n","    # for example, if we set padding to a specified max_length, for example the model max_length, is also an option, not the default though\n","    # the default is the dynamic padding\n","\n","    batch = [item for sublist in batch for item in sublist]\n","\n","    texts = [item['text'] for item in batch]\n","    labels = [item['label'] for item in batch]\n","    exps = [item['exp'] for item in batch]\n","\n","    # choose option\n","    tokenized_inputs = OPT_tokenizer(texts, padding=\"longest\", truncation=True, return_tensors=\"pt\")\n","    # tokenized_inputs = OPT_tokenizer(texts, padding=\"max_length\", max_length = 2048, truncation=True, return_tensors=\"pt\")\n","\n","    labels_tensor = torch.tensor(labels, dtype=torch.long)\n","    exps_tensor = torch.tensor(exps, dtype=torch.long).to(device)\n","\n","    # return here the outputs desired\n","    # we have chosen the input_ids, attention_mask, label of the validation samples\n","    return {\n","        'input_ids': tokenized_inputs['input_ids'],\n","        'attention_mask': tokenized_inputs['attention_mask'],\n","        'labels': labels_tensor,\n","        'exps': exps_tensor\n","    }\n","\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, combined_dataset):\n","        self.dataset = combined_dataset\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        return self.dataset[idx]\n"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"bfes_txOwuU7","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["bf1e2f69d38d4bdcb2a079305ce53a34","6bb88f079270405490e5d8c20933d857","219f90d07f934e67b9454907854d0659","67437d48055e4091801f44790074ea52","64f8b655fe6d4d7fb51ec8514febaf98","e5a0c835aada4323a98976ffaf2ec08e","7b0cf53a74fb4f57b51e8e07d021bc62","81835a9fd6c8410f8c8d9963dcfce854","c0671c5d6a4142088d8609b2dfc8f58d","74ea5d840ca64fbd8c0b84403dedeae4","dbdadad2922845c1a72fabe29eaabea2"]},"executionInfo":{"status":"ok","timestamp":1714523895239,"user_tz":-120,"elapsed":1182,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"ae7757af-f31d-4eac-82b2-c7f891be63d1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1024 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf1e2f69d38d4bdcb2a079305ce53a34"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<__main__.CustomDataset object at 0x7a1e3031ca30>\n"]}],"source":["# First the samples are formatted according to selection above\n","# Important to check selection and re-run cell above so that it is taken by the mapping function correctly\n","\n","formatted_val_dataset_ood = dataset_ood_val_sel.map(format_examples_validation_VALOOD)\n","\n","# Initialize custom dataset with the combined dataset\n","# print result to check correctness\n","\n","combined_dataset_VALOOD = create_combined_dataset_VALOOD(\n","                                          val_dataset = formatted_val_dataset_ood,\n","                                          num_expts=num_experiments\n","                                           )\n","\n","custom_dataset_VALOOD = CustomDataset(combined_dataset_VALOOD)\n","print(custom_dataset_VALOOD)\n","\n","custom_dataset_VALOOD_EXP = CustomDataset([item for item in custom_dataset_VALOOD if item[0]['exp'] == SEL_EXP_TRAIN_CD])\n","\n","# Last step, we create Dataloader passing the bx_size for inference (typically: 1, 4, 8, 16)\n","bx_size = bx_size # set it up at the beg of NB\n","dataloader_VALOOD = DataLoader(custom_dataset_VALOOD_EXP, batch_size=bx_size, collate_fn=dynamic_padding_collate_fn_VALOOD, shuffle=False) #shuffle=False for reproducibility"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"y7VxwC8iwuSo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523933466,"user_tz":-120,"elapsed":38229,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"06adf697-322b-4e1e-d566-0764ea3ec7af"},"outputs":[{"output_type":"stream","name":"stdout","text":["BATCH#:  0 NUM EXPTS TOTAL:  1\n","BATCH#:  0 NUM EXPTS TOTAL:  1 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1 NUM EXPTS TOTAL:  2\n","BATCH#:  1 NUM EXPTS TOTAL:  2 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  2 NUM EXPTS TOTAL:  3\n","BATCH#:  2 NUM EXPTS TOTAL:  3 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  3 NUM EXPTS TOTAL:  4\n","BATCH#:  3 NUM EXPTS TOTAL:  4 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  4 NUM EXPTS TOTAL:  5\n","BATCH#:  4 NUM EXPTS TOTAL:  5 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  5 NUM EXPTS TOTAL:  6\n","BATCH#:  5 NUM EXPTS TOTAL:  6 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  6 NUM EXPTS TOTAL:  7\n","BATCH#:  6 NUM EXPTS TOTAL:  7 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  7 NUM EXPTS TOTAL:  8\n","BATCH#:  7 NUM EXPTS TOTAL:  8 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  8 NUM EXPTS TOTAL:  9\n","BATCH#:  8 NUM EXPTS TOTAL:  9 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  9 NUM EXPTS TOTAL:  10\n","BATCH#:  9 NUM EXPTS TOTAL:  10 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  10 NUM EXPTS TOTAL:  11\n","BATCH#:  10 NUM EXPTS TOTAL:  11 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  11 NUM EXPTS TOTAL:  12\n","BATCH#:  11 NUM EXPTS TOTAL:  12 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  12 NUM EXPTS TOTAL:  13\n","BATCH#:  12 NUM EXPTS TOTAL:  13 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  13 NUM EXPTS TOTAL:  14\n","BATCH#:  13 NUM EXPTS TOTAL:  14 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  14 NUM EXPTS TOTAL:  15\n","BATCH#:  14 NUM EXPTS TOTAL:  15 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  15 NUM EXPTS TOTAL:  16\n","BATCH#:  15 NUM EXPTS TOTAL:  16 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  16 NUM EXPTS TOTAL:  17\n","BATCH#:  16 NUM EXPTS TOTAL:  17 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  17 NUM EXPTS TOTAL:  18\n","BATCH#:  17 NUM EXPTS TOTAL:  18 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  18 NUM EXPTS TOTAL:  19\n","BATCH#:  18 NUM EXPTS TOTAL:  19 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  19 NUM EXPTS TOTAL:  20\n","BATCH#:  19 NUM EXPTS TOTAL:  20 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  20 NUM EXPTS TOTAL:  21\n","BATCH#:  20 NUM EXPTS TOTAL:  21 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  21 NUM EXPTS TOTAL:  22\n","BATCH#:  21 NUM EXPTS TOTAL:  22 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  22 NUM EXPTS TOTAL:  23\n","BATCH#:  22 NUM EXPTS TOTAL:  23 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  23 NUM EXPTS TOTAL:  24\n","BATCH#:  23 NUM EXPTS TOTAL:  24 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  24 NUM EXPTS TOTAL:  25\n","BATCH#:  24 NUM EXPTS TOTAL:  25 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  25 NUM EXPTS TOTAL:  26\n","BATCH#:  25 NUM EXPTS TOTAL:  26 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  26 NUM EXPTS TOTAL:  27\n","BATCH#:  26 NUM EXPTS TOTAL:  27 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  27 NUM EXPTS TOTAL:  28\n","BATCH#:  27 NUM EXPTS TOTAL:  28 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  28 NUM EXPTS TOTAL:  29\n","BATCH#:  28 NUM EXPTS TOTAL:  29 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  29 NUM EXPTS TOTAL:  30\n","BATCH#:  29 NUM EXPTS TOTAL:  30 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  30 NUM EXPTS TOTAL:  31\n","BATCH#:  30 NUM EXPTS TOTAL:  31 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  31 NUM EXPTS TOTAL:  32\n","BATCH#:  31 NUM EXPTS TOTAL:  32 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  32 NUM EXPTS TOTAL:  33\n","BATCH#:  32 NUM EXPTS TOTAL:  33 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  33 NUM EXPTS TOTAL:  34\n","BATCH#:  33 NUM EXPTS TOTAL:  34 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  34 NUM EXPTS TOTAL:  35\n","BATCH#:  34 NUM EXPTS TOTAL:  35 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  35 NUM EXPTS TOTAL:  36\n","BATCH#:  35 NUM EXPTS TOTAL:  36 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  36 NUM EXPTS TOTAL:  37\n","BATCH#:  36 NUM EXPTS TOTAL:  37 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  37 NUM EXPTS TOTAL:  38\n","BATCH#:  37 NUM EXPTS TOTAL:  38 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  38 NUM EXPTS TOTAL:  39\n","BATCH#:  38 NUM EXPTS TOTAL:  39 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  39 NUM EXPTS TOTAL:  40\n","BATCH#:  39 NUM EXPTS TOTAL:  40 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  40 NUM EXPTS TOTAL:  41\n","BATCH#:  40 NUM EXPTS TOTAL:  41 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  41 NUM EXPTS TOTAL:  42\n","BATCH#:  41 NUM EXPTS TOTAL:  42 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  42 NUM EXPTS TOTAL:  43\n","BATCH#:  42 NUM EXPTS TOTAL:  43 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  43 NUM EXPTS TOTAL:  44\n","BATCH#:  43 NUM EXPTS TOTAL:  44 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  44 NUM EXPTS TOTAL:  45\n","BATCH#:  44 NUM EXPTS TOTAL:  45 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  45 NUM EXPTS TOTAL:  46\n","BATCH#:  45 NUM EXPTS TOTAL:  46 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  46 NUM EXPTS TOTAL:  47\n","BATCH#:  46 NUM EXPTS TOTAL:  47 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  47 NUM EXPTS TOTAL:  48\n","BATCH#:  47 NUM EXPTS TOTAL:  48 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  48 NUM EXPTS TOTAL:  49\n","BATCH#:  48 NUM EXPTS TOTAL:  49 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  49 NUM EXPTS TOTAL:  50\n","BATCH#:  49 NUM EXPTS TOTAL:  50 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  50 NUM EXPTS TOTAL:  51\n","BATCH#:  50 NUM EXPTS TOTAL:  51 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  51 NUM EXPTS TOTAL:  52\n","BATCH#:  51 NUM EXPTS TOTAL:  52 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  52 NUM EXPTS TOTAL:  53\n","BATCH#:  52 NUM EXPTS TOTAL:  53 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  53 NUM EXPTS TOTAL:  54\n","BATCH#:  53 NUM EXPTS TOTAL:  54 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  54 NUM EXPTS TOTAL:  55\n","BATCH#:  54 NUM EXPTS TOTAL:  55 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  55 NUM EXPTS TOTAL:  56\n","BATCH#:  55 NUM EXPTS TOTAL:  56 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  56 NUM EXPTS TOTAL:  57\n","BATCH#:  56 NUM EXPTS TOTAL:  57 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  57 NUM EXPTS TOTAL:  58\n","BATCH#:  57 NUM EXPTS TOTAL:  58 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  58 NUM EXPTS TOTAL:  59\n","BATCH#:  58 NUM EXPTS TOTAL:  59 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  59 NUM EXPTS TOTAL:  60\n","BATCH#:  59 NUM EXPTS TOTAL:  60 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  60 NUM EXPTS TOTAL:  61\n","BATCH#:  60 NUM EXPTS TOTAL:  61 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  61 NUM EXPTS TOTAL:  62\n","BATCH#:  61 NUM EXPTS TOTAL:  62 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  62 NUM EXPTS TOTAL:  63\n","BATCH#:  62 NUM EXPTS TOTAL:  63 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  63 NUM EXPTS TOTAL:  64\n","BATCH#:  63 NUM EXPTS TOTAL:  64 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  64 NUM EXPTS TOTAL:  65\n","BATCH#:  64 NUM EXPTS TOTAL:  65 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  65 NUM EXPTS TOTAL:  66\n","BATCH#:  65 NUM EXPTS TOTAL:  66 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  66 NUM EXPTS TOTAL:  67\n","BATCH#:  66 NUM EXPTS TOTAL:  67 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  67 NUM EXPTS TOTAL:  68\n","BATCH#:  67 NUM EXPTS TOTAL:  68 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  68 NUM EXPTS TOTAL:  69\n","BATCH#:  68 NUM EXPTS TOTAL:  69 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  69 NUM EXPTS TOTAL:  70\n","BATCH#:  69 NUM EXPTS TOTAL:  70 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  70 NUM EXPTS TOTAL:  71\n","BATCH#:  70 NUM EXPTS TOTAL:  71 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  71 NUM EXPTS TOTAL:  72\n","BATCH#:  71 NUM EXPTS TOTAL:  72 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  72 NUM EXPTS TOTAL:  73\n","BATCH#:  72 NUM EXPTS TOTAL:  73 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  73 NUM EXPTS TOTAL:  74\n","BATCH#:  73 NUM EXPTS TOTAL:  74 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  74 NUM EXPTS TOTAL:  75\n","BATCH#:  74 NUM EXPTS TOTAL:  75 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  75 NUM EXPTS TOTAL:  76\n","BATCH#:  75 NUM EXPTS TOTAL:  76 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  76 NUM EXPTS TOTAL:  77\n","BATCH#:  76 NUM EXPTS TOTAL:  77 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  77 NUM EXPTS TOTAL:  78\n","BATCH#:  77 NUM EXPTS TOTAL:  78 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  78 NUM EXPTS TOTAL:  79\n","BATCH#:  78 NUM EXPTS TOTAL:  79 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  79 NUM EXPTS TOTAL:  80\n","BATCH#:  79 NUM EXPTS TOTAL:  80 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  80 NUM EXPTS TOTAL:  81\n","BATCH#:  80 NUM EXPTS TOTAL:  81 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  81 NUM EXPTS TOTAL:  82\n","BATCH#:  81 NUM EXPTS TOTAL:  82 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  82 NUM EXPTS TOTAL:  83\n","BATCH#:  82 NUM EXPTS TOTAL:  83 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  83 NUM EXPTS TOTAL:  84\n","BATCH#:  83 NUM EXPTS TOTAL:  84 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  84 NUM EXPTS TOTAL:  85\n","BATCH#:  84 NUM EXPTS TOTAL:  85 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  85 NUM EXPTS TOTAL:  86\n","BATCH#:  85 NUM EXPTS TOTAL:  86 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  86 NUM EXPTS TOTAL:  87\n","BATCH#:  86 NUM EXPTS TOTAL:  87 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  87 NUM EXPTS TOTAL:  88\n","BATCH#:  87 NUM EXPTS TOTAL:  88 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  88 NUM EXPTS TOTAL:  89\n","BATCH#:  88 NUM EXPTS TOTAL:  89 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  89 NUM EXPTS TOTAL:  90\n","BATCH#:  89 NUM EXPTS TOTAL:  90 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  90 NUM EXPTS TOTAL:  91\n","BATCH#:  90 NUM EXPTS TOTAL:  91 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  91 NUM EXPTS TOTAL:  92\n","BATCH#:  91 NUM EXPTS TOTAL:  92 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  92 NUM EXPTS TOTAL:  93\n","BATCH#:  92 NUM EXPTS TOTAL:  93 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  93 NUM EXPTS TOTAL:  94\n","BATCH#:  93 NUM EXPTS TOTAL:  94 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  94 NUM EXPTS TOTAL:  95\n","BATCH#:  94 NUM EXPTS TOTAL:  95 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  95 NUM EXPTS TOTAL:  96\n","BATCH#:  95 NUM EXPTS TOTAL:  96 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  96 NUM EXPTS TOTAL:  97\n","BATCH#:  96 NUM EXPTS TOTAL:  97 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  97 NUM EXPTS TOTAL:  98\n","BATCH#:  97 NUM EXPTS TOTAL:  98 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  98 NUM EXPTS TOTAL:  99\n","BATCH#:  98 NUM EXPTS TOTAL:  99 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  99 NUM EXPTS TOTAL:  100\n","BATCH#:  99 NUM EXPTS TOTAL:  100 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  100 NUM EXPTS TOTAL:  101\n","BATCH#:  100 NUM EXPTS TOTAL:  101 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  101 NUM EXPTS TOTAL:  102\n","BATCH#:  101 NUM EXPTS TOTAL:  102 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  102 NUM EXPTS TOTAL:  103\n","BATCH#:  102 NUM EXPTS TOTAL:  103 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  103 NUM EXPTS TOTAL:  104\n","BATCH#:  103 NUM EXPTS TOTAL:  104 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  104 NUM EXPTS TOTAL:  105\n","BATCH#:  104 NUM EXPTS TOTAL:  105 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  105 NUM EXPTS TOTAL:  106\n","BATCH#:  105 NUM EXPTS TOTAL:  106 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  106 NUM EXPTS TOTAL:  107\n","BATCH#:  106 NUM EXPTS TOTAL:  107 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  107 NUM EXPTS TOTAL:  108\n","BATCH#:  107 NUM EXPTS TOTAL:  108 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  108 NUM EXPTS TOTAL:  109\n","BATCH#:  108 NUM EXPTS TOTAL:  109 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  109 NUM EXPTS TOTAL:  110\n","BATCH#:  109 NUM EXPTS TOTAL:  110 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  110 NUM EXPTS TOTAL:  111\n","BATCH#:  110 NUM EXPTS TOTAL:  111 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  111 NUM EXPTS TOTAL:  112\n","BATCH#:  111 NUM EXPTS TOTAL:  112 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  112 NUM EXPTS TOTAL:  113\n","BATCH#:  112 NUM EXPTS TOTAL:  113 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  113 NUM EXPTS TOTAL:  114\n","BATCH#:  113 NUM EXPTS TOTAL:  114 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  114 NUM EXPTS TOTAL:  115\n","BATCH#:  114 NUM EXPTS TOTAL:  115 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  115 NUM EXPTS TOTAL:  116\n","BATCH#:  115 NUM EXPTS TOTAL:  116 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  116 NUM EXPTS TOTAL:  117\n","BATCH#:  116 NUM EXPTS TOTAL:  117 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  117 NUM EXPTS TOTAL:  118\n","BATCH#:  117 NUM EXPTS TOTAL:  118 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  118 NUM EXPTS TOTAL:  119\n","BATCH#:  118 NUM EXPTS TOTAL:  119 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  119 NUM EXPTS TOTAL:  120\n","BATCH#:  119 NUM EXPTS TOTAL:  120 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  120 NUM EXPTS TOTAL:  121\n","BATCH#:  120 NUM EXPTS TOTAL:  121 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  121 NUM EXPTS TOTAL:  122\n","BATCH#:  121 NUM EXPTS TOTAL:  122 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  122 NUM EXPTS TOTAL:  123\n","BATCH#:  122 NUM EXPTS TOTAL:  123 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  123 NUM EXPTS TOTAL:  124\n","BATCH#:  123 NUM EXPTS TOTAL:  124 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  124 NUM EXPTS TOTAL:  125\n","BATCH#:  124 NUM EXPTS TOTAL:  125 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  125 NUM EXPTS TOTAL:  126\n","BATCH#:  125 NUM EXPTS TOTAL:  126 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  126 NUM EXPTS TOTAL:  127\n","BATCH#:  126 NUM EXPTS TOTAL:  127 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  127 NUM EXPTS TOTAL:  128\n","BATCH#:  127 NUM EXPTS TOTAL:  128 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  128 NUM EXPTS TOTAL:  129\n","BATCH#:  128 NUM EXPTS TOTAL:  129 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  129 NUM EXPTS TOTAL:  130\n","BATCH#:  129 NUM EXPTS TOTAL:  130 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  130 NUM EXPTS TOTAL:  131\n","BATCH#:  130 NUM EXPTS TOTAL:  131 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  131 NUM EXPTS TOTAL:  132\n","BATCH#:  131 NUM EXPTS TOTAL:  132 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  132 NUM EXPTS TOTAL:  133\n","BATCH#:  132 NUM EXPTS TOTAL:  133 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  133 NUM EXPTS TOTAL:  134\n","BATCH#:  133 NUM EXPTS TOTAL:  134 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  134 NUM EXPTS TOTAL:  135\n","BATCH#:  134 NUM EXPTS TOTAL:  135 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  135 NUM EXPTS TOTAL:  136\n","BATCH#:  135 NUM EXPTS TOTAL:  136 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  136 NUM EXPTS TOTAL:  137\n","BATCH#:  136 NUM EXPTS TOTAL:  137 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  137 NUM EXPTS TOTAL:  138\n","BATCH#:  137 NUM EXPTS TOTAL:  138 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  138 NUM EXPTS TOTAL:  139\n","BATCH#:  138 NUM EXPTS TOTAL:  139 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  139 NUM EXPTS TOTAL:  140\n","BATCH#:  139 NUM EXPTS TOTAL:  140 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  140 NUM EXPTS TOTAL:  141\n","BATCH#:  140 NUM EXPTS TOTAL:  141 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  141 NUM EXPTS TOTAL:  142\n","BATCH#:  141 NUM EXPTS TOTAL:  142 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  142 NUM EXPTS TOTAL:  143\n","BATCH#:  142 NUM EXPTS TOTAL:  143 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  143 NUM EXPTS TOTAL:  144\n","BATCH#:  143 NUM EXPTS TOTAL:  144 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  144 NUM EXPTS TOTAL:  145\n","BATCH#:  144 NUM EXPTS TOTAL:  145 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  145 NUM EXPTS TOTAL:  146\n","BATCH#:  145 NUM EXPTS TOTAL:  146 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  146 NUM EXPTS TOTAL:  147\n","BATCH#:  146 NUM EXPTS TOTAL:  147 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  147 NUM EXPTS TOTAL:  148\n","BATCH#:  147 NUM EXPTS TOTAL:  148 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  148 NUM EXPTS TOTAL:  149\n","BATCH#:  148 NUM EXPTS TOTAL:  149 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  149 NUM EXPTS TOTAL:  150\n","BATCH#:  149 NUM EXPTS TOTAL:  150 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  150 NUM EXPTS TOTAL:  151\n","BATCH#:  150 NUM EXPTS TOTAL:  151 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  151 NUM EXPTS TOTAL:  152\n","BATCH#:  151 NUM EXPTS TOTAL:  152 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  152 NUM EXPTS TOTAL:  153\n","BATCH#:  152 NUM EXPTS TOTAL:  153 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  153 NUM EXPTS TOTAL:  154\n","BATCH#:  153 NUM EXPTS TOTAL:  154 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  154 NUM EXPTS TOTAL:  155\n","BATCH#:  154 NUM EXPTS TOTAL:  155 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  155 NUM EXPTS TOTAL:  156\n","BATCH#:  155 NUM EXPTS TOTAL:  156 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  156 NUM EXPTS TOTAL:  157\n","BATCH#:  156 NUM EXPTS TOTAL:  157 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  157 NUM EXPTS TOTAL:  158\n","BATCH#:  157 NUM EXPTS TOTAL:  158 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  158 NUM EXPTS TOTAL:  159\n","BATCH#:  158 NUM EXPTS TOTAL:  159 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  159 NUM EXPTS TOTAL:  160\n","BATCH#:  159 NUM EXPTS TOTAL:  160 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  160 NUM EXPTS TOTAL:  161\n","BATCH#:  160 NUM EXPTS TOTAL:  161 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  161 NUM EXPTS TOTAL:  162\n","BATCH#:  161 NUM EXPTS TOTAL:  162 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  162 NUM EXPTS TOTAL:  163\n","BATCH#:  162 NUM EXPTS TOTAL:  163 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  163 NUM EXPTS TOTAL:  164\n","BATCH#:  163 NUM EXPTS TOTAL:  164 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  164 NUM EXPTS TOTAL:  165\n","BATCH#:  164 NUM EXPTS TOTAL:  165 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  165 NUM EXPTS TOTAL:  166\n","BATCH#:  165 NUM EXPTS TOTAL:  166 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  166 NUM EXPTS TOTAL:  167\n","BATCH#:  166 NUM EXPTS TOTAL:  167 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  167 NUM EXPTS TOTAL:  168\n","BATCH#:  167 NUM EXPTS TOTAL:  168 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  168 NUM EXPTS TOTAL:  169\n","BATCH#:  168 NUM EXPTS TOTAL:  169 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  169 NUM EXPTS TOTAL:  170\n","BATCH#:  169 NUM EXPTS TOTAL:  170 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  170 NUM EXPTS TOTAL:  171\n","BATCH#:  170 NUM EXPTS TOTAL:  171 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  171 NUM EXPTS TOTAL:  172\n","BATCH#:  171 NUM EXPTS TOTAL:  172 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  172 NUM EXPTS TOTAL:  173\n","BATCH#:  172 NUM EXPTS TOTAL:  173 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  173 NUM EXPTS TOTAL:  174\n","BATCH#:  173 NUM EXPTS TOTAL:  174 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  174 NUM EXPTS TOTAL:  175\n","BATCH#:  174 NUM EXPTS TOTAL:  175 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  175 NUM EXPTS TOTAL:  176\n","BATCH#:  175 NUM EXPTS TOTAL:  176 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  176 NUM EXPTS TOTAL:  177\n","BATCH#:  176 NUM EXPTS TOTAL:  177 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  177 NUM EXPTS TOTAL:  178\n","BATCH#:  177 NUM EXPTS TOTAL:  178 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  178 NUM EXPTS TOTAL:  179\n","BATCH#:  178 NUM EXPTS TOTAL:  179 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  179 NUM EXPTS TOTAL:  180\n","BATCH#:  179 NUM EXPTS TOTAL:  180 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  180 NUM EXPTS TOTAL:  181\n","BATCH#:  180 NUM EXPTS TOTAL:  181 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  181 NUM EXPTS TOTAL:  182\n","BATCH#:  181 NUM EXPTS TOTAL:  182 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  182 NUM EXPTS TOTAL:  183\n","BATCH#:  182 NUM EXPTS TOTAL:  183 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  183 NUM EXPTS TOTAL:  184\n","BATCH#:  183 NUM EXPTS TOTAL:  184 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  184 NUM EXPTS TOTAL:  185\n","BATCH#:  184 NUM EXPTS TOTAL:  185 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  185 NUM EXPTS TOTAL:  186\n","BATCH#:  185 NUM EXPTS TOTAL:  186 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  186 NUM EXPTS TOTAL:  187\n","BATCH#:  186 NUM EXPTS TOTAL:  187 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  187 NUM EXPTS TOTAL:  188\n","BATCH#:  187 NUM EXPTS TOTAL:  188 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  188 NUM EXPTS TOTAL:  189\n","BATCH#:  188 NUM EXPTS TOTAL:  189 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  189 NUM EXPTS TOTAL:  190\n","BATCH#:  189 NUM EXPTS TOTAL:  190 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  190 NUM EXPTS TOTAL:  191\n","BATCH#:  190 NUM EXPTS TOTAL:  191 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  191 NUM EXPTS TOTAL:  192\n","BATCH#:  191 NUM EXPTS TOTAL:  192 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  192 NUM EXPTS TOTAL:  193\n","BATCH#:  192 NUM EXPTS TOTAL:  193 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  193 NUM EXPTS TOTAL:  194\n","BATCH#:  193 NUM EXPTS TOTAL:  194 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  194 NUM EXPTS TOTAL:  195\n","BATCH#:  194 NUM EXPTS TOTAL:  195 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  195 NUM EXPTS TOTAL:  196\n","BATCH#:  195 NUM EXPTS TOTAL:  196 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  196 NUM EXPTS TOTAL:  197\n","BATCH#:  196 NUM EXPTS TOTAL:  197 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  197 NUM EXPTS TOTAL:  198\n","BATCH#:  197 NUM EXPTS TOTAL:  198 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  198 NUM EXPTS TOTAL:  199\n","BATCH#:  198 NUM EXPTS TOTAL:  199 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  199 NUM EXPTS TOTAL:  200\n","BATCH#:  199 NUM EXPTS TOTAL:  200 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  200 NUM EXPTS TOTAL:  201\n","BATCH#:  200 NUM EXPTS TOTAL:  201 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  201 NUM EXPTS TOTAL:  202\n","BATCH#:  201 NUM EXPTS TOTAL:  202 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  202 NUM EXPTS TOTAL:  203\n","BATCH#:  202 NUM EXPTS TOTAL:  203 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  203 NUM EXPTS TOTAL:  204\n","BATCH#:  203 NUM EXPTS TOTAL:  204 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  204 NUM EXPTS TOTAL:  205\n","BATCH#:  204 NUM EXPTS TOTAL:  205 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  205 NUM EXPTS TOTAL:  206\n","BATCH#:  205 NUM EXPTS TOTAL:  206 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  206 NUM EXPTS TOTAL:  207\n","BATCH#:  206 NUM EXPTS TOTAL:  207 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  207 NUM EXPTS TOTAL:  208\n","BATCH#:  207 NUM EXPTS TOTAL:  208 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  208 NUM EXPTS TOTAL:  209\n","BATCH#:  208 NUM EXPTS TOTAL:  209 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  209 NUM EXPTS TOTAL:  210\n","BATCH#:  209 NUM EXPTS TOTAL:  210 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  210 NUM EXPTS TOTAL:  211\n","BATCH#:  210 NUM EXPTS TOTAL:  211 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  211 NUM EXPTS TOTAL:  212\n","BATCH#:  211 NUM EXPTS TOTAL:  212 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  212 NUM EXPTS TOTAL:  213\n","BATCH#:  212 NUM EXPTS TOTAL:  213 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  213 NUM EXPTS TOTAL:  214\n","BATCH#:  213 NUM EXPTS TOTAL:  214 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  214 NUM EXPTS TOTAL:  215\n","BATCH#:  214 NUM EXPTS TOTAL:  215 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  215 NUM EXPTS TOTAL:  216\n","BATCH#:  215 NUM EXPTS TOTAL:  216 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  216 NUM EXPTS TOTAL:  217\n","BATCH#:  216 NUM EXPTS TOTAL:  217 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  217 NUM EXPTS TOTAL:  218\n","BATCH#:  217 NUM EXPTS TOTAL:  218 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  218 NUM EXPTS TOTAL:  219\n","BATCH#:  218 NUM EXPTS TOTAL:  219 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  219 NUM EXPTS TOTAL:  220\n","BATCH#:  219 NUM EXPTS TOTAL:  220 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  220 NUM EXPTS TOTAL:  221\n","BATCH#:  220 NUM EXPTS TOTAL:  221 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  221 NUM EXPTS TOTAL:  222\n","BATCH#:  221 NUM EXPTS TOTAL:  222 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  222 NUM EXPTS TOTAL:  223\n","BATCH#:  222 NUM EXPTS TOTAL:  223 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  223 NUM EXPTS TOTAL:  224\n","BATCH#:  223 NUM EXPTS TOTAL:  224 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  224 NUM EXPTS TOTAL:  225\n","BATCH#:  224 NUM EXPTS TOTAL:  225 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  225 NUM EXPTS TOTAL:  226\n","BATCH#:  225 NUM EXPTS TOTAL:  226 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  226 NUM EXPTS TOTAL:  227\n","BATCH#:  226 NUM EXPTS TOTAL:  227 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  227 NUM EXPTS TOTAL:  228\n","BATCH#:  227 NUM EXPTS TOTAL:  228 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  228 NUM EXPTS TOTAL:  229\n","BATCH#:  228 NUM EXPTS TOTAL:  229 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  229 NUM EXPTS TOTAL:  230\n","BATCH#:  229 NUM EXPTS TOTAL:  230 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  230 NUM EXPTS TOTAL:  231\n","BATCH#:  230 NUM EXPTS TOTAL:  231 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  231 NUM EXPTS TOTAL:  232\n","BATCH#:  231 NUM EXPTS TOTAL:  232 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  232 NUM EXPTS TOTAL:  233\n","BATCH#:  232 NUM EXPTS TOTAL:  233 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  233 NUM EXPTS TOTAL:  234\n","BATCH#:  233 NUM EXPTS TOTAL:  234 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  234 NUM EXPTS TOTAL:  235\n","BATCH#:  234 NUM EXPTS TOTAL:  235 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  235 NUM EXPTS TOTAL:  236\n","BATCH#:  235 NUM EXPTS TOTAL:  236 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  236 NUM EXPTS TOTAL:  237\n","BATCH#:  236 NUM EXPTS TOTAL:  237 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  237 NUM EXPTS TOTAL:  238\n","BATCH#:  237 NUM EXPTS TOTAL:  238 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  238 NUM EXPTS TOTAL:  239\n","BATCH#:  238 NUM EXPTS TOTAL:  239 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  239 NUM EXPTS TOTAL:  240\n","BATCH#:  239 NUM EXPTS TOTAL:  240 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  240 NUM EXPTS TOTAL:  241\n","BATCH#:  240 NUM EXPTS TOTAL:  241 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  241 NUM EXPTS TOTAL:  242\n","BATCH#:  241 NUM EXPTS TOTAL:  242 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  242 NUM EXPTS TOTAL:  243\n","BATCH#:  242 NUM EXPTS TOTAL:  243 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  243 NUM EXPTS TOTAL:  244\n","BATCH#:  243 NUM EXPTS TOTAL:  244 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  244 NUM EXPTS TOTAL:  245\n","BATCH#:  244 NUM EXPTS TOTAL:  245 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  245 NUM EXPTS TOTAL:  246\n","BATCH#:  245 NUM EXPTS TOTAL:  246 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  246 NUM EXPTS TOTAL:  247\n","BATCH#:  246 NUM EXPTS TOTAL:  247 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  247 NUM EXPTS TOTAL:  248\n","BATCH#:  247 NUM EXPTS TOTAL:  248 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  248 NUM EXPTS TOTAL:  249\n","BATCH#:  248 NUM EXPTS TOTAL:  249 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  249 NUM EXPTS TOTAL:  250\n","BATCH#:  249 NUM EXPTS TOTAL:  250 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  250 NUM EXPTS TOTAL:  251\n","BATCH#:  250 NUM EXPTS TOTAL:  251 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  251 NUM EXPTS TOTAL:  252\n","BATCH#:  251 NUM EXPTS TOTAL:  252 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  252 NUM EXPTS TOTAL:  253\n","BATCH#:  252 NUM EXPTS TOTAL:  253 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  253 NUM EXPTS TOTAL:  254\n","BATCH#:  253 NUM EXPTS TOTAL:  254 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  254 NUM EXPTS TOTAL:  255\n","BATCH#:  254 NUM EXPTS TOTAL:  255 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  255 NUM EXPTS TOTAL:  256\n","BATCH#:  255 NUM EXPTS TOTAL:  256 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  256 NUM EXPTS TOTAL:  257\n","BATCH#:  256 NUM EXPTS TOTAL:  257 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  257 NUM EXPTS TOTAL:  258\n","BATCH#:  257 NUM EXPTS TOTAL:  258 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  258 NUM EXPTS TOTAL:  259\n","BATCH#:  258 NUM EXPTS TOTAL:  259 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  259 NUM EXPTS TOTAL:  260\n","BATCH#:  259 NUM EXPTS TOTAL:  260 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  260 NUM EXPTS TOTAL:  261\n","BATCH#:  260 NUM EXPTS TOTAL:  261 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  261 NUM EXPTS TOTAL:  262\n","BATCH#:  261 NUM EXPTS TOTAL:  262 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  262 NUM EXPTS TOTAL:  263\n","BATCH#:  262 NUM EXPTS TOTAL:  263 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  263 NUM EXPTS TOTAL:  264\n","BATCH#:  263 NUM EXPTS TOTAL:  264 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  264 NUM EXPTS TOTAL:  265\n","BATCH#:  264 NUM EXPTS TOTAL:  265 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  265 NUM EXPTS TOTAL:  266\n","BATCH#:  265 NUM EXPTS TOTAL:  266 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  266 NUM EXPTS TOTAL:  267\n","BATCH#:  266 NUM EXPTS TOTAL:  267 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  267 NUM EXPTS TOTAL:  268\n","BATCH#:  267 NUM EXPTS TOTAL:  268 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  268 NUM EXPTS TOTAL:  269\n","BATCH#:  268 NUM EXPTS TOTAL:  269 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  269 NUM EXPTS TOTAL:  270\n","BATCH#:  269 NUM EXPTS TOTAL:  270 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  270 NUM EXPTS TOTAL:  271\n","BATCH#:  270 NUM EXPTS TOTAL:  271 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  271 NUM EXPTS TOTAL:  272\n","BATCH#:  271 NUM EXPTS TOTAL:  272 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  272 NUM EXPTS TOTAL:  273\n","BATCH#:  272 NUM EXPTS TOTAL:  273 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  273 NUM EXPTS TOTAL:  274\n","BATCH#:  273 NUM EXPTS TOTAL:  274 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  274 NUM EXPTS TOTAL:  275\n","BATCH#:  274 NUM EXPTS TOTAL:  275 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  275 NUM EXPTS TOTAL:  276\n","BATCH#:  275 NUM EXPTS TOTAL:  276 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  276 NUM EXPTS TOTAL:  277\n","BATCH#:  276 NUM EXPTS TOTAL:  277 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  277 NUM EXPTS TOTAL:  278\n","BATCH#:  277 NUM EXPTS TOTAL:  278 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  278 NUM EXPTS TOTAL:  279\n","BATCH#:  278 NUM EXPTS TOTAL:  279 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  279 NUM EXPTS TOTAL:  280\n","BATCH#:  279 NUM EXPTS TOTAL:  280 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  280 NUM EXPTS TOTAL:  281\n","BATCH#:  280 NUM EXPTS TOTAL:  281 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  281 NUM EXPTS TOTAL:  282\n","BATCH#:  281 NUM EXPTS TOTAL:  282 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  282 NUM EXPTS TOTAL:  283\n","BATCH#:  282 NUM EXPTS TOTAL:  283 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  283 NUM EXPTS TOTAL:  284\n","BATCH#:  283 NUM EXPTS TOTAL:  284 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  284 NUM EXPTS TOTAL:  285\n","BATCH#:  284 NUM EXPTS TOTAL:  285 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  285 NUM EXPTS TOTAL:  286\n","BATCH#:  285 NUM EXPTS TOTAL:  286 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  286 NUM EXPTS TOTAL:  287\n","BATCH#:  286 NUM EXPTS TOTAL:  287 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  287 NUM EXPTS TOTAL:  288\n","BATCH#:  287 NUM EXPTS TOTAL:  288 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  288 NUM EXPTS TOTAL:  289\n","BATCH#:  288 NUM EXPTS TOTAL:  289 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  289 NUM EXPTS TOTAL:  290\n","BATCH#:  289 NUM EXPTS TOTAL:  290 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  290 NUM EXPTS TOTAL:  291\n","BATCH#:  290 NUM EXPTS TOTAL:  291 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  291 NUM EXPTS TOTAL:  292\n","BATCH#:  291 NUM EXPTS TOTAL:  292 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  292 NUM EXPTS TOTAL:  293\n","BATCH#:  292 NUM EXPTS TOTAL:  293 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  293 NUM EXPTS TOTAL:  294\n","BATCH#:  293 NUM EXPTS TOTAL:  294 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  294 NUM EXPTS TOTAL:  295\n","BATCH#:  294 NUM EXPTS TOTAL:  295 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  295 NUM EXPTS TOTAL:  296\n","BATCH#:  295 NUM EXPTS TOTAL:  296 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  296 NUM EXPTS TOTAL:  297\n","BATCH#:  296 NUM EXPTS TOTAL:  297 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  297 NUM EXPTS TOTAL:  298\n","BATCH#:  297 NUM EXPTS TOTAL:  298 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  298 NUM EXPTS TOTAL:  299\n","BATCH#:  298 NUM EXPTS TOTAL:  299 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  299 NUM EXPTS TOTAL:  300\n","BATCH#:  299 NUM EXPTS TOTAL:  300 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  300 NUM EXPTS TOTAL:  301\n","BATCH#:  300 NUM EXPTS TOTAL:  301 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  301 NUM EXPTS TOTAL:  302\n","BATCH#:  301 NUM EXPTS TOTAL:  302 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  302 NUM EXPTS TOTAL:  303\n","BATCH#:  302 NUM EXPTS TOTAL:  303 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  303 NUM EXPTS TOTAL:  304\n","BATCH#:  303 NUM EXPTS TOTAL:  304 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  304 NUM EXPTS TOTAL:  305\n","BATCH#:  304 NUM EXPTS TOTAL:  305 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  305 NUM EXPTS TOTAL:  306\n","BATCH#:  305 NUM EXPTS TOTAL:  306 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  306 NUM EXPTS TOTAL:  307\n","BATCH#:  306 NUM EXPTS TOTAL:  307 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  307 NUM EXPTS TOTAL:  308\n","BATCH#:  307 NUM EXPTS TOTAL:  308 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  308 NUM EXPTS TOTAL:  309\n","BATCH#:  308 NUM EXPTS TOTAL:  309 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  309 NUM EXPTS TOTAL:  310\n","BATCH#:  309 NUM EXPTS TOTAL:  310 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  310 NUM EXPTS TOTAL:  311\n","BATCH#:  310 NUM EXPTS TOTAL:  311 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  311 NUM EXPTS TOTAL:  312\n","BATCH#:  311 NUM EXPTS TOTAL:  312 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  312 NUM EXPTS TOTAL:  313\n","BATCH#:  312 NUM EXPTS TOTAL:  313 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  313 NUM EXPTS TOTAL:  314\n","BATCH#:  313 NUM EXPTS TOTAL:  314 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  314 NUM EXPTS TOTAL:  315\n","BATCH#:  314 NUM EXPTS TOTAL:  315 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  315 NUM EXPTS TOTAL:  316\n","BATCH#:  315 NUM EXPTS TOTAL:  316 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  316 NUM EXPTS TOTAL:  317\n","BATCH#:  316 NUM EXPTS TOTAL:  317 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  317 NUM EXPTS TOTAL:  318\n","BATCH#:  317 NUM EXPTS TOTAL:  318 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  318 NUM EXPTS TOTAL:  319\n","BATCH#:  318 NUM EXPTS TOTAL:  319 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  319 NUM EXPTS TOTAL:  320\n","BATCH#:  319 NUM EXPTS TOTAL:  320 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  320 NUM EXPTS TOTAL:  321\n","BATCH#:  320 NUM EXPTS TOTAL:  321 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  321 NUM EXPTS TOTAL:  322\n","BATCH#:  321 NUM EXPTS TOTAL:  322 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  322 NUM EXPTS TOTAL:  323\n","BATCH#:  322 NUM EXPTS TOTAL:  323 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  323 NUM EXPTS TOTAL:  324\n","BATCH#:  323 NUM EXPTS TOTAL:  324 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  324 NUM EXPTS TOTAL:  325\n","BATCH#:  324 NUM EXPTS TOTAL:  325 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  325 NUM EXPTS TOTAL:  326\n","BATCH#:  325 NUM EXPTS TOTAL:  326 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  326 NUM EXPTS TOTAL:  327\n","BATCH#:  326 NUM EXPTS TOTAL:  327 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  327 NUM EXPTS TOTAL:  328\n","BATCH#:  327 NUM EXPTS TOTAL:  328 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  328 NUM EXPTS TOTAL:  329\n","BATCH#:  328 NUM EXPTS TOTAL:  329 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  329 NUM EXPTS TOTAL:  330\n","BATCH#:  329 NUM EXPTS TOTAL:  330 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  330 NUM EXPTS TOTAL:  331\n","BATCH#:  330 NUM EXPTS TOTAL:  331 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  331 NUM EXPTS TOTAL:  332\n","BATCH#:  331 NUM EXPTS TOTAL:  332 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  332 NUM EXPTS TOTAL:  333\n","BATCH#:  332 NUM EXPTS TOTAL:  333 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  333 NUM EXPTS TOTAL:  334\n","BATCH#:  333 NUM EXPTS TOTAL:  334 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  334 NUM EXPTS TOTAL:  335\n","BATCH#:  334 NUM EXPTS TOTAL:  335 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  335 NUM EXPTS TOTAL:  336\n","BATCH#:  335 NUM EXPTS TOTAL:  336 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  336 NUM EXPTS TOTAL:  337\n","BATCH#:  336 NUM EXPTS TOTAL:  337 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  337 NUM EXPTS TOTAL:  338\n","BATCH#:  337 NUM EXPTS TOTAL:  338 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  338 NUM EXPTS TOTAL:  339\n","BATCH#:  338 NUM EXPTS TOTAL:  339 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  339 NUM EXPTS TOTAL:  340\n","BATCH#:  339 NUM EXPTS TOTAL:  340 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  340 NUM EXPTS TOTAL:  341\n","BATCH#:  340 NUM EXPTS TOTAL:  341 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  341 NUM EXPTS TOTAL:  342\n","BATCH#:  341 NUM EXPTS TOTAL:  342 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  342 NUM EXPTS TOTAL:  343\n","BATCH#:  342 NUM EXPTS TOTAL:  343 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  343 NUM EXPTS TOTAL:  344\n","BATCH#:  343 NUM EXPTS TOTAL:  344 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  344 NUM EXPTS TOTAL:  345\n","BATCH#:  344 NUM EXPTS TOTAL:  345 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  345 NUM EXPTS TOTAL:  346\n","BATCH#:  345 NUM EXPTS TOTAL:  346 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  346 NUM EXPTS TOTAL:  347\n","BATCH#:  346 NUM EXPTS TOTAL:  347 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  347 NUM EXPTS TOTAL:  348\n","BATCH#:  347 NUM EXPTS TOTAL:  348 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  348 NUM EXPTS TOTAL:  349\n","BATCH#:  348 NUM EXPTS TOTAL:  349 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  349 NUM EXPTS TOTAL:  350\n","BATCH#:  349 NUM EXPTS TOTAL:  350 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  350 NUM EXPTS TOTAL:  351\n","BATCH#:  350 NUM EXPTS TOTAL:  351 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  351 NUM EXPTS TOTAL:  352\n","BATCH#:  351 NUM EXPTS TOTAL:  352 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  352 NUM EXPTS TOTAL:  353\n","BATCH#:  352 NUM EXPTS TOTAL:  353 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  353 NUM EXPTS TOTAL:  354\n","BATCH#:  353 NUM EXPTS TOTAL:  354 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  354 NUM EXPTS TOTAL:  355\n","BATCH#:  354 NUM EXPTS TOTAL:  355 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  355 NUM EXPTS TOTAL:  356\n","BATCH#:  355 NUM EXPTS TOTAL:  356 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  356 NUM EXPTS TOTAL:  357\n","BATCH#:  356 NUM EXPTS TOTAL:  357 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  357 NUM EXPTS TOTAL:  358\n","BATCH#:  357 NUM EXPTS TOTAL:  358 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  358 NUM EXPTS TOTAL:  359\n","BATCH#:  358 NUM EXPTS TOTAL:  359 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  359 NUM EXPTS TOTAL:  360\n","BATCH#:  359 NUM EXPTS TOTAL:  360 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  360 NUM EXPTS TOTAL:  361\n","BATCH#:  360 NUM EXPTS TOTAL:  361 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  361 NUM EXPTS TOTAL:  362\n","BATCH#:  361 NUM EXPTS TOTAL:  362 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  362 NUM EXPTS TOTAL:  363\n","BATCH#:  362 NUM EXPTS TOTAL:  363 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  363 NUM EXPTS TOTAL:  364\n","BATCH#:  363 NUM EXPTS TOTAL:  364 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  364 NUM EXPTS TOTAL:  365\n","BATCH#:  364 NUM EXPTS TOTAL:  365 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  365 NUM EXPTS TOTAL:  366\n","BATCH#:  365 NUM EXPTS TOTAL:  366 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  366 NUM EXPTS TOTAL:  367\n","BATCH#:  366 NUM EXPTS TOTAL:  367 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  367 NUM EXPTS TOTAL:  368\n","BATCH#:  367 NUM EXPTS TOTAL:  368 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  368 NUM EXPTS TOTAL:  369\n","BATCH#:  368 NUM EXPTS TOTAL:  369 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  369 NUM EXPTS TOTAL:  370\n","BATCH#:  369 NUM EXPTS TOTAL:  370 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  370 NUM EXPTS TOTAL:  371\n","BATCH#:  370 NUM EXPTS TOTAL:  371 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  371 NUM EXPTS TOTAL:  372\n","BATCH#:  371 NUM EXPTS TOTAL:  372 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  372 NUM EXPTS TOTAL:  373\n","BATCH#:  372 NUM EXPTS TOTAL:  373 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  373 NUM EXPTS TOTAL:  374\n","BATCH#:  373 NUM EXPTS TOTAL:  374 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  374 NUM EXPTS TOTAL:  375\n","BATCH#:  374 NUM EXPTS TOTAL:  375 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  375 NUM EXPTS TOTAL:  376\n","BATCH#:  375 NUM EXPTS TOTAL:  376 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  376 NUM EXPTS TOTAL:  377\n","BATCH#:  376 NUM EXPTS TOTAL:  377 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  377 NUM EXPTS TOTAL:  378\n","BATCH#:  377 NUM EXPTS TOTAL:  378 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  378 NUM EXPTS TOTAL:  379\n","BATCH#:  378 NUM EXPTS TOTAL:  379 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  379 NUM EXPTS TOTAL:  380\n","BATCH#:  379 NUM EXPTS TOTAL:  380 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  380 NUM EXPTS TOTAL:  381\n","BATCH#:  380 NUM EXPTS TOTAL:  381 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  381 NUM EXPTS TOTAL:  382\n","BATCH#:  381 NUM EXPTS TOTAL:  382 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  382 NUM EXPTS TOTAL:  383\n","BATCH#:  382 NUM EXPTS TOTAL:  383 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  383 NUM EXPTS TOTAL:  384\n","BATCH#:  383 NUM EXPTS TOTAL:  384 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  384 NUM EXPTS TOTAL:  385\n","BATCH#:  384 NUM EXPTS TOTAL:  385 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  385 NUM EXPTS TOTAL:  386\n","BATCH#:  385 NUM EXPTS TOTAL:  386 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  386 NUM EXPTS TOTAL:  387\n","BATCH#:  386 NUM EXPTS TOTAL:  387 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  387 NUM EXPTS TOTAL:  388\n","BATCH#:  387 NUM EXPTS TOTAL:  388 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  388 NUM EXPTS TOTAL:  389\n","BATCH#:  388 NUM EXPTS TOTAL:  389 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  389 NUM EXPTS TOTAL:  390\n","BATCH#:  389 NUM EXPTS TOTAL:  390 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  390 NUM EXPTS TOTAL:  391\n","BATCH#:  390 NUM EXPTS TOTAL:  391 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  391 NUM EXPTS TOTAL:  392\n","BATCH#:  391 NUM EXPTS TOTAL:  392 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  392 NUM EXPTS TOTAL:  393\n","BATCH#:  392 NUM EXPTS TOTAL:  393 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  393 NUM EXPTS TOTAL:  394\n","BATCH#:  393 NUM EXPTS TOTAL:  394 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  394 NUM EXPTS TOTAL:  395\n","BATCH#:  394 NUM EXPTS TOTAL:  395 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  395 NUM EXPTS TOTAL:  396\n","BATCH#:  395 NUM EXPTS TOTAL:  396 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  396 NUM EXPTS TOTAL:  397\n","BATCH#:  396 NUM EXPTS TOTAL:  397 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  397 NUM EXPTS TOTAL:  398\n","BATCH#:  397 NUM EXPTS TOTAL:  398 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  398 NUM EXPTS TOTAL:  399\n","BATCH#:  398 NUM EXPTS TOTAL:  399 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  399 NUM EXPTS TOTAL:  400\n","BATCH#:  399 NUM EXPTS TOTAL:  400 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  400 NUM EXPTS TOTAL:  401\n","BATCH#:  400 NUM EXPTS TOTAL:  401 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  401 NUM EXPTS TOTAL:  402\n","BATCH#:  401 NUM EXPTS TOTAL:  402 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  402 NUM EXPTS TOTAL:  403\n","BATCH#:  402 NUM EXPTS TOTAL:  403 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  403 NUM EXPTS TOTAL:  404\n","BATCH#:  403 NUM EXPTS TOTAL:  404 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  404 NUM EXPTS TOTAL:  405\n","BATCH#:  404 NUM EXPTS TOTAL:  405 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  405 NUM EXPTS TOTAL:  406\n","BATCH#:  405 NUM EXPTS TOTAL:  406 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  406 NUM EXPTS TOTAL:  407\n","BATCH#:  406 NUM EXPTS TOTAL:  407 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  407 NUM EXPTS TOTAL:  408\n","BATCH#:  407 NUM EXPTS TOTAL:  408 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  408 NUM EXPTS TOTAL:  409\n","BATCH#:  408 NUM EXPTS TOTAL:  409 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  409 NUM EXPTS TOTAL:  410\n","BATCH#:  409 NUM EXPTS TOTAL:  410 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  410 NUM EXPTS TOTAL:  411\n","BATCH#:  410 NUM EXPTS TOTAL:  411 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  411 NUM EXPTS TOTAL:  412\n","BATCH#:  411 NUM EXPTS TOTAL:  412 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  412 NUM EXPTS TOTAL:  413\n","BATCH#:  412 NUM EXPTS TOTAL:  413 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  413 NUM EXPTS TOTAL:  414\n","BATCH#:  413 NUM EXPTS TOTAL:  414 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  414 NUM EXPTS TOTAL:  415\n","BATCH#:  414 NUM EXPTS TOTAL:  415 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  415 NUM EXPTS TOTAL:  416\n","BATCH#:  415 NUM EXPTS TOTAL:  416 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  416 NUM EXPTS TOTAL:  417\n","BATCH#:  416 NUM EXPTS TOTAL:  417 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  417 NUM EXPTS TOTAL:  418\n","BATCH#:  417 NUM EXPTS TOTAL:  418 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  418 NUM EXPTS TOTAL:  419\n","BATCH#:  418 NUM EXPTS TOTAL:  419 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  419 NUM EXPTS TOTAL:  420\n","BATCH#:  419 NUM EXPTS TOTAL:  420 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  420 NUM EXPTS TOTAL:  421\n","BATCH#:  420 NUM EXPTS TOTAL:  421 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  421 NUM EXPTS TOTAL:  422\n","BATCH#:  421 NUM EXPTS TOTAL:  422 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  422 NUM EXPTS TOTAL:  423\n","BATCH#:  422 NUM EXPTS TOTAL:  423 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  423 NUM EXPTS TOTAL:  424\n","BATCH#:  423 NUM EXPTS TOTAL:  424 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  424 NUM EXPTS TOTAL:  425\n","BATCH#:  424 NUM EXPTS TOTAL:  425 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  425 NUM EXPTS TOTAL:  426\n","BATCH#:  425 NUM EXPTS TOTAL:  426 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  426 NUM EXPTS TOTAL:  427\n","BATCH#:  426 NUM EXPTS TOTAL:  427 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  427 NUM EXPTS TOTAL:  428\n","BATCH#:  427 NUM EXPTS TOTAL:  428 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  428 NUM EXPTS TOTAL:  429\n","BATCH#:  428 NUM EXPTS TOTAL:  429 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  429 NUM EXPTS TOTAL:  430\n","BATCH#:  429 NUM EXPTS TOTAL:  430 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  430 NUM EXPTS TOTAL:  431\n","BATCH#:  430 NUM EXPTS TOTAL:  431 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  431 NUM EXPTS TOTAL:  432\n","BATCH#:  431 NUM EXPTS TOTAL:  432 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  432 NUM EXPTS TOTAL:  433\n","BATCH#:  432 NUM EXPTS TOTAL:  433 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  433 NUM EXPTS TOTAL:  434\n","BATCH#:  433 NUM EXPTS TOTAL:  434 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  434 NUM EXPTS TOTAL:  435\n","BATCH#:  434 NUM EXPTS TOTAL:  435 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  435 NUM EXPTS TOTAL:  436\n","BATCH#:  435 NUM EXPTS TOTAL:  436 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  436 NUM EXPTS TOTAL:  437\n","BATCH#:  436 NUM EXPTS TOTAL:  437 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  437 NUM EXPTS TOTAL:  438\n","BATCH#:  437 NUM EXPTS TOTAL:  438 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  438 NUM EXPTS TOTAL:  439\n","BATCH#:  438 NUM EXPTS TOTAL:  439 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  439 NUM EXPTS TOTAL:  440\n","BATCH#:  439 NUM EXPTS TOTAL:  440 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  440 NUM EXPTS TOTAL:  441\n","BATCH#:  440 NUM EXPTS TOTAL:  441 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  441 NUM EXPTS TOTAL:  442\n","BATCH#:  441 NUM EXPTS TOTAL:  442 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  442 NUM EXPTS TOTAL:  443\n","BATCH#:  442 NUM EXPTS TOTAL:  443 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  443 NUM EXPTS TOTAL:  444\n","BATCH#:  443 NUM EXPTS TOTAL:  444 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  444 NUM EXPTS TOTAL:  445\n","BATCH#:  444 NUM EXPTS TOTAL:  445 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  445 NUM EXPTS TOTAL:  446\n","BATCH#:  445 NUM EXPTS TOTAL:  446 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  446 NUM EXPTS TOTAL:  447\n","BATCH#:  446 NUM EXPTS TOTAL:  447 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  447 NUM EXPTS TOTAL:  448\n","BATCH#:  447 NUM EXPTS TOTAL:  448 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  448 NUM EXPTS TOTAL:  449\n","BATCH#:  448 NUM EXPTS TOTAL:  449 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  449 NUM EXPTS TOTAL:  450\n","BATCH#:  449 NUM EXPTS TOTAL:  450 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  450 NUM EXPTS TOTAL:  451\n","BATCH#:  450 NUM EXPTS TOTAL:  451 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  451 NUM EXPTS TOTAL:  452\n","BATCH#:  451 NUM EXPTS TOTAL:  452 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  452 NUM EXPTS TOTAL:  453\n","BATCH#:  452 NUM EXPTS TOTAL:  453 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  453 NUM EXPTS TOTAL:  454\n","BATCH#:  453 NUM EXPTS TOTAL:  454 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  454 NUM EXPTS TOTAL:  455\n","BATCH#:  454 NUM EXPTS TOTAL:  455 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  455 NUM EXPTS TOTAL:  456\n","BATCH#:  455 NUM EXPTS TOTAL:  456 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  456 NUM EXPTS TOTAL:  457\n","BATCH#:  456 NUM EXPTS TOTAL:  457 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  457 NUM EXPTS TOTAL:  458\n","BATCH#:  457 NUM EXPTS TOTAL:  458 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  458 NUM EXPTS TOTAL:  459\n","BATCH#:  458 NUM EXPTS TOTAL:  459 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  459 NUM EXPTS TOTAL:  460\n","BATCH#:  459 NUM EXPTS TOTAL:  460 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  460 NUM EXPTS TOTAL:  461\n","BATCH#:  460 NUM EXPTS TOTAL:  461 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  461 NUM EXPTS TOTAL:  462\n","BATCH#:  461 NUM EXPTS TOTAL:  462 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  462 NUM EXPTS TOTAL:  463\n","BATCH#:  462 NUM EXPTS TOTAL:  463 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  463 NUM EXPTS TOTAL:  464\n","BATCH#:  463 NUM EXPTS TOTAL:  464 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  464 NUM EXPTS TOTAL:  465\n","BATCH#:  464 NUM EXPTS TOTAL:  465 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  465 NUM EXPTS TOTAL:  466\n","BATCH#:  465 NUM EXPTS TOTAL:  466 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  466 NUM EXPTS TOTAL:  467\n","BATCH#:  466 NUM EXPTS TOTAL:  467 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  467 NUM EXPTS TOTAL:  468\n","BATCH#:  467 NUM EXPTS TOTAL:  468 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  468 NUM EXPTS TOTAL:  469\n","BATCH#:  468 NUM EXPTS TOTAL:  469 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  469 NUM EXPTS TOTAL:  470\n","BATCH#:  469 NUM EXPTS TOTAL:  470 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  470 NUM EXPTS TOTAL:  471\n","BATCH#:  470 NUM EXPTS TOTAL:  471 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  471 NUM EXPTS TOTAL:  472\n","BATCH#:  471 NUM EXPTS TOTAL:  472 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  472 NUM EXPTS TOTAL:  473\n","BATCH#:  472 NUM EXPTS TOTAL:  473 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  473 NUM EXPTS TOTAL:  474\n","BATCH#:  473 NUM EXPTS TOTAL:  474 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  474 NUM EXPTS TOTAL:  475\n","BATCH#:  474 NUM EXPTS TOTAL:  475 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  475 NUM EXPTS TOTAL:  476\n","BATCH#:  475 NUM EXPTS TOTAL:  476 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  476 NUM EXPTS TOTAL:  477\n","BATCH#:  476 NUM EXPTS TOTAL:  477 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  477 NUM EXPTS TOTAL:  478\n","BATCH#:  477 NUM EXPTS TOTAL:  478 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  478 NUM EXPTS TOTAL:  479\n","BATCH#:  478 NUM EXPTS TOTAL:  479 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  479 NUM EXPTS TOTAL:  480\n","BATCH#:  479 NUM EXPTS TOTAL:  480 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  480 NUM EXPTS TOTAL:  481\n","BATCH#:  480 NUM EXPTS TOTAL:  481 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  481 NUM EXPTS TOTAL:  482\n","BATCH#:  481 NUM EXPTS TOTAL:  482 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  482 NUM EXPTS TOTAL:  483\n","BATCH#:  482 NUM EXPTS TOTAL:  483 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  483 NUM EXPTS TOTAL:  484\n","BATCH#:  483 NUM EXPTS TOTAL:  484 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  484 NUM EXPTS TOTAL:  485\n","BATCH#:  484 NUM EXPTS TOTAL:  485 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  485 NUM EXPTS TOTAL:  486\n","BATCH#:  485 NUM EXPTS TOTAL:  486 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  486 NUM EXPTS TOTAL:  487\n","BATCH#:  486 NUM EXPTS TOTAL:  487 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  487 NUM EXPTS TOTAL:  488\n","BATCH#:  487 NUM EXPTS TOTAL:  488 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  488 NUM EXPTS TOTAL:  489\n","BATCH#:  488 NUM EXPTS TOTAL:  489 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  489 NUM EXPTS TOTAL:  490\n","BATCH#:  489 NUM EXPTS TOTAL:  490 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  490 NUM EXPTS TOTAL:  491\n","BATCH#:  490 NUM EXPTS TOTAL:  491 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  491 NUM EXPTS TOTAL:  492\n","BATCH#:  491 NUM EXPTS TOTAL:  492 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  492 NUM EXPTS TOTAL:  493\n","BATCH#:  492 NUM EXPTS TOTAL:  493 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  493 NUM EXPTS TOTAL:  494\n","BATCH#:  493 NUM EXPTS TOTAL:  494 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  494 NUM EXPTS TOTAL:  495\n","BATCH#:  494 NUM EXPTS TOTAL:  495 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  495 NUM EXPTS TOTAL:  496\n","BATCH#:  495 NUM EXPTS TOTAL:  496 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  496 NUM EXPTS TOTAL:  497\n","BATCH#:  496 NUM EXPTS TOTAL:  497 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  497 NUM EXPTS TOTAL:  498\n","BATCH#:  497 NUM EXPTS TOTAL:  498 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  498 NUM EXPTS TOTAL:  499\n","BATCH#:  498 NUM EXPTS TOTAL:  499 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  499 NUM EXPTS TOTAL:  500\n","BATCH#:  499 NUM EXPTS TOTAL:  500 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  500 NUM EXPTS TOTAL:  501\n","BATCH#:  500 NUM EXPTS TOTAL:  501 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  501 NUM EXPTS TOTAL:  502\n","BATCH#:  501 NUM EXPTS TOTAL:  502 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  502 NUM EXPTS TOTAL:  503\n","BATCH#:  502 NUM EXPTS TOTAL:  503 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  503 NUM EXPTS TOTAL:  504\n","BATCH#:  503 NUM EXPTS TOTAL:  504 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  504 NUM EXPTS TOTAL:  505\n","BATCH#:  504 NUM EXPTS TOTAL:  505 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  505 NUM EXPTS TOTAL:  506\n","BATCH#:  505 NUM EXPTS TOTAL:  506 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  506 NUM EXPTS TOTAL:  507\n","BATCH#:  506 NUM EXPTS TOTAL:  507 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  507 NUM EXPTS TOTAL:  508\n","BATCH#:  507 NUM EXPTS TOTAL:  508 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  508 NUM EXPTS TOTAL:  509\n","BATCH#:  508 NUM EXPTS TOTAL:  509 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  509 NUM EXPTS TOTAL:  510\n","BATCH#:  509 NUM EXPTS TOTAL:  510 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  510 NUM EXPTS TOTAL:  511\n","BATCH#:  510 NUM EXPTS TOTAL:  511 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  511 NUM EXPTS TOTAL:  512\n","BATCH#:  511 NUM EXPTS TOTAL:  512 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  512 NUM EXPTS TOTAL:  513\n","BATCH#:  512 NUM EXPTS TOTAL:  513 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  513 NUM EXPTS TOTAL:  514\n","BATCH#:  513 NUM EXPTS TOTAL:  514 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  514 NUM EXPTS TOTAL:  515\n","BATCH#:  514 NUM EXPTS TOTAL:  515 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  515 NUM EXPTS TOTAL:  516\n","BATCH#:  515 NUM EXPTS TOTAL:  516 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  516 NUM EXPTS TOTAL:  517\n","BATCH#:  516 NUM EXPTS TOTAL:  517 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  517 NUM EXPTS TOTAL:  518\n","BATCH#:  517 NUM EXPTS TOTAL:  518 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  518 NUM EXPTS TOTAL:  519\n","BATCH#:  518 NUM EXPTS TOTAL:  519 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  519 NUM EXPTS TOTAL:  520\n","BATCH#:  519 NUM EXPTS TOTAL:  520 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  520 NUM EXPTS TOTAL:  521\n","BATCH#:  520 NUM EXPTS TOTAL:  521 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  521 NUM EXPTS TOTAL:  522\n","BATCH#:  521 NUM EXPTS TOTAL:  522 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  522 NUM EXPTS TOTAL:  523\n","BATCH#:  522 NUM EXPTS TOTAL:  523 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  523 NUM EXPTS TOTAL:  524\n","BATCH#:  523 NUM EXPTS TOTAL:  524 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  524 NUM EXPTS TOTAL:  525\n","BATCH#:  524 NUM EXPTS TOTAL:  525 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  525 NUM EXPTS TOTAL:  526\n","BATCH#:  525 NUM EXPTS TOTAL:  526 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  526 NUM EXPTS TOTAL:  527\n","BATCH#:  526 NUM EXPTS TOTAL:  527 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  527 NUM EXPTS TOTAL:  528\n","BATCH#:  527 NUM EXPTS TOTAL:  528 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  528 NUM EXPTS TOTAL:  529\n","BATCH#:  528 NUM EXPTS TOTAL:  529 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  529 NUM EXPTS TOTAL:  530\n","BATCH#:  529 NUM EXPTS TOTAL:  530 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  530 NUM EXPTS TOTAL:  531\n","BATCH#:  530 NUM EXPTS TOTAL:  531 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  531 NUM EXPTS TOTAL:  532\n","BATCH#:  531 NUM EXPTS TOTAL:  532 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  532 NUM EXPTS TOTAL:  533\n","BATCH#:  532 NUM EXPTS TOTAL:  533 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  533 NUM EXPTS TOTAL:  534\n","BATCH#:  533 NUM EXPTS TOTAL:  534 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  534 NUM EXPTS TOTAL:  535\n","BATCH#:  534 NUM EXPTS TOTAL:  535 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  535 NUM EXPTS TOTAL:  536\n","BATCH#:  535 NUM EXPTS TOTAL:  536 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  536 NUM EXPTS TOTAL:  537\n","BATCH#:  536 NUM EXPTS TOTAL:  537 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  537 NUM EXPTS TOTAL:  538\n","BATCH#:  537 NUM EXPTS TOTAL:  538 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  538 NUM EXPTS TOTAL:  539\n","BATCH#:  538 NUM EXPTS TOTAL:  539 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  539 NUM EXPTS TOTAL:  540\n","BATCH#:  539 NUM EXPTS TOTAL:  540 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  540 NUM EXPTS TOTAL:  541\n","BATCH#:  540 NUM EXPTS TOTAL:  541 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  541 NUM EXPTS TOTAL:  542\n","BATCH#:  541 NUM EXPTS TOTAL:  542 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  542 NUM EXPTS TOTAL:  543\n","BATCH#:  542 NUM EXPTS TOTAL:  543 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  543 NUM EXPTS TOTAL:  544\n","BATCH#:  543 NUM EXPTS TOTAL:  544 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  544 NUM EXPTS TOTAL:  545\n","BATCH#:  544 NUM EXPTS TOTAL:  545 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  545 NUM EXPTS TOTAL:  546\n","BATCH#:  545 NUM EXPTS TOTAL:  546 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  546 NUM EXPTS TOTAL:  547\n","BATCH#:  546 NUM EXPTS TOTAL:  547 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  547 NUM EXPTS TOTAL:  548\n","BATCH#:  547 NUM EXPTS TOTAL:  548 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  548 NUM EXPTS TOTAL:  549\n","BATCH#:  548 NUM EXPTS TOTAL:  549 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  549 NUM EXPTS TOTAL:  550\n","BATCH#:  549 NUM EXPTS TOTAL:  550 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  550 NUM EXPTS TOTAL:  551\n","BATCH#:  550 NUM EXPTS TOTAL:  551 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  551 NUM EXPTS TOTAL:  552\n","BATCH#:  551 NUM EXPTS TOTAL:  552 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  552 NUM EXPTS TOTAL:  553\n","BATCH#:  552 NUM EXPTS TOTAL:  553 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  553 NUM EXPTS TOTAL:  554\n","BATCH#:  553 NUM EXPTS TOTAL:  554 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  554 NUM EXPTS TOTAL:  555\n","BATCH#:  554 NUM EXPTS TOTAL:  555 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  555 NUM EXPTS TOTAL:  556\n","BATCH#:  555 NUM EXPTS TOTAL:  556 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  556 NUM EXPTS TOTAL:  557\n","BATCH#:  556 NUM EXPTS TOTAL:  557 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  557 NUM EXPTS TOTAL:  558\n","BATCH#:  557 NUM EXPTS TOTAL:  558 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  558 NUM EXPTS TOTAL:  559\n","BATCH#:  558 NUM EXPTS TOTAL:  559 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  559 NUM EXPTS TOTAL:  560\n","BATCH#:  559 NUM EXPTS TOTAL:  560 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  560 NUM EXPTS TOTAL:  561\n","BATCH#:  560 NUM EXPTS TOTAL:  561 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  561 NUM EXPTS TOTAL:  562\n","BATCH#:  561 NUM EXPTS TOTAL:  562 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  562 NUM EXPTS TOTAL:  563\n","BATCH#:  562 NUM EXPTS TOTAL:  563 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  563 NUM EXPTS TOTAL:  564\n","BATCH#:  563 NUM EXPTS TOTAL:  564 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  564 NUM EXPTS TOTAL:  565\n","BATCH#:  564 NUM EXPTS TOTAL:  565 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  565 NUM EXPTS TOTAL:  566\n","BATCH#:  565 NUM EXPTS TOTAL:  566 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  566 NUM EXPTS TOTAL:  567\n","BATCH#:  566 NUM EXPTS TOTAL:  567 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  567 NUM EXPTS TOTAL:  568\n","BATCH#:  567 NUM EXPTS TOTAL:  568 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  568 NUM EXPTS TOTAL:  569\n","BATCH#:  568 NUM EXPTS TOTAL:  569 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  569 NUM EXPTS TOTAL:  570\n","BATCH#:  569 NUM EXPTS TOTAL:  570 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  570 NUM EXPTS TOTAL:  571\n","BATCH#:  570 NUM EXPTS TOTAL:  571 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  571 NUM EXPTS TOTAL:  572\n","BATCH#:  571 NUM EXPTS TOTAL:  572 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  572 NUM EXPTS TOTAL:  573\n","BATCH#:  572 NUM EXPTS TOTAL:  573 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  573 NUM EXPTS TOTAL:  574\n","BATCH#:  573 NUM EXPTS TOTAL:  574 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  574 NUM EXPTS TOTAL:  575\n","BATCH#:  574 NUM EXPTS TOTAL:  575 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  575 NUM EXPTS TOTAL:  576\n","BATCH#:  575 NUM EXPTS TOTAL:  576 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  576 NUM EXPTS TOTAL:  577\n","BATCH#:  576 NUM EXPTS TOTAL:  577 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  577 NUM EXPTS TOTAL:  578\n","BATCH#:  577 NUM EXPTS TOTAL:  578 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  578 NUM EXPTS TOTAL:  579\n","BATCH#:  578 NUM EXPTS TOTAL:  579 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  579 NUM EXPTS TOTAL:  580\n","BATCH#:  579 NUM EXPTS TOTAL:  580 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  580 NUM EXPTS TOTAL:  581\n","BATCH#:  580 NUM EXPTS TOTAL:  581 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  581 NUM EXPTS TOTAL:  582\n","BATCH#:  581 NUM EXPTS TOTAL:  582 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  582 NUM EXPTS TOTAL:  583\n","BATCH#:  582 NUM EXPTS TOTAL:  583 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  583 NUM EXPTS TOTAL:  584\n","BATCH#:  583 NUM EXPTS TOTAL:  584 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  584 NUM EXPTS TOTAL:  585\n","BATCH#:  584 NUM EXPTS TOTAL:  585 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  585 NUM EXPTS TOTAL:  586\n","BATCH#:  585 NUM EXPTS TOTAL:  586 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  586 NUM EXPTS TOTAL:  587\n","BATCH#:  586 NUM EXPTS TOTAL:  587 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  587 NUM EXPTS TOTAL:  588\n","BATCH#:  587 NUM EXPTS TOTAL:  588 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  588 NUM EXPTS TOTAL:  589\n","BATCH#:  588 NUM EXPTS TOTAL:  589 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  589 NUM EXPTS TOTAL:  590\n","BATCH#:  589 NUM EXPTS TOTAL:  590 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  590 NUM EXPTS TOTAL:  591\n","BATCH#:  590 NUM EXPTS TOTAL:  591 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  591 NUM EXPTS TOTAL:  592\n","BATCH#:  591 NUM EXPTS TOTAL:  592 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  592 NUM EXPTS TOTAL:  593\n","BATCH#:  592 NUM EXPTS TOTAL:  593 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  593 NUM EXPTS TOTAL:  594\n","BATCH#:  593 NUM EXPTS TOTAL:  594 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  594 NUM EXPTS TOTAL:  595\n","BATCH#:  594 NUM EXPTS TOTAL:  595 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  595 NUM EXPTS TOTAL:  596\n","BATCH#:  595 NUM EXPTS TOTAL:  596 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  596 NUM EXPTS TOTAL:  597\n","BATCH#:  596 NUM EXPTS TOTAL:  597 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  597 NUM EXPTS TOTAL:  598\n","BATCH#:  597 NUM EXPTS TOTAL:  598 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  598 NUM EXPTS TOTAL:  599\n","BATCH#:  598 NUM EXPTS TOTAL:  599 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  599 NUM EXPTS TOTAL:  600\n","BATCH#:  599 NUM EXPTS TOTAL:  600 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  600 NUM EXPTS TOTAL:  601\n","BATCH#:  600 NUM EXPTS TOTAL:  601 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  601 NUM EXPTS TOTAL:  602\n","BATCH#:  601 NUM EXPTS TOTAL:  602 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  602 NUM EXPTS TOTAL:  603\n","BATCH#:  602 NUM EXPTS TOTAL:  603 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  603 NUM EXPTS TOTAL:  604\n","BATCH#:  603 NUM EXPTS TOTAL:  604 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  604 NUM EXPTS TOTAL:  605\n","BATCH#:  604 NUM EXPTS TOTAL:  605 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  605 NUM EXPTS TOTAL:  606\n","BATCH#:  605 NUM EXPTS TOTAL:  606 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  606 NUM EXPTS TOTAL:  607\n","BATCH#:  606 NUM EXPTS TOTAL:  607 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  607 NUM EXPTS TOTAL:  608\n","BATCH#:  607 NUM EXPTS TOTAL:  608 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  608 NUM EXPTS TOTAL:  609\n","BATCH#:  608 NUM EXPTS TOTAL:  609 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  609 NUM EXPTS TOTAL:  610\n","BATCH#:  609 NUM EXPTS TOTAL:  610 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  610 NUM EXPTS TOTAL:  611\n","BATCH#:  610 NUM EXPTS TOTAL:  611 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  611 NUM EXPTS TOTAL:  612\n","BATCH#:  611 NUM EXPTS TOTAL:  612 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  612 NUM EXPTS TOTAL:  613\n","BATCH#:  612 NUM EXPTS TOTAL:  613 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  613 NUM EXPTS TOTAL:  614\n","BATCH#:  613 NUM EXPTS TOTAL:  614 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  614 NUM EXPTS TOTAL:  615\n","BATCH#:  614 NUM EXPTS TOTAL:  615 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  615 NUM EXPTS TOTAL:  616\n","BATCH#:  615 NUM EXPTS TOTAL:  616 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  616 NUM EXPTS TOTAL:  617\n","BATCH#:  616 NUM EXPTS TOTAL:  617 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  617 NUM EXPTS TOTAL:  618\n","BATCH#:  617 NUM EXPTS TOTAL:  618 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  618 NUM EXPTS TOTAL:  619\n","BATCH#:  618 NUM EXPTS TOTAL:  619 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  619 NUM EXPTS TOTAL:  620\n","BATCH#:  619 NUM EXPTS TOTAL:  620 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  620 NUM EXPTS TOTAL:  621\n","BATCH#:  620 NUM EXPTS TOTAL:  621 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  621 NUM EXPTS TOTAL:  622\n","BATCH#:  621 NUM EXPTS TOTAL:  622 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  622 NUM EXPTS TOTAL:  623\n","BATCH#:  622 NUM EXPTS TOTAL:  623 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  623 NUM EXPTS TOTAL:  624\n","BATCH#:  623 NUM EXPTS TOTAL:  624 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  624 NUM EXPTS TOTAL:  625\n","BATCH#:  624 NUM EXPTS TOTAL:  625 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  625 NUM EXPTS TOTAL:  626\n","BATCH#:  625 NUM EXPTS TOTAL:  626 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  626 NUM EXPTS TOTAL:  627\n","BATCH#:  626 NUM EXPTS TOTAL:  627 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  627 NUM EXPTS TOTAL:  628\n","BATCH#:  627 NUM EXPTS TOTAL:  628 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  628 NUM EXPTS TOTAL:  629\n","BATCH#:  628 NUM EXPTS TOTAL:  629 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  629 NUM EXPTS TOTAL:  630\n","BATCH#:  629 NUM EXPTS TOTAL:  630 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  630 NUM EXPTS TOTAL:  631\n","BATCH#:  630 NUM EXPTS TOTAL:  631 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  631 NUM EXPTS TOTAL:  632\n","BATCH#:  631 NUM EXPTS TOTAL:  632 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  632 NUM EXPTS TOTAL:  633\n","BATCH#:  632 NUM EXPTS TOTAL:  633 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  633 NUM EXPTS TOTAL:  634\n","BATCH#:  633 NUM EXPTS TOTAL:  634 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  634 NUM EXPTS TOTAL:  635\n","BATCH#:  634 NUM EXPTS TOTAL:  635 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  635 NUM EXPTS TOTAL:  636\n","BATCH#:  635 NUM EXPTS TOTAL:  636 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  636 NUM EXPTS TOTAL:  637\n","BATCH#:  636 NUM EXPTS TOTAL:  637 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  637 NUM EXPTS TOTAL:  638\n","BATCH#:  637 NUM EXPTS TOTAL:  638 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  638 NUM EXPTS TOTAL:  639\n","BATCH#:  638 NUM EXPTS TOTAL:  639 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  639 NUM EXPTS TOTAL:  640\n","BATCH#:  639 NUM EXPTS TOTAL:  640 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  640 NUM EXPTS TOTAL:  641\n","BATCH#:  640 NUM EXPTS TOTAL:  641 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  641 NUM EXPTS TOTAL:  642\n","BATCH#:  641 NUM EXPTS TOTAL:  642 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  642 NUM EXPTS TOTAL:  643\n","BATCH#:  642 NUM EXPTS TOTAL:  643 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  643 NUM EXPTS TOTAL:  644\n","BATCH#:  643 NUM EXPTS TOTAL:  644 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  644 NUM EXPTS TOTAL:  645\n","BATCH#:  644 NUM EXPTS TOTAL:  645 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  645 NUM EXPTS TOTAL:  646\n","BATCH#:  645 NUM EXPTS TOTAL:  646 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  646 NUM EXPTS TOTAL:  647\n","BATCH#:  646 NUM EXPTS TOTAL:  647 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  647 NUM EXPTS TOTAL:  648\n","BATCH#:  647 NUM EXPTS TOTAL:  648 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  648 NUM EXPTS TOTAL:  649\n","BATCH#:  648 NUM EXPTS TOTAL:  649 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  649 NUM EXPTS TOTAL:  650\n","BATCH#:  649 NUM EXPTS TOTAL:  650 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  650 NUM EXPTS TOTAL:  651\n","BATCH#:  650 NUM EXPTS TOTAL:  651 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  651 NUM EXPTS TOTAL:  652\n","BATCH#:  651 NUM EXPTS TOTAL:  652 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  652 NUM EXPTS TOTAL:  653\n","BATCH#:  652 NUM EXPTS TOTAL:  653 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  653 NUM EXPTS TOTAL:  654\n","BATCH#:  653 NUM EXPTS TOTAL:  654 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  654 NUM EXPTS TOTAL:  655\n","BATCH#:  654 NUM EXPTS TOTAL:  655 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  655 NUM EXPTS TOTAL:  656\n","BATCH#:  655 NUM EXPTS TOTAL:  656 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  656 NUM EXPTS TOTAL:  657\n","BATCH#:  656 NUM EXPTS TOTAL:  657 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  657 NUM EXPTS TOTAL:  658\n","BATCH#:  657 NUM EXPTS TOTAL:  658 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  658 NUM EXPTS TOTAL:  659\n","BATCH#:  658 NUM EXPTS TOTAL:  659 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  659 NUM EXPTS TOTAL:  660\n","BATCH#:  659 NUM EXPTS TOTAL:  660 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  660 NUM EXPTS TOTAL:  661\n","BATCH#:  660 NUM EXPTS TOTAL:  661 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  661 NUM EXPTS TOTAL:  662\n","BATCH#:  661 NUM EXPTS TOTAL:  662 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  662 NUM EXPTS TOTAL:  663\n","BATCH#:  662 NUM EXPTS TOTAL:  663 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  663 NUM EXPTS TOTAL:  664\n","BATCH#:  663 NUM EXPTS TOTAL:  664 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  664 NUM EXPTS TOTAL:  665\n","BATCH#:  664 NUM EXPTS TOTAL:  665 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  665 NUM EXPTS TOTAL:  666\n","BATCH#:  665 NUM EXPTS TOTAL:  666 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  666 NUM EXPTS TOTAL:  667\n","BATCH#:  666 NUM EXPTS TOTAL:  667 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  667 NUM EXPTS TOTAL:  668\n","BATCH#:  667 NUM EXPTS TOTAL:  668 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  668 NUM EXPTS TOTAL:  669\n","BATCH#:  668 NUM EXPTS TOTAL:  669 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  669 NUM EXPTS TOTAL:  670\n","BATCH#:  669 NUM EXPTS TOTAL:  670 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  670 NUM EXPTS TOTAL:  671\n","BATCH#:  670 NUM EXPTS TOTAL:  671 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  671 NUM EXPTS TOTAL:  672\n","BATCH#:  671 NUM EXPTS TOTAL:  672 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  672 NUM EXPTS TOTAL:  673\n","BATCH#:  672 NUM EXPTS TOTAL:  673 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  673 NUM EXPTS TOTAL:  674\n","BATCH#:  673 NUM EXPTS TOTAL:  674 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  674 NUM EXPTS TOTAL:  675\n","BATCH#:  674 NUM EXPTS TOTAL:  675 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  675 NUM EXPTS TOTAL:  676\n","BATCH#:  675 NUM EXPTS TOTAL:  676 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  676 NUM EXPTS TOTAL:  677\n","BATCH#:  676 NUM EXPTS TOTAL:  677 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  677 NUM EXPTS TOTAL:  678\n","BATCH#:  677 NUM EXPTS TOTAL:  678 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  678 NUM EXPTS TOTAL:  679\n","BATCH#:  678 NUM EXPTS TOTAL:  679 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  679 NUM EXPTS TOTAL:  680\n","BATCH#:  679 NUM EXPTS TOTAL:  680 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  680 NUM EXPTS TOTAL:  681\n","BATCH#:  680 NUM EXPTS TOTAL:  681 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  681 NUM EXPTS TOTAL:  682\n","BATCH#:  681 NUM EXPTS TOTAL:  682 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  682 NUM EXPTS TOTAL:  683\n","BATCH#:  682 NUM EXPTS TOTAL:  683 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  683 NUM EXPTS TOTAL:  684\n","BATCH#:  683 NUM EXPTS TOTAL:  684 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  684 NUM EXPTS TOTAL:  685\n","BATCH#:  684 NUM EXPTS TOTAL:  685 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  685 NUM EXPTS TOTAL:  686\n","BATCH#:  685 NUM EXPTS TOTAL:  686 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  686 NUM EXPTS TOTAL:  687\n","BATCH#:  686 NUM EXPTS TOTAL:  687 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  687 NUM EXPTS TOTAL:  688\n","BATCH#:  687 NUM EXPTS TOTAL:  688 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  688 NUM EXPTS TOTAL:  689\n","BATCH#:  688 NUM EXPTS TOTAL:  689 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  689 NUM EXPTS TOTAL:  690\n","BATCH#:  689 NUM EXPTS TOTAL:  690 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  690 NUM EXPTS TOTAL:  691\n","BATCH#:  690 NUM EXPTS TOTAL:  691 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  691 NUM EXPTS TOTAL:  692\n","BATCH#:  691 NUM EXPTS TOTAL:  692 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  692 NUM EXPTS TOTAL:  693\n","BATCH#:  692 NUM EXPTS TOTAL:  693 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  693 NUM EXPTS TOTAL:  694\n","BATCH#:  693 NUM EXPTS TOTAL:  694 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  694 NUM EXPTS TOTAL:  695\n","BATCH#:  694 NUM EXPTS TOTAL:  695 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  695 NUM EXPTS TOTAL:  696\n","BATCH#:  695 NUM EXPTS TOTAL:  696 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  696 NUM EXPTS TOTAL:  697\n","BATCH#:  696 NUM EXPTS TOTAL:  697 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  697 NUM EXPTS TOTAL:  698\n","BATCH#:  697 NUM EXPTS TOTAL:  698 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  698 NUM EXPTS TOTAL:  699\n","BATCH#:  698 NUM EXPTS TOTAL:  699 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  699 NUM EXPTS TOTAL:  700\n","BATCH#:  699 NUM EXPTS TOTAL:  700 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  700 NUM EXPTS TOTAL:  701\n","BATCH#:  700 NUM EXPTS TOTAL:  701 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  701 NUM EXPTS TOTAL:  702\n","BATCH#:  701 NUM EXPTS TOTAL:  702 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  702 NUM EXPTS TOTAL:  703\n","BATCH#:  702 NUM EXPTS TOTAL:  703 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  703 NUM EXPTS TOTAL:  704\n","BATCH#:  703 NUM EXPTS TOTAL:  704 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  704 NUM EXPTS TOTAL:  705\n","BATCH#:  704 NUM EXPTS TOTAL:  705 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  705 NUM EXPTS TOTAL:  706\n","BATCH#:  705 NUM EXPTS TOTAL:  706 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  706 NUM EXPTS TOTAL:  707\n","BATCH#:  706 NUM EXPTS TOTAL:  707 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  707 NUM EXPTS TOTAL:  708\n","BATCH#:  707 NUM EXPTS TOTAL:  708 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  708 NUM EXPTS TOTAL:  709\n","BATCH#:  708 NUM EXPTS TOTAL:  709 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  709 NUM EXPTS TOTAL:  710\n","BATCH#:  709 NUM EXPTS TOTAL:  710 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  710 NUM EXPTS TOTAL:  711\n","BATCH#:  710 NUM EXPTS TOTAL:  711 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  711 NUM EXPTS TOTAL:  712\n","BATCH#:  711 NUM EXPTS TOTAL:  712 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  712 NUM EXPTS TOTAL:  713\n","BATCH#:  712 NUM EXPTS TOTAL:  713 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  713 NUM EXPTS TOTAL:  714\n","BATCH#:  713 NUM EXPTS TOTAL:  714 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  714 NUM EXPTS TOTAL:  715\n","BATCH#:  714 NUM EXPTS TOTAL:  715 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  715 NUM EXPTS TOTAL:  716\n","BATCH#:  715 NUM EXPTS TOTAL:  716 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  716 NUM EXPTS TOTAL:  717\n","BATCH#:  716 NUM EXPTS TOTAL:  717 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  717 NUM EXPTS TOTAL:  718\n","BATCH#:  717 NUM EXPTS TOTAL:  718 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  718 NUM EXPTS TOTAL:  719\n","BATCH#:  718 NUM EXPTS TOTAL:  719 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  719 NUM EXPTS TOTAL:  720\n","BATCH#:  719 NUM EXPTS TOTAL:  720 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  720 NUM EXPTS TOTAL:  721\n","BATCH#:  720 NUM EXPTS TOTAL:  721 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  721 NUM EXPTS TOTAL:  722\n","BATCH#:  721 NUM EXPTS TOTAL:  722 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  722 NUM EXPTS TOTAL:  723\n","BATCH#:  722 NUM EXPTS TOTAL:  723 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  723 NUM EXPTS TOTAL:  724\n","BATCH#:  723 NUM EXPTS TOTAL:  724 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  724 NUM EXPTS TOTAL:  725\n","BATCH#:  724 NUM EXPTS TOTAL:  725 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  725 NUM EXPTS TOTAL:  726\n","BATCH#:  725 NUM EXPTS TOTAL:  726 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  726 NUM EXPTS TOTAL:  727\n","BATCH#:  726 NUM EXPTS TOTAL:  727 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  727 NUM EXPTS TOTAL:  728\n","BATCH#:  727 NUM EXPTS TOTAL:  728 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  728 NUM EXPTS TOTAL:  729\n","BATCH#:  728 NUM EXPTS TOTAL:  729 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  729 NUM EXPTS TOTAL:  730\n","BATCH#:  729 NUM EXPTS TOTAL:  730 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  730 NUM EXPTS TOTAL:  731\n","BATCH#:  730 NUM EXPTS TOTAL:  731 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  731 NUM EXPTS TOTAL:  732\n","BATCH#:  731 NUM EXPTS TOTAL:  732 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  732 NUM EXPTS TOTAL:  733\n","BATCH#:  732 NUM EXPTS TOTAL:  733 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  733 NUM EXPTS TOTAL:  734\n","BATCH#:  733 NUM EXPTS TOTAL:  734 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  734 NUM EXPTS TOTAL:  735\n","BATCH#:  734 NUM EXPTS TOTAL:  735 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  735 NUM EXPTS TOTAL:  736\n","BATCH#:  735 NUM EXPTS TOTAL:  736 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  736 NUM EXPTS TOTAL:  737\n","BATCH#:  736 NUM EXPTS TOTAL:  737 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  737 NUM EXPTS TOTAL:  738\n","BATCH#:  737 NUM EXPTS TOTAL:  738 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  738 NUM EXPTS TOTAL:  739\n","BATCH#:  738 NUM EXPTS TOTAL:  739 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  739 NUM EXPTS TOTAL:  740\n","BATCH#:  739 NUM EXPTS TOTAL:  740 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  740 NUM EXPTS TOTAL:  741\n","BATCH#:  740 NUM EXPTS TOTAL:  741 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  741 NUM EXPTS TOTAL:  742\n","BATCH#:  741 NUM EXPTS TOTAL:  742 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  742 NUM EXPTS TOTAL:  743\n","BATCH#:  742 NUM EXPTS TOTAL:  743 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  743 NUM EXPTS TOTAL:  744\n","BATCH#:  743 NUM EXPTS TOTAL:  744 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  744 NUM EXPTS TOTAL:  745\n","BATCH#:  744 NUM EXPTS TOTAL:  745 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  745 NUM EXPTS TOTAL:  746\n","BATCH#:  745 NUM EXPTS TOTAL:  746 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  746 NUM EXPTS TOTAL:  747\n","BATCH#:  746 NUM EXPTS TOTAL:  747 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  747 NUM EXPTS TOTAL:  748\n","BATCH#:  747 NUM EXPTS TOTAL:  748 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  748 NUM EXPTS TOTAL:  749\n","BATCH#:  748 NUM EXPTS TOTAL:  749 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  749 NUM EXPTS TOTAL:  750\n","BATCH#:  749 NUM EXPTS TOTAL:  750 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  750 NUM EXPTS TOTAL:  751\n","BATCH#:  750 NUM EXPTS TOTAL:  751 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  751 NUM EXPTS TOTAL:  752\n","BATCH#:  751 NUM EXPTS TOTAL:  752 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  752 NUM EXPTS TOTAL:  753\n","BATCH#:  752 NUM EXPTS TOTAL:  753 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  753 NUM EXPTS TOTAL:  754\n","BATCH#:  753 NUM EXPTS TOTAL:  754 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  754 NUM EXPTS TOTAL:  755\n","BATCH#:  754 NUM EXPTS TOTAL:  755 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  755 NUM EXPTS TOTAL:  756\n","BATCH#:  755 NUM EXPTS TOTAL:  756 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  756 NUM EXPTS TOTAL:  757\n","BATCH#:  756 NUM EXPTS TOTAL:  757 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  757 NUM EXPTS TOTAL:  758\n","BATCH#:  757 NUM EXPTS TOTAL:  758 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  758 NUM EXPTS TOTAL:  759\n","BATCH#:  758 NUM EXPTS TOTAL:  759 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  759 NUM EXPTS TOTAL:  760\n","BATCH#:  759 NUM EXPTS TOTAL:  760 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  760 NUM EXPTS TOTAL:  761\n","BATCH#:  760 NUM EXPTS TOTAL:  761 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  761 NUM EXPTS TOTAL:  762\n","BATCH#:  761 NUM EXPTS TOTAL:  762 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  762 NUM EXPTS TOTAL:  763\n","BATCH#:  762 NUM EXPTS TOTAL:  763 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  763 NUM EXPTS TOTAL:  764\n","BATCH#:  763 NUM EXPTS TOTAL:  764 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  764 NUM EXPTS TOTAL:  765\n","BATCH#:  764 NUM EXPTS TOTAL:  765 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  765 NUM EXPTS TOTAL:  766\n","BATCH#:  765 NUM EXPTS TOTAL:  766 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  766 NUM EXPTS TOTAL:  767\n","BATCH#:  766 NUM EXPTS TOTAL:  767 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  767 NUM EXPTS TOTAL:  768\n","BATCH#:  767 NUM EXPTS TOTAL:  768 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  768 NUM EXPTS TOTAL:  769\n","BATCH#:  768 NUM EXPTS TOTAL:  769 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  769 NUM EXPTS TOTAL:  770\n","BATCH#:  769 NUM EXPTS TOTAL:  770 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  770 NUM EXPTS TOTAL:  771\n","BATCH#:  770 NUM EXPTS TOTAL:  771 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  771 NUM EXPTS TOTAL:  772\n","BATCH#:  771 NUM EXPTS TOTAL:  772 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  772 NUM EXPTS TOTAL:  773\n","BATCH#:  772 NUM EXPTS TOTAL:  773 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  773 NUM EXPTS TOTAL:  774\n","BATCH#:  773 NUM EXPTS TOTAL:  774 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  774 NUM EXPTS TOTAL:  775\n","BATCH#:  774 NUM EXPTS TOTAL:  775 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  775 NUM EXPTS TOTAL:  776\n","BATCH#:  775 NUM EXPTS TOTAL:  776 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  776 NUM EXPTS TOTAL:  777\n","BATCH#:  776 NUM EXPTS TOTAL:  777 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  777 NUM EXPTS TOTAL:  778\n","BATCH#:  777 NUM EXPTS TOTAL:  778 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  778 NUM EXPTS TOTAL:  779\n","BATCH#:  778 NUM EXPTS TOTAL:  779 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  779 NUM EXPTS TOTAL:  780\n","BATCH#:  779 NUM EXPTS TOTAL:  780 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  780 NUM EXPTS TOTAL:  781\n","BATCH#:  780 NUM EXPTS TOTAL:  781 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  781 NUM EXPTS TOTAL:  782\n","BATCH#:  781 NUM EXPTS TOTAL:  782 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  782 NUM EXPTS TOTAL:  783\n","BATCH#:  782 NUM EXPTS TOTAL:  783 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  783 NUM EXPTS TOTAL:  784\n","BATCH#:  783 NUM EXPTS TOTAL:  784 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  784 NUM EXPTS TOTAL:  785\n","BATCH#:  784 NUM EXPTS TOTAL:  785 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  785 NUM EXPTS TOTAL:  786\n","BATCH#:  785 NUM EXPTS TOTAL:  786 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  786 NUM EXPTS TOTAL:  787\n","BATCH#:  786 NUM EXPTS TOTAL:  787 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  787 NUM EXPTS TOTAL:  788\n","BATCH#:  787 NUM EXPTS TOTAL:  788 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  788 NUM EXPTS TOTAL:  789\n","BATCH#:  788 NUM EXPTS TOTAL:  789 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  789 NUM EXPTS TOTAL:  790\n","BATCH#:  789 NUM EXPTS TOTAL:  790 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  790 NUM EXPTS TOTAL:  791\n","BATCH#:  790 NUM EXPTS TOTAL:  791 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  791 NUM EXPTS TOTAL:  792\n","BATCH#:  791 NUM EXPTS TOTAL:  792 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  792 NUM EXPTS TOTAL:  793\n","BATCH#:  792 NUM EXPTS TOTAL:  793 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  793 NUM EXPTS TOTAL:  794\n","BATCH#:  793 NUM EXPTS TOTAL:  794 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  794 NUM EXPTS TOTAL:  795\n","BATCH#:  794 NUM EXPTS TOTAL:  795 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  795 NUM EXPTS TOTAL:  796\n","BATCH#:  795 NUM EXPTS TOTAL:  796 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  796 NUM EXPTS TOTAL:  797\n","BATCH#:  796 NUM EXPTS TOTAL:  797 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  797 NUM EXPTS TOTAL:  798\n","BATCH#:  797 NUM EXPTS TOTAL:  798 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  798 NUM EXPTS TOTAL:  799\n","BATCH#:  798 NUM EXPTS TOTAL:  799 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  799 NUM EXPTS TOTAL:  800\n","BATCH#:  799 NUM EXPTS TOTAL:  800 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  800 NUM EXPTS TOTAL:  801\n","BATCH#:  800 NUM EXPTS TOTAL:  801 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  801 NUM EXPTS TOTAL:  802\n","BATCH#:  801 NUM EXPTS TOTAL:  802 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  802 NUM EXPTS TOTAL:  803\n","BATCH#:  802 NUM EXPTS TOTAL:  803 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  803 NUM EXPTS TOTAL:  804\n","BATCH#:  803 NUM EXPTS TOTAL:  804 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  804 NUM EXPTS TOTAL:  805\n","BATCH#:  804 NUM EXPTS TOTAL:  805 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  805 NUM EXPTS TOTAL:  806\n","BATCH#:  805 NUM EXPTS TOTAL:  806 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  806 NUM EXPTS TOTAL:  807\n","BATCH#:  806 NUM EXPTS TOTAL:  807 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  807 NUM EXPTS TOTAL:  808\n","BATCH#:  807 NUM EXPTS TOTAL:  808 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  808 NUM EXPTS TOTAL:  809\n","BATCH#:  808 NUM EXPTS TOTAL:  809 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  809 NUM EXPTS TOTAL:  810\n","BATCH#:  809 NUM EXPTS TOTAL:  810 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  810 NUM EXPTS TOTAL:  811\n","BATCH#:  810 NUM EXPTS TOTAL:  811 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  811 NUM EXPTS TOTAL:  812\n","BATCH#:  811 NUM EXPTS TOTAL:  812 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  812 NUM EXPTS TOTAL:  813\n","BATCH#:  812 NUM EXPTS TOTAL:  813 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  813 NUM EXPTS TOTAL:  814\n","BATCH#:  813 NUM EXPTS TOTAL:  814 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  814 NUM EXPTS TOTAL:  815\n","BATCH#:  814 NUM EXPTS TOTAL:  815 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  815 NUM EXPTS TOTAL:  816\n","BATCH#:  815 NUM EXPTS TOTAL:  816 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  816 NUM EXPTS TOTAL:  817\n","BATCH#:  816 NUM EXPTS TOTAL:  817 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  817 NUM EXPTS TOTAL:  818\n","BATCH#:  817 NUM EXPTS TOTAL:  818 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  818 NUM EXPTS TOTAL:  819\n","BATCH#:  818 NUM EXPTS TOTAL:  819 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  819 NUM EXPTS TOTAL:  820\n","BATCH#:  819 NUM EXPTS TOTAL:  820 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  820 NUM EXPTS TOTAL:  821\n","BATCH#:  820 NUM EXPTS TOTAL:  821 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  821 NUM EXPTS TOTAL:  822\n","BATCH#:  821 NUM EXPTS TOTAL:  822 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  822 NUM EXPTS TOTAL:  823\n","BATCH#:  822 NUM EXPTS TOTAL:  823 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  823 NUM EXPTS TOTAL:  824\n","BATCH#:  823 NUM EXPTS TOTAL:  824 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  824 NUM EXPTS TOTAL:  825\n","BATCH#:  824 NUM EXPTS TOTAL:  825 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  825 NUM EXPTS TOTAL:  826\n","BATCH#:  825 NUM EXPTS TOTAL:  826 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  826 NUM EXPTS TOTAL:  827\n","BATCH#:  826 NUM EXPTS TOTAL:  827 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  827 NUM EXPTS TOTAL:  828\n","BATCH#:  827 NUM EXPTS TOTAL:  828 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  828 NUM EXPTS TOTAL:  829\n","BATCH#:  828 NUM EXPTS TOTAL:  829 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  829 NUM EXPTS TOTAL:  830\n","BATCH#:  829 NUM EXPTS TOTAL:  830 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  830 NUM EXPTS TOTAL:  831\n","BATCH#:  830 NUM EXPTS TOTAL:  831 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  831 NUM EXPTS TOTAL:  832\n","BATCH#:  831 NUM EXPTS TOTAL:  832 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  832 NUM EXPTS TOTAL:  833\n","BATCH#:  832 NUM EXPTS TOTAL:  833 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  833 NUM EXPTS TOTAL:  834\n","BATCH#:  833 NUM EXPTS TOTAL:  834 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  834 NUM EXPTS TOTAL:  835\n","BATCH#:  834 NUM EXPTS TOTAL:  835 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  835 NUM EXPTS TOTAL:  836\n","BATCH#:  835 NUM EXPTS TOTAL:  836 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  836 NUM EXPTS TOTAL:  837\n","BATCH#:  836 NUM EXPTS TOTAL:  837 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  837 NUM EXPTS TOTAL:  838\n","BATCH#:  837 NUM EXPTS TOTAL:  838 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  838 NUM EXPTS TOTAL:  839\n","BATCH#:  838 NUM EXPTS TOTAL:  839 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  839 NUM EXPTS TOTAL:  840\n","BATCH#:  839 NUM EXPTS TOTAL:  840 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  840 NUM EXPTS TOTAL:  841\n","BATCH#:  840 NUM EXPTS TOTAL:  841 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  841 NUM EXPTS TOTAL:  842\n","BATCH#:  841 NUM EXPTS TOTAL:  842 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  842 NUM EXPTS TOTAL:  843\n","BATCH#:  842 NUM EXPTS TOTAL:  843 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  843 NUM EXPTS TOTAL:  844\n","BATCH#:  843 NUM EXPTS TOTAL:  844 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  844 NUM EXPTS TOTAL:  845\n","BATCH#:  844 NUM EXPTS TOTAL:  845 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  845 NUM EXPTS TOTAL:  846\n","BATCH#:  845 NUM EXPTS TOTAL:  846 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  846 NUM EXPTS TOTAL:  847\n","BATCH#:  846 NUM EXPTS TOTAL:  847 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  847 NUM EXPTS TOTAL:  848\n","BATCH#:  847 NUM EXPTS TOTAL:  848 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  848 NUM EXPTS TOTAL:  849\n","BATCH#:  848 NUM EXPTS TOTAL:  849 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  849 NUM EXPTS TOTAL:  850\n","BATCH#:  849 NUM EXPTS TOTAL:  850 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  850 NUM EXPTS TOTAL:  851\n","BATCH#:  850 NUM EXPTS TOTAL:  851 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  851 NUM EXPTS TOTAL:  852\n","BATCH#:  851 NUM EXPTS TOTAL:  852 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  852 NUM EXPTS TOTAL:  853\n","BATCH#:  852 NUM EXPTS TOTAL:  853 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  853 NUM EXPTS TOTAL:  854\n","BATCH#:  853 NUM EXPTS TOTAL:  854 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  854 NUM EXPTS TOTAL:  855\n","BATCH#:  854 NUM EXPTS TOTAL:  855 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  855 NUM EXPTS TOTAL:  856\n","BATCH#:  855 NUM EXPTS TOTAL:  856 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  856 NUM EXPTS TOTAL:  857\n","BATCH#:  856 NUM EXPTS TOTAL:  857 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  857 NUM EXPTS TOTAL:  858\n","BATCH#:  857 NUM EXPTS TOTAL:  858 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  858 NUM EXPTS TOTAL:  859\n","BATCH#:  858 NUM EXPTS TOTAL:  859 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  859 NUM EXPTS TOTAL:  860\n","BATCH#:  859 NUM EXPTS TOTAL:  860 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  860 NUM EXPTS TOTAL:  861\n","BATCH#:  860 NUM EXPTS TOTAL:  861 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  861 NUM EXPTS TOTAL:  862\n","BATCH#:  861 NUM EXPTS TOTAL:  862 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  862 NUM EXPTS TOTAL:  863\n","BATCH#:  862 NUM EXPTS TOTAL:  863 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  863 NUM EXPTS TOTAL:  864\n","BATCH#:  863 NUM EXPTS TOTAL:  864 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  864 NUM EXPTS TOTAL:  865\n","BATCH#:  864 NUM EXPTS TOTAL:  865 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  865 NUM EXPTS TOTAL:  866\n","BATCH#:  865 NUM EXPTS TOTAL:  866 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  866 NUM EXPTS TOTAL:  867\n","BATCH#:  866 NUM EXPTS TOTAL:  867 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  867 NUM EXPTS TOTAL:  868\n","BATCH#:  867 NUM EXPTS TOTAL:  868 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  868 NUM EXPTS TOTAL:  869\n","BATCH#:  868 NUM EXPTS TOTAL:  869 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  869 NUM EXPTS TOTAL:  870\n","BATCH#:  869 NUM EXPTS TOTAL:  870 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  870 NUM EXPTS TOTAL:  871\n","BATCH#:  870 NUM EXPTS TOTAL:  871 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  871 NUM EXPTS TOTAL:  872\n","BATCH#:  871 NUM EXPTS TOTAL:  872 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  872 NUM EXPTS TOTAL:  873\n","BATCH#:  872 NUM EXPTS TOTAL:  873 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  873 NUM EXPTS TOTAL:  874\n","BATCH#:  873 NUM EXPTS TOTAL:  874 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  874 NUM EXPTS TOTAL:  875\n","BATCH#:  874 NUM EXPTS TOTAL:  875 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  875 NUM EXPTS TOTAL:  876\n","BATCH#:  875 NUM EXPTS TOTAL:  876 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  876 NUM EXPTS TOTAL:  877\n","BATCH#:  876 NUM EXPTS TOTAL:  877 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  877 NUM EXPTS TOTAL:  878\n","BATCH#:  877 NUM EXPTS TOTAL:  878 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  878 NUM EXPTS TOTAL:  879\n","BATCH#:  878 NUM EXPTS TOTAL:  879 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  879 NUM EXPTS TOTAL:  880\n","BATCH#:  879 NUM EXPTS TOTAL:  880 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  880 NUM EXPTS TOTAL:  881\n","BATCH#:  880 NUM EXPTS TOTAL:  881 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  881 NUM EXPTS TOTAL:  882\n","BATCH#:  881 NUM EXPTS TOTAL:  882 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  882 NUM EXPTS TOTAL:  883\n","BATCH#:  882 NUM EXPTS TOTAL:  883 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  883 NUM EXPTS TOTAL:  884\n","BATCH#:  883 NUM EXPTS TOTAL:  884 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  884 NUM EXPTS TOTAL:  885\n","BATCH#:  884 NUM EXPTS TOTAL:  885 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  885 NUM EXPTS TOTAL:  886\n","BATCH#:  885 NUM EXPTS TOTAL:  886 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  886 NUM EXPTS TOTAL:  887\n","BATCH#:  886 NUM EXPTS TOTAL:  887 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  887 NUM EXPTS TOTAL:  888\n","BATCH#:  887 NUM EXPTS TOTAL:  888 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  888 NUM EXPTS TOTAL:  889\n","BATCH#:  888 NUM EXPTS TOTAL:  889 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  889 NUM EXPTS TOTAL:  890\n","BATCH#:  889 NUM EXPTS TOTAL:  890 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  890 NUM EXPTS TOTAL:  891\n","BATCH#:  890 NUM EXPTS TOTAL:  891 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  891 NUM EXPTS TOTAL:  892\n","BATCH#:  891 NUM EXPTS TOTAL:  892 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  892 NUM EXPTS TOTAL:  893\n","BATCH#:  892 NUM EXPTS TOTAL:  893 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  893 NUM EXPTS TOTAL:  894\n","BATCH#:  893 NUM EXPTS TOTAL:  894 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  894 NUM EXPTS TOTAL:  895\n","BATCH#:  894 NUM EXPTS TOTAL:  895 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  895 NUM EXPTS TOTAL:  896\n","BATCH#:  895 NUM EXPTS TOTAL:  896 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  896 NUM EXPTS TOTAL:  897\n","BATCH#:  896 NUM EXPTS TOTAL:  897 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  897 NUM EXPTS TOTAL:  898\n","BATCH#:  897 NUM EXPTS TOTAL:  898 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  898 NUM EXPTS TOTAL:  899\n","BATCH#:  898 NUM EXPTS TOTAL:  899 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  899 NUM EXPTS TOTAL:  900\n","BATCH#:  899 NUM EXPTS TOTAL:  900 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  900 NUM EXPTS TOTAL:  901\n","BATCH#:  900 NUM EXPTS TOTAL:  901 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  901 NUM EXPTS TOTAL:  902\n","BATCH#:  901 NUM EXPTS TOTAL:  902 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  902 NUM EXPTS TOTAL:  903\n","BATCH#:  902 NUM EXPTS TOTAL:  903 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  903 NUM EXPTS TOTAL:  904\n","BATCH#:  903 NUM EXPTS TOTAL:  904 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  904 NUM EXPTS TOTAL:  905\n","BATCH#:  904 NUM EXPTS TOTAL:  905 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  905 NUM EXPTS TOTAL:  906\n","BATCH#:  905 NUM EXPTS TOTAL:  906 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  906 NUM EXPTS TOTAL:  907\n","BATCH#:  906 NUM EXPTS TOTAL:  907 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  907 NUM EXPTS TOTAL:  908\n","BATCH#:  907 NUM EXPTS TOTAL:  908 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  908 NUM EXPTS TOTAL:  909\n","BATCH#:  908 NUM EXPTS TOTAL:  909 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  909 NUM EXPTS TOTAL:  910\n","BATCH#:  909 NUM EXPTS TOTAL:  910 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  910 NUM EXPTS TOTAL:  911\n","BATCH#:  910 NUM EXPTS TOTAL:  911 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  911 NUM EXPTS TOTAL:  912\n","BATCH#:  911 NUM EXPTS TOTAL:  912 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  912 NUM EXPTS TOTAL:  913\n","BATCH#:  912 NUM EXPTS TOTAL:  913 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  913 NUM EXPTS TOTAL:  914\n","BATCH#:  913 NUM EXPTS TOTAL:  914 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  914 NUM EXPTS TOTAL:  915\n","BATCH#:  914 NUM EXPTS TOTAL:  915 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  915 NUM EXPTS TOTAL:  916\n","BATCH#:  915 NUM EXPTS TOTAL:  916 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  916 NUM EXPTS TOTAL:  917\n","BATCH#:  916 NUM EXPTS TOTAL:  917 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  917 NUM EXPTS TOTAL:  918\n","BATCH#:  917 NUM EXPTS TOTAL:  918 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  918 NUM EXPTS TOTAL:  919\n","BATCH#:  918 NUM EXPTS TOTAL:  919 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  919 NUM EXPTS TOTAL:  920\n","BATCH#:  919 NUM EXPTS TOTAL:  920 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  920 NUM EXPTS TOTAL:  921\n","BATCH#:  920 NUM EXPTS TOTAL:  921 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  921 NUM EXPTS TOTAL:  922\n","BATCH#:  921 NUM EXPTS TOTAL:  922 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  922 NUM EXPTS TOTAL:  923\n","BATCH#:  922 NUM EXPTS TOTAL:  923 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  923 NUM EXPTS TOTAL:  924\n","BATCH#:  923 NUM EXPTS TOTAL:  924 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  924 NUM EXPTS TOTAL:  925\n","BATCH#:  924 NUM EXPTS TOTAL:  925 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  925 NUM EXPTS TOTAL:  926\n","BATCH#:  925 NUM EXPTS TOTAL:  926 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  926 NUM EXPTS TOTAL:  927\n","BATCH#:  926 NUM EXPTS TOTAL:  927 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  927 NUM EXPTS TOTAL:  928\n","BATCH#:  927 NUM EXPTS TOTAL:  928 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  928 NUM EXPTS TOTAL:  929\n","BATCH#:  928 NUM EXPTS TOTAL:  929 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  929 NUM EXPTS TOTAL:  930\n","BATCH#:  929 NUM EXPTS TOTAL:  930 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  930 NUM EXPTS TOTAL:  931\n","BATCH#:  930 NUM EXPTS TOTAL:  931 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  931 NUM EXPTS TOTAL:  932\n","BATCH#:  931 NUM EXPTS TOTAL:  932 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  932 NUM EXPTS TOTAL:  933\n","BATCH#:  932 NUM EXPTS TOTAL:  933 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  933 NUM EXPTS TOTAL:  934\n","BATCH#:  933 NUM EXPTS TOTAL:  934 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  934 NUM EXPTS TOTAL:  935\n","BATCH#:  934 NUM EXPTS TOTAL:  935 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  935 NUM EXPTS TOTAL:  936\n","BATCH#:  935 NUM EXPTS TOTAL:  936 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  936 NUM EXPTS TOTAL:  937\n","BATCH#:  936 NUM EXPTS TOTAL:  937 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  937 NUM EXPTS TOTAL:  938\n","BATCH#:  937 NUM EXPTS TOTAL:  938 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  938 NUM EXPTS TOTAL:  939\n","BATCH#:  938 NUM EXPTS TOTAL:  939 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  939 NUM EXPTS TOTAL:  940\n","BATCH#:  939 NUM EXPTS TOTAL:  940 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  940 NUM EXPTS TOTAL:  941\n","BATCH#:  940 NUM EXPTS TOTAL:  941 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  941 NUM EXPTS TOTAL:  942\n","BATCH#:  941 NUM EXPTS TOTAL:  942 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  942 NUM EXPTS TOTAL:  943\n","BATCH#:  942 NUM EXPTS TOTAL:  943 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  943 NUM EXPTS TOTAL:  944\n","BATCH#:  943 NUM EXPTS TOTAL:  944 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  944 NUM EXPTS TOTAL:  945\n","BATCH#:  944 NUM EXPTS TOTAL:  945 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  945 NUM EXPTS TOTAL:  946\n","BATCH#:  945 NUM EXPTS TOTAL:  946 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  946 NUM EXPTS TOTAL:  947\n","BATCH#:  946 NUM EXPTS TOTAL:  947 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  947 NUM EXPTS TOTAL:  948\n","BATCH#:  947 NUM EXPTS TOTAL:  948 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  948 NUM EXPTS TOTAL:  949\n","BATCH#:  948 NUM EXPTS TOTAL:  949 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  949 NUM EXPTS TOTAL:  950\n","BATCH#:  949 NUM EXPTS TOTAL:  950 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  950 NUM EXPTS TOTAL:  951\n","BATCH#:  950 NUM EXPTS TOTAL:  951 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  951 NUM EXPTS TOTAL:  952\n","BATCH#:  951 NUM EXPTS TOTAL:  952 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  952 NUM EXPTS TOTAL:  953\n","BATCH#:  952 NUM EXPTS TOTAL:  953 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  953 NUM EXPTS TOTAL:  954\n","BATCH#:  953 NUM EXPTS TOTAL:  954 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  954 NUM EXPTS TOTAL:  955\n","BATCH#:  954 NUM EXPTS TOTAL:  955 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  955 NUM EXPTS TOTAL:  956\n","BATCH#:  955 NUM EXPTS TOTAL:  956 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  956 NUM EXPTS TOTAL:  957\n","BATCH#:  956 NUM EXPTS TOTAL:  957 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  957 NUM EXPTS TOTAL:  958\n","BATCH#:  957 NUM EXPTS TOTAL:  958 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  958 NUM EXPTS TOTAL:  959\n","BATCH#:  958 NUM EXPTS TOTAL:  959 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  959 NUM EXPTS TOTAL:  960\n","BATCH#:  959 NUM EXPTS TOTAL:  960 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  960 NUM EXPTS TOTAL:  961\n","BATCH#:  960 NUM EXPTS TOTAL:  961 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  961 NUM EXPTS TOTAL:  962\n","BATCH#:  961 NUM EXPTS TOTAL:  962 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  962 NUM EXPTS TOTAL:  963\n","BATCH#:  962 NUM EXPTS TOTAL:  963 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  963 NUM EXPTS TOTAL:  964\n","BATCH#:  963 NUM EXPTS TOTAL:  964 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  964 NUM EXPTS TOTAL:  965\n","BATCH#:  964 NUM EXPTS TOTAL:  965 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  965 NUM EXPTS TOTAL:  966\n","BATCH#:  965 NUM EXPTS TOTAL:  966 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  966 NUM EXPTS TOTAL:  967\n","BATCH#:  966 NUM EXPTS TOTAL:  967 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  967 NUM EXPTS TOTAL:  968\n","BATCH#:  967 NUM EXPTS TOTAL:  968 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  968 NUM EXPTS TOTAL:  969\n","BATCH#:  968 NUM EXPTS TOTAL:  969 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  969 NUM EXPTS TOTAL:  970\n","BATCH#:  969 NUM EXPTS TOTAL:  970 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  970 NUM EXPTS TOTAL:  971\n","BATCH#:  970 NUM EXPTS TOTAL:  971 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  971 NUM EXPTS TOTAL:  972\n","BATCH#:  971 NUM EXPTS TOTAL:  972 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  972 NUM EXPTS TOTAL:  973\n","BATCH#:  972 NUM EXPTS TOTAL:  973 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  973 NUM EXPTS TOTAL:  974\n","BATCH#:  973 NUM EXPTS TOTAL:  974 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  974 NUM EXPTS TOTAL:  975\n","BATCH#:  974 NUM EXPTS TOTAL:  975 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  975 NUM EXPTS TOTAL:  976\n","BATCH#:  975 NUM EXPTS TOTAL:  976 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  976 NUM EXPTS TOTAL:  977\n","BATCH#:  976 NUM EXPTS TOTAL:  977 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  977 NUM EXPTS TOTAL:  978\n","BATCH#:  977 NUM EXPTS TOTAL:  978 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  978 NUM EXPTS TOTAL:  979\n","BATCH#:  978 NUM EXPTS TOTAL:  979 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  979 NUM EXPTS TOTAL:  980\n","BATCH#:  979 NUM EXPTS TOTAL:  980 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  980 NUM EXPTS TOTAL:  981\n","BATCH#:  980 NUM EXPTS TOTAL:  981 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  981 NUM EXPTS TOTAL:  982\n","BATCH#:  981 NUM EXPTS TOTAL:  982 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  982 NUM EXPTS TOTAL:  983\n","BATCH#:  982 NUM EXPTS TOTAL:  983 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  983 NUM EXPTS TOTAL:  984\n","BATCH#:  983 NUM EXPTS TOTAL:  984 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  984 NUM EXPTS TOTAL:  985\n","BATCH#:  984 NUM EXPTS TOTAL:  985 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  985 NUM EXPTS TOTAL:  986\n","BATCH#:  985 NUM EXPTS TOTAL:  986 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  986 NUM EXPTS TOTAL:  987\n","BATCH#:  986 NUM EXPTS TOTAL:  987 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  987 NUM EXPTS TOTAL:  988\n","BATCH#:  987 NUM EXPTS TOTAL:  988 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  988 NUM EXPTS TOTAL:  989\n","BATCH#:  988 NUM EXPTS TOTAL:  989 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  989 NUM EXPTS TOTAL:  990\n","BATCH#:  989 NUM EXPTS TOTAL:  990 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  990 NUM EXPTS TOTAL:  991\n","BATCH#:  990 NUM EXPTS TOTAL:  991 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  991 NUM EXPTS TOTAL:  992\n","BATCH#:  991 NUM EXPTS TOTAL:  992 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  992 NUM EXPTS TOTAL:  993\n","BATCH#:  992 NUM EXPTS TOTAL:  993 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  993 NUM EXPTS TOTAL:  994\n","BATCH#:  993 NUM EXPTS TOTAL:  994 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  994 NUM EXPTS TOTAL:  995\n","BATCH#:  994 NUM EXPTS TOTAL:  995 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  995 NUM EXPTS TOTAL:  996\n","BATCH#:  995 NUM EXPTS TOTAL:  996 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  996 NUM EXPTS TOTAL:  997\n","BATCH#:  996 NUM EXPTS TOTAL:  997 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  997 NUM EXPTS TOTAL:  998\n","BATCH#:  997 NUM EXPTS TOTAL:  998 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  998 NUM EXPTS TOTAL:  999\n","BATCH#:  998 NUM EXPTS TOTAL:  999 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  999 NUM EXPTS TOTAL:  1000\n","BATCH#:  999 NUM EXPTS TOTAL:  1000 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1000 NUM EXPTS TOTAL:  1001\n","BATCH#:  1000 NUM EXPTS TOTAL:  1001 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1001 NUM EXPTS TOTAL:  1002\n","BATCH#:  1001 NUM EXPTS TOTAL:  1002 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1002 NUM EXPTS TOTAL:  1003\n","BATCH#:  1002 NUM EXPTS TOTAL:  1003 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1003 NUM EXPTS TOTAL:  1004\n","BATCH#:  1003 NUM EXPTS TOTAL:  1004 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1004 NUM EXPTS TOTAL:  1005\n","BATCH#:  1004 NUM EXPTS TOTAL:  1005 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1005 NUM EXPTS TOTAL:  1006\n","BATCH#:  1005 NUM EXPTS TOTAL:  1006 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1006 NUM EXPTS TOTAL:  1007\n","BATCH#:  1006 NUM EXPTS TOTAL:  1007 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1007 NUM EXPTS TOTAL:  1008\n","BATCH#:  1007 NUM EXPTS TOTAL:  1008 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1008 NUM EXPTS TOTAL:  1009\n","BATCH#:  1008 NUM EXPTS TOTAL:  1009 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1009 NUM EXPTS TOTAL:  1010\n","BATCH#:  1009 NUM EXPTS TOTAL:  1010 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1010 NUM EXPTS TOTAL:  1011\n","BATCH#:  1010 NUM EXPTS TOTAL:  1011 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1011 NUM EXPTS TOTAL:  1012\n","BATCH#:  1011 NUM EXPTS TOTAL:  1012 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1012 NUM EXPTS TOTAL:  1013\n","BATCH#:  1012 NUM EXPTS TOTAL:  1013 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1013 NUM EXPTS TOTAL:  1014\n","BATCH#:  1013 NUM EXPTS TOTAL:  1014 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1014 NUM EXPTS TOTAL:  1015\n","BATCH#:  1014 NUM EXPTS TOTAL:  1015 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1015 NUM EXPTS TOTAL:  1016\n","BATCH#:  1015 NUM EXPTS TOTAL:  1016 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1016 NUM EXPTS TOTAL:  1017\n","BATCH#:  1016 NUM EXPTS TOTAL:  1017 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1017 NUM EXPTS TOTAL:  1018\n","BATCH#:  1017 NUM EXPTS TOTAL:  1018 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1018 NUM EXPTS TOTAL:  1019\n","BATCH#:  1018 NUM EXPTS TOTAL:  1019 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1019 NUM EXPTS TOTAL:  1020\n","BATCH#:  1019 NUM EXPTS TOTAL:  1020 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1020 NUM EXPTS TOTAL:  1021\n","BATCH#:  1020 NUM EXPTS TOTAL:  1021 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1021 NUM EXPTS TOTAL:  1022\n","BATCH#:  1021 NUM EXPTS TOTAL:  1022 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([0])\n","BATCH#:  1022 NUM EXPTS TOTAL:  1023\n","BATCH#:  1022 NUM EXPTS TOTAL:  1023 PREDICTION:  tensor([1.], device='cuda:0') TRUE LABELS:  tensor([1])\n","BATCH#:  1023 NUM EXPTS TOTAL:  1024\n","BATCH#:  1023 NUM EXPTS TOTAL:  1024 PREDICTION:  tensor([0.], device='cuda:0') TRUE LABELS:  tensor([1])\n","Average OOD Experiment Accuracy:  49.51171875\n"]}],"source":["# Set eval model for inference\n","# initialize to store results of model predictions and compare with ground-truth\n","# use generate text with only one token\n","# extract only the max score token YES (0 label) or NO (1 label)\n","\n","example_myOPT_CD_FT.eval()\n","\n","model_pred = torch.zeros(0, dtype=torch.long).to(device)\n","ground_truth = torch.zeros(0, dtype=torch.long).to(device)\n","\n","with torch.no_grad():\n","    for i, batch in enumerate(dataloader_VALOOD):\n","\n","        print(\"BATCH#: \", i, \"NUM EXPTS TOTAL: \", (i+1)*bx_size)\n","\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","\n","        gen_tokens = torch.tensor(1)\n","        gen_tokens = gen_tokens.to(device)\n","\n","\n","        # output only the binary yes/no,\n","        _, binary_yes_no, _ = example_myOPT_CD_FT.generate_text(input_ids, attention_mask, gen_tokens=gen_tokens)\n","        model_pred = torch.cat((model_pred, binary_yes_no), dim=0)\n","        ground_truth = torch.cat((ground_truth, batch['labels'].to(device)), dim=0)\n","\n","        print(\"BATCH#: \", i, \"NUM EXPTS TOTAL: \", (i+1)*bx_size, \"PREDICTION: \", binary_yes_no, \"TRUE LABELS: \", batch['labels'].detach())\n","\n","accuracy_calc = (100*torch.sum(model_pred == ground_truth)/(model_pred.shape[0])).item()\n","print(\"Average OOD Experiment Accuracy: \", accuracy_calc)"]},{"cell_type":"code","execution_count":71,"metadata":{"id":"uFlmmLnPwuQJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523933466,"user_tz":-120,"elapsed":32,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"d19c40f1-3892-4413-b473-ae0d87eb672b"},"outputs":[{"output_type":"stream","name":"stdout","text":["YES answer (%):  78.61328125\n","NO  answer (%):  21.38671875\n"]}],"source":["# Evaluate results beyond accuracy:\n","\n","print(\"YES answer (%): \", ((torch.sum(model_pred==0))/len(model_pred)).item()*100)\n","print(\"NO  answer (%): \", ((torch.sum(model_pred==1))/len(model_pred)).item()*100)"]},{"cell_type":"code","source":[],"metadata":{"id":"vQQTA8ZmCsoq","executionInfo":{"status":"ok","timestamp":1714523933466,"user_tz":-120,"elapsed":5,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":["# 8. ANALYSIS OF EMBEDDING WEIGHTS AND EXPORT TO CSV"],"metadata":{"id":"OHmtIZY2MSL6"}},{"cell_type":"code","source":["# Check parameters change and store results for later use"],"metadata":{"id":"9OHBvY-BDV_l","executionInfo":{"status":"ok","timestamp":1714523933466,"user_tz":-120,"elapsed":4,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["diff_emb_weights = torch.abs(example_myOPT_CD_FT.coreOPT.decoder.embed_tokens.weight - example_myBaseOPT_CD.coreOPT.decoder.embed_tokens.weight)\n","print(diff_emb_weights.shape)\n","diff_emb_weights_norm = torch.norm(diff_emb_weights, dim=1)\n","print(diff_emb_weights_norm.shape)\n","diff_emb_weights_norm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ko1CCVJriOQ","executionInfo":{"status":"ok","timestamp":1714523933466,"user_tz":-120,"elapsed":4,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"916fcb6b-1c91-43be-e324-ccd829fc8ede"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([50272, 2048])\n","torch.Size([50272])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([0.0000, 0.0000, 0.1862,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0',\n","       grad_fn=<LinalgVectorNormBackward0>)"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["values, indices = torch.sort(diff_emb_weights_norm, descending=True)\n","non_zero_indices = torch.nonzero(diff_emb_weights_norm).squeeze()\n","print(\"Number of embedding weights that have changed: \", len(non_zero_indices))\n","values_non_zero = values[:len(non_zero_indices)]\n","indices_non_zero = indices[:len(non_zero_indices)]"],"metadata":{"id":"AtSl6yOcriMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523933806,"user_tz":-120,"elapsed":343,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"32ccbfc4-976d-4cd9-8270-74ce28367b01"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of embedding weights that have changed:  254\n"]}]},{"cell_type":"code","source":["values_nz = values_non_zero.flatten()\n","indices_nz = indices_non_zero.flatten()\n","for ind_value, ind_index in zip(values_nz, indices_nz):\n","      print(f\"Value: {ind_value.item()}, Index: {ind_index.item()}, Token: {OPT_tokenizer.batch_decode(torch.unsqueeze(ind_index, 0))}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7QffRhKXPYu_","executionInfo":{"status":"ok","timestamp":1714523933806,"user_tz":-120,"elapsed":9,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}},"outputId":"6c056782-02af-482c-faf3-1978c6492f01"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["Value: 0.3321962058544159, Index: 50, Token: [' or']\n","Value: 0.3097049295902252, Index: 440, Token: [' No']\n","Value: 0.24301064014434814, Index: 116, Token: ['?']\n","Value: 0.24140039086341858, Index: 1948, Token: [' answer']\n","Value: 0.23455820977687836, Index: 3216, Token: [' Yes']\n","Value: 0.22624626755714417, Index: 21402, Token: ['�']\n","Value: 0.21894554793834686, Index: 49463, Token: ['.}']\n","Value: 0.20666323602199554, Index: 35, Token: [':']\n","Value: 0.19814372062683105, Index: 4236, Token: [' �']\n","Value: 0.18844076991081238, Index: 25522, Token: [' {']\n","Value: 0.18623562157154083, Index: 2, Token: ['</s>']\n","Value: 0.1838894933462143, Index: 864, Token: [' question']\n","Value: 0.16511039435863495, Index: 8, Token: [' and']\n","Value: 0.15229174494743347, Index: 45152, Token: ['{']\n","Value: 0.1484680026769638, Index: 7, Token: [' to']\n","Value: 0.14085376262664795, Index: 24303, Token: ['}']\n","Value: 0.13564009964466095, Index: 45, Token: [' not']\n","Value: 0.13509123027324677, Index: 243, Token: ['It']\n","Value: 0.13352066278457642, Index: 5, Token: [' the']\n","Value: 0.12981343269348145, Index: 41, Token: [' an']\n","Value: 0.1268085539340973, Index: 7298, Token: [' History']\n","Value: 0.12588447332382202, Index: 35524, Token: [' }']\n","Value: 0.12454686313867569, Index: 3292, Token: [' Art']\n","Value: 0.12333764135837555, Index: 18, Token: [\"'s\"]\n","Value: 0.12274503707885742, Index: 16, Token: [' is']\n","Value: 0.12237290292978287, Index: 23295, Token: ['Art']\n","Value: 0.12116774171590805, Index: 657, Token: [' love']\n","Value: 0.12108185887336731, Index: 11, Token: [' in']\n","Value: 0.12064015120267868, Index: 42803, Token: ['yeah']\n","Value: 0.12047325819730759, Index: 22138, Token: ['Young']\n","Value: 0.12041892111301422, Index: 240, Token: [' need']\n","Value: 0.12027596682310104, Index: 6968, Token: ['you']\n","Value: 0.11886681616306305, Index: 6, Token: [',']\n","Value: 0.1180545911192894, Index: 4, Token: ['.']\n","Value: 0.11749830096960068, Index: 142, Token: [' because']\n","Value: 0.11724597960710526, Index: 9, Token: [' of']\n","Value: 0.11708321422338486, Index: 13, Token: [' for']\n","Value: 0.11696740239858627, Index: 82, Token: [' people']\n","Value: 0.11616840958595276, Index: 10062, Token: [' instant']\n","Value: 0.11573991179466248, Index: 452, Token: [' today']\n","Value: 0.11472821980714798, Index: 37561, Token: [' gratification']\n","Value: 0.11466604471206665, Index: 2362, Token: ['no']\n","Value: 0.11433488875627518, Index: 165, Token: [' team']\n","Value: 0.11431427299976349, Index: 38261, Token: ['History']\n","Value: 0.11414941400289536, Index: 939, Token: [' i']\n","Value: 0.11392799019813538, Index: 23979, Token: [' entertained']\n","Value: 0.11341971904039383, Index: 960, Token: [' everything']\n","Value: 0.1128862202167511, Index: 28, Token: [' be']\n","Value: 0.11182881146669388, Index: 101, Token: [' like']\n","Value: 0.1117447018623352, Index: 1437, Token: [' ']\n","Value: 0.11169096827507019, Index: 47, Token: [' you']\n","Value: 0.11120688170194626, Index: 269, Token: [' really']\n","Value: 0.11065014451742172, Index: 65, Token: [' one']\n","Value: 0.10961852222681046, Index: 75, Token: [\"'t\"]\n","Value: 0.10957440733909607, Index: 216, Token: [' know']\n","Value: 0.109166719019413, Index: 34, Token: [' has']\n","Value: 0.10914876312017441, Index: 12, Token: ['-']\n","Value: 0.10896117985248566, Index: 544, Token: [' service']\n","Value: 0.10835131257772446, Index: 103, Token: [' some']\n","Value: 0.10804101079702377, Index: 1279, Token: ['term']\n","Value: 0.10749184340238571, Index: 37463, Token: [' uh']\n","Value: 0.10708329826593399, Index: 24180, Token: [' Buddy']\n","Value: 0.10666340589523315, Index: 3846, Token: [' Eagles']\n","Value: 0.10649722814559937, Index: 2674, Token: [' favorite']\n","Value: 0.10641678422689438, Index: 192, Token: [' see']\n","Value: 0.10634693503379822, Index: 3169, Token: [' immediate']\n","Value: 0.10571162402629852, Index: 53, Token: [' but']\n","Value: 0.10569071024656296, Index: 350, Token: [' too']\n","Value: 0.10545583814382553, Index: 32, Token: [' are']\n","Value: 0.10522422939538956, Index: 5779, Token: [' disappointed']\n","Value: 0.10499006509780884, Index: 664, Token: [' young']\n","Value: 0.10441578179597855, Index: 1171, Token: [' includes']\n","Value: 0.10417097806930542, Index: 938, Token: [' wasn']\n","Value: 0.103859081864357, Index: 120, Token: [' get']\n","Value: 0.1038261204957962, Index: 524, Token: [' am']\n","Value: 0.1035216674208641, Index: 21, Token: [' was']\n","Value: 0.10336154699325562, Index: 456, Token: [' again']\n","Value: 0.10331396013498306, Index: 100, Token: ['I']\n","Value: 0.10250845551490784, Index: 4029, Token: [' fee']\n","Value: 0.10245095193386078, Index: 7970, Token: [' reward']\n","Value: 0.10214326530694962, Index: 97, Token: [' other']\n","Value: 0.10196208208799362, Index: 765, Token: [' short']\n","Value: 0.10191190987825394, Index: 98, Token: [' so']\n","Value: 0.10175886005163193, Index: 1980, Token: [' ones']\n","Value: 0.1017066240310669, Index: 127, Token: [' my']\n","Value: 0.10166537761688232, Index: 1013, Token: [' annual']\n","Value: 0.10157179832458496, Index: 205, Token: [' good']\n","Value: 0.10156930238008499, Index: 2607, Token: [' helps']\n","Value: 0.1015656441450119, Index: 1531, Token: [' fun']\n","Value: 0.10133035480976105, Index: 5863, Token: [' comfort']\n","Value: 0.10126607120037079, Index: 33, Token: [' have']\n","Value: 0.10102955251932144, Index: 2167, Token: [' specific']\n","Value: 0.10092715173959732, Index: 2217, Token: [' lose']\n","Value: 0.10058911889791489, Index: 766, Token: [' name']\n","Value: 0.10045801848173141, Index: 1774, Token: [' Ryan']\n","Value: 0.10026093572378159, Index: 251, Token: [' long']\n","Value: 0.10015477985143661, Index: 12443, Token: [' stranger']\n","Value: 0.10000131279230118, Index: 1118, Token: [' compared']\n","Value: 0.09983675181865692, Index: 3958, Token: [' guests']\n","Value: 0.09944555163383484, Index: 1081, Token: [' personal']\n","Value: 0.09939565509557724, Index: 114, Token: [' if']\n","Value: 0.09919268637895584, Index: 358, Token: [' every']\n","Value: 0.0989212617278099, Index: 372, Token: [' great']\n","Value: 0.09891704469919205, Index: 76, Token: [' year']\n","Value: 0.09887845814228058, Index: 9335, Token: ['OK']\n","Value: 0.09811308234930038, Index: 356, Token: [' look']\n","Value: 0.09807281941175461, Index: 1427, Token: [' charge']\n","Value: 0.09780187904834747, Index: 28094, Token: [' oriented']\n","Value: 0.0975656658411026, Index: 29473, Token: [' mailing']\n","Value: 0.09743834286928177, Index: 106, Token: [' them']\n","Value: 0.09734096378087997, Index: 49, Token: [' their']\n","Value: 0.09701456874608994, Index: 218, Token: [' don']\n","Value: 0.09700479358434677, Index: 1579, Token: [' message']\n","Value: 0.09694529324769974, Index: 15, Token: [' on']\n","Value: 0.09681404381990433, Index: 1743, Token: [' systems']\n","Value: 0.09529396891593933, Index: 1067, Token: [' talk']\n","Value: 0.09502527862787247, Index: 10, Token: [' a']\n","Value: 0.09496181458234787, Index: 174, Token: [' told']\n","Value: 0.09486667066812515, Index: 190, Token: [' even']\n","Value: 0.09469311684370041, Index: 25, Token: [' as']\n","Value: 0.09457817673683167, Index: 133, Token: ['The']\n","Value: 0.09457255154848099, Index: 10483, Token: [' pleasure']\n","Value: 0.09436551481485367, Index: 8435, Token: ['aked']\n","Value: 0.09399046748876572, Index: 8633, Token: [' cre']\n","Value: 0.0939648300409317, Index: 9643, Token: [' incentives']\n","Value: 0.09366043657064438, Index: 699, Token: [' clear']\n","Value: 0.09362936019897461, Index: 67, Token: [' also']\n","Value: 0.0935685858130455, Index: 89, Token: [' there']\n","Value: 0.09356129914522171, Index: 5636, Token: [' personally']\n","Value: 0.09345616400241852, Index: 265, Token: [' business']\n","Value: 0.09333261102437973, Index: 78, Token: [' first']\n","Value: 0.09246645122766495, Index: 3651, Token: [' stronger']\n","Value: 0.09215380251407623, Index: 55, Token: [' more']\n","Value: 0.0920535996556282, Index: 10980, Token: ['Mr']\n","Value: 0.09196297079324722, Index: 36, Token: [' (']\n","Value: 0.0918748676776886, Index: 70, Token: [' all']\n","Value: 0.0911334678530693, Index: 714, Token: [' policy']\n","Value: 0.09094859659671783, Index: 14, Token: [' that']\n","Value: 0.0907304435968399, Index: 746, Token: [' total']\n","Value: 0.09046467393636703, Index: 2650, Token: ['ful']\n","Value: 0.09046076238155365, Index: 460, Token: [' always']\n","Value: 0.09042200446128845, Index: 32312, Token: [' establishes']\n","Value: 0.09041912108659744, Index: 51, Token: [' they']\n","Value: 0.09034688770771027, Index: 956, Token: [' needed']\n","Value: 0.09026377648115158, Index: 4010, Token: [' specifically']\n","Value: 0.08947763592004776, Index: 277, Token: [' another']\n","Value: 0.08938106894493103, Index: 71, Token: [' after']\n","Value: 0.08931204676628113, Index: 304, Token: [' use']\n","Value: 0.08916103839874268, Index: 4876, Token: [' weapon']\n","Value: 0.08900892734527588, Index: 2623, Token: [' developing']\n","Value: 0.08898308128118515, Index: 5475, Token: [' conversations']\n","Value: 0.08862721174955368, Index: 3493, Token: [' pictures']\n","Value: 0.0885186567902565, Index: 31, Token: [' from']\n","Value: 0.08833613246679306, Index: 959, Token: [' however']\n","Value: 0.08821920305490494, Index: 889, Token: [' list']\n","Value: 0.08804824948310852, Index: 1158, Token: [' starting']\n","Value: 0.08798839151859283, Index: 3857, Token: [' acquisition']\n","Value: 0.0879204124212265, Index: 24, Token: [' it']\n","Value: 0.08789733052253723, Index: 606, Token: [' comes']\n","Value: 0.08766300976276398, Index: 28339, Token: [' adventurous']\n","Value: 0.08756869286298752, Index: 7208, Token: [' framework']\n","Value: 0.08752623200416565, Index: 22597, Token: ['aned']\n","Value: 0.08705161511898041, Index: 206, Token: [' think']\n","Value: 0.08701463788747787, Index: 154, Token: ['ing']\n","Value: 0.08695532381534576, Index: 3989, Token: [' shape']\n","Value: 0.08684081584215164, Index: 38, Token: [' I']\n","Value: 0.08669000118970871, Index: 109, Token: [' do']\n","Value: 0.08641523867845535, Index: 11491, Token: [' gro']\n","Value: 0.08622658252716064, Index: 15833, Token: ['Look']\n","Value: 0.08599646389484406, Index: 131, Token: [';']\n","Value: 0.08599475026130676, Index: 16920, Token: [' disciplined']\n","Value: 0.08582589775323868, Index: 10358, Token: [' timely']\n","Value: 0.0853995606303215, Index: 2377, Token: [' drivers']\n","Value: 0.0853065699338913, Index: 2045, Token: [' seem']\n","Value: 0.08519889414310455, Index: 2802, Token: ['ver']\n","Value: 0.08504000306129456, Index: 69, Token: [' her']\n","Value: 0.08502772450447083, Index: 1306, Token: [' ensure']\n","Value: 0.08500685542821884, Index: 7939, Token: ['Let']\n","Value: 0.0849987119436264, Index: 95, Token: [' just']\n","Value: 0.08471684902906418, Index: 964, Token: [' friends']\n","Value: 0.08427980542182922, Index: 9977, Token: [' uns']\n","Value: 0.08417031913995743, Index: 7201, Token: [' articles']\n","Value: 0.08340364694595337, Index: 43, Token: [')']\n","Value: 0.08331495523452759, Index: 4954, Token: [' OK']\n","Value: 0.08303644508123398, Index: 405, Token: ['it']\n","Value: 0.0830167904496193, Index: 202, Token: [' still']\n","Value: 0.08295023441314697, Index: 23, Token: [' at']\n","Value: 0.08293124288320541, Index: 16424, Token: ['kill']\n","Value: 0.08285148441791534, Index: 631, Token: [' thing']\n","Value: 0.08270074427127838, Index: 4353, Token: [' aggressive']\n","Value: 0.08269652724266052, Index: 19, Token: [' with']\n","Value: 0.08203907310962677, Index: 39132, Token: ['killed']\n","Value: 0.08200903236865997, Index: 1006, Token: [' worked']\n","Value: 0.08164357393980026, Index: 18494, Token: [' Hastings']\n","Value: 0.08160799741744995, Index: 3056, Token: ['well']\n","Value: 0.08151795715093613, Index: 2655, Token: [' knowledge']\n","Value: 0.08135554939508438, Index: 8608, Token: [' criteria']\n","Value: 0.08116674423217773, Index: 4320, Token: [' magazine']\n","Value: 0.08105938881635666, Index: 2088, Token: ['ive']\n","Value: 0.08092040568590164, Index: 1686, Token: [' talking']\n","Value: 0.0808480829000473, Index: 87, Token: [' than']\n","Value: 0.08061803877353668, Index: 4545, Token: [' Defense']\n","Value: 0.08060909062623978, Index: 466, Token: ['9']\n","Value: 0.08060254901647568, Index: 31552, Token: [' adherence']\n","Value: 0.07996049523353577, Index: 5951, Token: [' ag']\n","Value: 0.0798555538058281, Index: 28586, Token: ['French']\n","Value: 0.07974372059106827, Index: 26472, Token: [' carriage']\n","Value: 0.07968228310346603, Index: 21514, Token: [' interviewing']\n","Value: 0.07920245826244354, Index: 1325, Token: [' receive']\n","Value: 0.07911929488182068, Index: 1195, Token: [' rather']\n","Value: 0.07909892499446869, Index: 5604, Token: [' capture']\n","Value: 0.07856591045856476, Index: 2104, Token: [' equipment']\n","Value: 0.07825852185487747, Index: 894, Token: ['He']\n","Value: 0.07813246548175812, Index: 641, Token: [' Department']\n","Value: 0.07811783999204636, Index: 28269, Token: [' noisy']\n","Value: 0.0778275728225708, Index: 568, Token: [' decision']\n","Value: 0.07767295092344284, Index: 442, Token: [' making']\n","Value: 0.07756847143173218, Index: 244, Token: [' help']\n","Value: 0.07743148505687714, Index: 546, Token: [' looking']\n","Value: 0.07682141661643982, Index: 1086, Token: [' whole']\n","Value: 0.07612607628107071, Index: 495, Token: ['D']\n","Value: 0.0758611336350441, Index: 2790, Token: [' protest']\n","Value: 0.07568901777267456, Index: 1593, Token: [' wrong']\n","Value: 0.07523316144943237, Index: 1705, Token: [' couldn']\n","Value: 0.07505530118942261, Index: 427, Token: [' Mr']\n","Value: 0.07494163513183594, Index: 9325, Token: ['Be']\n","Value: 0.07377641648054123, Index: 878, Token: [' running']\n","Value: 0.07320806384086609, Index: 21152, Token: [' tha']\n","Value: 0.07308971136808395, Index: 13584, Token: ['Her']\n","Value: 0.07301840931177139, Index: 7111, Token: ['OD']\n","Value: 0.07271220535039902, Index: 27515, Token: [' noticing']\n","Value: 0.07261545956134796, Index: 62, Token: [' up']\n","Value: 0.07233421504497528, Index: 1411, Token: [' goes']\n","Value: 0.07135851681232452, Index: 37, Token: [' he']\n","Value: 0.07113833725452423, Index: 2460, Token: [' prepared']\n","Value: 0.0699632316827774, Index: 8311, Token: [' VR']\n","Value: 0.069147028028965, Index: 5329, Token: [' indeed']\n","Value: 0.06913194060325623, Index: 13332, Token: [' wa']\n","Value: 0.06841219216585159, Index: 1708, Token: ['But']\n","Value: 0.06738151609897614, Index: 3992, Token: [' stress']\n","Value: 0.06398369371891022, Index: 3361, Token: ['ess']\n","Value: 0.06286309659481049, Index: 17865, Token: ['rg']\n","Value: 0.0625709518790245, Index: 393, Token: [' never']\n","Value: 0.059810735285282135, Index: 319, Token: [' lot']\n","Value: 0.059410177171230316, Index: 431, Token: [' reported']\n","Value: 0.05930270627140999, Index: 4556, Token: [' Com']\n","Value: 0.05677979439496994, Index: 170, Token: ['We']\n","Value: 0.056087344884872437, Index: 58, Token: [' were']\n","Value: 0.05557902157306671, Index: 20601, Token: [' emergencies']\n","Value: 0.0551275797188282, Index: 143, Token: [' any']\n","Value: 0.0550449900329113, Index: 26, Token: [' said']\n","Value: 0.05464579164981842, Index: 432, Token: [' deal']\n","Value: 0.05397918075323105, Index: 2013, Token: ['art']\n","Value: 0.05032912641763687, Index: 14721, Token: ['Com']\n"]}]},{"cell_type":"code","source":["import csv\n","\n","with open('embeddings_' + str(model_name[13:]) +'_exp_' + str(SEL_EXP_TRAIN_CD)+'.csv', 'w', newline='') as file:\n","    writer = csv.writer(file)\n","\n","    # Write headers\n","    writer.writerow(['Value', 'Index'])\n","\n","    # Write the values and indices to the CSV file\n","    for value, index in zip(values_non_zero, indices_non_zero):\n","        writer.writerow([value.item(), index.item()])"],"metadata":{"id":"YvnDH-hpriJ1","executionInfo":{"status":"ok","timestamp":1714523933806,"user_tz":-120,"elapsed":5,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ufRQiuSGgwMM","executionInfo":{"status":"ok","timestamp":1714523933806,"user_tz":-120,"elapsed":5,"user":{"displayName":"Javier NR","userId":"06898084318145327297"}}},"execution_count":76,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"gpuType":"L4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"98eec8c8c9f54cdc9b571396a72e55c3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8886b0ec30004646b5b1683744bf5f17","IPY_MODEL_17b3b18c921f445ea8930af5957261e8","IPY_MODEL_a34d75415f984687bd6c5b18680f4cf4"],"layout":"IPY_MODEL_90fa18c6ef2e48c89d17f5574aa8e732"}},"8886b0ec30004646b5b1683744bf5f17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bb0cb6161bf479fb8743876cf699272","placeholder":"​","style":"IPY_MODEL_b749e2f006e942879f0afbf0d81442a2","value":"Map: 100%"}},"17b3b18c921f445ea8930af5957261e8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d6aa790629c44a3a047347b8a3df61d","max":1024,"min":0,"orientation":"horizontal","style":"IPY_MODEL_223ce77fd3c346d281150e6008e4f988","value":1024}},"a34d75415f984687bd6c5b18680f4cf4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53616da3724e4efcb1eea5719e6ad8eb","placeholder":"​","style":"IPY_MODEL_d7e31382d8b6439790e634c0d5aa1882","value":" 1024/1024 [00:00&lt;00:00, 8291.38 examples/s]"}},"90fa18c6ef2e48c89d17f5574aa8e732":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bb0cb6161bf479fb8743876cf699272":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b749e2f006e942879f0afbf0d81442a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d6aa790629c44a3a047347b8a3df61d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"223ce77fd3c346d281150e6008e4f988":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53616da3724e4efcb1eea5719e6ad8eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7e31382d8b6439790e634c0d5aa1882":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e815468c3e9d480f853757c5a8d534a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a90eac8b75e94a619f2c5ca95a6fe24a","IPY_MODEL_8dee333e3fe143d5928a04366a551841","IPY_MODEL_5fcea17a3c9f483f84f444bf846754e7"],"layout":"IPY_MODEL_a213a54abb6344209ded5534a0c9e580"}},"a90eac8b75e94a619f2c5ca95a6fe24a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b422d529a24f49868aee0a6c74645226","placeholder":"​","style":"IPY_MODEL_43f49bf0403f4f02a87b54715f764f92","value":"Downloading data: 100%"}},"8dee333e3fe143d5928a04366a551841":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbfddeaf8fe94ccbb5d77e3b2c5ad68e","max":3144823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_300db2731aad43a0af2c6b6dacf698f0","value":3144823}},"5fcea17a3c9f483f84f444bf846754e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5268142df9ab445e8e521beef33eaacf","placeholder":"​","style":"IPY_MODEL_971bbcf5801b429e9cdb4dcc71e9793c","value":" 3.14M/3.14M [00:00&lt;00:00, 13.5MB/s]"}},"a213a54abb6344209ded5534a0c9e580":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b422d529a24f49868aee0a6c74645226":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43f49bf0403f4f02a87b54715f764f92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dbfddeaf8fe94ccbb5d77e3b2c5ad68e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"300db2731aad43a0af2c6b6dacf698f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5268142df9ab445e8e521beef33eaacf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"971bbcf5801b429e9cdb4dcc71e9793c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"416182fe882c432a90fc24c4d77b445a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99a63d8e9b754ad8a7500139ce298e5e","IPY_MODEL_1e5d4b23c3f8470c9aebc3b9a5c253db","IPY_MODEL_1487f683d1124a829cc02e1c33c1ff4d"],"layout":"IPY_MODEL_5f86887f9ffb4bc3b2ecf7af63e8a722"}},"99a63d8e9b754ad8a7500139ce298e5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb09763048c142a9bc997d97a4a00c76","placeholder":"​","style":"IPY_MODEL_18789117dedf47c5846d204aa732de8e","value":"Downloading data: 100%"}},"1e5d4b23c3f8470c9aebc3b9a5c253db":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_baad8b8d4ad04554911979b86d71df7e","max":3139577,"min":0,"orientation":"horizontal","style":"IPY_MODEL_366a7af4e9a14782948c90bf461c2866","value":3139577}},"1487f683d1124a829cc02e1c33c1ff4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75159a4e3430479199f348269ba01cc3","placeholder":"​","style":"IPY_MODEL_addaad64db134f3dbd3396708803c666","value":" 3.14M/3.14M [00:00&lt;00:00, 26.6MB/s]"}},"5f86887f9ffb4bc3b2ecf7af63e8a722":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb09763048c142a9bc997d97a4a00c76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18789117dedf47c5846d204aa732de8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"baad8b8d4ad04554911979b86d71df7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"366a7af4e9a14782948c90bf461c2866":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75159a4e3430479199f348269ba01cc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"addaad64db134f3dbd3396708803c666":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"272fbe610d3b49bbb7503ce05d76b31a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_968843910cb647eabe74e00786c39d5f","IPY_MODEL_2f4ba675d8b94a31ad01e4220221b221","IPY_MODEL_fd8e610fb7c74ac58e0f7805bd9e59d4"],"layout":"IPY_MODEL_6c8aa005860741aca3a2fe707dc7476a"}},"968843910cb647eabe74e00786c39d5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c5d54279af8410fa08f6437a73a951f","placeholder":"​","style":"IPY_MODEL_834291d71c93429894acf5f1bfa64e8f","value":"Generating train split: 100%"}},"2f4ba675d8b94a31ad01e4220221b221":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_655f16aa65c14362a2f293621e3f237c","max":30000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71a039ad1f154134afd905df5da89f60","value":30000}},"fd8e610fb7c74ac58e0f7805bd9e59d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d358b5597804179a301e7acd3bff3b4","placeholder":"​","style":"IPY_MODEL_2a2e3ee0c18c43668227fe5352c02821","value":" 30000/30000 [00:00&lt;00:00, 419938.53 examples/s]"}},"6c8aa005860741aca3a2fe707dc7476a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c5d54279af8410fa08f6437a73a951f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"834291d71c93429894acf5f1bfa64e8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"655f16aa65c14362a2f293621e3f237c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71a039ad1f154134afd905df5da89f60":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d358b5597804179a301e7acd3bff3b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a2e3ee0c18c43668227fe5352c02821":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c088451519744bcb0b8e3665c4ab18f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_10d1a77d35f44abcb3cde1ea7820ac3b","IPY_MODEL_84f6ff00483c4a349e140573618a6c47","IPY_MODEL_e725016bfd25408ca0f6fc3048c806fd"],"layout":"IPY_MODEL_12d7648b8790413992f33144b7a7d9de"}},"10d1a77d35f44abcb3cde1ea7820ac3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a9e5548d3f942a2bbfea7edd4d7e55c","placeholder":"​","style":"IPY_MODEL_a1d3da4dc1b04ad98edf49859ea32b61","value":"Generating validation split: 100%"}},"84f6ff00483c4a349e140573618a6c47":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbc8ea3c152546248ecb4df39d2586b5","max":30000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8fd65ba133314e22adbf857f4952ec84","value":30000}},"e725016bfd25408ca0f6fc3048c806fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8f18bf97d0f41449a42d7726423d479","placeholder":"​","style":"IPY_MODEL_17e752e5e935459e8cd5169dc8e8b25b","value":" 30000/30000 [00:00&lt;00:00, 474653.13 examples/s]"}},"12d7648b8790413992f33144b7a7d9de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a9e5548d3f942a2bbfea7edd4d7e55c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1d3da4dc1b04ad98edf49859ea32b61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbc8ea3c152546248ecb4df39d2586b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fd65ba133314e22adbf857f4952ec84":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8f18bf97d0f41449a42d7726423d479":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17e752e5e935459e8cd5169dc8e8b25b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d0e6b604743450cb14a7803f19112a2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e09e2bcc0df4691b03f708104c74233","IPY_MODEL_c0bd42af1e2741989ac52a8b9f6d80c3","IPY_MODEL_b3b153ab20054c1d9924e751e653ab87"],"layout":"IPY_MODEL_889c0bec65f44c8f9d2c1acee93a3c19"}},"0e09e2bcc0df4691b03f708104c74233":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d733c18de6f424b897df3a7bb562ce2","placeholder":"​","style":"IPY_MODEL_6364556479854c35ae353527d159c66a","value":"Filter: 100%"}},"c0bd42af1e2741989ac52a8b9f6d80c3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac5f05581573444c8d3fd66b8807d7d4","max":30000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e3118c0ce4734a3ea39bc7d8a5827e09","value":30000}},"b3b153ab20054c1d9924e751e653ab87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ad0603114184b868e9e222be3d4a4b2","placeholder":"​","style":"IPY_MODEL_17c425d0f77e4dd19420e5f43a0c20fd","value":" 30000/30000 [00:00&lt;00:00, 72575.78 examples/s]"}},"889c0bec65f44c8f9d2c1acee93a3c19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d733c18de6f424b897df3a7bb562ce2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6364556479854c35ae353527d159c66a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac5f05581573444c8d3fd66b8807d7d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3118c0ce4734a3ea39bc7d8a5827e09":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ad0603114184b868e9e222be3d4a4b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17c425d0f77e4dd19420e5f43a0c20fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf1e2f69d38d4bdcb2a079305ce53a34":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6bb88f079270405490e5d8c20933d857","IPY_MODEL_219f90d07f934e67b9454907854d0659","IPY_MODEL_67437d48055e4091801f44790074ea52"],"layout":"IPY_MODEL_64f8b655fe6d4d7fb51ec8514febaf98"}},"6bb88f079270405490e5d8c20933d857":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5a0c835aada4323a98976ffaf2ec08e","placeholder":"​","style":"IPY_MODEL_7b0cf53a74fb4f57b51e8e07d021bc62","value":"Map: 100%"}},"219f90d07f934e67b9454907854d0659":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_81835a9fd6c8410f8c8d9963dcfce854","max":1024,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0671c5d6a4142088d8609b2dfc8f58d","value":1024}},"67437d48055e4091801f44790074ea52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74ea5d840ca64fbd8c0b84403dedeae4","placeholder":"​","style":"IPY_MODEL_dbdadad2922845c1a72fabe29eaabea2","value":" 1024/1024 [00:00&lt;00:00, 6444.85 examples/s]"}},"64f8b655fe6d4d7fb51ec8514febaf98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5a0c835aada4323a98976ffaf2ec08e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b0cf53a74fb4f57b51e8e07d021bc62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81835a9fd6c8410f8c8d9963dcfce854":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0671c5d6a4142088d8609b2dfc8f58d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"74ea5d840ca64fbd8c0b84403dedeae4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbdadad2922845c1a72fabe29eaabea2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}